Smallest SV
Epoch: 0, trainingloss: 0.20162990887824708 | validation loss: 0.20076073539854028
Epoch: 1, trainingloss: 0.05595057486958578 | validation loss: 0.05582662376669428
Epoch: 2, trainingloss: 0.03917085732125989 | validation loss: 0.03943053912429872
Epoch: 3, trainingloss: 0.03320155975649454 | validation loss: 0.033722322241814026
Epoch: 4, trainingloss: 0.02930869212946551 | validation loss: 0.02966338946121292
Epoch: 5, trainingloss: 0.02793457261264025 | validation loss: 0.02826903359476063
Epoch: 6, trainingloss: 0.022774771512469524 | validation loss: 0.023230710230894198
Epoch: 7, trainingloss: 0.022962709193449584 | validation loss: 0.02333259909699554
Epoch: 8, trainingloss: 0.022516740118773214 | validation loss: 0.022916727089425055
Epoch: 9, trainingloss: 0.02183752135106674 | validation loss: 0.022236497976960652
Epoch: 10, trainingloss: 0.01717628995737505 | validation loss: 0.017399469770775746
Epoch: 11, trainingloss: 0.018561850279970118 | validation loss: 0.018921660299947907
Epoch: 12, trainingloss: 0.01687137828386978 | validation loss: 0.01714843766741326
Epoch: 13, trainingloss: 0.01493637873592103 | validation loss: 0.015416267875693961
Epoch: 14, trainingloss: 0.016200079955667725 | validation loss: 0.01659437461201299
Epoch: 15, trainingloss: 0.013492134488320352 | validation loss: 0.013875614929273854
Epoch: 16, trainingloss: 0.014364799322621007 | validation loss: 0.014686091154612387
Epoch: 17, trainingloss: 0.0130919152803045 | validation loss: 0.013492392039831071
Epoch: 18, trainingloss: 0.012878979165200576 | validation loss: 0.013230780157831128
Epoch: 19, trainingloss: 0.013852324919240927 | validation loss: 0.014265172792530128
Epoch: 20, trainingloss: 0.012383767049485855 | validation loss: 0.012762191912721705
Epoch: 21, trainingloss: 0.012418387758467368 | validation loss: 0.012881949571798848
Epoch: 22, trainingloss: 0.012192239384372437 | validation loss: 0.012598130881186994
Epoch: 23, trainingloss: 0.011240696105875463 | validation loss: 0.011590315247241995
Epoch: 24, trainingloss: 0.012577804042539787 | validation loss: 0.012854143727536254
Epoch: 25, trainingloss: 0.012293302405510654 | validation loss: 0.012690708859263692
Epoch: 26, trainingloss: 0.011368207921164242 | validation loss: 0.011611822437603057
Epoch: 27, trainingloss: 0.011689465881377018 | validation loss: 0.01197042544498288
Epoch: 28, trainingloss: 0.012636418305460029 | validation loss: 0.012925216384909746
Epoch: 29, trainingloss: 0.01077940238667743 | validation loss: 0.011212730673197155
Epoch: 30, trainingloss: 0.010328814828328673 | validation loss: 0.010721133106203968
Epoch: 31, trainingloss: 0.010586478287156581 | validation loss: 0.010876097172386414
Epoch: 32, trainingloss: 0.010338056594828912 | validation loss: 0.010717512320747068
Epoch: 33, trainingloss: 0.010521921613740845 | validation loss: 0.010902101402013215
Epoch: 34, trainingloss: 0.011145983930407785 | validation loss: 0.011484546710711828
Epoch: 35, trainingloss: 0.010231417409602227 | validation loss: 0.010592629556797243
Epoch: 36, trainingloss: 0.009853842998368148 | validation loss: 0.010213601912577605
Epoch: 37, trainingloss: 0.009101283716663829 | validation loss: 0.009423087259518615
Epoch: 38, trainingloss: 0.009280766650755936 | validation loss: 0.009669513039431647
Epoch: 39, trainingloss: 0.008976283380631058 | validation loss: 0.00944640581144304
Epoch: 40, trainingloss: 0.009414158808046191 | validation loss: 0.009704393245681196
Epoch: 41, trainingloss: 0.01079051626075574 | validation loss: 0.011127253498470461
Epoch: 42, trainingloss: 0.01027026798856487 | validation loss: 0.010605803298148078
Epoch: 43, trainingloss: 0.009050561308173338 | validation loss: 0.00953667801011701
Epoch: 44, trainingloss: 0.009535768115880628 | validation loss: 0.009978558120640591
Epoch: 45, trainingloss: 0.009170681753787357 | validation loss: 0.00949804264549593
Epoch: 46, trainingloss: 0.009916609300181397 | validation loss: 0.010301682749946835
Epoch: 47, trainingloss: 0.008790823885459025 | validation loss: 0.009246032033819912
Epoch: 48, trainingloss: 0.009008313052362717 | validation loss: 0.009419971738972334
Epoch: 49, trainingloss: 0.009105265684630168 | validation loss: 0.009467093174454386
Epoch: 50, trainingloss: 0.009772043544741683 | validation loss: 0.010197799043099854
Epoch: 51, trainingloss: 0.009931745591826939 | validation loss: 0.010347367517729062
Epoch: 52, trainingloss: 0.008459172461723943 | validation loss: 0.008915868717349371
Epoch: 53, trainingloss: 0.008750154175147486 | validation loss: 0.009241669005644717
Epoch: 54, trainingloss: 0.009077765602823827 | validation loss: 0.009613395349603237
Epoch: 55, trainingloss: 0.008949039654813548 | validation loss: 0.009345331214127065
Epoch: 56, trainingloss: 0.008533652878569942 | validation loss: 0.009030477575287825
Epoch: 57, trainingloss: 0.008734795396359499 | validation loss: 0.009100605282205845
Epoch: 58, trainingloss: 0.007933743793931263 | validation loss: 0.008454549119602375
Epoch: 59, trainingloss: 0.008548747085907166 | validation loss: 0.008990327301802605
Epoch: 60, trainingloss: 0.008177632494281446 | validation loss: 0.008645887684939707
Epoch: 61, trainingloss: 0.008301412915325644 | validation loss: 0.008819383101008788
Epoch: 62, trainingloss: 0.008313450788513895 | validation loss: 0.008707637967955567
Epoch: 63, trainingloss: 0.008845481477180669 | validation loss: 0.009342263261366193
Epoch: 64, trainingloss: 0.00912916888958882 | validation loss: 0.009617948463927018
Epoch: 65, trainingloss: 0.007859977094548987 | validation loss: 0.008341478725883644
Epoch: 66, trainingloss: 0.008170148080598676 | validation loss: 0.008605409117046728
Epoch: 67, trainingloss: 0.008200363506699294 | validation loss: 0.008616650183811334
Epoch: 68, trainingloss: 0.008410006298862351 | validation loss: 0.008869256370251079
Epoch: 69, trainingloss: 0.008528643220509885 | validation loss: 0.008907355056566089
Epoch: 70, trainingloss: 0.008184168597628386 | validation loss: 0.008616275759261601
Epoch: 71, trainingloss: 0.007380773791028413 | validation loss: 0.007851867000549797
Epoch: 72, trainingloss: 0.007325609627273238 | validation loss: 0.007858927534518861
Epoch: 73, trainingloss: 0.007623530444710107 | validation loss: 0.008063401879192121
Epoch: 74, trainingloss: 0.007987024177990083 | validation loss: 0.008396295344782864
Epoch: 75, trainingloss: 0.007994074541847857 | validation loss: 0.008421769031004457
Epoch: 76, trainingloss: 0.007409140976494813 | validation loss: 0.007844174088761391
Epoch: 77, trainingloss: 0.00795771830303446 | validation loss: 0.008355993347757298
Epoch: 78, trainingloss: 0.008439394657740804 | validation loss: 0.008832577865600762
Epoch: 79, trainingloss: 0.008103606834668802 | validation loss: 0.008478587657771826
Epoch: 80, trainingloss: 0.007575362347589752 | validation loss: 0.008061336847255702
Epoch: 81, trainingloss: 0.00688919205779683 | validation loss: 0.007389519539632488
Epoch: 82, trainingloss: 0.007602689238026738 | validation loss: 0.008027890020112267
Epoch: 83, trainingloss: 0.007325403011309263 | validation loss: 0.007772503869039029
Epoch: 84, trainingloss: 0.007810535714200762 | validation loss: 0.008208248678982307
Epoch: 85, trainingloss: 0.008374086735697284 | validation loss: 0.008864969996404596
Epoch: 86, trainingloss: 0.00752144164446199 | validation loss: 0.007950112167207661
Epoch: 87, trainingloss: 0.006933240669502682 | validation loss: 0.007422798864615697
Epoch: 88, trainingloss: 0.007587655726334503 | validation loss: 0.008041668642942805
Epoch: 89, trainingloss: 0.007142206561957838 | validation loss: 0.007588288617092479
Epoch: 90, trainingloss: 0.0075040524836590084 | validation loss: 0.00796035571489071
Epoch: 91, trainingloss: 0.0069530182478737485 | validation loss: 0.007431127847046517
Epoch: 92, trainingloss: 0.008484451303073747 | validation loss: 0.008972958088853589
Epoch: 93, trainingloss: 0.0074622703906604216 | validation loss: 0.00794899408264504
Epoch: 94, trainingloss: 0.0073769289371211815 | validation loss: 0.007858692902646817
Epoch: 95, trainingloss: 0.007680460403907723 | validation loss: 0.008111061549176108
Epoch: 96, trainingloss: 0.006535843522598887 | validation loss: 0.007081006117154977
Epoch: 97, trainingloss: 0.007203022662943531 | validation loss: 0.007638942859954331
Epoch: 98, trainingloss: 0.006647294220185249 | validation loss: 0.0071791035164072755
Epoch: 99, trainingloss: 0.008164483737189462 | validation loss: 0.008567533896018751
Epoch: 100, trainingloss: 0.007336578499436118 | validation loss: 0.0077943845822063505
Epoch: 101, trainingloss: 0.007701212816284535 | validation loss: 0.008080702848450735
Epoch: 102, trainingloss: 0.0066614569671750385 | validation loss: 0.007156246401210342
Epoch: 103, trainingloss: 0.006922238933383869 | validation loss: 0.0074009489473756684
Epoch: 104, trainingloss: 0.006616239095802473 | validation loss: 0.007072836916439826
Epoch: 105, trainingloss: 0.006283867859877233 | validation loss: 0.006781454450992439
Epoch: 106, trainingloss: 0.006343434692578489 | validation loss: 0.006812913493882732
Epoch: 107, trainingloss: 0.0064816434622149725 | validation loss: 0.006962912465123469
Epoch: 108, trainingloss: 0.007154427605022157 | validation loss: 0.007544689025434544
Epoch: 109, trainingloss: 0.007142439161361818 | validation loss: 0.0076035461832287665
Epoch: 110, trainingloss: 0.006688270482245334 | validation loss: 0.007135715829937579
Epoch: 111, trainingloss: 0.006461331554473452 | validation loss: 0.006924906080130586
Epoch: 112, trainingloss: 0.006777156773851359 | validation loss: 0.0071990715132023535
Epoch: 113, trainingloss: 0.006578688089124603 | validation loss: 0.0070291895891258435
Epoch: 114, trainingloss: 0.006910014138875484 | validation loss: 0.0073254547758987995
Epoch: 115, trainingloss: 0.007003125191832552 | validation loss: 0.007417132348099456
Epoch: 116, trainingloss: 0.006508348759798794 | validation loss: 0.006976916768864007
Epoch: 117, trainingloss: 0.006225316601713586 | validation loss: 0.006658117991203913
Epoch: 118, trainingloss: 0.006982348907182996 | validation loss: 0.007437334978051486
Epoch: 119, trainingloss: 0.006562468986037547 | validation loss: 0.006989502425276833
Epoch: 120, trainingloss: 0.006566551302333508 | validation loss: 0.007041279232314551
Epoch: 121, trainingloss: 0.006381476113044698 | validation loss: 0.006855700361743789
Epoch: 122, trainingloss: 0.006348758535330797 | validation loss: 0.0068010624128488385
Epoch: 123, trainingloss: 0.006569097269107817 | validation loss: 0.007000321666876783
Epoch: 124, trainingloss: 0.006196069659644389 | validation loss: 0.006653936185080866
Epoch: 125, trainingloss: 0.0063200228545022465 | validation loss: 0.0067583587045791605
Epoch: 126, trainingloss: 0.006500177044008862 | validation loss: 0.006951923021533131
Epoch: 127, trainingloss: 0.006236315734072754 | validation loss: 0.006708174546747054
Epoch: 128, trainingloss: 0.006049627603673515 | validation loss: 0.006462514904114844
Epoch: 129, trainingloss: 0.006169748351413904 | validation loss: 0.006694616423716438
Epoch: 130, trainingloss: 0.00646171349185481 | validation loss: 0.006923076688346834
Epoch: 131, trainingloss: 0.0064077175037406875 | validation loss: 0.006814945106066372
Epoch: 132, trainingloss: 0.006441593891578128 | validation loss: 0.006880244455630724
Epoch: 133, trainingloss: 0.006286820052854345 | validation loss: 0.006758892076091055
Epoch: 134, trainingloss: 0.006005619327168736 | validation loss: 0.006501666850998852
Epoch: 135, trainingloss: 0.005989343312320386 | validation loss: 0.006516936607846594
Epoch: 136, trainingloss: 0.005876486747825873 | validation loss: 0.0064103823426452265
Epoch: 137, trainingloss: 0.006488966259526487 | validation loss: 0.006882132762584117
Epoch: 138, trainingloss: 0.006186091864120845 | validation loss: 0.006619244082411601
Epoch: 139, trainingloss: 0.00659097709316038 | validation loss: 0.007061402857492757
Epoch: 140, trainingloss: 0.006137588800280893 | validation loss: 0.00661938352884791
Epoch: 141, trainingloss: 0.007007857057535154 | validation loss: 0.007496074782100491
Epoch: 142, trainingloss: 0.006410676589671023 | validation loss: 0.006842414308975019
Epoch: 143, trainingloss: 0.006199694334266095 | validation loss: 0.006670760095694953
Epoch: 144, trainingloss: 0.006962206249142099 | validation loss: 0.007404864371338392
Epoch: 145, trainingloss: 0.006246824790466108 | validation loss: 0.006742858505319829
Epoch: 146, trainingloss: 0.0061093782055300265 | validation loss: 0.006591045427315229
Epoch: 147, trainingloss: 0.006253598979054955 | validation loss: 0.006707613991541359
Epoch: 148, trainingloss: 0.005930214680555464 | validation loss: 0.006407017655885275
Epoch: 149, trainingloss: 0.005970383291242073 | validation loss: 0.0064560180892740335
Epoch: 150, trainingloss: 0.006020110606778051 | validation loss: 0.006483614859756912
Epoch: 151, trainingloss: 0.0062002361792918926 | validation loss: 0.006631358077963225
Epoch: 152, trainingloss: 0.005628856724487463 | validation loss: 0.006117838823831908
Epoch: 153, trainingloss: 0.005907081261229296 | validation loss: 0.006421057429953217
Epoch: 154, trainingloss: 0.005944092987131594 | validation loss: 0.006439094879744391
Epoch: 155, trainingloss: 0.00581448615745146 | validation loss: 0.006328283328158659
Epoch: 156, trainingloss: 0.005720474012326212 | validation loss: 0.00619456748635067
Epoch: 157, trainingloss: 0.0070073081184341465 | validation loss: 0.00744434030740128
Epoch: 158, trainingloss: 0.00594628144376286 | validation loss: 0.006425420887255532
Epoch: 159, trainingloss: 0.0057223205338130115 | validation loss: 0.006168693401957294
Epoch: 160, trainingloss: 0.005790749894251601 | validation loss: 0.006271225599691826
Epoch: 161, trainingloss: 0.006221692934313225 | validation loss: 0.006705461127590044
Epoch: 162, trainingloss: 0.0060032353425615356 | validation loss: 0.0064267575350981775
Epoch: 163, trainingloss: 0.005937461601083617 | validation loss: 0.0064174521938829285
Epoch: 164, trainingloss: 0.005629454786204262 | validation loss: 0.0061126697565539075
Epoch: 165, trainingloss: 0.00596918606988541 | validation loss: 0.006413019564921539
Epoch: 166, trainingloss: 0.005948517999170649 | validation loss: 0.0064403951432765606
Epoch: 167, trainingloss: 0.00589193273587492 | validation loss: 0.006384746912734307
Epoch: 168, trainingloss: 0.00535277826552304 | validation loss: 0.005896574248851936
Epoch: 169, trainingloss: 0.006186882561633726 | validation loss: 0.006603122817814119
Epoch: 170, trainingloss: 0.006305031517947141 | validation loss: 0.006757336485542967
Epoch: 171, trainingloss: 0.005918583030743478 | validation loss: 0.006413652797166691
Epoch: 172, trainingloss: 0.0057947543351343 | validation loss: 0.00624505924511066
Epoch: 173, trainingloss: 0.005506149436419037 | validation loss: 0.00600717229883952
Epoch: 174, trainingloss: 0.005960334719694513 | validation loss: 0.006415881613027881
Epoch: 175, trainingloss: 0.006142786921291938 | validation loss: 0.006595466490630414
Epoch: 176, trainingloss: 0.006063192621368873 | validation loss: 0.006553061433314717
Epoch: 177, trainingloss: 0.005951052916806014 | validation loss: 0.0063723168099405585
Epoch: 178, trainingloss: 0.005618863577801149 | validation loss: 0.006113667266882743
Epoch: 179, trainingloss: 0.005872731606408294 | validation loss: 0.006345739346704458
Epoch: 180, trainingloss: 0.005667901094763367 | validation loss: 0.006184142568709106
Epoch: 181, trainingloss: 0.005900382650366444 | validation loss: 0.0063572813322307145
Epoch: 182, trainingloss: 0.006209542734303776 | validation loss: 0.006642254463986934
Epoch: 183, trainingloss: 0.005796375980982117 | validation loss: 0.00629540730061436
Epoch: 184, trainingloss: 0.006190683786089509 | validation loss: 0.006625219721668677
Epoch: 185, trainingloss: 0.0054886833889465836 | validation loss: 0.005961236505430835
Epoch: 186, trainingloss: 0.006136379302040426 | validation loss: 0.006536219414443994
Epoch: 187, trainingloss: 0.006581923000661336 | validation loss: 0.0069649484720948705
Epoch: 188, trainingloss: 0.0057492588330194565 | validation loss: 0.00616170064758411
Epoch: 189, trainingloss: 0.005636287168820107 | validation loss: 0.006137221957352158
Epoch: 190, trainingloss: 0.0059206201874054685 | validation loss: 0.006347921895867509
Epoch: 191, trainingloss: 0.005709368307312807 | validation loss: 0.006209211254680361
Epoch: 192, trainingloss: 0.006001516647842049 | validation loss: 0.006433453104390071
Epoch: 193, trainingloss: 0.005964438434428229 | validation loss: 0.006434289692853702
Epoch: 194, trainingloss: 0.006143111805200183 | validation loss: 0.006575643785733037
Epoch: 195, trainingloss: 0.0056196762238106554 | validation loss: 0.006093935535062718
Epoch: 196, trainingloss: 0.005276456763079614 | validation loss: 0.005769128935468616
Epoch: 197, trainingloss: 0.00590552110037365 | validation loss: 0.00634029532781722
Epoch: 198, trainingloss: 0.006243679476187587 | validation loss: 0.006646450711400233
Epoch: 199, trainingloss: 0.005381626829212513 | validation loss: 0.005850347024293855
Epoch: 200, trainingloss: 0.0064783483449080866 | validation loss: 0.006913763370861213
Epoch: 201, trainingloss: 0.006007130221199397 | validation loss: 0.0064567273349479155
Epoch: 202, trainingloss: 0.006033201825711394 | validation loss: 0.006498780743710566
Epoch: 203, trainingloss: 0.005769582009168063 | validation loss: 0.006240365277599021
Epoch: 204, trainingloss: 0.006574598383111234 | validation loss: 0.006992383082250737
Epoch: 205, trainingloss: 0.005628682140190463 | validation loss: 0.006095830366501188
Epoch: 206, trainingloss: 0.005319464107894552 | validation loss: 0.005804983923915136
Epoch: 207, trainingloss: 0.005879360571929374 | validation loss: 0.006323968075559888
Epoch: 208, trainingloss: 0.00523021576269233 | validation loss: 0.0056984593943163065
Epoch: 209, trainingloss: 0.0057569997365214875 | validation loss: 0.006181092145942229
Epoch: 210, trainingloss: 0.0059313207849498685 | validation loss: 0.006367605320325379
Epoch: 211, trainingloss: 0.006527083464304539 | validation loss: 0.006934361231704908
Epoch: 212, trainingloss: 0.005403043326132266 | validation loss: 0.0058689100327598285
Epoch: 213, trainingloss: 0.006163499095514312 | validation loss: 0.006565084736783703
Epoch: 214, trainingloss: 0.005175756364578956 | validation loss: 0.005693916402007617
Epoch: 215, trainingloss: 0.00572876136686405 | validation loss: 0.006176162619760686
Epoch: 216, trainingloss: 0.005974967440662454 | validation loss: 0.006398507557986414
Epoch: 217, trainingloss: 0.006148945775538713 | validation loss: 0.006596893251957226
Epoch: 218, trainingloss: 0.005496220371887321 | validation loss: 0.0059628845615677505
Epoch: 219, trainingloss: 0.005568413026687807 | validation loss: 0.006011639916672142
Epoch: 220, trainingloss: 0.005258215545124325 | validation loss: 0.005748198280907922
Epoch: 221, trainingloss: 0.005900507115317431 | validation loss: 0.0063627437100606315
Epoch: 222, trainingloss: 0.005491703086856078 | validation loss: 0.005996903262345066
Epoch: 223, trainingloss: 0.006011630200134681 | validation loss: 0.006476784465240874
Epoch: 224, trainingloss: 0.005328466920141132 | validation loss: 0.005802746614148645
Epoch: 225, trainingloss: 0.005869480860255218 | validation loss: 0.0063327256545764226
Epoch: 226, trainingloss: 0.0060775230401627295 | validation loss: 0.0065487767438405
Epoch: 227, trainingloss: 0.005495351056906659 | validation loss: 0.005966252391499278
Epoch: 228, trainingloss: 0.005872178415667146 | validation loss: 0.0063481170720884805
Epoch: 229, trainingloss: 0.006093211288708804 | validation loss: 0.006562306960041238
Epoch: 230, trainingloss: 0.0062728507876840985 | validation loss: 0.006701407171558534
Epoch: 231, trainingloss: 0.00610073374615653 | validation loss: 0.0065376198282373595
Epoch: 232, trainingloss: 0.006370302389834287 | validation loss: 0.006827319168077631
Epoch: 233, trainingloss: 0.005775721123179974 | validation loss: 0.006260187014434545
Epoch: 234, trainingloss: 0.005483851075599101 | validation loss: 0.005959331722776049
Epoch: 235, trainingloss: 0.005601812074980884 | validation loss: 0.0060657814353912935
Epoch: 236, trainingloss: 0.005426062421024747 | validation loss: 0.0059132901332454154
Epoch: 237, trainingloss: 0.004997360878255382 | validation loss: 0.005496486234466994
Epoch: 238, trainingloss: 0.005978752449440959 | validation loss: 0.006428974243696372
Epoch: 239, trainingloss: 0.005350891691255832 | validation loss: 0.0058527165030443015
Epoch: 240, trainingloss: 0.006031481414777674 | validation loss: 0.0064742846508662666
Epoch: 241, trainingloss: 0.00641406873501451 | validation loss: 0.00685350170459013
Epoch: 242, trainingloss: 0.005670272955165009 | validation loss: 0.006090860100095485
Epoch: 243, trainingloss: 0.005067041817995996 | validation loss: 0.005571801524783015
Epoch: 244, trainingloss: 0.005460737770717334 | validation loss: 0.005926810275715232
Epoch: 245, trainingloss: 0.005301085149115525 | validation loss: 0.00580191220830404
Epoch: 246, trainingloss: 0.005112005920629884 | validation loss: 0.005631103844298998
Epoch: 247, trainingloss: 0.0054099823558712195 | validation loss: 0.005918203669996774
Epoch: 248, trainingloss: 0.005301676881984697 | validation loss: 0.005807442398487005
Epoch: 249, trainingloss: 0.006058210114604256 | validation loss: 0.006515899604473936
Epoch: 250, trainingloss: 0.0052576608911623504 | validation loss: 0.005761885370268226
Epoch: 251, trainingloss: 0.005309654117619828 | validation loss: 0.0058008700838735
Epoch: 252, trainingloss: 0.005452830663937956 | validation loss: 0.005936027706144682
Epoch: 253, trainingloss: 0.0052303664713898345 | validation loss: 0.005733193194657237
Epoch: 254, trainingloss: 0.005816347700738236 | validation loss: 0.006290039809279451
Epoch: 255, trainingloss: 0.005482910560318954 | validation loss: 0.0059760293869038535
Epoch: 256, trainingloss: 0.0058358726035900995 | validation loss: 0.006323983753571782
Epoch: 257, trainingloss: 0.0054882453268247314 | validation loss: 0.005959838630817185
Epoch: 258, trainingloss: 0.0051720737359402715 | validation loss: 0.0056530729257187745
Epoch: 259, trainingloss: 0.005795773001150346 | validation loss: 0.006260210519069888
Epoch: 260, trainingloss: 0.006580519888341982 | validation loss: 0.0070218428259003485
Epoch: 261, trainingloss: 0.005483938329230985 | validation loss: 0.0059539804412499136
Epoch: 262, trainingloss: 0.005410500174783795 | validation loss: 0.005902234441132744
Epoch: 263, trainingloss: 0.00526580828970081 | validation loss: 0.00574354714039495
Epoch: 264, trainingloss: 0.00572733357082925 | validation loss: 0.006169598659004516
Epoch: 265, trainingloss: 0.005546807296739621 | validation loss: 0.006014470654915111
Epoch: 266, trainingloss: 0.005990441998436995 | validation loss: 0.006402255609843941
Epoch: 267, trainingloss: 0.005480525000484653 | validation loss: 0.005924932228258427
Epoch: 268, trainingloss: 0.005297573882809277 | validation loss: 0.005775232893456165
Epoch: 269, trainingloss: 0.005185760798334318 | validation loss: 0.0056088749560434135
Epoch: 270, trainingloss: 0.005190326056689213 | validation loss: 0.005720567733886078
Epoch: 271, trainingloss: 0.005111036099531061 | validation loss: 0.0056345458615644954
Epoch: 272, trainingloss: 0.005442038489509947 | validation loss: 0.005904387974811172
Epoch: 273, trainingloss: 0.00532812214006007 | validation loss: 0.005793032227144532
Epoch: 274, trainingloss: 0.005841144783001932 | validation loss: 0.006298953575333025
Epoch: 275, trainingloss: 0.005343623513949199 | validation loss: 0.005819248434530901
Epoch: 276, trainingloss: 0.005214795825741785 | validation loss: 0.005687463827636917
Epoch: 277, trainingloss: 0.006498438937743614 | validation loss: 0.006924979649342497
Epoch: 278, trainingloss: 0.00557446169654385 | validation loss: 0.0060299121727847745
Epoch: 279, trainingloss: 0.005244812836978251 | validation loss: 0.0057202781489424466
Epoch: 280, trainingloss: 0.005320291371117671 | validation loss: 0.0058298987764625184
Epoch: 281, trainingloss: 0.0056519707399711695 | validation loss: 0.0061242269856518735
Epoch: 282, trainingloss: 0.00569080133767515 | validation loss: 0.006105941046784194
Epoch: 283, trainingloss: 0.005165398474070943 | validation loss: 0.005703182942664971
Epoch: 284, trainingloss: 0.005490534072848562 | validation loss: 0.005978246328848346
Epoch: 285, trainingloss: 0.005388887725748614 | validation loss: 0.0058640306895717245
Epoch: 286, trainingloss: 0.005911251183712834 | validation loss: 0.00635251882784562
Epoch: 287, trainingloss: 0.005004896596162405 | validation loss: 0.005492555600768995
Epoch: 288, trainingloss: 0.005845053452780004 | validation loss: 0.006290176516284271
Epoch: 289, trainingloss: 0.0055817843426267544 | validation loss: 0.006003232485363413
Epoch: 290, trainingloss: 0.005281606777669771 | validation loss: 0.005759479105009953
Epoch: 291, trainingloss: 0.005776717161231846 | validation loss: 0.006212502854339189
Epoch: 292, trainingloss: 0.005320135579078622 | validation loss: 0.0058009580436979066
Epoch: 293, trainingloss: 0.005464003138376293 | validation loss: 0.005898373878857065
Epoch: 294, trainingloss: 0.004992235788551987 | validation loss: 0.005480053386340307
Epoch: 295, trainingloss: 0.005183189142743517 | validation loss: 0.005692725633551064
Epoch: 296, trainingloss: 0.00585591003453557 | validation loss: 0.0062612599565489615
Epoch: 297, trainingloss: 0.005484995654682962 | validation loss: 0.005890697557286089
Epoch: 298, trainingloss: 0.005293527430845471 | validation loss: 0.005729059068472687
Epoch: 299, trainingloss: 0.0055227845243450095 | validation loss: 0.00598283388913492
Epoch: 300, trainingloss: 0.005567474936590837 | validation loss: 0.005995243613816115
Epoch: 301, trainingloss: 0.005336901723754597 | validation loss: 0.005802535484847469
Epoch: 302, trainingloss: 0.005827878898119488 | validation loss: 0.006251670163702327
Epoch: 303, trainingloss: 0.0050527608966052144 | validation loss: 0.00554300494018154
Epoch: 304, trainingloss: 0.0051407840221865935 | validation loss: 0.005610435022809363
Epoch: 305, trainingloss: 0.004672940022094514 | validation loss: 0.005139196990228625
Epoch: 306, trainingloss: 0.00517664547670436 | validation loss: 0.005636420173733653
Epoch: 307, trainingloss: 0.005073562096659955 | validation loss: 0.0055204469006586675
Epoch: 308, trainingloss: 0.005276738277857828 | validation loss: 0.005662849020508586
Epoch: 309, trainingloss: 0.00460325705080705 | validation loss: 0.0051313642104470975
Epoch: 310, trainingloss: 0.00546034815404951 | validation loss: 0.005899909401424399
Epoch: 311, trainingloss: 0.004710129983282312 | validation loss: 0.005223031979545793
Epoch: 312, trainingloss: 0.004881121457873973 | validation loss: 0.00536190789784606
Epoch: 313, trainingloss: 0.005035490269257201 | validation loss: 0.005524446169260905
Epoch: 314, trainingloss: 0.004530014038639984 | validation loss: 0.005078383369470358
Epoch: 315, trainingloss: 0.005680438025728525 | validation loss: 0.006117558749262973
Epoch: 316, trainingloss: 0.0047858310515687605 | validation loss: 0.005311036548850521
Epoch: 317, trainingloss: 0.0054310759412238094 | validation loss: 0.005886723122953022
Epoch: 318, trainingloss: 0.006340735934042984 | validation loss: 0.00669341376380757
Epoch: 319, trainingloss: 0.005239848994347267 | validation loss: 0.005675143509890739
Epoch: 320, trainingloss: 0.00541329860207233 | validation loss: 0.005855203644916977
Epoch: 321, trainingloss: 0.004967870651573509 | validation loss: 0.00543652117847097
Epoch: 322, trainingloss: 0.005980148926320635 | validation loss: 0.006418768952672327
Epoch: 323, trainingloss: 0.0048572455922750194 | validation loss: 0.0053841877953234585
Epoch: 324, trainingloss: 0.004870623341390715 | validation loss: 0.0053325661099348776
Epoch: 325, trainingloss: 0.005285282893061715 | validation loss: 0.005753437617638911
Epoch: 326, trainingloss: 0.00474415808134708 | validation loss: 0.0052438235152153
Epoch: 327, trainingloss: 0.005076895106031137 | validation loss: 0.005530330045071666
Epoch: 328, trainingloss: 0.005256127127386023 | validation loss: 0.0056950544815307464
Epoch: 329, trainingloss: 0.004775574014286774 | validation loss: 0.0052647221034582085
Epoch: 330, trainingloss: 0.004863017193170059 | validation loss: 0.005374302413237278
Epoch: 331, trainingloss: 0.005173805650973507 | validation loss: 0.005669414896344464
Epoch: 332, trainingloss: 0.004782783399062403 | validation loss: 0.005253248045280356
Epoch: 333, trainingloss: 0.0052206707487706975 | validation loss: 0.005639846088192593
Epoch: 334, trainingloss: 0.0051947239699271465 | validation loss: 0.005630467962279793
Epoch: 335, trainingloss: 0.004898652937198828 | validation loss: 0.005389713706938382
Epoch: 336, trainingloss: 0.005484201556912431 | validation loss: 0.005934594846187431
Epoch: 337, trainingloss: 0.006121150219725579 | validation loss: 0.006532286058475113
Epoch: 338, trainingloss: 0.004983076216608248 | validation loss: 0.0054687954553269864
Epoch: 339, trainingloss: 0.0053709380469440906 | validation loss: 0.005820884449186334
Epoch: 340, trainingloss: 0.005156201721269056 | validation loss: 0.005605199227649128
Epoch: 341, trainingloss: 0.005579837114164069 | validation loss: 0.005998425815012182
Epoch: 342, trainingloss: 0.005463920368842428 | validation loss: 0.00592647827511432
Epoch: 343, trainingloss: 0.005413270089904151 | validation loss: 0.005821312130465432
Epoch: 344, trainingloss: 0.005290999058258848 | validation loss: 0.005756019579679978
Epoch: 345, trainingloss: 0.004842911535257589 | validation loss: 0.00532820678559965
Epoch: 346, trainingloss: 0.004849197672362863 | validation loss: 0.005276514610942964
Epoch: 347, trainingloss: 0.005534231294414087 | validation loss: 0.005966381285253739
Epoch: 348, trainingloss: 0.0052369573458863694 | validation loss: 0.005631074976887125
Epoch: 349, trainingloss: 0.005407854576804785 | validation loss: 0.0058530913454872355
Epoch: 350, trainingloss: 0.004992060850620455 | validation loss: 0.005447535610768358
Epoch: 351, trainingloss: 0.005334470106878792 | validation loss: 0.0057783273964219
Epoch: 352, trainingloss: 0.005019387897798186 | validation loss: 0.005480988264610636
Epoch: 353, trainingloss: 0.005299920166080332 | validation loss: 0.005728360486021455
Epoch: 354, trainingloss: 0.00486125846125572 | validation loss: 0.005327798200604982
Epoch: 355, trainingloss: 0.005076489757927443 | validation loss: 0.005576702144038278
Epoch: 356, trainingloss: 0.0051375630160955385 | validation loss: 0.005565194203217385
Epoch: 357, trainingloss: 0.004891752744800663 | validation loss: 0.005353272999640974
Epoch: 358, trainingloss: 0.005255047529537222 | validation loss: 0.005701166654610573
Epoch: 359, trainingloss: 0.004672944644903724 | validation loss: 0.005124115046652495
Epoch: 360, trainingloss: 0.004822868030756017 | validation loss: 0.005279358798462415
Epoch: 361, trainingloss: 0.004675867597233044 | validation loss: 0.005176129242485975
Epoch: 362, trainingloss: 0.004999090533901064 | validation loss: 0.005456986402465466
Epoch: 363, trainingloss: 0.004892527931732404 | validation loss: 0.005351124581370454
Epoch: 364, trainingloss: 0.005054904149468459 | validation loss: 0.005495137466783506
Epoch: 365, trainingloss: 0.0051544054157246465 | validation loss: 0.005607905919497626
Epoch: 366, trainingloss: 0.004737572505425876 | validation loss: 0.005226093085745656
Epoch: 367, trainingloss: 0.004974005735962143 | validation loss: 0.0054160966137119645
Epoch: 368, trainingloss: 0.004916424616709852 | validation loss: 0.005381204467974434
Epoch: 369, trainingloss: 0.005126045219638695 | validation loss: 0.005583912732872632
Epoch: 370, trainingloss: 0.004966458074992211 | validation loss: 0.005423863662693633
Epoch: 371, trainingloss: 0.00446534592162136 | validation loss: 0.005010343615031448
Epoch: 372, trainingloss: 0.005254129133295631 | validation loss: 0.0057060794702620075
Epoch: 373, trainingloss: 0.005154012820152722 | validation loss: 0.0055868976106549185
Epoch: 374, trainingloss: 0.005504377158962442 | validation loss: 0.005874289684696309
Epoch: 375, trainingloss: 0.005832651817745282 | validation loss: 0.006188988245348368
Epoch: 376, trainingloss: 0.004974046106582656 | validation loss: 0.005380444916658598
Epoch: 377, trainingloss: 0.004650847110470044 | validation loss: 0.00513448563503886
Epoch: 378, trainingloss: 0.0054769191508692505 | validation loss: 0.0059194268077708955
Epoch: 379, trainingloss: 0.005631956782618432 | validation loss: 0.006060903298715131
Epoch: 380, trainingloss: 0.005224694920499271 | validation loss: 0.005623987546307095
Epoch: 381, trainingloss: 0.005220129994431888 | validation loss: 0.005638811507654428
Epoch: 382, trainingloss: 0.005209201453591359 | validation loss: 0.005679884040504851
Epoch: 383, trainingloss: 0.0047473645743928705 | validation loss: 0.00523629732198085
Epoch: 384, trainingloss: 0.0049307719805471 | validation loss: 0.00539135329197837
Epoch: 385, trainingloss: 0.0050335451299339026 | validation loss: 0.00549561849316933
Epoch: 386, trainingloss: 0.0048901038407194305 | validation loss: 0.005353075499945673
Epoch: 387, trainingloss: 0.004835314777066124 | validation loss: 0.005304936727989613
Epoch: 388, trainingloss: 0.005162698389234932 | validation loss: 0.005602545276260149
Epoch: 389, trainingloss: 0.005135120060679855 | validation loss: 0.0055908187549611995
Epoch: 390, trainingloss: 0.004655860262133751 | validation loss: 0.00510706592249648
Epoch: 391, trainingloss: 0.004640164103506525 | validation loss: 0.005119718628335411
Epoch: 392, trainingloss: 0.004654697453988867 | validation loss: 0.005134002255911393
Epoch: 393, trainingloss: 0.005189222818851659 | validation loss: 0.005638844721352589
Epoch: 394, trainingloss: 0.0048947419670134305 | validation loss: 0.005364032164793929
Epoch: 395, trainingloss: 0.005178358525434925 | validation loss: 0.0056011860399771225
Epoch: 396, trainingloss: 0.005502667882976941 | validation loss: 0.005941777281919787
Epoch: 397, trainingloss: 0.005012951732116012 | validation loss: 0.005452977603022741
Epoch: 398, trainingloss: 0.005036059291436155 | validation loss: 0.005466480613702904
Epoch: 399, trainingloss: 0.004565842470526869 | validation loss: 0.00505916249629269
Epoch: 400, trainingloss: 0.004614070241501854 | validation loss: 0.00507413914516895
Epoch: 401, trainingloss: 0.004503563551233159 | validation loss: 0.0050050847863580515
Epoch: 402, trainingloss: 0.004946031471543847 | validation loss: 0.005418287152952509
Epoch: 403, trainingloss: 0.0048855125092216465 | validation loss: 0.005382605192262244
Epoch: 404, trainingloss: 0.005179811982972843 | validation loss: 0.005598046826228498
Epoch: 405, trainingloss: 0.0045982479369192095 | validation loss: 0.005087974967405235
Epoch: 406, trainingloss: 0.004615822150019352 | validation loss: 0.005109881091116791
Epoch: 407, trainingloss: 0.005589989191518403 | validation loss: 0.006025600402583278
Epoch: 408, trainingloss: 0.005455737942027163 | validation loss: 0.005893208811706815
Epoch: 409, trainingloss: 0.004695434697026668 | validation loss: 0.00514105709873553
Epoch: 410, trainingloss: 0.005017624183610335 | validation loss: 0.00544384607737962
Epoch: 411, trainingloss: 0.00492813285183917 | validation loss: 0.005372482682972669
Epoch: 412, trainingloss: 0.004743303781233685 | validation loss: 0.005178818488351173
Epoch: 413, trainingloss: 0.004717090525662063 | validation loss: 0.005163145215582753
Epoch: 414, trainingloss: 0.00489048338757463 | validation loss: 0.005320484816454311
Epoch: 415, trainingloss: 0.004840887737793855 | validation loss: 0.005292156871045318
Epoch: 416, trainingloss: 0.005453524920761667 | validation loss: 0.005866518106381815
Epoch: 417, trainingloss: 0.004740634167016672 | validation loss: 0.005197292966558647
Epoch: 418, trainingloss: 0.00475631472604955 | validation loss: 0.005224667786785202
Epoch: 419, trainingloss: 0.004886348626411114 | validation loss: 0.0053329679791022724
Epoch: 420, trainingloss: 0.004648079972335846 | validation loss: 0.0051521008491583215
Epoch: 421, trainingloss: 0.0049016961239131615 | validation loss: 0.00537047103354379
Epoch: 422, trainingloss: 0.004624617193887373 | validation loss: 0.0050750949894339745
Epoch: 423, trainingloss: 0.004954482836312951 | validation loss: 0.00538884141313347
Epoch: 424, trainingloss: 0.004901516094056555 | validation loss: 0.00529444942057695
Epoch: 425, trainingloss: 0.005424206089293428 | validation loss: 0.005822736068323924
Epoch: 426, trainingloss: 0.005009218644239121 | validation loss: 0.005423452381188596
Epoch: 427, trainingloss: 0.005067629743261811 | validation loss: 0.005461229203026912
Epoch: 428, trainingloss: 0.004820737896334256 | validation loss: 0.005264439281179611
Epoch: 429, trainingloss: 0.004830919169599227 | validation loss: 0.005268776213463059
Epoch: 430, trainingloss: 0.004529945877818531 | validation loss: 0.0049930662131572245
Epoch: 431, trainingloss: 0.00512342809002176 | validation loss: 0.005520232618040273
Epoch: 432, trainingloss: 0.004641192197170877 | validation loss: 0.005096569938972869
Epoch: 433, trainingloss: 0.004784079680577183 | validation loss: 0.005215592275236
Epoch: 434, trainingloss: 0.004632799229342357 | validation loss: 0.005098426257164661
Epoch: 435, trainingloss: 0.0044362876962052485 | validation loss: 0.004938220071803774
Epoch: 436, trainingloss: 0.005263439012301294 | validation loss: 0.005695021792355989
Epoch: 437, trainingloss: 0.0051768912514010505 | validation loss: 0.0056262631716202036
Epoch: 438, trainingloss: 0.005224876720152723 | validation loss: 0.00562590713005294
Epoch: 439, trainingloss: 0.004910987053653019 | validation loss: 0.005373437011445021
Epoch: 440, trainingloss: 0.004912289399232996 | validation loss: 0.005355534427100256
Epoch: 441, trainingloss: 0.0050261794627917255 | validation loss: 0.005486368069345298
Epoch: 442, trainingloss: 0.004359061752676191 | validation loss: 0.004852715827766888
Epoch: 443, trainingloss: 0.005032773606653961 | validation loss: 0.005475574138764355
Epoch: 444, trainingloss: 0.005153995904044842 | validation loss: 0.005582146150811125
Epoch: 445, trainingloss: 0.004626351338928797 | validation loss: 0.005065904198606377
Epoch: 446, trainingloss: 0.005152345040183252 | validation loss: 0.005602976618627923
Epoch: 447, trainingloss: 0.004565277338932569 | validation loss: 0.00503094525413827
Epoch: 448, trainingloss: 0.004393533262101942 | validation loss: 0.004842713961379382
Epoch: 449, trainingloss: 0.005072413238465093 | validation loss: 0.005487738485891427
Epoch: 450, trainingloss: 0.004646649036416626 | validation loss: 0.0051395448617082
Epoch: 451, trainingloss: 0.0046502451250791 | validation loss: 0.0051171120820470645
Epoch: 452, trainingloss: 0.004366459121848301 | validation loss: 0.004899435815422028
Epoch: 453, trainingloss: 0.004951007830562293 | validation loss: 0.0054031031141949515
Epoch: 454, trainingloss: 0.004596718968629912 | validation loss: 0.005056759479585027
Epoch: 455, trainingloss: 0.00541078441358842 | validation loss: 0.0058227003949316465
Epoch: 456, trainingloss: 0.004554119275029862 | validation loss: 0.0050302654259646385
Epoch: 457, trainingloss: 0.005339783949289034 | validation loss: 0.005729951872872234
Epoch: 458, trainingloss: 0.0051273556920608575 | validation loss: 0.005567695542829992
Epoch: 459, trainingloss: 0.0044579307479405555 | validation loss: 0.004922689685487584
Epoch: 460, trainingloss: 0.004588645016123843 | validation loss: 0.005055972908344718
Epoch: 461, trainingloss: 0.004698142961793404 | validation loss: 0.005159141787349599
Epoch: 462, trainingloss: 0.00501664637961576 | validation loss: 0.0054523948677017925
Epoch: 463, trainingloss: 0.004664148617860197 | validation loss: 0.005120323965354924
Epoch: 464, trainingloss: 0.004606837710061275 | validation loss: 0.0050859756295328976
Epoch: 465, trainingloss: 0.004737503601025961 | validation loss: 0.005214270618122363
Epoch: 466, trainingloss: 0.004640748900974653 | validation loss: 0.005097667453111612
Epoch: 467, trainingloss: 0.0045524637301509446 | validation loss: 0.005002270594720369
Epoch: 468, trainingloss: 0.005146291393863592 | validation loss: 0.005592031260630394
Epoch: 469, trainingloss: 0.00467540386502266 | validation loss: 0.005156301634960552
Epoch: 470, trainingloss: 0.004604117134225355 | validation loss: 0.005067964698505766
Epoch: 471, trainingloss: 0.004603094433702834 | validation loss: 0.005110855885552933
Epoch: 472, trainingloss: 0.005169552781153003 | validation loss: 0.005596782913265065
Epoch: 473, trainingloss: 0.0048913214815160715 | validation loss: 0.005287487099891728
Epoch: 474, trainingloss: 0.004941648041750381 | validation loss: 0.005386803849880678
Epoch: 475, trainingloss: 0.004596628180658811 | validation loss: 0.005045926834064971
Epoch: 476, trainingloss: 0.004705233946082653 | validation loss: 0.005144612628584865
Epoch: 477, trainingloss: 0.00496814187968259 | validation loss: 0.005349969216245946
Epoch: 478, trainingloss: 0.004575127317682562 | validation loss: 0.00503559345358337
Epoch: 479, trainingloss: 0.004706725187354609 | validation loss: 0.005171936940043744
Epoch: 480, trainingloss: 0.00509715721651222 | validation loss: 0.005491507360183816
Epoch: 481, trainingloss: 0.004722178381390883 | validation loss: 0.005173439868175476
Epoch: 482, trainingloss: 0.004836470251389586 | validation loss: 0.005272452759112649
Epoch: 483, trainingloss: 0.004387111185833114 | validation loss: 0.00483924621666364
Epoch: 484, trainingloss: 0.004780311734910638 | validation loss: 0.005209564524768534
Epoch: 485, trainingloss: 0.004353644231562161 | validation loss: 0.004856176193459395
Epoch: 486, trainingloss: 0.004611540769623717 | validation loss: 0.005079511946348838
Epoch: 487, trainingloss: 0.004732072147053327 | validation loss: 0.005159989150733336
Epoch: 488, trainingloss: 0.0047583038341070735 | validation loss: 0.005235306309116287
Epoch: 489, trainingloss: 0.0045785819918626874 | validation loss: 0.005019429922219206
Epoch: 490, trainingloss: 0.004910372147693179 | validation loss: 0.005311911318761019
Epoch: 491, trainingloss: 0.004740695921742789 | validation loss: 0.005185655264064734
Epoch: 492, trainingloss: 0.004476014874616947 | validation loss: 0.004944182542799567
Epoch: 493, trainingloss: 0.004702665945792818 | validation loss: 0.005139118173027714
Epoch: 494, trainingloss: 0.004740126509058443 | validation loss: 0.005193319620791398
Epoch: 495, trainingloss: 0.004875379448543229 | validation loss: 0.005332386271671029
Epoch: 496, trainingloss: 0.0047818416756447045 | validation loss: 0.005256604514192961
Epoch: 497, trainingloss: 0.00473293850402332 | validation loss: 0.005190442867002487
Epoch: 498, trainingloss: 0.004693375693968926 | validation loss: 0.005163824835403927
Epoch: 499, trainingloss: 0.004434542945005787 | validation loss: 0.004898597977643681
Epoch: 500, trainingloss: 0.004644266770468414 | validation loss: 0.005123848437238226
Epoch: 501, trainingloss: 0.004772943083708449 | validation loss: 0.0052274203913271955
Epoch: 502, trainingloss: 0.005000391781005559 | validation loss: 0.005449114326464175
Epoch: 503, trainingloss: 0.004690824652374984 | validation loss: 0.005132997869416215
Epoch: 504, trainingloss: 0.004463746107604582 | validation loss: 0.004911106340145703
Epoch: 505, trainingloss: 0.0046419502043680725 | validation loss: 0.005054542168169001
Epoch: 506, trainingloss: 0.00496211718432681 | validation loss: 0.005401795503858532
Epoch: 507, trainingloss: 0.004355967877621509 | validation loss: 0.004864442023711697
Epoch: 508, trainingloss: 0.005328204856293235 | validation loss: 0.0057119354609863
Epoch: 509, trainingloss: 0.0046301671572195864 | validation loss: 0.005064899359619345
Epoch: 510, trainingloss: 0.004709699913741971 | validation loss: 0.005163357781759382
Epoch: 511, trainingloss: 0.0044124687515902684 | validation loss: 0.004899710440177178
Epoch: 512, trainingloss: 0.0048639183056330085 | validation loss: 0.005281888630017717

Smallest SV 5000
Epoch: 0, trainingloss: 0.2003593680275578 | validation loss: 0.19990511117435147
Epoch: 1, trainingloss: 0.042650772309916776 | validation loss: 0.042733842891578715
Epoch: 2, trainingloss: 0.03225166337269733 | validation loss: 0.03251615314996244
Epoch: 3, trainingloss: 0.026080968192455423 | validation loss: 0.026385215792668167
Epoch: 4, trainingloss: 0.02158472391269009 | validation loss: 0.021937514691503953
Epoch: 5, trainingloss: 0.01833529313049808 | validation loss: 0.018652823064386728
Epoch: 6, trainingloss: 0.016489896491804483 | validation loss: 0.01666991780700538
Epoch: 7, trainingloss: 0.016386525349224315 | validation loss: 0.01660964746013804
Epoch: 8, trainingloss: 0.016092531475228707 | validation loss: 0.016316637372820735
Epoch: 9, trainingloss: 0.014266366010979246 | validation loss: 0.014480445137123092
Epoch: 10, trainingloss: 0.014168081935203986 | validation loss: 0.014485672943111377
Epoch: 11, trainingloss: 0.012427644790198497 | validation loss: 0.012728337920724477
Epoch: 12, trainingloss: 0.012151719965366709 | validation loss: 0.012457554387073213
Epoch: 13, trainingloss: 0.012938353643908598 | validation loss: 0.013304553319455382
Epoch: 14, trainingloss: 0.011350879483872998 | validation loss: 0.01167665887690504
Epoch: 15, trainingloss: 0.011638090460420341 | validation loss: 0.011824554854876516
Epoch: 16, trainingloss: 0.011086286887003846 | validation loss: 0.011429386910501058
Epoch: 17, trainingloss: 0.011681135413433501 | validation loss: 0.011969414236849487
Epoch: 18, trainingloss: 0.011102367132133705 | validation loss: 0.011318013373965846
Epoch: 19, trainingloss: 0.01044745547020095 | validation loss: 0.010721671461383916
Epoch: 20, trainingloss: 0.010217193719464475 | validation loss: 0.010489329233836312
Epoch: 21, trainingloss: 0.009691809526475347 | validation loss: 0.009950997791647336
Epoch: 22, trainingloss: 0.010014494078380886 | validation loss: 0.010318357905154073
Epoch: 23, trainingloss: 0.01007743590893781 | validation loss: 0.010302197632697147
Epoch: 24, trainingloss: 0.00890517286205772 | validation loss: 0.009194819993288434
Epoch: 25, trainingloss: 0.009509121888510054 | validation loss: 0.009797666312821857
Epoch: 26, trainingloss: 0.009714466641068356 | validation loss: 0.009945197428358124
Epoch: 27, trainingloss: 0.010095095528021406 | validation loss: 0.010344366785772975
Epoch: 28, trainingloss: 0.00877965161731535 | validation loss: 0.009037894012916598
Epoch: 29, trainingloss: 0.009180033562671277 | validation loss: 0.009371579016273142
Epoch: 30, trainingloss: 0.009188686635985209 | validation loss: 0.009413482371789388
Epoch: 31, trainingloss: 0.009032266558288347 | validation loss: 0.009324914276399787
Epoch: 32, trainingloss: 0.0086265708042442 | validation loss: 0.008920759847174907
Epoch: 33, trainingloss: 0.00939988789808774 | validation loss: 0.009638974105181662
Epoch: 34, trainingloss: 0.008729922907396227 | validation loss: 0.008936328840924395
Epoch: 35, trainingloss: 0.008007194720149399 | validation loss: 0.008322961695005838
Epoch: 36, trainingloss: 0.008196808054776577 | validation loss: 0.00844355932904202
Epoch: 37, trainingloss: 0.007738828941737874 | validation loss: 0.008019526733607585
Epoch: 38, trainingloss: 0.007744402279008823 | validation loss: 0.007991909116729139
Epoch: 39, trainingloss: 0.010068976934404806 | validation loss: 0.010258218359464088
Epoch: 40, trainingloss: 0.008034783210126229 | validation loss: 0.008289869120999068
Epoch: 41, trainingloss: 0.008466334561942115 | validation loss: 0.008693379385910745
Epoch: 42, trainingloss: 0.008927445654055528 | validation loss: 0.009131153698809298
Epoch: 43, trainingloss: 0.008070855752662209 | validation loss: 0.008317499352371908
Epoch: 44, trainingloss: 0.008055998896277275 | validation loss: 0.008305278268182968
Epoch: 45, trainingloss: 0.009209128696809265 | validation loss: 0.009344421481313476
Epoch: 46, trainingloss: 0.009413187357344843 | validation loss: 0.009555050439531159
Epoch: 47, trainingloss: 0.007772406242580874 | validation loss: 0.007976110639773933
Epoch: 48, trainingloss: 0.0075232338482077695 | validation loss: 0.007817363638733511
Epoch: 49, trainingloss: 0.007870113677479505 | validation loss: 0.00805873186963209
Epoch: 50, trainingloss: 0.008935471640140698 | validation loss: 0.009195662262790845
Epoch: 51, trainingloss: 0.008741204541495021 | validation loss: 0.0089514435201231
Epoch: 52, trainingloss: 0.008085830487235683 | validation loss: 0.008259605173356303
Epoch: 53, trainingloss: 0.007655144996201116 | validation loss: 0.007833457214289739
Epoch: 54, trainingloss: 0.0077410571476997534 | validation loss: 0.008013137518505442
Epoch: 55, trainingloss: 0.007888372647562486 | validation loss: 0.008077466115166285
Epoch: 56, trainingloss: 0.007658734582206879 | validation loss: 0.007976510650299655
Epoch: 57, trainingloss: 0.007251756177662031 | validation loss: 0.007520589118781604
Epoch: 58, trainingloss: 0.007781616750246633 | validation loss: 0.008014713821219448
Epoch: 59, trainingloss: 0.007783007299564756 | validation loss: 0.00800566058192866
Epoch: 60, trainingloss: 0.007169679721507718 | validation loss: 0.007425771479724807
Epoch: 61, trainingloss: 0.006740014029198619 | validation loss: 0.00696984920574875
Epoch: 62, trainingloss: 0.006852044745469621 | validation loss: 0.007104800224374009
Epoch: 63, trainingloss: 0.006377765581389907 | validation loss: 0.0066102921757733865
Epoch: 64, trainingloss: 0.0073901946074081595 | validation loss: 0.007590328524930614
Epoch: 65, trainingloss: 0.007139482505669807 | validation loss: 0.007455901659541456
Epoch: 66, trainingloss: 0.008246544841740594 | validation loss: 0.008368220836785173
Epoch: 67, trainingloss: 0.007100758499658787 | validation loss: 0.007388227212145664
Epoch: 68, trainingloss: 0.007175924409523367 | validation loss: 0.007380355929440662
Epoch: 69, trainingloss: 0.007805471488218572 | validation loss: 0.008022498269059332
Epoch: 70, trainingloss: 0.006355210090965642 | validation loss: 0.0065852782789809355
Epoch: 71, trainingloss: 0.007136980220050799 | validation loss: 0.0073804637433745246
Epoch: 72, trainingloss: 0.007059007433706691 | validation loss: 0.007301251461606079
Epoch: 73, trainingloss: 0.0068494234303461896 | validation loss: 0.007071937458839068
Epoch: 74, trainingloss: 0.007020376416531106 | validation loss: 0.007240297126506734
Epoch: 75, trainingloss: 0.006521931212605958 | validation loss: 0.006750602630215744
Epoch: 76, trainingloss: 0.006302601331888956 | validation loss: 0.006540746944637782
Epoch: 77, trainingloss: 0.007050863040501219 | validation loss: 0.007303288502751249
Epoch: 78, trainingloss: 0.007497833130183834 | validation loss: 0.007745458105408576
Epoch: 79, trainingloss: 0.006788699922343099 | validation loss: 0.0070542471541644265
Epoch: 80, trainingloss: 0.006345212644486845 | validation loss: 0.006575555648018549
Epoch: 81, trainingloss: 0.006501903690621018 | validation loss: 0.006764703179737779
Epoch: 82, trainingloss: 0.0062422670529102145 | validation loss: 0.006470183363821825
Epoch: 83, trainingloss: 0.0069632823424649925 | validation loss: 0.007144534897519824
Epoch: 84, trainingloss: 0.006042759506521 | validation loss: 0.0063370470302644985
Epoch: 85, trainingloss: 0.006555027753358104 | validation loss: 0.006831363667569663
Epoch: 86, trainingloss: 0.006514917508805058 | validation loss: 0.006785715728915875
Epoch: 87, trainingloss: 0.005845670160620423 | validation loss: 0.006117679429740428
Epoch: 88, trainingloss: 0.0064242908077694495 | validation loss: 0.0067016103574969324
Epoch: 89, trainingloss: 0.005878831663120706 | validation loss: 0.006156033654549797
Epoch: 90, trainingloss: 0.0059374923926247755 | validation loss: 0.006204052653323195
Epoch: 91, trainingloss: 0.006739130299508591 | validation loss: 0.0070398378459963
Epoch: 92, trainingloss: 0.007469204454993846 | validation loss: 0.007695837178748924
Epoch: 93, trainingloss: 0.006690409713388917 | validation loss: 0.006990788562915122
Epoch: 94, trainingloss: 0.005337690427064389 | validation loss: 0.005670385835778777
Epoch: 95, trainingloss: 0.006628233734493165 | validation loss: 0.006892819035925752
Epoch: 96, trainingloss: 0.005767913933164063 | validation loss: 0.006074252446027249
Epoch: 97, trainingloss: 0.005891694957044217 | validation loss: 0.006164086861963263
Epoch: 98, trainingloss: 0.006160926133585032 | validation loss: 0.0064728554248396864
Epoch: 99, trainingloss: 0.006184391579171815 | validation loss: 0.0064854710917991755
Epoch: 100, trainingloss: 0.006250979590488457 | validation loss: 0.0065237373612313885
Epoch: 101, trainingloss: 0.0057812859641339885 | validation loss: 0.006137377713699525
Epoch: 102, trainingloss: 0.006011651451123662 | validation loss: 0.006307044679885137
Epoch: 103, trainingloss: 0.006797644815157497 | validation loss: 0.0071030829044714
Epoch: 104, trainingloss: 0.006839235650758132 | validation loss: 0.0070442306906035685
Epoch: 105, trainingloss: 0.006231872811424572 | validation loss: 0.006493913707016301
Epoch: 106, trainingloss: 0.005680461201381955 | validation loss: 0.005984267508761625
Epoch: 107, trainingloss: 0.006011169951294316 | validation loss: 0.006312791420232131
Epoch: 108, trainingloss: 0.005543368318275688 | validation loss: 0.005860547013731199
Epoch: 109, trainingloss: 0.005654253493715426 | validation loss: 0.005931654789956321
Epoch: 110, trainingloss: 0.006122066817803282 | validation loss: 0.006424931004576163
Epoch: 111, trainingloss: 0.005337325972608107 | validation loss: 0.0056410887536756
Epoch: 112, trainingloss: 0.00567883616963844 | validation loss: 0.005976761284746659
Epoch: 113, trainingloss: 0.006516209417162569 | validation loss: 0.006748513157024265
Epoch: 114, trainingloss: 0.006951886871247365 | validation loss: 0.0071961413882873585
Epoch: 115, trainingloss: 0.006395687434739483 | validation loss: 0.0066711555264735494
Epoch: 116, trainingloss: 0.005800639740620947 | validation loss: 0.006130428903313093
Epoch: 117, trainingloss: 0.005334067336623183 | validation loss: 0.005661079029768034
Epoch: 118, trainingloss: 0.005536826979005536 | validation loss: 0.005833795344422944
Epoch: 119, trainingloss: 0.006376331235639509 | validation loss: 0.006606451030443685
Epoch: 120, trainingloss: 0.006041739875133913 | validation loss: 0.00632399832446726
Epoch: 121, trainingloss: 0.005517017626553788 | validation loss: 0.005851874188668195
Epoch: 122, trainingloss: 0.005544653276977225 | validation loss: 0.005864848542024401
Epoch: 123, trainingloss: 0.005703783007831302 | validation loss: 0.005998630317951752
Epoch: 124, trainingloss: 0.0053754435799477545 | validation loss: 0.0056596826374495975
Epoch: 125, trainingloss: 0.006066340547635926 | validation loss: 0.006309321541128709
Epoch: 126, trainingloss: 0.004954390437612287 | validation loss: 0.005245397095729757
Epoch: 127, trainingloss: 0.005184262423081766 | validation loss: 0.00545453825205214
Epoch: 128, trainingloss: 0.005435359975307587 | validation loss: 0.005673683403735908
Epoch: 129, trainingloss: 0.0050343240607301516 | validation loss: 0.005365186719492184
Epoch: 130, trainingloss: 0.0054826232215905634 | validation loss: 0.00583336020519241
Epoch: 131, trainingloss: 0.005585018920814504 | validation loss: 0.005890556177781716
Epoch: 132, trainingloss: 0.00534678939193414 | validation loss: 0.0056125840488437774
Epoch: 133, trainingloss: 0.005851888439992539 | validation loss: 0.006103018229549659
Epoch: 134, trainingloss: 0.005237487369838291 | validation loss: 0.005512937614942045
Epoch: 135, trainingloss: 0.00552234398501971 | validation loss: 0.0058175815966344585
Epoch: 136, trainingloss: 0.005044445721808231 | validation loss: 0.005349536418795154
Epoch: 137, trainingloss: 0.005686139060852676 | validation loss: 0.005910379783775912
Epoch: 138, trainingloss: 0.005189789050158768 | validation loss: 0.005509711789459403
Epoch: 139, trainingloss: 0.005082590163382208 | validation loss: 0.005388999050662966
Epoch: 140, trainingloss: 0.005603182893984706 | validation loss: 0.005877891440977165
Epoch: 141, trainingloss: 0.005058555154301756 | validation loss: 0.005357609286091784
Epoch: 142, trainingloss: 0.005560949657115395 | validation loss: 0.0058179051436351254
Epoch: 143, trainingloss: 0.00557121449371589 | validation loss: 0.005807310018715034
Epoch: 144, trainingloss: 0.006679620815314999 | validation loss: 0.006907171840535581
Epoch: 145, trainingloss: 0.005054232520504956 | validation loss: 0.005332702991699131
Epoch: 146, trainingloss: 0.005313603618628382 | validation loss: 0.0055878917028945015
Epoch: 147, trainingloss: 0.005085482330829192 | validation loss: 0.005354782091833565
Epoch: 148, trainingloss: 0.006768081322023021 | validation loss: 0.006999634242055708
Epoch: 149, trainingloss: 0.005074234030336616 | validation loss: 0.005408963296057729
Epoch: 150, trainingloss: 0.005445689863620316 | validation loss: 0.0057196778913982445
Epoch: 151, trainingloss: 0.005566238237746261 | validation loss: 0.005836334147893484
Epoch: 152, trainingloss: 0.004946555202815906 | validation loss: 0.005221927761811242
Epoch: 153, trainingloss: 0.00534037805867194 | validation loss: 0.005603053318480861
Epoch: 154, trainingloss: 0.0048696785490129485 | validation loss: 0.005137330610788458
Epoch: 155, trainingloss: 0.0050036336038530626 | validation loss: 0.005298751168340109
Epoch: 156, trainingloss: 0.0047482792764974155 | validation loss: 0.0050797850097414055
Epoch: 157, trainingloss: 0.00490052668655438 | validation loss: 0.005164537177467336
Epoch: 158, trainingloss: 0.005877094958351692 | validation loss: 0.006179205049962463
Epoch: 159, trainingloss: 0.004946926917875161 | validation loss: 0.005244027690662945
Epoch: 160, trainingloss: 0.0056996547862069435 | validation loss: 0.005949969696613412
Epoch: 161, trainingloss: 0.005188052212500111 | validation loss: 0.005460297650158796
Epoch: 162, trainingloss: 0.004835798553114756 | validation loss: 0.005127356387713095
Epoch: 163, trainingloss: 0.004891422711937168 | validation loss: 0.005147981356397457
Epoch: 164, trainingloss: 0.004719012159338849 | validation loss: 0.005038211689855008
Epoch: 165, trainingloss: 0.004731098297543693 | validation loss: 0.004993426042173193
Epoch: 166, trainingloss: 0.005024123359217444 | validation loss: 0.005364771103001966
Epoch: 167, trainingloss: 0.0050367414114335885 | validation loss: 0.005356097623725053
Epoch: 168, trainingloss: 0.00467446529531798 | validation loss: 0.004960955402224647
Epoch: 169, trainingloss: 0.004706864440796918 | validation loss: 0.004996764552391522
Epoch: 170, trainingloss: 0.005226611518747856 | validation loss: 0.0055250955825259865
Epoch: 171, trainingloss: 0.004948594679330001 | validation loss: 0.005229724590297296
Epoch: 172, trainingloss: 0.005050525209363995 | validation loss: 0.005326106091976783
Epoch: 173, trainingloss: 0.004841433585817627 | validation loss: 0.0051357818650611545
Epoch: 174, trainingloss: 0.004970361398728402 | validation loss: 0.005253109208064443
Epoch: 175, trainingloss: 0.004829640663636214 | validation loss: 0.0051075200729417776
Epoch: 176, trainingloss: 0.004936511198543495 | validation loss: 0.005172967152567564
Epoch: 177, trainingloss: 0.005171824907885812 | validation loss: 0.0054075274570110675
Epoch: 178, trainingloss: 0.004875174129738021 | validation loss: 0.005207338035830756
Epoch: 179, trainingloss: 0.006259755100664064 | validation loss: 0.006523614684893187
Epoch: 180, trainingloss: 0.004800554554863229 | validation loss: 0.00510510842592576
Epoch: 181, trainingloss: 0.0063037628848881385 | validation loss: 0.006526136986940853
Epoch: 182, trainingloss: 0.0052716080754573085 | validation loss: 0.0055651969501493825
Epoch: 183, trainingloss: 0.004832581206943088 | validation loss: 0.0051504988780721435
Epoch: 184, trainingloss: 0.004451248557522487 | validation loss: 0.004764954705523871
Epoch: 185, trainingloss: 0.004454048732454001 | validation loss: 0.004756693377230987
Epoch: 186, trainingloss: 0.0054715009585099995 | validation loss: 0.005677949227193977
Epoch: 187, trainingloss: 0.005748813344734816 | validation loss: 0.005955145622899082
Epoch: 188, trainingloss: 0.004962780426051544 | validation loss: 0.005168815308716728
Epoch: 189, trainingloss: 0.004743113860849383 | validation loss: 0.00503899639408229
Epoch: 190, trainingloss: 0.004694067410482912 | validation loss: 0.005017129785873184
Epoch: 191, trainingloss: 0.004624108090623575 | validation loss: 0.004939978115044165
Epoch: 192, trainingloss: 0.004725046105226208 | validation loss: 0.004973126759069765
Epoch: 193, trainingloss: 0.0051827942503215995 | validation loss: 0.005466105360877463
Epoch: 194, trainingloss: 0.004869262230583295 | validation loss: 0.0051399743349228545
Epoch: 195, trainingloss: 0.004989304971312133 | validation loss: 0.005286717438939455
Epoch: 196, trainingloss: 0.004794969681886172 | validation loss: 0.005113426755911134
Epoch: 197, trainingloss: 0.004404309543661267 | validation loss: 0.0047122308932774385
Epoch: 198, trainingloss: 0.005115028059022701 | validation loss: 0.00537057563894822
Epoch: 199, trainingloss: 0.004814041565317936 | validation loss: 0.005091508630779056
Epoch: 200, trainingloss: 0.005188580721645092 | validation loss: 0.005416002778738246
Epoch: 201, trainingloss: 0.004832360234145146 | validation loss: 0.00510972771783525
Epoch: 202, trainingloss: 0.00491814178644836 | validation loss: 0.005139641553318451
Epoch: 203, trainingloss: 0.004807423299250348 | validation loss: 0.005091980623828317
Epoch: 204, trainingloss: 0.005322643134934779 | validation loss: 0.005552877500688106
Epoch: 205, trainingloss: 0.004363586676831493 | validation loss: 0.00470518857055373
Epoch: 206, trainingloss: 0.00475554086608189 | validation loss: 0.0050319922572290504
Epoch: 207, trainingloss: 0.00517173917197671 | validation loss: 0.005439486559340493
Epoch: 208, trainingloss: 0.005477315789007984 | validation loss: 0.005746745142579184
Epoch: 209, trainingloss: 0.00521688002023387 | validation loss: 0.005493260455262354
Epoch: 210, trainingloss: 0.004765046473747789 | validation loss: 0.005055624747543172
Epoch: 211, trainingloss: 0.004865046973386975 | validation loss: 0.005117408288765894
Epoch: 212, trainingloss: 0.005038421706163102 | validation loss: 0.005353218448952646
Epoch: 213, trainingloss: 0.004641242972084694 | validation loss: 0.004919039716064192
Epoch: 214, trainingloss: 0.00499910469534409 | validation loss: 0.005299939807551443
Epoch: 215, trainingloss: 0.004606012217454405 | validation loss: 0.0049432770637262025
Epoch: 216, trainingloss: 0.005121535234306293 | validation loss: 0.005402149977740469
Epoch: 217, trainingloss: 0.004972383317853615 | validation loss: 0.0052238932833545675
Epoch: 218, trainingloss: 0.0042566724367844085 | validation loss: 0.004587950842080257
Epoch: 219, trainingloss: 0.004618052931364168 | validation loss: 0.004907069523106189
Epoch: 220, trainingloss: 0.004848061661220267 | validation loss: 0.005124851246417984
Epoch: 221, trainingloss: 0.00447583165975101 | validation loss: 0.004779892593289411
Epoch: 222, trainingloss: 0.005897730010442703 | validation loss: 0.006138213271871403
Epoch: 223, trainingloss: 0.0044524038951009644 | validation loss: 0.004765065012955637
Epoch: 224, trainingloss: 0.005260036514296401 | validation loss: 0.005482941789823309
Epoch: 225, trainingloss: 0.004616296043005369 | validation loss: 0.004918438600972614
Epoch: 226, trainingloss: 0.004568791986556559 | validation loss: 0.004874198107566023
Epoch: 227, trainingloss: 0.0044192619649922465 | validation loss: 0.004722244091477097
Epoch: 228, trainingloss: 0.004792028468459873 | validation loss: 0.005048160690699961
Epoch: 229, trainingloss: 0.004341294424590035 | validation loss: 0.004639000902092881
Epoch: 230, trainingloss: 0.004485872313678162 | validation loss: 0.004740475405511904
Epoch: 231, trainingloss: 0.004665211875307114 | validation loss: 0.004939260737853441
Epoch: 232, trainingloss: 0.004729778797622333 | validation loss: 0.004992023633924022
Epoch: 233, trainingloss: 0.005573795183382491 | validation loss: 0.005771552636527412
Epoch: 234, trainingloss: 0.0048180052098879085 | validation loss: 0.005079407384053489
Epoch: 235, trainingloss: 0.005186914343143387 | validation loss: 0.005455992696683695
Epoch: 236, trainingloss: 0.004613749872073746 | validation loss: 0.004877563026135218
Epoch: 237, trainingloss: 0.004399839642608376 | validation loss: 0.004696433559366062
Epoch: 238, trainingloss: 0.004788667841861031 | validation loss: 0.005076695260231014
Epoch: 239, trainingloss: 0.004517705820504755 | validation loss: 0.004798544830917932
Epoch: 240, trainingloss: 0.004611887178150984 | validation loss: 0.004879427955833373
Epoch: 241, trainingloss: 0.004847612187791747 | validation loss: 0.00508745237438001
Epoch: 242, trainingloss: 0.004569530095890532 | validation loss: 0.004829275361163366
Epoch: 243, trainingloss: 0.004439837780456785 | validation loss: 0.004735153132089444
Epoch: 244, trainingloss: 0.0047004124169281085 | validation loss: 0.004921647453848542
Epoch: 245, trainingloss: 0.004536421665378094 | validation loss: 0.0048203720494047015
Epoch: 246, trainingloss: 0.0047280937677795865 | validation loss: 0.005003897579281333
Epoch: 247, trainingloss: 0.004439108886775597 | validation loss: 0.004747597787929545
Epoch: 248, trainingloss: 0.004532655706795177 | validation loss: 0.004781933186783324
Epoch: 249, trainingloss: 0.004705746701859805 | validation loss: 0.005003704964168392
Epoch: 250, trainingloss: 0.004880269059145687 | validation loss: 0.005149179805173781
Epoch: 251, trainingloss: 0.004597491683135721 | validation loss: 0.004848086051692626
Epoch: 252, trainingloss: 0.00452501838562141 | validation loss: 0.004802781907990187
Epoch: 253, trainingloss: 0.005265760397357785 | validation loss: 0.0055478026814801485
Epoch: 254, trainingloss: 0.004454694927508279 | validation loss: 0.004691093339220114
Epoch: 255, trainingloss: 0.004302435281080654 | validation loss: 0.004607536206948567
Epoch: 256, trainingloss: 0.0048308224171135635 | validation loss: 0.005101861750717342
Epoch: 257, trainingloss: 0.00472588388271499 | validation loss: 0.004980486054003059
Epoch: 258, trainingloss: 0.004783296036868916 | validation loss: 0.005063830562522994
Epoch: 259, trainingloss: 0.0046243891109409045 | validation loss: 0.004869016674338302
Epoch: 260, trainingloss: 0.004287171253138962 | validation loss: 0.00460161092843579
Epoch: 261, trainingloss: 0.004898293262165281 | validation loss: 0.005139538379080969
Epoch: 262, trainingloss: 0.004402615116423077 | validation loss: 0.004731341317462659
Epoch: 263, trainingloss: 0.0047240214654558615 | validation loss: 0.0049880796138433384
Epoch: 264, trainingloss: 0.004788610144091427 | validation loss: 0.005071069810068778
Epoch: 265, trainingloss: 0.004376850938831479 | validation loss: 0.0046289453583498626
Epoch: 266, trainingloss: 0.004568157696508258 | validation loss: 0.004847545496416179
Epoch: 267, trainingloss: 0.005365029699203361 | validation loss: 0.00558209486391267
Epoch: 268, trainingloss: 0.004667427587029109 | validation loss: 0.004949716147638452
Epoch: 269, trainingloss: 0.004650087413285133 | validation loss: 0.004905051121456049
Epoch: 270, trainingloss: 0.004700698620839624 | validation loss: 0.004963174658784269
Epoch: 271, trainingloss: 0.004806926428243363 | validation loss: 0.005062910600623897
Epoch: 272, trainingloss: 0.004276796055673725 | validation loss: 0.004575514731997174
Epoch: 273, trainingloss: 0.004362222760658058 | validation loss: 0.004635483502922506
Epoch: 274, trainingloss: 0.004890390108248147 | validation loss: 0.005128637526192394
Epoch: 275, trainingloss: 0.004504523282873001 | validation loss: 0.00482312077479751
Epoch: 276, trainingloss: 0.004960198948836896 | validation loss: 0.005244044568070751
Epoch: 277, trainingloss: 0.0041412960320781995 | validation loss: 0.0044386901933056435
Epoch: 278, trainingloss: 0.003869824140259695 | validation loss: 0.004171697932096648
Epoch: 279, trainingloss: 0.0053488741350608765 | validation loss: 0.00555990748161136
Epoch: 280, trainingloss: 0.0049255433427213245 | validation loss: 0.005174832556856801
Epoch: 281, trainingloss: 0.004520986642785734 | validation loss: 0.0048189379275288624
Epoch: 282, trainingloss: 0.004509503152526846 | validation loss: 0.004764980375169897
Epoch: 283, trainingloss: 0.004351846565862618 | validation loss: 0.004618263320805235
Epoch: 284, trainingloss: 0.004955815098769963 | validation loss: 0.0051852734835293205
Epoch: 285, trainingloss: 0.004708854162161518 | validation loss: 0.004975230342694355
Epoch: 286, trainingloss: 0.004649230792097795 | validation loss: 0.004955671047542383
Epoch: 287, trainingloss: 0.004404700870271194 | validation loss: 0.004668880207745548
Epoch: 288, trainingloss: 0.004172265835066742 | validation loss: 0.004488868227746998
Epoch: 289, trainingloss: 0.005114182516934198 | validation loss: 0.005344566569606531
Epoch: 290, trainingloss: 0.003940217745268447 | validation loss: 0.00424473997296558
Epoch: 291, trainingloss: 0.004173981506253395 | validation loss: 0.004523177123746101
Epoch: 292, trainingloss: 0.004306869184674251 | validation loss: 0.004602600888457496
Epoch: 293, trainingloss: 0.003938667467077423 | validation loss: 0.004287540097187404
Epoch: 294, trainingloss: 0.0043795770708164395 | validation loss: 0.0046300153278298894
Epoch: 295, trainingloss: 0.004473427673004191 | validation loss: 0.004793946105903769
Epoch: 296, trainingloss: 0.004571785754778737 | validation loss: 0.004866438138320144
Epoch: 297, trainingloss: 0.00431538750189322 | validation loss: 0.004618151397946725
Epoch: 298, trainingloss: 0.004447484720411973 | validation loss: 0.00472970266402052
Epoch: 299, trainingloss: 0.004401032278710862 | validation loss: 0.004662351478632165
Epoch: 300, trainingloss: 0.00419012828661264 | validation loss: 0.004524931792931873
Epoch: 301, trainingloss: 0.004708183045427944 | validation loss: 0.004992403696937148
Epoch: 302, trainingloss: 0.004437873780178459 | validation loss: 0.004721530000231101
Epoch: 303, trainingloss: 0.004429796453994828 | validation loss: 0.0046859312479038675
Epoch: 304, trainingloss: 0.005866856778075772 | validation loss: 0.006097317508102695
Epoch: 305, trainingloss: 0.004594355032656193 | validation loss: 0.004879875849288399
Epoch: 306, trainingloss: 0.005298007014213294 | validation loss: 0.005534689115079129
Epoch: 307, trainingloss: 0.004874620849658011 | validation loss: 0.005164133729450148
Epoch: 308, trainingloss: 0.004452204817623561 | validation loss: 0.004715728835925084
Epoch: 309, trainingloss: 0.004183141912020837 | validation loss: 0.004541367596026427
Epoch: 310, trainingloss: 0.004469635732905859 | validation loss: 0.0047854897036001594
Epoch: 311, trainingloss: 0.004096140497003223 | validation loss: 0.004394503068009706
Epoch: 312, trainingloss: 0.004782223962744988 | validation loss: 0.005042001129136293
Epoch: 313, trainingloss: 0.004582951412496945 | validation loss: 0.004862221842769952
Epoch: 314, trainingloss: 0.004574644334528843 | validation loss: 0.00485069908918728
Epoch: 315, trainingloss: 0.004781215551813886 | validation loss: 0.005003227416535705
Epoch: 316, trainingloss: 0.004729313707854601 | validation loss: 0.004992211419394898
Epoch: 317, trainingloss: 0.004473683179749026 | validation loss: 0.004743079325713163
Epoch: 318, trainingloss: 0.0046903274523641516 | validation loss: 0.004951336558190013
Epoch: 319, trainingloss: 0.00429667427119303 | validation loss: 0.004582985241792876
Epoch: 320, trainingloss: 0.004279941724196044 | validation loss: 0.004597744804470303
Epoch: 321, trainingloss: 0.004831659252671862 | validation loss: 0.00507154414080118
Epoch: 322, trainingloss: 0.004200321294680017 | validation loss: 0.0044807750696643275
Epoch: 323, trainingloss: 0.004408800237226751 | validation loss: 0.004723949010337623
Epoch: 324, trainingloss: 0.004558814189844418 | validation loss: 0.004856552269423215
Epoch: 325, trainingloss: 0.004355027272456063 | validation loss: 0.0046529492050423485
Epoch: 326, trainingloss: 0.00512823260413103 | validation loss: 0.0053839624193632255
Epoch: 327, trainingloss: 0.004499064910365155 | validation loss: 0.004821490392792034
Epoch: 328, trainingloss: 0.0046436177296505085 | validation loss: 0.004922670505130162
Epoch: 329, trainingloss: 0.004356668543013992 | validation loss: 0.004644825909780792
Epoch: 330, trainingloss: 0.004902231811953565 | validation loss: 0.005163613294432568
Epoch: 331, trainingloss: 0.004879781948094009 | validation loss: 0.005123869752327265
Epoch: 332, trainingloss: 0.004057414700049882 | validation loss: 0.00438145635581489
Epoch: 333, trainingloss: 0.00464661748890282 | validation loss: 0.00494190131853734
Epoch: 334, trainingloss: 0.004614336491430632 | validation loss: 0.00489256861888132
Epoch: 335, trainingloss: 0.004899701556716498 | validation loss: 0.005132571234796073
Epoch: 336, trainingloss: 0.004701869733539028 | validation loss: 0.004987260296779855
Epoch: 337, trainingloss: 0.004240219967416172 | validation loss: 0.004527101863801808
Epoch: 338, trainingloss: 0.00419442742305543 | validation loss: 0.004504330204309233
Epoch: 339, trainingloss: 0.00401028094347769 | validation loss: 0.004351126177663751
Epoch: 340, trainingloss: 0.004698778093887425 | validation loss: 0.005003913810568766
Epoch: 341, trainingloss: 0.0042149145024460806 | validation loss: 0.004496794325232942
Epoch: 342, trainingloss: 0.00439836191131726 | validation loss: 0.004718536857653144
Epoch: 343, trainingloss: 0.004577425198226546 | validation loss: 0.0048651119435908895
Epoch: 344, trainingloss: 0.0050645100280370375 | validation loss: 0.0052723537478589185
Epoch: 345, trainingloss: 0.005112026866576429 | validation loss: 0.005340384911075773
Epoch: 346, trainingloss: 0.004422287567539849 | validation loss: 0.004722591615809793
Epoch: 347, trainingloss: 0.004817682696874173 | validation loss: 0.005075560678378522
Epoch: 348, trainingloss: 0.004242161936820928 | validation loss: 0.004538375039575379
Epoch: 349, trainingloss: 0.004702603740185014 | validation loss: 0.004975763015571903
Epoch: 350, trainingloss: 0.0043167729624786705 | validation loss: 0.0046006423816745
Epoch: 351, trainingloss: 0.004027747291544472 | validation loss: 0.004363880976814172
Epoch: 352, trainingloss: 0.004180548643831783 | validation loss: 0.004456967703554569
Epoch: 353, trainingloss: 0.004098155834344541 | validation loss: 0.004431780887674758
Epoch: 354, trainingloss: 0.004045987095620144 | validation loss: 0.004338479814700676
Epoch: 355, trainingloss: 0.004070221979243793 | validation loss: 0.00433956355445686
Epoch: 356, trainingloss: 0.0046949034624263475 | validation loss: 0.004996589622977155
Epoch: 357, trainingloss: 0.004688736853019941 | validation loss: 0.0049731236688555685
Epoch: 358, trainingloss: 0.004603451428529249 | validation loss: 0.004900098401209704
Epoch: 359, trainingloss: 0.00496644243855342 | validation loss: 0.00518534716892198
Epoch: 360, trainingloss: 0.004478003708490468 | validation loss: 0.004797781246178512
Epoch: 361, trainingloss: 0.004318874641108927 | validation loss: 0.0046390880336114005
Epoch: 362, trainingloss: 0.004498186370377708 | validation loss: 0.004745207944729809
Epoch: 363, trainingloss: 0.004472163926629409 | validation loss: 0.0047157686869087456
Epoch: 364, trainingloss: 0.004284601867587314 | validation loss: 0.004560745859003993
Epoch: 365, trainingloss: 0.004419092387947673 | validation loss: 0.004726005700738697
Epoch: 366, trainingloss: 0.003979953367894038 | validation loss: 0.004272279881721316
Epoch: 367, trainingloss: 0.004234227961437366 | validation loss: 0.0045008599255040495
Epoch: 368, trainingloss: 0.004073927086680491 | validation loss: 0.004401381504364086
Epoch: 369, trainingloss: 0.003953635133331304 | validation loss: 0.004271474261207811
Epoch: 370, trainingloss: 0.004130363236355374 | validation loss: 0.004435582790137241
Epoch: 371, trainingloss: 0.004113861605380035 | validation loss: 0.004430800061503634
Epoch: 372, trainingloss: 0.004550213030722943 | validation loss: 0.0048129017506164115
Epoch: 373, trainingloss: 0.004864655948866261 | validation loss: 0.00510378095907968
Epoch: 374, trainingloss: 0.004924133457314224 | validation loss: 0.005139247618122145
Epoch: 375, trainingloss: 0.005007391032655345 | validation loss: 0.005207620037478854
Epoch: 376, trainingloss: 0.004617702354770082 | validation loss: 0.004885158859758022
Epoch: 377, trainingloss: 0.0041961103771895065 | validation loss: 0.004514807869973065
Epoch: 378, trainingloss: 0.004796286987948048 | validation loss: 0.00504715415803407
Epoch: 379, trainingloss: 0.004140644050905714 | validation loss: 0.004422608623491867
Epoch: 380, trainingloss: 0.004290323054738258 | validation loss: 0.0045901284970319145
Epoch: 381, trainingloss: 0.0043932428636418676 | validation loss: 0.004685518826428523
Epoch: 382, trainingloss: 0.003955422221951166 | validation loss: 0.00425577058351724
Epoch: 383, trainingloss: 0.004038566245441151 | validation loss: 0.004326177961418572
Epoch: 384, trainingloss: 0.004361971823114635 | validation loss: 0.004653782552919812
Epoch: 385, trainingloss: 0.00457797297148024 | validation loss: 0.004847302927020782
Epoch: 386, trainingloss: 0.004293473288504563 | validation loss: 0.004587036500023681
Epoch: 387, trainingloss: 0.0045389760435897075 | validation loss: 0.004803366041587953
Epoch: 388, trainingloss: 0.004563151761184109 | validation loss: 0.004868446071310031
Epoch: 389, trainingloss: 0.004014861715724441 | validation loss: 0.004338362903714768
Epoch: 390, trainingloss: 0.004273070594777548 | validation loss: 0.004605862667483384
Epoch: 391, trainingloss: 0.004833466469896602 | validation loss: 0.005090189196957708
Epoch: 392, trainingloss: 0.0049209216328777085 | validation loss: 0.00517817199555406
Epoch: 393, trainingloss: 0.004327190487311882 | validation loss: 0.004609241307531353
Epoch: 394, trainingloss: 0.004290032807077377 | validation loss: 0.004611019348011624
Epoch: 395, trainingloss: 0.0042875344359400765 | validation loss: 0.004572435607545874
Epoch: 396, trainingloss: 0.004457024598294376 | validation loss: 0.004753545984784437
Epoch: 397, trainingloss: 0.004315984745884909 | validation loss: 0.004618030007011518
Epoch: 398, trainingloss: 0.0040267565102389095 | validation loss: 0.00433286570252827
Epoch: 399, trainingloss: 0.005006032742651461 | validation loss: 0.0052691207031640395
Epoch: 400, trainingloss: 0.00462298209090034 | validation loss: 0.004926403784033799
Epoch: 401, trainingloss: 0.004139915876655295 | validation loss: 0.004451284421311601
Epoch: 402, trainingloss: 0.004848670478712569 | validation loss: 0.0051083699571684345
Epoch: 403, trainingloss: 0.004784802389310105 | validation loss: 0.005066827683987785
Epoch: 404, trainingloss: 0.004571472730557454 | validation loss: 0.004863561628818249
Epoch: 405, trainingloss: 0.004295297401337581 | validation loss: 0.004629957638455774
Epoch: 406, trainingloss: 0.004671204034285195 | validation loss: 0.004899205810948193
Epoch: 407, trainingloss: 0.004620598014007843 | validation loss: 0.004886892518958519
Epoch: 408, trainingloss: 0.004362403073860726 | validation loss: 0.0046467536064345
Epoch: 409, trainingloss: 0.004344557748048604 | validation loss: 0.004659189507744868
Epoch: 410, trainingloss: 0.004249591239242586 | validation loss: 0.0045524135219716325
Epoch: 411, trainingloss: 0.004154264437713282 | validation loss: 0.004438853451789435
Epoch: 412, trainingloss: 0.004683353480837019 | validation loss: 0.004961892913689697
Epoch: 413, trainingloss: 0.0042280519010415366 | validation loss: 0.004523558779264714
Epoch: 414, trainingloss: 0.00428978850590245 | validation loss: 0.004561096417417309
Epoch: 415, trainingloss: 0.003972399917932782 | validation loss: 0.004315853510730193
Epoch: 416, trainingloss: 0.004326950022463735 | validation loss: 0.004646785827179681
Epoch: 417, trainingloss: 0.005207998456515173 | validation loss: 0.0054453915260525175
Epoch: 418, trainingloss: 0.004335150949958488 | validation loss: 0.004622617673831975
Epoch: 419, trainingloss: 0.004295774542317464 | validation loss: 0.0045562083343261735
Epoch: 420, trainingloss: 0.004242456592683531 | validation loss: 0.004558750437006377
Epoch: 421, trainingloss: 0.004377444791038232 | validation loss: 0.004661675993483661
Epoch: 422, trainingloss: 0.004433047576253118 | validation loss: 0.004771623724612945
Epoch: 423, trainingloss: 0.003866517656750722 | validation loss: 0.004155884967956624
Epoch: 424, trainingloss: 0.00407527928271092 | validation loss: 0.004409476726586005
Epoch: 425, trainingloss: 0.0038240395327648557 | validation loss: 0.004162380062001097
Epoch: 426, trainingloss: 0.003908144099973347 | validation loss: 0.004246294674308488
Epoch: 427, trainingloss: 0.003983229954314968 | validation loss: 0.00433746418566152
Epoch: 428, trainingloss: 0.004265858124854858 | validation loss: 0.004529026245247356
Epoch: 429, trainingloss: 0.004429552073511767 | validation loss: 0.004697709821079183
Epoch: 430, trainingloss: 0.004409007613174424 | validation loss: 0.004704572430920677
Epoch: 431, trainingloss: 0.003974827984713515 | validation loss: 0.004241064619430615
Epoch: 432, trainingloss: 0.004688186481792713 | validation loss: 0.004987303653914461
Epoch: 433, trainingloss: 0.003824434482121312 | validation loss: 0.004151887338243996
Epoch: 434, trainingloss: 0.003906342626702481 | validation loss: 0.004218396588087086
Epoch: 435, trainingloss: 0.004345090819322121 | validation loss: 0.004643303778544732
Epoch: 436, trainingloss: 0.004687357501563999 | validation loss: 0.005009758680442668
Epoch: 437, trainingloss: 0.0038999246709959267 | validation loss: 0.004229410957431846
Epoch: 438, trainingloss: 0.0041705068304537275 | validation loss: 0.004448395842013277
Epoch: 439, trainingloss: 0.004093427372637024 | validation loss: 0.004380075420462075
Epoch: 440, trainingloss: 0.0037731219897698762 | validation loss: 0.004085444852001575
Epoch: 441, trainingloss: 0.0040471875505911775 | validation loss: 0.004336821277805043
Epoch: 442, trainingloss: 0.004521111143712906 | validation loss: 0.004828792443544414
Epoch: 443, trainingloss: 0.004167604233382397 | validation loss: 0.00441928154073367
Epoch: 444, trainingloss: 0.004128193240609863 | validation loss: 0.004436382030446248
Epoch: 445, trainingloss: 0.004115978667675838 | validation loss: 0.004437306168423712
Epoch: 446, trainingloss: 0.004208895887963603 | validation loss: 0.004497016887727536
Epoch: 447, trainingloss: 0.003759796414912625 | validation loss: 0.004074546294630215
Epoch: 448, trainingloss: 0.00438921806502966 | validation loss: 0.004677997403069689
Epoch: 449, trainingloss: 0.004288154802166931 | validation loss: 0.004596579988970567
Epoch: 450, trainingloss: 0.004011401855182596 | validation loss: 0.004326353050390152
Epoch: 451, trainingloss: 0.0036104310677798936 | validation loss: 0.003926990720820613
Epoch: 452, trainingloss: 0.0038474251390983112 | validation loss: 0.004166484253816262
Epoch: 453, trainingloss: 0.003907120457134731 | validation loss: 0.004199415552968521
Epoch: 454, trainingloss: 0.0041460732200178305 | validation loss: 0.004441973026827111
Epoch: 455, trainingloss: 0.00441178180916355 | validation loss: 0.004661714503635012
Epoch: 456, trainingloss: 0.004607256172981579 | validation loss: 0.004844848227457877
Epoch: 457, trainingloss: 0.00416603000315237 | validation loss: 0.004462848139700291
Epoch: 458, trainingloss: 0.0038546557987858437 | validation loss: 0.004162679492254511
Epoch: 459, trainingloss: 0.004194797461316426 | validation loss: 0.004467778842970166
Epoch: 460, trainingloss: 0.003856897742759041 | validation loss: 0.004146777970393019
Epoch: 461, trainingloss: 0.0046952472005212555 | validation loss: 0.00493599098318131
Epoch: 462, trainingloss: 0.004213899967233662 | validation loss: 0.004506133272468621
Epoch: 463, trainingloss: 0.0044948761024317715 | validation loss: 0.00477890899661906
Epoch: 464, trainingloss: 0.004232093392961527 | validation loss: 0.004500524734042329
Epoch: 465, trainingloss: 0.00412950224824492 | validation loss: 0.004398637294034669
Epoch: 466, trainingloss: 0.00396394307763059 | validation loss: 0.004277231678960486
Epoch: 467, trainingloss: 0.003967407220663784 | validation loss: 0.004275888267731655
Epoch: 468, trainingloss: 0.00397618121549525 | validation loss: 0.004279437538116535
Epoch: 469, trainingloss: 0.0040760699384321765 | validation loss: 0.004423252267001965
Epoch: 470, trainingloss: 0.004678645282330439 | validation loss: 0.004959589937794093
Epoch: 471, trainingloss: 0.003987107951298845 | validation loss: 0.004310018631995326
Epoch: 472, trainingloss: 0.0038583571821403885 | validation loss: 0.004216620291973263
Epoch: 473, trainingloss: 0.004211365201239113 | validation loss: 0.00451914162039673
Epoch: 474, trainingloss: 0.00369778748041634 | validation loss: 0.004006018700704684
Epoch: 475, trainingloss: 0.004031441823030472 | validation loss: 0.004343709318111369
Epoch: 476, trainingloss: 0.004396645460728293 | validation loss: 0.004658796800017301
Epoch: 477, trainingloss: 0.004223239276852864 | validation loss: 0.004508315291278912
Epoch: 478, trainingloss: 0.004326406043742195 | validation loss: 0.004592911277814518
Epoch: 479, trainingloss: 0.004375228457148106 | validation loss: 0.0046799045991934305
Epoch: 480, trainingloss: 0.004125083344997996 | validation loss: 0.0044401722580171415
Epoch: 481, trainingloss: 0.004447601293907532 | validation loss: 0.0047286399145783295
Epoch: 482, trainingloss: 0.004454631587922678 | validation loss: 0.004733037155577115
Epoch: 483, trainingloss: 0.004834039027013303 | validation loss: 0.005096758335939833
Epoch: 484, trainingloss: 0.004063890521005335 | validation loss: 0.0043555153373300475
Epoch: 485, trainingloss: 0.004315982389614044 | validation loss: 0.004631205216495145
Epoch: 486, trainingloss: 0.003884705087655793 | validation loss: 0.004206165390656409
Epoch: 487, trainingloss: 0.004327637069832787 | validation loss: 0.004632322740119297
Epoch: 488, trainingloss: 0.004375353868506328 | validation loss: 0.004628304652647626
Epoch: 489, trainingloss: 0.003912463207689584 | validation loss: 0.004238763335952529
Epoch: 490, trainingloss: 0.004140433600271714 | validation loss: 0.004444253067796528
Epoch: 491, trainingloss: 0.004464795208893921 | validation loss: 0.004783956204798874
Epoch: 492, trainingloss: 0.004383079866627555 | validation loss: 0.004624169607124117
Epoch: 493, trainingloss: 0.0042942034545855315 | validation loss: 0.0046208392030040015
Epoch: 494, trainingloss: 0.00408526694537814 | validation loss: 0.004368100959190248
Epoch: 495, trainingloss: 0.004222693029678751 | validation loss: 0.004502202856224473
Epoch: 496, trainingloss: 0.004136945794771897 | validation loss: 0.0044598257105009555
Epoch: 497, trainingloss: 0.0036785260241487252 | validation loss: 0.004042677907678302
Epoch: 498, trainingloss: 0.0037905951976975353 | validation loss: 0.004144740513228613
Epoch: 499, trainingloss: 0.0038799298427348405 | validation loss: 0.004206924532326771
Epoch: 500, trainingloss: 0.004298332977190793 | validation loss: 0.004585387766138709
Epoch: 501, trainingloss: 0.004680325185007206 | validation loss: 0.004936418994469448
Epoch: 502, trainingloss: 0.0037434617424826414 | validation loss: 0.004054510886024684
Epoch: 503, trainingloss: 0.004002297425028729 | validation loss: 0.004316133107806647
Epoch: 504, trainingloss: 0.0043331148904930455 | validation loss: 0.004635874974591406
Epoch: 505, trainingloss: 0.004020794524043009 | validation loss: 0.004372856185525923
Epoch: 506, trainingloss: 0.004701941266907099 | validation loss: 0.004972702611352388
Epoch: 507, trainingloss: 0.004220161122808759 | validation loss: 0.004570536973672422
Epoch: 508, trainingloss: 0.003919029702028279 | validation loss: 0.004219536712622888
Epoch: 509, trainingloss: 0.004139879929536289 | validation loss: 0.004461523956600867
Epoch: 510, trainingloss: 0.0038931258587786765 | validation loss: 0.004206833313410168
Epoch: 511, trainingloss: 0.003974679677149416 | validation loss: 0.0043100572835495544
Epoch: 512, trainingloss: 0.003787103591938464 | validation loss: 0.004124506024367216
Epoch: 513, trainingloss: 0.004156909845225068 | validation loss: 0.004468350400219953
Epoch: 514, trainingloss: 0.004395299199311263 | validation loss: 0.004656739698030937
Epoch: 515, trainingloss: 0.00406741369476703 | validation loss: 0.004357311153214998
Epoch: 516, trainingloss: 0.004142034147671002 | validation loss: 0.004426750358545511
Epoch: 517, trainingloss: 0.004152642916383306 | validation loss: 0.004451365872617889
Epoch: 518, trainingloss: 0.003655996052611721 | validation loss: 0.003959270179835915
Epoch: 519, trainingloss: 0.003994821918114448 | validation loss: 0.004342732332854053
Epoch: 520, trainingloss: 0.004423859222446481 | validation loss: 0.004709389424838035
Epoch: 521, trainingloss: 0.0038918047689997662 | validation loss: 0.004190151967655014
Epoch: 522, trainingloss: 0.00429964179404011 | validation loss: 0.004554067844565192
Epoch: 523, trainingloss: 0.003943508521441147 | validation loss: 0.004264344972296952
Epoch: 524, trainingloss: 0.003856021163777143 | validation loss: 0.004165025493686324
Epoch: 525, trainingloss: 0.004584395846960159 | validation loss: 0.0048777072437746405
Epoch: 526, trainingloss: 0.004184201856714378 | validation loss: 0.004502629234492176
Epoch: 527, trainingloss: 0.004229499688432673 | validation loss: 0.0045351381825972335
Epoch: 528, trainingloss: 0.003822121137653934 | validation loss: 0.0041224918006712375
Epoch: 529, trainingloss: 0.004599946088853867 | validation loss: 0.004858673482920142
Epoch: 530, trainingloss: 0.004005964562019257 | validation loss: 0.004327911788831637
Epoch: 531, trainingloss: 0.003920176962117956 | validation loss: 0.004231456414042632
Epoch: 532, trainingloss: 0.0042789633455401245 | validation loss: 0.004596577283545973
Epoch: 533, trainingloss: 0.004376616054728652 | validation loss: 0.004602452962669207
Epoch: 534, trainingloss: 0.004282500382229854 | validation loss: 0.004530852257198611
Epoch: 535, trainingloss: 0.00412294136442976 | validation loss: 0.004412699129972952
Epoch: 536, trainingloss: 0.004106677772825762 | validation loss: 0.004383455999352114
Epoch: 537, trainingloss: 0.004091186777690203 | validation loss: 0.004403548289197241
Epoch: 538, trainingloss: 0.003665726307955908 | validation loss: 0.003966717384829879
Epoch: 539, trainingloss: 0.004126579564896489 | validation loss: 0.004371245509876934
Epoch: 540, trainingloss: 0.0040925306667083505 | validation loss: 0.0043921226792212435
Epoch: 541, trainingloss: 0.0039281748698239295 | validation loss: 0.004247809652063544
Epoch: 542, trainingloss: 0.0037555502721491143 | validation loss: 0.00406840355130275
Epoch: 543, trainingloss: 0.0039471162693729 | validation loss: 0.004261018794026759
Epoch: 544, trainingloss: 0.003728680302490193 | validation loss: 0.0040430168753443066
Epoch: 545, trainingloss: 0.004486706130755897 | validation loss: 0.004756349849798791
Epoch: 546, trainingloss: 0.0037445320485994357 | validation loss: 0.0040951632322259015
Epoch: 547, trainingloss: 0.004188154453936574 | validation loss: 0.0044879034118921555
Epoch: 548, trainingloss: 0.003812925646792779 | validation loss: 0.004085542256311423
Epoch: 549, trainingloss: 0.003964677748108799 | validation loss: 0.004270570172813747
Epoch: 550, trainingloss: 0.004118462197666427 | validation loss: 0.004387340858155882
Epoch: 551, trainingloss: 0.004686596423395878 | validation loss: 0.00492343286349746
Epoch: 552, trainingloss: 0.004089329611703268 | validation loss: 0.004409899918319698
Epoch: 553, trainingloss: 0.003498386371406697 | validation loss: 0.003843217074949213
Epoch: 554, trainingloss: 0.004141939042592566 | validation loss: 0.004450078006952153
Epoch: 555, trainingloss: 0.0037202086272583043 | validation loss: 0.004034726278140782
Epoch: 556, trainingloss: 0.0036138995514425694 | validation loss: 0.00392578202881096
Epoch: 557, trainingloss: 0.0038463798392574093 | validation loss: 0.004158970753149922
Epoch: 558, trainingloss: 0.0036660735260425348 | validation loss: 0.003992753026934502
Epoch: 559, trainingloss: 0.003994673133330865 | validation loss: 0.0043209293735910325
Epoch: 560, trainingloss: 0.0036592464677541714 | validation loss: 0.003995728499218196
Epoch: 561, trainingloss: 0.0044725487784736135 | validation loss: 0.004791747687434066
Epoch: 562, trainingloss: 0.0038266851581073803 | validation loss: 0.00415689389805191
Epoch: 563, trainingloss: 0.003964220271606914 | validation loss: 0.004323725517811188
Epoch: 564, trainingloss: 0.004129016849163197 | validation loss: 0.004440310479801941
Epoch: 565, trainingloss: 0.0037535576032783438 | validation loss: 0.004042404362158873
Epoch: 566, trainingloss: 0.003826483183296564 | validation loss: 0.004152778449891925
Epoch: 567, trainingloss: 0.004291326591541026 | validation loss: 0.004617101849458645
Epoch: 568, trainingloss: 0.0038096980512321325 | validation loss: 0.004135841300681293
Epoch: 569, trainingloss: 0.003679183387430292 | validation loss: 0.004015231775317264
Epoch: 570, trainingloss: 0.003934997079948404 | validation loss: 0.004214301203940448
Epoch: 571, trainingloss: 0.003815155008275056 | validation loss: 0.0041608908784487525
Epoch: 572, trainingloss: 0.0035710231926543395 | validation loss: 0.0038995081293633264
Epoch: 573, trainingloss: 0.003609511260091391 | validation loss: 0.0039477063071217955
Epoch: 574, trainingloss: 0.003930717123240777 | validation loss: 0.004187181015475647
Epoch: 575, trainingloss: 0.004449999226780416 | validation loss: 0.004698168228831106
Epoch: 576, trainingloss: 0.0037969423441146623 | validation loss: 0.004100538661826084
Epoch: 577, trainingloss: 0.003916317428849056 | validation loss: 0.004201130986532977
Epoch: 578, trainingloss: 0.004046886679948119 | validation loss: 0.004363646356858181
Epoch: 579, trainingloss: 0.0037675401611884495 | validation loss: 0.004110783091766751
Epoch: 580, trainingloss: 0.0036532124592505892 | validation loss: 0.003987754865338466
Epoch: 581, trainingloss: 0.004030357788827482 | validation loss: 0.004314138844139018
Epoch: 582, trainingloss: 0.0038501086113978617 | validation loss: 0.004139787327111106
Epoch: 583, trainingloss: 0.003789385138768154 | validation loss: 0.004092183977726379
Epoch: 584, trainingloss: 0.004067308696569028 | validation loss: 0.004338892019724261
Epoch: 585, trainingloss: 0.003760568201644938 | validation loss: 0.0040935118696981245
Epoch: 586, trainingloss: 0.004312091549091938 | validation loss: 0.004608329143792146
Epoch: 587, trainingloss: 0.003973395536962973 | validation loss: 0.004278105539556086
Epoch: 588, trainingloss: 0.0038200195552533516 | validation loss: 0.004091227818883988
Epoch: 589, trainingloss: 0.0036735749714671704 | validation loss: 0.003975741699121549
Epoch: 590, trainingloss: 0.004433348923936027 | validation loss: 0.004699032968516779
Epoch: 591, trainingloss: 0.004158349030585546 | validation loss: 0.004439368973376743
Epoch: 592, trainingloss: 0.004378025687042199 | validation loss: 0.0046766072709341295
Epoch: 593, trainingloss: 0.004313875860206012 | validation loss: 0.004590805396052258
Epoch: 594, trainingloss: 0.003880740302001236 | validation loss: 0.004221020552723712
Epoch: 595, trainingloss: 0.003934735659477728 | validation loss: 0.004278914401541655
Epoch: 596, trainingloss: 0.004078251531317013 | validation loss: 0.004383024567548799
Epoch: 597, trainingloss: 0.0036860214884877423 | validation loss: 0.0040402888338971765
Epoch: 598, trainingloss: 0.004097940308003304 | validation loss: 0.004368305462259015
Epoch: 599, trainingloss: 0.004130511033192491 | validation loss: 0.004446837599529064
Epoch: 600, trainingloss: 0.00405254477348195 | validation loss: 0.004326433039956366
Epoch: 601, trainingloss: 0.003722342586220899 | validation loss: 0.00403064023401466
Epoch: 602, trainingloss: 0.003988794450298438 | validation loss: 0.004317374323751279
Epoch: 603, trainingloss: 0.003679210174540949 | validation loss: 0.003987843681120289
Epoch: 604, trainingloss: 0.0036458010074866963 | validation loss: 0.003978096973047059
Epoch: 605, trainingloss: 0.00406147117593897 | validation loss: 0.0043787500987855985
Epoch: 606, trainingloss: 0.004066000838867264 | validation loss: 0.004329369231098834
Epoch: 607, trainingloss: 0.004136766522268886 | validation loss: 0.00441186356264316
Epoch: 608, trainingloss: 0.004331994980678187 | validation loss: 0.004610337751980484
Epoch: 609, trainingloss: 0.0038332124549812613 | validation loss: 0.004155631657150156
Epoch: 610, trainingloss: 0.003983932151199781 | validation loss: 0.004246982197972606
Epoch: 611, trainingloss: 0.003798669185858552 | validation loss: 0.004132320845041482
Epoch: 612, trainingloss: 0.004278749159576944 | validation loss: 0.004547870955334372
Epoch: 613, trainingloss: 0.0035210434631918162 | validation loss: 0.0038457988923982457
Epoch: 614, trainingloss: 0.0039605381368940954 | validation loss: 0.004209097828861363
Epoch: 615, trainingloss: 0.004228635233513936 | validation loss: 0.00451493827102737
Epoch: 616, trainingloss: 0.003974516277124586 | validation loss: 0.004301848040697722
Epoch: 617, trainingloss: 0.0036235619115639935 | validation loss: 0.003951227283465447
Epoch: 618, trainingloss: 0.004013665435709864 | validation loss: 0.004313305267704683
Epoch: 619, trainingloss: 0.003980496760162319 | validation loss: 0.004269848486577799
Epoch: 620, trainingloss: 0.003618157941659267 | validation loss: 0.003960655299082912
Epoch: 621, trainingloss: 0.0037570091309462113 | validation loss: 0.004077306624181278
Epoch: 622, trainingloss: 0.003997096503403623 | validation loss: 0.004319824043604418
Epoch: 623, trainingloss: 0.004058600243849741 | validation loss: 0.004369542161733143
Epoch: 624, trainingloss: 0.004011108188544903 | validation loss: 0.00424654459913439
Epoch: 625, trainingloss: 0.003827371518531894 | validation loss: 0.0041320857825578525
Epoch: 626, trainingloss: 0.003876331675426506 | validation loss: 0.004137183192996406
Epoch: 627, trainingloss: 0.0041868357081563815 | validation loss: 0.004471128319588834
Epoch: 628, trainingloss: 0.0036888898990321303 | validation loss: 0.003988330453356017
Epoch: 629, trainingloss: 0.003936424954035713 | validation loss: 0.004234002087258461
Epoch: 630, trainingloss: 0.003964663311726033 | validation loss: 0.00427631462696243
Epoch: 631, trainingloss: 0.0042175172462806205 | validation loss: 0.004493148070314247
Epoch: 632, trainingloss: 0.0035858055890381946 | validation loss: 0.0039148550363484755
Epoch: 633, trainingloss: 0.003642941582584844 | validation loss: 0.003928734129455274
Epoch: 634, trainingloss: 0.0038519440103330794 | validation loss: 0.004166500200858681
Epoch: 635, trainingloss: 0.0036271881869899152 | validation loss: 0.003933623284710091
Epoch: 636, trainingloss: 0.0035342033054648787 | validation loss: 0.0038613758851734617
Epoch: 637, trainingloss: 0.004002012121816485 | validation loss: 0.0042750191337863055
Epoch: 638, trainingloss: 0.003704113450416012 | validation loss: 0.0040236344925152845
Epoch: 639, trainingloss: 0.003831308352856762 | validation loss: 0.00410732376907152
Epoch: 640, trainingloss: 0.0038164080114371102 | validation loss: 0.00411465491885285
Epoch: 641, trainingloss: 0.004024858561941128 | validation loss: 0.004301271897109392
Epoch: 642, trainingloss: 0.00404567367907974 | validation loss: 0.004322337356810848
Epoch: 643, trainingloss: 0.0039023682103568346 | validation loss: 0.0041658534761385415
Epoch: 644, trainingloss: 0.0037018274531658408 | validation loss: 0.004023574387268302
Epoch: 645, trainingloss: 0.0037965840234839504 | validation loss: 0.0040808217573959525
Epoch: 646, trainingloss: 0.004180872962863035 | validation loss: 0.004472148975842862
Epoch: 647, trainingloss: 0.004106923145365717 | validation loss: 0.004387708436190833
Epoch: 648, trainingloss: 0.0035300087386743806 | validation loss: 0.0038679748514406677
Epoch: 649, trainingloss: 0.0036719133838105577 | validation loss: 0.0040179081208306594
Epoch: 650, trainingloss: 0.0038385039429375835 | validation loss: 0.004111626249224043
Epoch: 651, trainingloss: 0.003629934399699455 | validation loss: 0.003936792684686529
Epoch: 652, trainingloss: 0.00419892722104626 | validation loss: 0.004489678712567649
Epoch: 653, trainingloss: 0.0037057924872537186 | validation loss: 0.0039994486340969556
Epoch: 654, trainingloss: 0.00396871641311446 | validation loss: 0.004232699670681876
Epoch: 655, trainingloss: 0.003872196764806007 | validation loss: 0.004173143067108282
Epoch: 656, trainingloss: 0.0037760568422777227 | validation loss: 0.0040366093304161155
Epoch: 657, trainingloss: 0.0038235307653573095 | validation loss: 0.00413493243454465
Epoch: 658, trainingloss: 0.004181877802679314 | validation loss: 0.004430079076635586
Epoch: 659, trainingloss: 0.003638391695920452 | validation loss: 0.003944194637809888
Epoch: 660, trainingloss: 0.004029075465135493 | validation loss: 0.004289314986808471
Epoch: 661, trainingloss: 0.0037810937362994855 | validation loss: 0.004065090250171786
Epoch: 662, trainingloss: 0.0036507327879452575 | validation loss: 0.003953092203151295
Epoch: 663, trainingloss: 0.003945283096416743 | validation loss: 0.0042391317373862945
Epoch: 664, trainingloss: 0.0038915586602851293 | validation loss: 0.004196562526242984
Epoch: 665, trainingloss: 0.0040689016359808025 | validation loss: 0.004361995469583866
Epoch: 666, trainingloss: 0.003571088369357782 | validation loss: 0.0038856680412181475
Epoch: 667, trainingloss: 0.0038958875319542977 | validation loss: 0.004192319592834856
Epoch: 668, trainingloss: 0.0037813624403861424 | validation loss: 0.004101238576750227
Epoch: 669, trainingloss: 0.004213788385903014 | validation loss: 0.004492631091338184
Epoch: 670, trainingloss: 0.003933915060215443 | validation loss: 0.0042325335150335125
Epoch: 671, trainingloss: 0.0037076152174520417 | validation loss: 0.004005171374786701
Epoch: 672, trainingloss: 0.003797813295343004 | validation loss: 0.004127430369516443
Epoch: 673, trainingloss: 0.004212276050387581 | validation loss: 0.004463014333720374
Epoch: 674, trainingloss: 0.003809259020135165 | validation loss: 0.004113536531662214
Epoch: 675, trainingloss: 0.003645523090643681 | validation loss: 0.0039788727767610275
Epoch: 676, trainingloss: 0.004086562355626629 | validation loss: 0.004330609852389051
Epoch: 677, trainingloss: 0.0036719569151143004 | validation loss: 0.0039608539780407875
Epoch: 678, trainingloss: 0.004005230707859006 | validation loss: 0.004278930217949407
Epoch: 679, trainingloss: 0.003846687133381581 | validation loss: 0.004121510252302512
Epoch: 680, trainingloss: 0.004365996291472386 | validation loss: 0.004610656300914374
Epoch: 681, trainingloss: 0.00368430442556491 | validation loss: 0.004000191579062359
Epoch: 682, trainingloss: 0.0037691671674556382 | validation loss: 0.004073087819938654
Epoch: 683, trainingloss: 0.003660605390235687 | validation loss: 0.003981469419268323
Epoch: 684, trainingloss: 0.003410852241969423 | validation loss: 0.0037476457968745685
Epoch: 685, trainingloss: 0.0037528169358670795 | validation loss: 0.0040560190717713026
Epoch: 686, trainingloss: 0.003608513143573961 | validation loss: 0.003914068148456006
Epoch: 687, trainingloss: 0.004476936100842752 | validation loss: 0.004745462034469852
Epoch: 688, trainingloss: 0.0037695677109353142 | validation loss: 0.004086576166381195
Epoch: 689, trainingloss: 0.004081213712813249 | validation loss: 0.004361156852190357
Epoch: 690, trainingloss: 0.004129324853775823 | validation loss: 0.004427853692606386
Epoch: 691, trainingloss: 0.0036379681987045403 | validation loss: 0.003981861490904083
Epoch: 692, trainingloss: 0.004089491178396515 | validation loss: 0.004375015965012355
Epoch: 693, trainingloss: 0.0036911668563925915 | validation loss: 0.003981624005824122
Epoch: 694, trainingloss: 0.004123076277866974 | validation loss: 0.004425482303980975
Epoch: 695, trainingloss: 0.0037616136034653237 | validation loss: 0.004058428046725446
Epoch: 696, trainingloss: 0.0036397946031550285 | validation loss: 0.003945959140236223
Epoch: 697, trainingloss: 0.003726681744580336 | validation loss: 0.004023988916163689
Epoch: 698, trainingloss: 0.0037445837689567213 | validation loss: 0.004058917635935609
Epoch: 699, trainingloss: 0.0037309868036111736 | validation loss: 0.004057152239133006
Epoch: 700, trainingloss: 0.0036026789618633756 | validation loss: 0.0038937761588293085
Epoch: 701, trainingloss: 0.00417052513042906 | validation loss: 0.004455094764910618
Epoch: 702, trainingloss: 0.003948942709038496 | validation loss: 0.004234817621299317
Epoch: 703, trainingloss: 0.003691034249358763 | validation loss: 0.00399805269659511
Epoch: 704, trainingloss: 0.0036009756588971428 | validation loss: 0.0039071766975689514
Epoch: 705, trainingloss: 0.0035615610944406207 | validation loss: 0.003870558042946143
Epoch: 706, trainingloss: 0.003756677337281472 | validation loss: 0.004063407031742369
Epoch: 707, trainingloss: 0.004205047804929383 | validation loss: 0.004459479990637544
Epoch: 708, trainingloss: 0.004110948621518855 | validation loss: 0.004379151642541756
Epoch: 709, trainingloss: 0.0035765370459595034 | validation loss: 0.0038941754849571297
Epoch: 710, trainingloss: 0.0034475136988180266 | validation loss: 0.0037492255742406096
Epoch: 711, trainingloss: 0.003793822602369931 | validation loss: 0.004086227317808215
Epoch: 712, trainingloss: 0.003442437309970378 | validation loss: 0.003777829719389309
Epoch: 713, trainingloss: 0.003677203990013892 | validation loss: 0.003973667821476111
Epoch: 714, trainingloss: 0.004169415062880683 | validation loss: 0.004426788645437511
Epoch: 715, trainingloss: 0.00368928106182861 | validation loss: 0.00400703093588235
Epoch: 716, trainingloss: 0.0038262560617087836 | validation loss: 0.004134612881382779
Epoch: 717, trainingloss: 0.0038934261920257726 | validation loss: 0.004207284924937177
Epoch: 718, trainingloss: 0.0037276925223474608 | validation loss: 0.0040193271495938074
Epoch: 719, trainingloss: 0.0036893145482470883 | validation loss: 0.003992149281841696
Epoch: 720, trainingloss: 0.003802713770149435 | validation loss: 0.004133598350884293
Epoch: 721, trainingloss: 0.003624379028041516 | validation loss: 0.0039218063258243075
Epoch: 722, trainingloss: 0.00345014694462079 | validation loss: 0.003771983498554946
Epoch: 723, trainingloss: 0.003710203052108001 | validation loss: 0.003994006050562025
Epoch: 724, trainingloss: 0.004164319360391309 | validation loss: 0.004449025465394346
Epoch: 725, trainingloss: 0.003890925328737487 | validation loss: 0.00415987700604891
Epoch: 726, trainingloss: 0.004203182624166028 | validation loss: 0.004502446480761124
Epoch: 727, trainingloss: 0.003848143749374249 | validation loss: 0.004140525737928293
Epoch: 728, trainingloss: 0.0036063343243003232 | validation loss: 0.0038915965483708307
Epoch: 729, trainingloss: 0.00392985106456107 | validation loss: 0.00423969448732774
Epoch: 730, trainingloss: 0.004559837009413432 | validation loss: 0.004827050124608431
Epoch: 731, trainingloss: 0.003681655515439105 | validation loss: 0.004012860317858948
Epoch: 732, trainingloss: 0.0035950052757020485 | validation loss: 0.003900675834248377
Epoch: 733, trainingloss: 0.003511844701731053 | validation loss: 0.003852923119515939
Epoch: 734, trainingloss: 0.003961329829015253 | validation loss: 0.004260649871439458
Epoch: 735, trainingloss: 0.0038465693671628125 | validation loss: 0.004127359916352435
Epoch: 736, trainingloss: 0.003773219281286103 | validation loss: 0.004085315923413927
Epoch: 737, trainingloss: 0.003519164322513676 | validation loss: 0.003838978928055749
Epoch: 738, trainingloss: 0.0036526038600215647 | validation loss: 0.003982567537028928
Epoch: 739, trainingloss: 0.0044877777048607705 | validation loss: 0.004748831375781504
Epoch: 740, trainingloss: 0.004047098033991755 | validation loss: 0.004355726808788254
Epoch: 741, trainingloss: 0.0035381983458132415 | validation loss: 0.0038910473958132324
Epoch: 742, trainingloss: 0.003649021303575023 | validation loss: 0.003956884322665888
Epoch: 743, trainingloss: 0.0036384655677727993 | validation loss: 0.00394224496317639
Epoch: 744, trainingloss: 0.003908576841841904 | validation loss: 0.004221272277034622
Epoch: 745, trainingloss: 0.003593245245587134 | validation loss: 0.003891525205022555
Epoch: 746, trainingloss: 0.003765943848221703 | validation loss: 0.004120300275535915
Epoch: 747, trainingloss: 0.003922517259425281 | validation loss: 0.004246158903319945
Epoch: 748, trainingloss: 0.003765589928566388 | validation loss: 0.00406758533980409
Epoch: 749, trainingloss: 0.004054523407124993 | validation loss: 0.004337544015030351
Epoch: 750, trainingloss: 0.0037157175399625117 | validation loss: 0.004017894283985153
Epoch: 751, trainingloss: 0.0037834331547408418 | validation loss: 0.00406700764578062
Epoch: 752, trainingloss: 0.0034140892520192877 | validation loss: 0.0037360222925292034
Epoch: 753, trainingloss: 0.003554736172909003 | validation loss: 0.0038730775665303243
Epoch: 754, trainingloss: 0.003607457058756937 | validation loss: 0.003966750756223436
Epoch: 755, trainingloss: 0.003705795464241966 | validation loss: 0.004020017218817768
Epoch: 756, trainingloss: 0.003860122991957217 | validation loss: 0.00414798173183707
Epoch: 757, trainingloss: 0.003498387498557257 | validation loss: 0.0038451029285945324
Epoch: 758, trainingloss: 0.0037223177439993024 | validation loss: 0.0040521087240953085
Epoch: 759, trainingloss: 0.0037714045156633964 | validation loss: 0.004069754436756071
Epoch: 760, trainingloss: 0.0034755161692175108 | validation loss: 0.003832124094443486
Epoch: 761, trainingloss: 0.0036358026755004737 | validation loss: 0.0039704952510692185
Epoch: 762, trainingloss: 0.004167221515515991 | validation loss: 0.004426598895392183
Epoch: 763, trainingloss: 0.0035078636820478635 | validation loss: 0.003844878762654275
Epoch: 764, trainingloss: 0.004208475699281493 | validation loss: 0.004538284401689316
Epoch: 765, trainingloss: 0.0039067402049776205 | validation loss: 0.004241693862682929
Epoch: 766, trainingloss: 0.003708096523340072 | validation loss: 0.004009046535122275
Epoch: 767, trainingloss: 0.003555331753007191 | validation loss: 0.00387023471877346
Epoch: 768, trainingloss: 0.0033370750523257805 | validation loss: 0.003682566714129885
Epoch: 769, trainingloss: 0.003826450491615806 | validation loss: 0.004106914017392417
Epoch: 770, trainingloss: 0.003781786544778883 | validation loss: 0.004075180460839171
Epoch: 771, trainingloss: 0.003956122908681551 | validation loss: 0.004267370069261118
Epoch: 772, trainingloss: 0.004141713196683777 | validation loss: 0.004426163344691759
Epoch: 773, trainingloss: 0.0034884717557256387 | validation loss: 0.003816340459992852
Epoch: 774, trainingloss: 0.003595300353410049 | validation loss: 0.003919952316960202
Epoch: 775, trainingloss: 0.0037947358119926277 | validation loss: 0.004089909274899686
Epoch: 776, trainingloss: 0.0034734545522828457 | validation loss: 0.0037943753850157662
Epoch: 777, trainingloss: 0.0038527771953912903 | validation loss: 0.004158079100001922
Epoch: 778, trainingloss: 0.0036570379619052787 | validation loss: 0.003976851131681699
Epoch: 779, trainingloss: 0.0037798546748032302 | validation loss: 0.004075420808113654
Epoch: 780, trainingloss: 0.004262258036159818 | validation loss: 0.00451040032168075
Epoch: 781, trainingloss: 0.0037117344265438605 | validation loss: 0.004024245213282775
Epoch: 782, trainingloss: 0.003984820172488317 | validation loss: 0.004308823125948031
Epoch: 783, trainingloss: 0.004213980637171926 | validation loss: 0.0045044897437520465
Epoch: 784, trainingloss: 0.003565402925369022 | validation loss: 0.003915157827136288
Epoch: 785, trainingloss: 0.003563035808952931 | validation loss: 0.0038862691336265832
Epoch: 786, trainingloss: 0.003526166768021568 | validation loss: 0.00384635815132398
Epoch: 787, trainingloss: 0.00387391001537015 | validation loss: 0.004174934466263917
Epoch: 788, trainingloss: 0.0040804221425908005 | validation loss: 0.004348726507489267
Epoch: 789, trainingloss: 0.0037018451718907825 | validation loss: 0.0039887761436232455
Epoch: 790, trainingloss: 0.003744876277250146 | validation loss: 0.0040229822937466785
Epoch: 791, trainingloss: 0.003942328601617988 | validation loss: 0.004220671293235784
Epoch: 792, trainingloss: 0.003796184770252013 | validation loss: 0.0041200617232373315
Epoch: 793, trainingloss: 0.0035513164746448864 | validation loss: 0.003898538207756788
Epoch: 794, trainingloss: 0.003871239195590613 | validation loss: 0.004208201785189428
Epoch: 795, trainingloss: 0.0034478378547206597 | validation loss: 0.0037525510632097562
Epoch: 796, trainingloss: 0.0037248328491571833 | validation loss: 0.00402013523704534
Epoch: 797, trainingloss: 0.004054478459246148 | validation loss: 0.004359738558821362
Epoch: 798, trainingloss: 0.003484639231768913 | validation loss: 0.0038009180058095984
Epoch: 799, trainingloss: 0.0036779292310054955 | validation loss: 0.003992821669677626
Epoch: 800, trainingloss: 0.0034483222092758716 | validation loss: 0.0038201036998619527
Epoch: 801, trainingloss: 0.0036722585717215 | validation loss: 0.003989457609694197
Epoch: 802, trainingloss: 0.004129167279734191 | validation loss: 0.004392782436759994
Epoch: 803, trainingloss: 0.003941348386364357 | validation loss: 0.004247189760401568
Epoch: 804, trainingloss: 0.0037146054315429877 | validation loss: 0.003999924305700677
Epoch: 805, trainingloss: 0.003748616161021053 | validation loss: 0.004054425984803963
Epoch: 806, trainingloss: 0.0037123399471628332 | validation loss: 0.004015263606189254
Epoch: 807, trainingloss: 0.0036135180086043434 | validation loss: 0.0038988505107937902
Epoch: 808, trainingloss: 0.003558872607146577 | validation loss: 0.0038574903977645954
Epoch: 809, trainingloss: 0.0037525015976767532 | validation loss: 0.0040698403681488065
Epoch: 810, trainingloss: 0.004013261461739775 | validation loss: 0.004313613343386345
Epoch: 811, trainingloss: 0.004207173625475891 | validation loss: 0.004480777114437157
Epoch: 812, trainingloss: 0.0037910492710693106 | validation loss: 0.004073436425049441
Epoch: 813, trainingloss: 0.0037231135533827347 | validation loss: 0.00402701119763072
Epoch: 814, trainingloss: 0.0034287562335468245 | validation loss: 0.003758690288902703
Epoch: 815, trainingloss: 0.003581839420297612 | validation loss: 0.003895388474015594
Epoch: 816, trainingloss: 0.003931188499198384 | validation loss: 0.004224329965479614
Epoch: 817, trainingloss: 0.004208865958360482 | validation loss: 0.004466235000780725
Epoch: 818, trainingloss: 0.0036677128097523204 | validation loss: 0.003957556684576983
Epoch: 819, trainingloss: 0.0036520959506977633 | validation loss: 0.0039538342167667285
Epoch: 820, trainingloss: 0.003748663589651936 | validation loss: 0.004060130667062921
Epoch: 821, trainingloss: 0.0038904065969379248 | validation loss: 0.0041608498897100265
Epoch: 822, trainingloss: 0.0037440175461041464 | validation loss: 0.00408377325536502
Epoch: 823, trainingloss: 0.0037065528515222526 | validation loss: 0.004014496094352158
Epoch: 824, trainingloss: 0.0038213193121144563 | validation loss: 0.004098122024154109
Epoch: 825, trainingloss: 0.0046618726291860185 | validation loss: 0.0049069259628106935
Epoch: 826, trainingloss: 0.0037506681200250957 | validation loss: 0.004037579387240373
Epoch: 827, trainingloss: 0.0036063013686793532 | validation loss: 0.003924692986680965
Epoch: 828, trainingloss: 0.0036688816993318113 | validation loss: 0.003973017825639061
Epoch: 829, trainingloss: 0.004188929470770739 | validation loss: 0.004454510717150017
Epoch: 830, trainingloss: 0.004046920953912135 | validation loss: 0.004326668143241744
Epoch: 831, trainingloss: 0.0036122902658966964 | validation loss: 0.003950315477561547
Epoch: 832, trainingloss: 0.0038563164671839415 | validation loss: 0.0041675548503181
Epoch: 833, trainingloss: 0.003484292138394305 | validation loss: 0.0038278160776465393
Epoch: 834, trainingloss: 0.003542818727620572 | validation loss: 0.0038638552793754982
Epoch: 835, trainingloss: 0.004081299706478183 | validation loss: 0.004383901319445063
Epoch: 836, trainingloss: 0.0038297171355999664 | validation loss: 0.004137616532814784
Epoch: 837, trainingloss: 0.004034484452108131 | validation loss: 0.004295799182052248
Epoch: 838, trainingloss: 0.003374067558374626 | validation loss: 0.003714029601419699
Epoch: 839, trainingloss: 0.0035095943323796347 | validation loss: 0.0038132691990879794
Epoch: 840, trainingloss: 0.00351197154330026 | validation loss: 0.0038404891111378705
Epoch: 841, trainingloss: 0.003656857193438354 | validation loss: 0.004018300542984873
Epoch: 842, trainingloss: 0.003828021914715019 | validation loss: 0.004185869263842787
Epoch: 843, trainingloss: 0.003773463539425542 | validation loss: 0.0040740604360487934
Epoch: 844, trainingloss: 0.0037827742362987137 | validation loss: 0.004086883581804061
Epoch: 845, trainingloss: 0.005060206012318978 | validation loss: 0.005254370940203872
Epoch: 846, trainingloss: 0.0036425821970828757 | validation loss: 0.003976585882691225
Epoch: 847, trainingloss: 0.004433782019352208 | validation loss: 0.004665288659517223
Epoch: 848, trainingloss: 0.0038789526943979963 | validation loss: 0.004191753048111623
Epoch: 849, trainingloss: 0.003725400114894621 | validation loss: 0.004028331703910526
Epoch: 850, trainingloss: 0.003438119302413316 | validation loss: 0.0037696385668511126
Epoch: 851, trainingloss: 0.0035892353389362975 | validation loss: 0.003918745079858503
Epoch: 852, trainingloss: 0.004029911822620391 | validation loss: 0.004360927184006357
Epoch: 853, trainingloss: 0.0039304286509453746 | validation loss: 0.004250350520962297
Epoch: 854, trainingloss: 0.0038050529748258136 | validation loss: 0.004125329551139457
Epoch: 855, trainingloss: 0.0034684321573779336 | validation loss: 0.0038363607288806607
Epoch: 856, trainingloss: 0.0036181195454515697 | validation loss: 0.003940996542596581
Epoch: 857, trainingloss: 0.004004775872670345 | validation loss: 0.0042883689724334175
Epoch: 858, trainingloss: 0.004197336025655852 | validation loss: 0.004503143807753837
Epoch: 859, trainingloss: 0.0038978137885907734 | validation loss: 0.004218464507747635
Epoch: 860, trainingloss: 0.0034860880622344446 | validation loss: 0.003801007192953429
Epoch: 861, trainingloss: 0.0038228378831007396 | validation loss: 0.004132052819831577
Epoch: 862, trainingloss: 0.0039044900845104733 | validation loss: 0.00425851882433577
Epoch: 863, trainingloss: 0.0036719039805676625 | validation loss: 0.003980852350477813
Epoch: 864, trainingloss: 0.004412520232099614 | validation loss: 0.004680151875825972
Epoch: 865, trainingloss: 0.00407599272084199 | validation loss: 0.004347595268697996
Epoch: 866, trainingloss: 0.003790876082579608 | validation loss: 0.0040872624641112775
Epoch: 867, trainingloss: 0.003670489441688313 | validation loss: 0.003961423029073687
Epoch: 868, trainingloss: 0.0036388064410907326 | validation loss: 0.003950823570790645
Epoch: 869, trainingloss: 0.004030260466630026 | validation loss: 0.004269319340855991
Epoch: 870, trainingloss: 0.003640617365795387 | validation loss: 0.003912711173015124
Epoch: 871, trainingloss: 0.003820289717829219 | validation loss: 0.004124482159504734
Epoch: 872, trainingloss: 0.003928472178540703 | validation loss: 0.004242148812809454
Epoch: 873, trainingloss: 0.0037783362985389585 | validation loss: 0.004093888259926382
Epoch: 874, trainingloss: 0.0041247683577692994 | validation loss: 0.0044203702564325625
Epoch: 875, trainingloss: 0.003864692360594991 | validation loss: 0.004153055922475718
Epoch: 876, trainingloss: 0.004002761547280038 | validation loss: 0.004276235171648348
Epoch: 877, trainingloss: 0.00412523088055863 | validation loss: 0.004390463486177745
Epoch: 878, trainingloss: 0.0037361324697307166 | validation loss: 0.00405877404122888
Epoch: 879, trainingloss: 0.0038426748717839813 | validation loss: 0.004115591181965899
Epoch: 880, trainingloss: 0.003625011203207078 | validation loss: 0.003985389948677444
Epoch: 881, trainingloss: 0.0035758960112271987 | validation loss: 0.003895261952008277
Epoch: 882, trainingloss: 0.003468225263418583 | validation loss: 0.0037881076934880254
Epoch: 883, trainingloss: 0.0037675006980399076 | validation loss: 0.004082706920197512
Epoch: 884, trainingloss: 0.004312354598590057 | validation loss: 0.00462124480555325
Epoch: 885, trainingloss: 0.0041880263168619465 | validation loss: 0.004466197525385303
Epoch: 886, trainingloss: 0.003863335055923193 | validation loss: 0.004159656052536652
Epoch: 887, trainingloss: 0.0037098780581210767 | validation loss: 0.004012868836310779
Epoch: 888, trainingloss: 0.003508374971768874 | validation loss: 0.0038142389675917547
Epoch: 889, trainingloss: 0.0038646345125869404 | validation loss: 0.004168659340844768
Epoch: 890, trainingloss: 0.003901868674535659 | validation loss: 0.004208673210958528
Epoch: 891, trainingloss: 0.004084545727237048 | validation loss: 0.004353757155479983
Epoch: 892, trainingloss: 0.0043882991076833935 | validation loss: 0.004661586503105611
Epoch: 893, trainingloss: 0.0039289005345792315 | validation loss: 0.004204696300353902
Epoch: 894, trainingloss: 0.0035495843338834783 | validation loss: 0.0038853527765433066
Epoch: 895, trainingloss: 0.003700212193835783 | validation loss: 0.004023598659270207
Epoch: 896, trainingloss: 0.0035549653372933597 | validation loss: 0.0038870888727668045
Epoch: 897, trainingloss: 0.003921222298043526 | validation loss: 0.0042214317637248285
Epoch: 898, trainingloss: 0.004060302524963766 | validation loss: 0.0043571819728362255
Epoch: 899, trainingloss: 0.0035823418042912193 | validation loss: 0.0038941536911159132
Epoch: 900, trainingloss: 0.004145226183836693 | validation loss: 0.004429537774755964
Epoch: 901, trainingloss: 0.003592954365917018 | validation loss: 0.003928350797743301
Epoch: 902, trainingloss: 0.0043374733212276214 | validation loss: 0.004641831499976671
Epoch: 903, trainingloss: 0.0036195639959031695 | validation loss: 0.00390614404594907
Epoch: 904, trainingloss: 0.0035157018250039185 | validation loss: 0.0038492138974390824
Epoch: 905, trainingloss: 0.004403974332898032 | validation loss: 0.004659147317668538
Epoch: 906, trainingloss: 0.0036067486900999116 | validation loss: 0.0039053650526045176
Epoch: 907, trainingloss: 0.0035656328041581546 | validation loss: 0.0038967873241810827
Epoch: 908, trainingloss: 0.0038010747633522557 | validation loss: 0.004104162827848103
Epoch: 909, trainingloss: 0.003629501050697025 | validation loss: 0.003950731037672034
Epoch: 910, trainingloss: 0.0038943513739008715 | validation loss: 0.004199960220886301
Epoch: 911, trainingloss: 0.003703894542253508 | validation loss: 0.004011789708689251
Epoch: 912, trainingloss: 0.0038343331003351773 | validation loss: 0.004123201230212888
Epoch: 913, trainingloss: 0.003719069682735727 | validation loss: 0.0040175784384602195
Epoch: 914, trainingloss: 0.003555049762968926 | validation loss: 0.003867767155749786
Epoch: 915, trainingloss: 0.003768619737781242 | validation loss: 0.004059221336881015
Epoch: 916, trainingloss: 0.0036501103273857303 | validation loss: 0.00395660212922055
Epoch: 917, trainingloss: 0.0038559046343594203 | validation loss: 0.0041453893882453414
Epoch: 918, trainingloss: 0.0039104322929802105 | validation loss: 0.00420354725365812
Epoch: 919, trainingloss: 0.0037911506635307205 | validation loss: 0.004114026582312088
Epoch: 920, trainingloss: 0.003804648238036852 | validation loss: 0.004094012228597414
Epoch: 921, trainingloss: 0.00392139221214589 | validation loss: 0.004230438878672747
Epoch: 922, trainingloss: 0.00392486700962803 | validation loss: 0.004242655840326349
Epoch: 923, trainingloss: 0.0039697755599979396 | validation loss: 0.004238546802498298
Epoch: 924, trainingloss: 0.0036137541094202804 | validation loss: 0.003919091572391305
Epoch: 925, trainingloss: 0.003479623779570534 | validation loss: 0.0037864958173753904
Epoch: 926, trainingloss: 0.0038758128882095933 | validation loss: 0.004171090450942662
Epoch: 927, trainingloss: 0.00389464334417211 | validation loss: 0.004177276719241721
Epoch: 928, trainingloss: 0.003779403591695915 | validation loss: 0.004024267604428227
Epoch: 929, trainingloss: 0.0034095166440104166 | validation loss: 0.003746855092838112
Epoch: 930, trainingloss: 0.0039867468721719295 | validation loss: 0.004289195853508109
Epoch: 931, trainingloss: 0.003933850057999395 | validation loss: 0.004170699506041205
Epoch: 932, trainingloss: 0.0035893476603549145 | validation loss: 0.003920420976043394
Epoch: 933, trainingloss: 0.0038900377650821524 | validation loss: 0.004211039746998775
Epoch: 934, trainingloss: 0.004155057936033724 | validation loss: 0.004433648881960938
Epoch: 935, trainingloss: 0.004521441803995066 | validation loss: 0.004765013244772712
Epoch: 936, trainingloss: 0.003922794150584548 | validation loss: 0.004221368563837655
Epoch: 937, trainingloss: 0.003706527175946279 | validation loss: 0.0040292078052434335
Epoch: 938, trainingloss: 0.003478574188718595 | validation loss: 0.0037953638572182768
Epoch: 939, trainingloss: 0.0035747929155966686 | validation loss: 0.00391938391087064
Epoch: 940, trainingloss: 0.00393735135765494 | validation loss: 0.004263240693193264
Epoch: 941, trainingloss: 0.0035972711659505874 | validation loss: 0.003936728904227705
Epoch: 942, trainingloss: 0.003711520260922468 | validation loss: 0.004030081376969426
Epoch: 943, trainingloss: 0.0037500644026070363 | validation loss: 0.004075214739723313
Epoch: 944, trainingloss: 0.003997890444771324 | validation loss: 0.0042910865589705915
Epoch: 945, trainingloss: 0.004061393456333238 | validation loss: 0.004359333662447882
Epoch: 946, trainingloss: 0.0037232779592098813 | validation loss: 0.003967633639350713
Epoch: 947, trainingloss: 0.0037088120749555805 | validation loss: 0.004010724563320402
Epoch: 948, trainingloss: 0.0038474057335982515 | validation loss: 0.004175457378883102
Epoch: 949, trainingloss: 0.003583886606612727 | validation loss: 0.0038928646633452552
Epoch: 950, trainingloss: 0.0037435958968278656 | validation loss: 0.004062726245881316
Epoch: 951, trainingloss: 0.0038939916020393384 | validation loss: 0.004190267697398924
Epoch: 952, trainingloss: 0.0038715554292388945 | validation loss: 0.004168977684393748
Epoch: 953, trainingloss: 0.0038262982385003598 | validation loss: 0.004104019166869796
Epoch: 954, trainingloss: 0.003536206687066779 | validation loss: 0.0038756851708005094
Epoch: 955, trainingloss: 0.004154350302415753 | validation loss: 0.004429370132815496
Epoch: 956, trainingloss: 0.003541410816796304 | validation loss: 0.0038860900365634264
Epoch: 957, trainingloss: 0.004305710338101278 | validation loss: 0.004594048825805492
Epoch: 958, trainingloss: 0.003876550217912907 | validation loss: 0.004192940762390512
Epoch: 959, trainingloss: 0.003872884946147486 | validation loss: 0.004183103126667713
Epoch: 960, trainingloss: 0.0041786262042211985 | validation loss: 0.0045026048568681445
Epoch: 961, trainingloss: 0.0039825476991440555 | validation loss: 0.004276654648854278
Epoch: 962, trainingloss: 0.0037643172704917007 | validation loss: 0.004088385758899792
Epoch: 963, trainingloss: 0.0036415443239740854 | validation loss: 0.003948831905730073
Epoch: 964, trainingloss: 0.0038733408679967156 | validation loss: 0.004176413682348152
Epoch: 965, trainingloss: 0.003834678284420437 | validation loss: 0.004159500553596004
Epoch: 966, trainingloss: 0.004079792330880403 | validation loss: 0.004343681369784713
Epoch: 967, trainingloss: 0.0039601887121515165 | validation loss: 0.004231939348573759
Epoch: 968, trainingloss: 0.0034470558344051883 | validation loss: 0.003789634729488118
Epoch: 969, trainingloss: 0.0037700556783082932 | validation loss: 0.004054233333091393
Epoch: 970, trainingloss: 0.0035443468069159467 | validation loss: 0.0038671611516261136
Epoch: 971, trainingloss: 0.003601678967614222 | validation loss: 0.00391137254359704
Epoch: 972, trainingloss: 0.003909229439450765 | validation loss: 0.004201769177453724
Epoch: 973, trainingloss: 0.00406477543495562 | validation loss: 0.004350336970920678
Epoch: 974, trainingloss: 0.00368462371741096 | validation loss: 0.003978879928857125
Epoch: 975, trainingloss: 0.0035793778361032876 | validation loss: 0.0038948933106146087
Epoch: 976, trainingloss: 0.0038378394488513593 | validation loss: 0.004146347836382993
Epoch: 977, trainingloss: 0.0038219847843231547 | validation loss: 0.00413691831927535
Epoch: 978, trainingloss: 0.003838882715764227 | validation loss: 0.004138858329912888
Epoch: 979, trainingloss: 0.003638045805145684 | validation loss: 0.003925171216908024
Epoch: 980, trainingloss: 0.003587076016983426 | validation loss: 0.0039206529276872605
Epoch: 981, trainingloss: 0.0036594861152794904 | validation loss: 0.003993459718279835
Epoch: 982, trainingloss: 0.003789240838135244 | validation loss: 0.004106582830365448
Epoch: 983, trainingloss: 0.00337645298004457 | validation loss: 0.0037172135780638898
Epoch: 984, trainingloss: 0.004177520026043038 | validation loss: 0.004471094585725049
Epoch: 985, trainingloss: 0.004186682695701009 | validation loss: 0.004438202427625208
Epoch: 986, trainingloss: 0.0035549576237282493 | validation loss: 0.003906760094325513
Epoch: 987, trainingloss: 0.0036186794946848054 | validation loss: 0.003929310817016805
Epoch: 988, trainingloss: 0.004279399720159337 | validation loss: 0.004598756542201187
Epoch: 989, trainingloss: 0.003978236250056638 | validation loss: 0.0042647867080228994
Epoch: 990, trainingloss: 0.0036712040747804253 | validation loss: 0.003978866885107668
Epoch: 991, trainingloss: 0.003651964034399704 | validation loss: 0.003968935602617705
Epoch: 992, trainingloss: 0.0038655645257842943 | validation loss: 0.004185381143526736
Epoch: 993, trainingloss: 0.003537483077875337 | validation loss: 0.0038725115982776812
Epoch: 994, trainingloss: 0.003711322884624812 | validation loss: 0.004035039852267704
Epoch: 995, trainingloss: 0.003914337097789214 | validation loss: 0.004234981242988352
Epoch: 996, trainingloss: 0.0036806673499009206 | validation loss: 0.004000212285550108
Epoch: 997, trainingloss: 0.0035897896760968442 | validation loss: 0.00390505300214559
Epoch: 998, trainingloss: 0.003987374267318528 | validation loss: 0.004287502999832124
Epoch: 999, trainingloss: 0.0036525933771818556 | validation loss: 0.003975760172196121
Epoch: 1000, trainingloss: 0.003884981324787023 | validation loss: 0.004184710908956331
Epoch: 1001, trainingloss: 0.0036802238290213167 | validation loss: 0.003998671041582659
Epoch: 1002, trainingloss: 0.003582550978719619 | validation loss: 0.003927230029124566
Epoch: 1003, trainingloss: 0.0036484689171337103 | validation loss: 0.003994679249046503
Epoch: 1004, trainingloss: 0.0036079494356253974 | validation loss: 0.003953526830933286
Epoch: 1005, trainingloss: 0.0035565847448555538 | validation loss: 0.003862473204183663
Epoch: 1006, trainingloss: 0.0035713102257691025 | validation loss: 0.003874621832326896
Epoch: 1007, trainingloss: 0.003680704959178131 | validation loss: 0.004003455601462171
Epoch: 1008, trainingloss: 0.003753999747324154 | validation loss: 0.0041051269050437714
Epoch: 1009, trainingloss: 0.003490176129124522 | validation loss: 0.0038309018050706406
Epoch: 1010, trainingloss: 0.0037794864229619292 | validation loss: 0.0040640079245818014
Epoch: 1011, trainingloss: 0.00354900992185379 | validation loss: 0.0038613603440869797
Epoch: 1012, trainingloss: 0.0038454386986180905 | validation loss: 0.004111890799168008
Epoch: 1013, trainingloss: 0.0037115532048314663 | validation loss: 0.0040350501762533115
Epoch: 1014, trainingloss: 0.003494725804373995 | validation loss: 0.003828212021391971
Epoch: 1015, trainingloss: 0.0038398077490462085 | validation loss: 0.004137281020045335
Epoch: 1016, trainingloss: 0.0037336274648201184 | validation loss: 0.004031447902042959
Epoch: 1017, trainingloss: 0.0035138440568771726 | validation loss: 0.0038263765096032743
Epoch: 1018, trainingloss: 0.003536903885897074 | validation loss: 0.0038908742785453837
Epoch: 1019, trainingloss: 0.0035949109133994574 | validation loss: 0.0038952451018478256
Epoch: 1020, trainingloss: 0.0038175641644553893 | validation loss: 0.0041005885883097955
Epoch: 1021, trainingloss: 0.0041660564259390544 | validation loss: 0.004466975474610696
Epoch: 1022, trainingloss: 0.0034375789014687826 | validation loss: 0.003801196764782894
Epoch: 1023, trainingloss: 0.003528616940012195 | validation loss: 0.0038599498498112154
Epoch: 1024, trainingloss: 0.004829918334143013 | validation loss: 0.005059303530205386
Epoch: 1025, trainingloss: 0.0035336033670087504 | validation loss: 0.003840039475057631
Epoch: 1026, trainingloss: 0.004014134727582379 | validation loss: 0.004281762340726973
Epoch: 1027, trainingloss: 0.0036557634410914596 | validation loss: 0.003964580994878657
Epoch: 1028, trainingloss: 0.0036667952104305953 | validation loss: 0.00397187858845454
Epoch: 1029, trainingloss: 0.0035520906382114775 | validation loss: 0.003880659645151374
Epoch: 1030, trainingloss: 0.0034665320456609082 | validation loss: 0.003796986130900028
Epoch: 1031, trainingloss: 0.004234626683524584 | validation loss: 0.004489615087641885
Epoch: 1032, trainingloss: 0.0037433540796147037 | validation loss: 0.004049434865634481
Epoch: 1033, trainingloss: 0.004033176879418521 | validation loss: 0.004325920110136963
Epoch: 1034, trainingloss: 0.0038240152942105522 | validation loss: 0.004103686962092497
Epoch: 1035, trainingloss: 0.004156606897259569 | validation loss: 0.004445561091022096
Epoch: 1036, trainingloss: 0.0037282433344862547 | validation loss: 0.004059026483427839
Epoch: 1037, trainingloss: 0.0036033824695360563 | validation loss: 0.0038978209147580217
Epoch: 1038, trainingloss: 0.0036571347117103415 | validation loss: 0.0039350739692398905
Epoch: 1039, trainingloss: 0.0034236608199739995 | validation loss: 0.0037202193304035403
Epoch: 1040, trainingloss: 0.0035718818082922242 | validation loss: 0.0039009555983613923
Epoch: 1041, trainingloss: 0.004235475491818468 | validation loss: 0.004504419088807933
Epoch: 1042, trainingloss: 0.004707517003388252 | validation loss: 0.004945830093786608
Epoch: 1043, trainingloss: 0.0035704682175948022 | validation loss: 0.003895134905212914
Epoch: 1044, trainingloss: 0.003991065479693673 | validation loss: 0.004263041488842542
Epoch: 1045, trainingloss: 0.003595697682426775 | validation loss: 0.003925702290644349
Epoch: 1046, trainingloss: 0.004006979392572476 | validation loss: 0.004282055697623103
Epoch: 1047, trainingloss: 0.0034137831690917763 | validation loss: 0.003772621643835868
Epoch: 1048, trainingloss: 0.0033823793379846273 | validation loss: 0.0037382105560041083
Epoch: 1049, trainingloss: 0.003817614091281094 | validation loss: 0.004141302595617142
Epoch: 1050, trainingloss: 0.0036817795738949472 | validation loss: 0.004005442860348424
Epoch: 1051, trainingloss: 0.0034176458367716207 | validation loss: 0.003766615297149592
Epoch: 1052, trainingloss: 0.0033154807556662583 | validation loss: 0.003702331272634907
Epoch: 1053, trainingloss: 0.003740912214320438 | validation loss: 0.004031335963264677
Epoch: 1054, trainingloss: 0.0037837698763375357 | validation loss: 0.004058111740717498
Epoch: 1055, trainingloss: 0.003447365763816839 | validation loss: 0.0037663156346706187
Epoch: 1056, trainingloss: 0.0036459489276186117 | validation loss: 0.003966273555575583
Epoch: 1057, trainingloss: 0.004064924871046091 | validation loss: 0.004377023464852947
Epoch: 1058, trainingloss: 0.003787468124242777 | validation loss: 0.004105898797542452
Epoch: 1059, trainingloss: 0.0035353307423386772 | validation loss: 0.0038865918968751844
Epoch: 1060, trainingloss: 0.0036988542024792765 | validation loss: 0.004031734689640703
Epoch: 1061, trainingloss: 0.004215213921134125 | validation loss: 0.004531662583263362
Epoch: 1062, trainingloss: 0.003566193948935823 | validation loss: 0.0038757472256732654
Epoch: 1063, trainingloss: 0.0038817620745114226 | validation loss: 0.004194305073924111
Epoch: 1064, trainingloss: 0.0035276048864524364 | validation loss: 0.003832015823542409
Epoch: 1065, trainingloss: 0.0035209084424482583 | validation loss: 0.0038756176881371814
Epoch: 1066, trainingloss: 0.003550385322529455 | validation loss: 0.0038731818115802846
Epoch: 1067, trainingloss: 0.0037661622156039405 | validation loss: 0.004084398449338408
Epoch: 1068, trainingloss: 0.0033424051153910944 | validation loss: 0.0037028014311788113
Epoch: 1069, trainingloss: 0.003891423160996112 | validation loss: 0.004198819644891995
Epoch: 1070, trainingloss: 0.004182634734284506 | validation loss: 0.004468750749516154
Epoch: 1071, trainingloss: 0.0039516767163647855 | validation loss: 0.004232697120704851
Epoch: 1072, trainingloss: 0.00368438826067097 | validation loss: 0.004026212474384876
Epoch: 1073, trainingloss: 0.003549993673715839 | validation loss: 0.0038898683731913124
Epoch: 1074, trainingloss: 0.003735380414855299 | validation loss: 0.004020414076775711
Epoch: 1075, trainingloss: 0.0036453256459081785 | validation loss: 0.003956587943108804
Epoch: 1076, trainingloss: 0.00340060249027469 | validation loss: 0.0037406683326408115
Epoch: 1077, trainingloss: 0.0036205264325199324 | validation loss: 0.003961923008024241
Epoch: 1078, trainingloss: 0.003518637569264761 | validation loss: 0.0038563536240298225
Epoch: 1079, trainingloss: 0.003612777706958655 | validation loss: 0.003940056105321878
Epoch: 1080, trainingloss: 0.003836187197446776 | validation loss: 0.004138712390949436
Epoch: 1081, trainingloss: 0.0035493329186108823 | validation loss: 0.0038795737404035847
Epoch: 1082, trainingloss: 0.003657506035510255 | validation loss: 0.003985670291002893
Epoch: 1083, trainingloss: 0.0034163464818300674 | validation loss: 0.0037228350519650775
Epoch: 1084, trainingloss: 0.0036797403303324614 | validation loss: 0.003979039530658959
Epoch: 1085, trainingloss: 0.003908723474160428 | validation loss: 0.004222356328133802
Epoch: 1086, trainingloss: 0.004209458926756423 | validation loss: 0.004514752840466176
Epoch: 1087, trainingloss: 0.003848699010200106 | validation loss: 0.004130962130098852
Epoch: 1088, trainingloss: 0.003934849665357828 | validation loss: 0.004211335876074588
Epoch: 1089, trainingloss: 0.0036481730979995987 | validation loss: 0.003962640585318716
Epoch: 1090, trainingloss: 0.003923477218050104 | validation loss: 0.004215289174428009
Epoch: 1091, trainingloss: 0.003592232247293505 | validation loss: 0.003909055368180907
Epoch: 1092, trainingloss: 0.0034537338867413835 | validation loss: 0.0037710948224044657
Epoch: 1093, trainingloss: 0.0038027507653985767 | validation loss: 0.004123305646395994
Epoch: 1094, trainingloss: 0.0036880828850394906 | validation loss: 0.003986658915194605
Epoch: 1095, trainingloss: 0.004253193140391324 | validation loss: 0.004501097386640386
Epoch: 1096, trainingloss: 0.004808658485337681 | validation loss: 0.005031849879348022
Epoch: 1097, trainingloss: 0.0037155466750579515 | validation loss: 0.004042454719727744
Epoch: 1098, trainingloss: 0.0036085431567040673 | validation loss: 0.0039139534206797675
Epoch: 1099, trainingloss: 0.003740130815579748 | validation loss: 0.004046550203192126
Epoch: 1100, trainingloss: 0.0035789276828550255 | validation loss: 0.0039088487882693755
Epoch: 1101, trainingloss: 0.0038538696295752103 | validation loss: 0.004152194084649348
Epoch: 1102, trainingloss: 0.0037354206447287497 | validation loss: 0.004064431216477434
Epoch: 1103, trainingloss: 0.00409227988659972 | validation loss: 0.0043935287405113994
Epoch: 1104, trainingloss: 0.003744403970738606 | validation loss: 0.004038825710281624
Epoch: 1105, trainingloss: 0.003741840128866523 | validation loss: 0.0040523288642442205
Epoch: 1106, trainingloss: 0.0036272619772474615 | validation loss: 0.003950779604540017
Epoch: 1107, trainingloss: 0.003883987074088556 | validation loss: 0.004162495996103077
Epoch: 1108, trainingloss: 0.0035388728083623378 | validation loss: 0.0038752958993233263
Epoch: 1109, trainingloss: 0.004092158341768353 | validation loss: 0.004384929498384546
Epoch: 1110, trainingloss: 0.003614991711115384 | validation loss: 0.00392472152006285
Epoch: 1111, trainingloss: 0.003759308069572552 | validation loss: 0.004095472136655164
Epoch: 1112, trainingloss: 0.0033769581916524728 | validation loss: 0.0037445960740328894
Epoch: 1113, trainingloss: 0.003985871225437856 | validation loss: 0.004311697626505737
Epoch: 1114, trainingloss: 0.00371750097803791 | validation loss: 0.004018000353924217
Epoch: 1115, trainingloss: 0.0035152914266870575 | validation loss: 0.0038392737970246644
Epoch: 1116, trainingloss: 0.003918664442198638 | validation loss: 0.004218780740069935
Epoch: 1117, trainingloss: 0.004005316190899108 | validation loss: 0.004327390575434342
Epoch: 1118, trainingloss: 0.0037572016103008124 | validation loss: 0.0040710034101958115
Epoch: 1119, trainingloss: 0.0034242247841439707 | validation loss: 0.003788468180701501
Epoch: 1120, trainingloss: 0.004159878653683305 | validation loss: 0.0043980786451102045
Epoch: 1121, trainingloss: 0.0035883312899905127 | validation loss: 0.003932514749219241
Epoch: 1122, trainingloss: 0.00396348780966255 | validation loss: 0.004262877540701099
Epoch: 1123, trainingloss: 0.003707734753446272 | validation loss: 0.004049441322057138
Epoch: 1124, trainingloss: 0.0038548527364519274 | validation loss: 0.004142794115682561
Epoch: 1125, trainingloss: 0.003676383837901173 | validation loss: 0.003974185395770354
Epoch: 1126, trainingloss: 0.003438766026614612 | validation loss: 0.003791073736108527
Epoch: 1127, trainingloss: 0.0034423446648536257 | validation loss: 0.0037803164392207285
Epoch: 1128, trainingloss: 0.004121570093388593 | validation loss: 0.004432536993743381
Epoch: 1129, trainingloss: 0.0034393811098656314 | validation loss: 0.0037829649578194546
Epoch: 1130, trainingloss: 0.004232243389114644 | validation loss: 0.004529010548205048
Epoch: 1131, trainingloss: 0.0036544980068942638 | validation loss: 0.003995107199984999
Epoch: 1132, trainingloss: 0.0038296803958755604 | validation loss: 0.0041310367232471135
Epoch: 1133, trainingloss: 0.0036920912133188337 | validation loss: 0.004038670182935658
Epoch: 1134, trainingloss: 0.003311144203710615 | validation loss: 0.0036769998714630257
Epoch: 1135, trainingloss: 0.003520860736246413 | validation loss: 0.0038569697555632986
Epoch: 1136, trainingloss: 0.0037237363359827955 | validation loss: 0.004066655825570404
Epoch: 1137, trainingloss: 0.0037328911280829343 | validation loss: 0.004086239900165256
Epoch: 1138, trainingloss: 0.003605716845353752 | validation loss: 0.003910735541256105
Epoch: 1139, trainingloss: 0.0035733673876348197 | validation loss: 0.0038983533930094824
Epoch: 1140, trainingloss: 0.0035873744319554037 | validation loss: 0.003923191975202532
Epoch: 1141, trainingloss: 0.003731789578638741 | validation loss: 0.004045930439174262
Epoch: 1142, trainingloss: 0.0036606105313964805 | validation loss: 0.003966051895443902
Epoch: 1143, trainingloss: 0.0034688346343873305 | validation loss: 0.0037847700532639686
Epoch: 1144, trainingloss: 0.003815993184016302 | validation loss: 0.004112991095863221
Epoch: 1145, trainingloss: 0.003997794113319541 | validation loss: 0.004310088863102682
Epoch: 1146, trainingloss: 0.0034585269759772343 | validation loss: 0.0037721823134110118
Epoch: 1147, trainingloss: 0.003916109352204141 | validation loss: 0.004205586505451372
Epoch: 1148, trainingloss: 0.003395371116066207 | validation loss: 0.003747024917181789
Epoch: 1149, trainingloss: 0.0038230409919484025 | validation loss: 0.004165936506915085
Epoch: 1150, trainingloss: 0.0037301650086684892 | validation loss: 0.004075591223152982
Epoch: 1151, trainingloss: 0.003868010551380553 | validation loss: 0.004203738992878938
Epoch: 1152, trainingloss: 0.00379850239578419 | validation loss: 0.004113596387861361
Epoch: 1153, trainingloss: 0.004577972296296284 | validation loss: 0.004869434397445491
Epoch: 1154, trainingloss: 0.003867476445489708 | validation loss: 0.0041385410520265705
Epoch: 1155, trainingloss: 0.0035403960752970294 | validation loss: 0.003828506929682411
Epoch: 1156, trainingloss: 0.004215226359757272 | validation loss: 0.00450050128053224
Epoch: 1157, trainingloss: 0.003697141987812266 | validation loss: 0.003992614213990752
Epoch: 1158, trainingloss: 0.0035326682140148238 | validation loss: 0.003847838379652211
Epoch: 1159, trainingloss: 0.0038255169525197785 | validation loss: 0.004140510319705528
Epoch: 1160, trainingloss: 0.003457235226259828 | validation loss: 0.0038270981713294377
Epoch: 1161, trainingloss: 0.004231222231338655 | validation loss: 0.004542382551277149
Epoch: 1162, trainingloss: 0.0034747088985071207 | validation loss: 0.0038300606296846683
Epoch: 1163, trainingloss: 0.0035272481773548883 | validation loss: 0.0038678883275399946
Epoch: 1164, trainingloss: 0.0037655543940586836 | validation loss: 0.004092523845592349
Epoch: 1165, trainingloss: 0.00372936281558821 | validation loss: 0.004034347488454379
Epoch: 1166, trainingloss: 0.0037597306062978992 | validation loss: 0.004081815814002411
Epoch: 1167, trainingloss: 0.0035492378459006943 | validation loss: 0.003894899404707774
Epoch: 1168, trainingloss: 0.0036854649628699976 | validation loss: 0.00401803128198247
Epoch: 1169, trainingloss: 0.0035036501662179718 | validation loss: 0.0038476489021015956
Epoch: 1170, trainingloss: 0.00403255542731754 | validation loss: 0.004340759123265325
Epoch: 1171, trainingloss: 0.003634665761150425 | validation loss: 0.003948075097770397
Epoch: 1172, trainingloss: 0.00386706477065795 | validation loss: 0.004162482009617487
Epoch: 1173, trainingloss: 0.003749374749003325 | validation loss: 0.004048832573280231
Epoch: 1174, trainingloss: 0.0038443857157701637 | validation loss: 0.00415739587334849
Epoch: 1175, trainingloss: 0.003811110794710704 | validation loss: 0.004149482697351537
Epoch: 1176, trainingloss: 0.0037885128393937264 | validation loss: 0.004113909073612781
Epoch: 1177, trainingloss: 0.0037577057899420324 | validation loss: 0.004050645736436812
Epoch: 1178, trainingloss: 0.003653303489469826 | validation loss: 0.003972478785338513
Epoch: 1179, trainingloss: 0.003667040093569012 | validation loss: 0.003969218819515065
Epoch: 1180, trainingloss: 0.0034154148471438467 | validation loss: 0.003753435960449751
Epoch: 1181, trainingloss: 0.0036747746538769222 | validation loss: 0.003991452078704244
Epoch: 1182, trainingloss: 0.0034379286801640672 | validation loss: 0.0037777770532250714
Epoch: 1183, trainingloss: 0.004079476804928042 | validation loss: 0.004381577749182142
Epoch: 1184, trainingloss: 0.00429821420469688 | validation loss: 0.00455523733025214
Epoch: 1185, trainingloss: 0.0036205779537241503 | validation loss: 0.003987592721960574
Epoch: 1186, trainingloss: 0.0034058323492239424 | validation loss: 0.0037573256374421847
Epoch: 1187, trainingloss: 0.004014701568705308 | validation loss: 0.00432447681994639
Epoch: 1188, trainingloss: 0.004090519319517217 | validation loss: 0.004366192228249729
Epoch: 1189, trainingloss: 0.0036601796907832496 | validation loss: 0.0039917594632753245
Epoch: 1190, trainingloss: 0.003699663816825553 | validation loss: 0.003993163886022993
Epoch: 1191, trainingloss: 0.0036524796241110594 | validation loss: 0.00399674060527644
Epoch: 1192, trainingloss: 0.003407004910844445 | validation loss: 0.003749173415187768
Epoch: 1193, trainingloss: 0.004326410825936356 | validation loss: 0.004649221685955563
Epoch: 1194, trainingloss: 0.003709679671479374 | validation loss: 0.0040222803130711415
Epoch: 1195, trainingloss: 0.003682070021882913 | validation loss: 0.004005819778456052
Epoch: 1196, trainingloss: 0.003894222404968977 | validation loss: 0.004190358264490728
Epoch: 1197, trainingloss: 0.003534485191475065 | validation loss: 0.0038735911733942564
Epoch: 1198, trainingloss: 0.004233812065866519 | validation loss: 0.004498095309264319
Epoch: 1199, trainingloss: 0.003588374830331547 | validation loss: 0.003919672463647151
Epoch: 1200, trainingloss: 0.0037428576322668106 | validation loss: 0.004089260105931754
Epoch: 1201, trainingloss: 0.0036131982343832205 | validation loss: 0.003973168537786158
Epoch: 1202, trainingloss: 0.004005511732620999 | validation loss: 0.00432235982648414
Epoch: 1203, trainingloss: 0.003644494645024373 | validation loss: 0.003942127160218411
Epoch: 1204, trainingloss: 0.0035688227140667863 | validation loss: 0.0038837738975217406
Epoch: 1205, trainingloss: 0.0036426366083311 | validation loss: 0.003971755507793019
Epoch: 1206, trainingloss: 0.0033514778382351352 | validation loss: 0.003693414963661567
Epoch: 1207, trainingloss: 0.003970189895800297 | validation loss: 0.0042762092177343735
Epoch: 1208, trainingloss: 0.0036227041954846485 | validation loss: 0.003943175812384797
Epoch: 1209, trainingloss: 0.003431774910162207 | validation loss: 0.0037469856025141328
Epoch: 1210, trainingloss: 0.003978133921171591 | validation loss: 0.004297186772921006
Epoch: 1211, trainingloss: 0.0034629463699129524 | validation loss: 0.003815817719294431
Epoch: 1212, trainingloss: 0.0035905511612647095 | validation loss: 0.003917547755832382
Epoch: 1213, trainingloss: 0.0034294665530755423 | validation loss: 0.003783158362366898
Epoch: 1214, trainingloss: 0.003449424304104697 | validation loss: 0.00377818864999137
Epoch: 1215, trainingloss: 0.0033435100376184154 | validation loss: 0.003683160274239732
Epoch: 1216, trainingloss: 0.0036873907305906813 | validation loss: 0.004042871415533235
Epoch: 1217, trainingloss: 0.003455173933615352 | validation loss: 0.0037879140236961382
Epoch: 1218, trainingloss: 0.0033388807223091 | validation loss: 0.003715718030318427
Epoch: 1219, trainingloss: 0.0034320621947861256 | validation loss: 0.003783883442723132
Epoch: 1220, trainingloss: 0.0038703403631927613 | validation loss: 0.004187213715049922
Epoch: 1221, trainingloss: 0.0038184257664543265 | validation loss: 0.0041524435517098415
Epoch: 1222, trainingloss: 0.00402627377588324 | validation loss: 0.00434212345073943
Epoch: 1223, trainingloss: 0.003362602725879648 | validation loss: 0.00372717127365067
Epoch: 1224, trainingloss: 0.003496396435356937 | validation loss: 0.0038278709652507957
Epoch: 1225, trainingloss: 0.003668277029458592 | validation loss: 0.003997330607021408
Epoch: 1226, trainingloss: 0.003988227207025415 | validation loss: 0.004320664984109994
Epoch: 1227, trainingloss: 0.003352349710860216 | validation loss: 0.003732576031578764
Epoch: 1228, trainingloss: 0.0035023435666944585 | validation loss: 0.003839779146808043
Epoch: 1229, trainingloss: 0.00380019269376772 | validation loss: 0.00409879269388604
Epoch: 1230, trainingloss: 0.003295759997384887 | validation loss: 0.003662902748303055
Epoch: 1231, trainingloss: 0.0037725233942453584 | validation loss: 0.004078350303337649
Epoch: 1232, trainingloss: 0.003406166772623139 | validation loss: 0.0037732956334370045
Epoch: 1233, trainingloss: 0.003611198641542996 | validation loss: 0.003933902914297179
Epoch: 1234, trainingloss: 0.003445351539066932 | validation loss: 0.003786301979778969
Epoch: 1235, trainingloss: 0.003836252843740648 | validation loss: 0.004178026613826565
Epoch: 1236, trainingloss: 0.0036892108728514956 | validation loss: 0.004015401826866484
Epoch: 1237, trainingloss: 0.0033111927294613474 | validation loss: 0.0036940132392917833
Epoch: 1238, trainingloss: 0.0033766194300844233 | validation loss: 0.0037090428460597137
Epoch: 1239, trainingloss: 0.0034182080336578606 | validation loss: 0.003795414591346795
Epoch: 1240, trainingloss: 0.003850254479347137 | validation loss: 0.004200240330136071
Epoch: 1241, trainingloss: 0.003970389658810545 | validation loss: 0.00428017075986721
Epoch: 1242, trainingloss: 0.003444038698909392 | validation loss: 0.0037649944652061317
Epoch: 1243, trainingloss: 0.003948701992770056 | validation loss: 0.004214802575569935
Epoch: 1244, trainingloss: 0.00363705547888081 | validation loss: 0.003943872034708972
Epoch: 1245, trainingloss: 0.003647968195276902 | validation loss: 0.003986881307208235
Epoch: 1246, trainingloss: 0.0035210631668104327 | validation loss: 0.003851908496487898
Epoch: 1247, trainingloss: 0.0035548551682831175 | validation loss: 0.0039073509129831
Epoch: 1248, trainingloss: 0.0032869519959569018 | validation loss: 0.003656403528169332
Epoch: 1249, trainingloss: 0.0037117792059802725 | validation loss: 0.004046289771473017
Epoch: 1250, trainingloss: 0.0034696729479876984 | validation loss: 0.0038250596962309813
Epoch: 1251, trainingloss: 0.003382374264011516 | validation loss: 0.0037450500503157643
Epoch: 1252, trainingloss: 0.003765350417509252 | validation loss: 0.004108066956833385
Epoch: 1253, trainingloss: 0.004055072645960631 | validation loss: 0.00433214473939192
Epoch: 1254, trainingloss: 0.0034711753270736233 | validation loss: 0.0038137811009400983
Epoch: 1255, trainingloss: 0.0036090031906429332 | validation loss: 0.003965562495332082
Epoch: 1256, trainingloss: 0.003726618546040298 | validation loss: 0.004039765612962345
Epoch: 1257, trainingloss: 0.003624999198012941 | validation loss: 0.0039288280970885
Epoch: 1258, trainingloss: 0.004034945420726468 | validation loss: 0.004323558509911587
Epoch: 1259, trainingloss: 0.003442801007922172 | validation loss: 0.0038048594322346277
Epoch: 1260, trainingloss: 0.003650798579149222 | validation loss: 0.003984601242157625
Epoch: 1261, trainingloss: 0.0034315420490693997 | validation loss: 0.0038185823992668367
Epoch: 1262, trainingloss: 0.003631672370498922 | validation loss: 0.003979559438955884
Epoch: 1263, trainingloss: 0.003294818675519211 | validation loss: 0.003673648256604288
Epoch: 1264, trainingloss: 0.0038597674799874864 | validation loss: 0.004176672546438273
Epoch: 1265, trainingloss: 0.003314908583681655 | validation loss: 0.0036906577524551194
Epoch: 1266, trainingloss: 0.003354059611356162 | validation loss: 0.003723612318929453
Epoch: 1267, trainingloss: 0.0036872609920317 | validation loss: 0.003970477176884464
Epoch: 1268, trainingloss: 0.0034999647837335255 | validation loss: 0.0038292389255139498
Epoch: 1269, trainingloss: 0.003691145488261955 | validation loss: 0.004019473525525636
Epoch: 1270, trainingloss: 0.004312110901177229 | validation loss: 0.004570828551673526
Epoch: 1271, trainingloss: 0.003317419812543797 | validation loss: 0.0036461762052297417
Epoch: 1272, trainingloss: 0.003394205738815066 | validation loss: 0.0037688941744562065
Epoch: 1273, trainingloss: 0.003512978683257674 | validation loss: 0.0038550499964781367
Epoch: 1274, trainingloss: 0.0037341862997696423 | validation loss: 0.004066004619048915
Epoch: 1275, trainingloss: 0.0036043664661869626 | validation loss: 0.003965513380575027
Epoch: 1276, trainingloss: 0.0038236552119183826 | validation loss: 0.004116823683657701
Epoch: 1277, trainingloss: 0.0036564308949871825 | validation loss: 0.003979869622971924
Epoch: 1278, trainingloss: 0.003945541296838932 | validation loss: 0.004243781152326161
Epoch: 1279, trainingloss: 0.003577269314583351 | validation loss: 0.0039037106257523604
Epoch: 1280, trainingloss: 0.0036064063562120793 | validation loss: 0.003928725552900217
Epoch: 1281, trainingloss: 0.0033474443536771355 | validation loss: 0.003733423154799327
Epoch: 1282, trainingloss: 0.0041219353639211885 | validation loss: 0.004428134032017147
Epoch: 1283, trainingloss: 0.0036921991434362665 | validation loss: 0.004020633089077469
Epoch: 1284, trainingloss: 0.0035183124534979397 | validation loss: 0.0038797693839853196
Epoch: 1285, trainingloss: 0.003579645410689561 | validation loss: 0.003877067977770936
Epoch: 1286, trainingloss: 0.0037845306809778743 | validation loss: 0.004115298882440161
Epoch: 1287, trainingloss: 0.003953826320229025 | validation loss: 0.004229774787293842
Epoch: 1288, trainingloss: 0.003809753776813858 | validation loss: 0.004119549884001968
Epoch: 1289, trainingloss: 0.003543665339928067 | validation loss: 0.0038851674877231177
Epoch: 1290, trainingloss: 0.003699686786021364 | validation loss: 0.004016490785918418
Epoch: 1291, trainingloss: 0.0037623354821004684 | validation loss: 0.004084824545850675
Epoch: 1292, trainingloss: 0.003571965765965465 | validation loss: 0.003904668782639304
Epoch: 1293, trainingloss: 0.003598376075348286 | validation loss: 0.00394404821400619
Epoch: 1294, trainingloss: 0.0034466073823732502 | validation loss: 0.0038123117199407174
Epoch: 1295, trainingloss: 0.004157561796098314 | validation loss: 0.00443954651159076
Epoch: 1296, trainingloss: 0.0037038922687458154 | validation loss: 0.004026507457796217
Epoch: 1297, trainingloss: 0.004446278643725592 | validation loss: 0.00469851352427919
Epoch: 1298, trainingloss: 0.003518088551028352 | validation loss: 0.003870653974082206
Epoch: 1299, trainingloss: 0.0036342533405727038 | validation loss: 0.00399179950588578
Epoch: 1300, trainingloss: 0.003389662594472835 | validation loss: 0.0037259355711488033
Epoch: 1301, trainingloss: 0.0034932223969254034 | validation loss: 0.0038655969022328533
Epoch: 1302, trainingloss: 0.003551952113509169 | validation loss: 0.0038995969850116716
Epoch: 1303, trainingloss: 0.0040091630834876504 | validation loss: 0.004313863030655169
Epoch: 1304, trainingloss: 0.0035393212698501047 | validation loss: 0.0038802738608681897
Epoch: 1305, trainingloss: 0.003605847701065595 | validation loss: 0.003920871571726202
Epoch: 1306, trainingloss: 0.003695952654332045 | validation loss: 0.00401993739384172
Epoch: 1307, trainingloss: 0.003825133252374721 | validation loss: 0.004113382356836251
Epoch: 1308, trainingloss: 0.00337751155524102 | validation loss: 0.0037388827090161472
Epoch: 1309, trainingloss: 0.004035626959557751 | validation loss: 0.004367134501836237
Epoch: 1310, trainingloss: 0.004015210219505821 | validation loss: 0.004292641368292241
Epoch: 1311, trainingloss: 0.0034628077903655673 | validation loss: 0.0037997922614386973
Epoch: 1312, trainingloss: 0.00341487730676483 | validation loss: 0.003771289973593973
Epoch: 1313, trainingloss: 0.0034726003730152543 | validation loss: 0.0038137455929998635
Epoch: 1314, trainingloss: 0.003778335099607814 | validation loss: 0.004098516367128893
Epoch: 1315, trainingloss: 0.0037556464835171765 | validation loss: 0.004066764362135717
Epoch: 1316, trainingloss: 0.003425732523612497 | validation loss: 0.003776413706775994
Epoch: 1317, trainingloss: 0.0043600037082821 | validation loss: 0.004633677787228322
Epoch: 1318, trainingloss: 0.003502872665113569 | validation loss: 0.0038383856262060277
Epoch: 1319, trainingloss: 0.003709354981605362 | validation loss: 0.004011428564308795
Epoch: 1320, trainingloss: 0.0034539350513350902 | validation loss: 0.0037860972169171973
Epoch: 1321, trainingloss: 0.003737550437603427 | validation loss: 0.004045974542303875
Epoch: 1322, trainingloss: 0.003566732513607615 | validation loss: 0.003908150093110287
Epoch: 1323, trainingloss: 0.0036841567955204426 | validation loss: 0.003972519697832458
Epoch: 1324, trainingloss: 0.0036884178382987857 | validation loss: 0.004037739113187577
Epoch: 1325, trainingloss: 0.003670157393623293 | validation loss: 0.004001986114899761
Epoch: 1326, trainingloss: 0.00360596411965145 | validation loss: 0.0039193855131240685
Epoch: 1327, trainingloss: 0.003433715796585643 | validation loss: 0.003764531941874673
Epoch: 1328, trainingloss: 0.0032487304871873547 | validation loss: 0.003600940375538262
Epoch: 1329, trainingloss: 0.0034464841206179285 | validation loss: 0.003813398058445037
Epoch: 1330, trainingloss: 0.0036066958714709705 | validation loss: 0.003928010262250772
Epoch: 1331, trainingloss: 0.004005968080081003 | validation loss: 0.004283471976063838
Epoch: 1332, trainingloss: 0.0034803250679007348 | validation loss: 0.0038388632432160776
Epoch: 1333, trainingloss: 0.0038605125981226065 | validation loss: 0.004174686174504433
Epoch: 1334, trainingloss: 0.0034627526024712707 | validation loss: 0.0038069982347414834
Epoch: 1335, trainingloss: 0.003386034293380749 | validation loss: 0.003749158315838918
Epoch: 1336, trainingloss: 0.003596258340036705 | validation loss: 0.003947295717001275
Epoch: 1337, trainingloss: 0.0033979192188013678 | validation loss: 0.0037792176714694305
Epoch: 1338, trainingloss: 0.003455105578544979 | validation loss: 0.0038149358695343787
Epoch: 1339, trainingloss: 0.003525223110842606 | validation loss: 0.0038724348628903144
Epoch: 1340, trainingloss: 0.0035745925928404206 | validation loss: 0.0039047753928292605
Epoch: 1341, trainingloss: 0.0036464923141436285 | validation loss: 0.003984342851089746
Epoch: 1342, trainingloss: 0.0034141849417412403 | validation loss: 0.003783246479027509
Epoch: 1343, trainingloss: 0.003566583168298718 | validation loss: 0.003931480412641871
Epoch: 1344, trainingloss: 0.004245783671615792 | validation loss: 0.004474441209771657
Epoch: 1345, trainingloss: 0.0037353952298096703 | validation loss: 0.0040186982344559965
Epoch: 1346, trainingloss: 0.0033652332193699875 | validation loss: 0.003711576714383381
Epoch: 1347, trainingloss: 0.0034413772967543553 | validation loss: 0.0037688212103053147
Epoch: 1348, trainingloss: 0.003925844777117342 | validation loss: 0.0042486566382956194
Epoch: 1349, trainingloss: 0.0034322373237131885 | validation loss: 0.0037762347315023603
Epoch: 1350, trainingloss: 0.003922818534507269 | validation loss: 0.004193711648567982
Epoch: 1351, trainingloss: 0.0036462849437869393 | validation loss: 0.003983407776228914
Epoch: 1352, trainingloss: 0.003533911732099851 | validation loss: 0.003852933438419116
Epoch: 1353, trainingloss: 0.003779293670273175 | validation loss: 0.004066215227301848
Epoch: 1354, trainingloss: 0.0036406669602459286 | validation loss: 0.003983524995376235
Epoch: 1355, trainingloss: 0.0035167090729262577 | validation loss: 0.003833442337395156
Epoch: 1356, trainingloss: 0.00378948186494768 | validation loss: 0.004087229046726602
Epoch: 1357, trainingloss: 0.003766362352458517 | validation loss: 0.004106706217820199
Epoch: 1358, trainingloss: 0.003554270419883818 | validation loss: 0.0039025171414576974
Epoch: 1359, trainingloss: 0.003256497785638486 | validation loss: 0.003614673589243801
Epoch: 1360, trainingloss: 0.003660403703721168 | validation loss: 0.003951838755874773
Epoch: 1361, trainingloss: 0.003878877158733499 | validation loss: 0.004155379118207145
Epoch: 1362, trainingloss: 0.0034618055309354567 | validation loss: 0.003810201104141719
Epoch: 1363, trainingloss: 0.003357028494830226 | validation loss: 0.00370565824338883
Epoch: 1364, trainingloss: 0.003435228914945116 | validation loss: 0.0037884811508336748
Epoch: 1365, trainingloss: 0.0034795469458723644 | validation loss: 0.0038406169785484712
Epoch: 1366, trainingloss: 0.003536592504415814 | validation loss: 0.0038647522024283115
Epoch: 1367, trainingloss: 0.003807143970415329 | validation loss: 0.004152085862864385
Epoch: 1368, trainingloss: 0.003738046305298748 | validation loss: 0.004068409555122003
Epoch: 1369, trainingloss: 0.0038771832428669286 | validation loss: 0.004150522829184163
Epoch: 1370, trainingloss: 0.0035606986047857993 | validation loss: 0.0038989066216601645
Epoch: 1371, trainingloss: 0.003737938673689284 | validation loss: 0.004040293447694506
Epoch: 1372, trainingloss: 0.0034227074424516865 | validation loss: 0.0037969872679822062
Epoch: 1373, trainingloss: 0.003829238967893606 | validation loss: 0.0041799871859798665
Epoch: 1374, trainingloss: 0.0034526872803162943 | validation loss: 0.003805370642651375
Epoch: 1375, trainingloss: 0.0037528546418858846 | validation loss: 0.004076067007300632
Epoch: 1376, trainingloss: 0.004053319407300773 | validation loss: 0.004320511840432146
Epoch: 1377, trainingloss: 0.0036208174523786867 | validation loss: 0.003988839980669489
Epoch: 1378, trainingloss: 0.004233877017465182 | validation loss: 0.004474488357634325
Epoch: 1379, trainingloss: 0.0035001147296919648 | validation loss: 0.0038467169331792093
Epoch: 1380, trainingloss: 0.003970776592957742 | validation loss: 0.004286952038881469
Epoch: 1381, trainingloss: 0.003536167152540682 | validation loss: 0.003869717972665353
Epoch: 1382, trainingloss: 0.0034516442679887512 | validation loss: 0.0037888670228071334
Epoch: 1383, trainingloss: 0.0036346447758854026 | validation loss: 0.003937647447296042
Epoch: 1384, trainingloss: 0.003577537549118517 | validation loss: 0.003927475672647702
Epoch: 1385, trainingloss: 0.003540201221766678 | validation loss: 0.0038814745235847704
Epoch: 1386, trainingloss: 0.0036607102735350693 | validation loss: 0.003981371815641247
Epoch: 1387, trainingloss: 0.0036498103004501212 | validation loss: 0.00397312865985231
Epoch: 1388, trainingloss: 0.003967331863706838 | validation loss: 0.004267675541415121
Epoch: 1389, trainingloss: 0.0035640328549637994 | validation loss: 0.0038920136839591785
Epoch: 1390, trainingloss: 0.0036461679655222312 | validation loss: 0.00399763685095273
Epoch: 1391, trainingloss: 0.004055965720525754 | validation loss: 0.004381179102197645
Epoch: 1392, trainingloss: 0.0035522480652778916 | validation loss: 0.0038962602011985417
Epoch: 1393, trainingloss: 0.003777703320977348 | validation loss: 0.004085211909476799
Epoch: 1394, trainingloss: 0.00375351633256145 | validation loss: 0.004076530617972815
Epoch: 1395, trainingloss: 0.0035692569406382225 | validation loss: 0.003881738386525436
Epoch: 1396, trainingloss: 0.0034495647686588497 | validation loss: 0.0038056529354913503
Epoch: 1397, trainingloss: 0.0032809740830127125 | validation loss: 0.0036347920331366084
Epoch: 1398, trainingloss: 0.003636129958844886 | validation loss: 0.0039717561455660366
Epoch: 1399, trainingloss: 0.003967325893768746 | validation loss: 0.00422644417776098
Epoch: 1400, trainingloss: 0.004098223058208257 | validation loss: 0.0044301152360140695
Epoch: 1401, trainingloss: 0.0036238868647070163 | validation loss: 0.003940005028120057
Epoch: 1402, trainingloss: 0.003617780893282709 | validation loss: 0.003920677063079867
Epoch: 1403, trainingloss: 0.0042316363388289905 | validation loss: 0.004471942871433577
Epoch: 1404, trainingloss: 0.0038480440119527002 | validation loss: 0.0041116880605389875
Epoch: 1405, trainingloss: 0.0034720003715909427 | validation loss: 0.0037856205550199674
Epoch: 1406, trainingloss: 0.0036468697671945003 | validation loss: 0.004001831979911483
Epoch: 1407, trainingloss: 0.003591486491351523 | validation loss: 0.003930188092473938
Epoch: 1408, trainingloss: 0.0036654851001579063 | validation loss: 0.003992550767168018
Epoch: 1409, trainingloss: 0.0034423538778870608 | validation loss: 0.0038174651580059533
Epoch: 1410, trainingloss: 0.004205417965948645 | validation loss: 0.004479112042586384
Epoch: 1411, trainingloss: 0.003583347461165333 | validation loss: 0.003926386940988403
Epoch: 1412, trainingloss: 0.003650513707991743 | validation loss: 0.003997092941682422
Epoch: 1413, trainingloss: 0.0035778552455099314 | validation loss: 0.0038936497279701255
Epoch: 1414, trainingloss: 0.0037311095050806516 | validation loss: 0.004036646005765766
Epoch: 1415, trainingloss: 0.003456026155828697 | validation loss: 0.0038166262590254123
Epoch: 1416, trainingloss: 0.003844815682071163 | validation loss: 0.004145262671390708
Epoch: 1417, trainingloss: 0.0036341135851322903 | validation loss: 0.003992488695031885
Epoch: 1418, trainingloss: 0.0035152338475473045 | validation loss: 0.003857663878671582
Epoch: 1419, trainingloss: 0.0034718339166634857 | validation loss: 0.003824602172332607
Epoch: 1420, trainingloss: 0.0036473538410048065 | validation loss: 0.003996332445908411
Epoch: 1421, trainingloss: 0.003645124055719107 | validation loss: 0.004016475631682187
Epoch: 1422, trainingloss: 0.0036303889808942925 | validation loss: 0.003974027086268112
Epoch: 1423, trainingloss: 0.003642832304827181 | validation loss: 0.0039662178974455755
Epoch: 1424, trainingloss: 0.0036734026488707953 | validation loss: 0.003990284115839825
Epoch: 1425, trainingloss: 0.0033031206405824023 | validation loss: 0.0037022681627471867
Epoch: 1426, trainingloss: 0.0033673165888797626 | validation loss: 0.00376180762114698
Epoch: 1427, trainingloss: 0.0034434820388634384 | validation loss: 0.003799732454485698
Epoch: 1428, trainingloss: 0.003563994969506973 | validation loss: 0.003916362694897755
Epoch: 1429, trainingloss: 0.0032968626426764956 | validation loss: 0.0036828684988633766
Epoch: 1430, trainingloss: 0.0037476741122861256 | validation loss: 0.004065680716102114
Epoch: 1431, trainingloss: 0.0034623056010940154 | validation loss: 0.003802001118272126
Epoch: 1432, trainingloss: 0.0038476586849579258 | validation loss: 0.004165562187639693
Epoch: 1433, trainingloss: 0.0035844960148168083 | validation loss: 0.003946745955972238
Epoch: 1434, trainingloss: 0.0034880596900519097 | validation loss: 0.0038375364658456775
Epoch: 1435, trainingloss: 0.0036341314780151393 | validation loss: 0.003999501542897647
Epoch: 1436, trainingloss: 0.0036654373785620343 | validation loss: 0.003969109622820347
Epoch: 1437, trainingloss: 0.0037083456986531376 | validation loss: 0.004043011395013404
Epoch: 1438, trainingloss: 0.0033672912068641765 | validation loss: 0.003717814334386551
Epoch: 1439, trainingloss: 0.003434872845543407 | validation loss: 0.0037995186138196474
Epoch: 1440, trainingloss: 0.0037257071607108188 | validation loss: 0.0040555588533142594
Epoch: 1441, trainingloss: 0.0037848554815919414 | validation loss: 0.004126791589108999
Epoch: 1442, trainingloss: 0.003380000037799479 | validation loss: 0.003714630459332963
Epoch: 1443, trainingloss: 0.003888843497210064 | validation loss: 0.004244677470992307
Epoch: 1444, trainingloss: 0.0037901657470315693 | validation loss: 0.004093752104374626
Epoch: 1445, trainingloss: 0.0039039310050987142 | validation loss: 0.004223786626659297
Epoch: 1446, trainingloss: 0.0036508622939267644 | validation loss: 0.003980995659129915
Epoch: 1447, trainingloss: 0.0038642111797201465 | validation loss: 0.0041658027367090225
Epoch: 1448, trainingloss: 0.0037384821336718306 | validation loss: 0.00406737568356457
Epoch: 1449, trainingloss: 0.0040498746078739415 | validation loss: 0.004338327662338389
Epoch: 1450, trainingloss: 0.004267478975411185 | validation loss: 0.004530177903113758
Epoch: 1451, trainingloss: 0.0035761141169165112 | validation loss: 0.003948751634495293
Epoch: 1452, trainingloss: 0.003560130390788359 | validation loss: 0.003933426221855356
Epoch: 1453, trainingloss: 0.0037603503157715777 | validation loss: 0.0041079158897674726
Epoch: 1454, trainingloss: 0.00381968609802652 | validation loss: 0.004139800348388611
Epoch: 1455, trainingloss: 0.0034513568919457157 | validation loss: 0.0038266265921042433
Epoch: 1456, trainingloss: 0.0036426871379248013 | validation loss: 0.003955320866289106
Epoch: 1457, trainingloss: 0.0036184325774339774 | validation loss: 0.003982657439837641
Epoch: 1458, trainingloss: 0.003674096717722317 | validation loss: 0.004038006466861988
Epoch: 1459, trainingloss: 0.003629995455331313 | validation loss: 0.003981434236158357
Epoch: 1460, trainingloss: 0.003360106929757441 | validation loss: 0.003702492335125597
Epoch: 1461, trainingloss: 0.003830485098042344 | validation loss: 0.004161650829674706
Epoch: 1462, trainingloss: 0.0037643672424817923 | validation loss: 0.004053535856791085
Epoch: 1463, trainingloss: 0.003646555287258904 | validation loss: 0.004006416734393758
Epoch: 1464, trainingloss: 0.0034254426712427887 | validation loss: 0.0037618500698994397
Epoch: 1465, trainingloss: 0.003173579123635589 | validation loss: 0.0035671711787348378
Epoch: 1466, trainingloss: 0.0038268863505549634 | validation loss: 0.004177487798438813
Epoch: 1467, trainingloss: 0.0033044688475180927 | validation loss: 0.003696849545681485
Epoch: 1468, trainingloss: 0.003756067917979564 | validation loss: 0.004111992198460741
Epoch: 1469, trainingloss: 0.003755109331082781 | validation loss: 0.004097756627076129
Epoch: 1470, trainingloss: 0.003989530129376909 | validation loss: 0.004280491244263591
Epoch: 1471, trainingloss: 0.003528675037624345 | validation loss: 0.003876361618914987
Epoch: 1472, trainingloss: 0.003921025260675489 | validation loss: 0.004231426479477916
Epoch: 1473, trainingloss: 0.003711567517185928 | validation loss: 0.004053338195738533
Epoch: 1474, trainingloss: 0.003486273724480955 | validation loss: 0.0038421018335797626
Epoch: 1475, trainingloss: 0.004042977050598499 | validation loss: 0.0043337953059006135
Epoch: 1476, trainingloss: 0.0037649146581454004 | validation loss: 0.004110366066373467
Epoch: 1477, trainingloss: 0.00339295341211502 | validation loss: 0.003761905552623206
Epoch: 1478, trainingloss: 0.003592185886548906 | validation loss: 0.0039388115664249265
Epoch: 1479, trainingloss: 0.003448027365970637 | validation loss: 0.0038092205272598294
Epoch: 1480, trainingloss: 0.003658345004463125 | validation loss: 0.003990107480685522
Epoch: 1481, trainingloss: 0.0036442141984093525 | validation loss: 0.003996830724365971
Epoch: 1482, trainingloss: 0.0035058719645203133 | validation loss: 0.0038507201327666065
Epoch: 1483, trainingloss: 0.003463133983689731 | validation loss: 0.0038320397477096717
Epoch: 1484, trainingloss: 0.0034925034667421086 | validation loss: 0.0038599514889723152
Epoch: 1485, trainingloss: 0.0032806667206285384 | validation loss: 0.0036315558253641952
Epoch: 1486, trainingloss: 0.0034091161222645156 | validation loss: 0.003747587915201915
Epoch: 1487, trainingloss: 0.003731948079759511 | validation loss: 0.00407192453377856
Epoch: 1488, trainingloss: 0.0035296128965837874 | validation loss: 0.0038723252189040934
Epoch: 1489, trainingloss: 0.004017574743416339 | validation loss: 0.004317125573207245
Epoch: 1490, trainingloss: 0.0035553503656504007 | validation loss: 0.003908684033577644
Epoch: 1491, trainingloss: 0.0035002161146238165 | validation loss: 0.0038405015891865035
Epoch: 1492, trainingloss: 0.0035791138528395165 | validation loss: 0.003928987116746382
Epoch: 1493, trainingloss: 0.0035209781633461007 | validation loss: 0.0038781959927566513
Epoch: 1494, trainingloss: 0.003423745835601315 | validation loss: 0.0037854328559024856
Epoch: 1495, trainingloss: 0.004082079812503768 | validation loss: 0.00443300802336719
Epoch: 1496, trainingloss: 0.003770561517249285 | validation loss: 0.0040936931381724915
Epoch: 1497, trainingloss: 0.004053464763097559 | validation loss: 0.004342225924006862
Epoch: 1498, trainingloss: 0.0036941578413884884 | validation loss: 0.004017327392111147
Epoch: 1499, trainingloss: 0.0036677871560466904 | validation loss: 0.0040116027838595246
Epoch: 1500, trainingloss: 0.0035211164265079686 | validation loss: 0.003890266439530167
Epoch: 1501, trainingloss: 0.003822955978376174 | validation loss: 0.004108019265936223
Epoch: 1502, trainingloss: 0.0036252137686309588 | validation loss: 0.003956800770150342
Epoch: 1503, trainingloss: 0.004171161185054186 | validation loss: 0.004492838323006039
Epoch: 1504, trainingloss: 0.0035206982967297376 | validation loss: 0.0038809523748061054
Epoch: 1505, trainingloss: 0.00391100022719712 | validation loss: 0.004210837044126525
Epoch: 1506, trainingloss: 0.004265336808226631 | validation loss: 0.0045153770340620675
Epoch: 1507, trainingloss: 0.0033100519297339687 | validation loss: 0.003674121285638472
Epoch: 1508, trainingloss: 0.0035547535792395933 | validation loss: 0.003892461605555262
Epoch: 1509, trainingloss: 0.0036916171320871085 | validation loss: 0.004033679213224869
Epoch: 1510, trainingloss: 0.0035203353079771363 | validation loss: 0.003886330377725497
Epoch: 1511, trainingloss: 0.003770975969937146 | validation loss: 0.004087521704777892
Epoch: 1512, trainingloss: 0.0037383300944802585 | validation loss: 0.004042191419121813
Epoch: 1513, trainingloss: 0.003371054846451741 | validation loss: 0.003755076389253273
Epoch: 1514, trainingloss: 0.0037502063824436135 | validation loss: 0.004096275144548685
Epoch: 1515, trainingloss: 0.0032578045208228913 | validation loss: 0.003643367679319681
Epoch: 1516, trainingloss: 0.003607414932172583 | validation loss: 0.0039590218657557736
Epoch: 1517, trainingloss: 0.003861026516598362 | validation loss: 0.0042192597591262935
Epoch: 1518, trainingloss: 0.003735099770403805 | validation loss: 0.0041087393380384125
Epoch: 1519, trainingloss: 0.0034872624607995206 | validation loss: 0.0038208037503856397
Epoch: 1520, trainingloss: 0.0036616956731626983 | validation loss: 0.004004455241015845
Epoch: 1521, trainingloss: 0.0033508852944495017 | validation loss: 0.0037072135059079245
Epoch: 1522, trainingloss: 0.003336149567323375 | validation loss: 0.003712216870584057
Epoch: 1523, trainingloss: 0.0034782358552578507 | validation loss: 0.0038221364151336417
Epoch: 1524, trainingloss: 0.003671270201265409 | validation loss: 0.003991842983682415
Epoch: 1525, trainingloss: 0.004116570397074895 | validation loss: 0.004369686306046584
Epoch: 1526, trainingloss: 0.0045581841581368455 | validation loss: 0.004836959254612917
Epoch: 1527, trainingloss: 0.003899703296735565 | validation loss: 0.004242489902551292
Epoch: 1528, trainingloss: 0.004122023563065477 | validation loss: 0.004453525359766942
Epoch: 1529, trainingloss: 0.004066924122030118 | validation loss: 0.004341417321486028
Epoch: 1530, trainingloss: 0.0034599940995329805 | validation loss: 0.003830983412571037
Epoch: 1531, trainingloss: 0.003499273761811101 | validation loss: 0.0038433136730717664
Epoch: 1532, trainingloss: 0.0033873025869817584 | validation loss: 0.0037854879661446475
Epoch: 1533, trainingloss: 0.0038155277021252004 | validation loss: 0.004173056171188347
Epoch: 1534, trainingloss: 0.0041733060036839706 | validation loss: 0.004421193056494156
Epoch: 1535, trainingloss: 0.003725745435740835 | validation loss: 0.004087601315368635
Epoch: 1536, trainingloss: 0.003615079442950777 | validation loss: 0.003984106917356131
Epoch: 1537, trainingloss: 0.0035144143262983364 | validation loss: 0.0038586969253149575
Epoch: 1538, trainingloss: 0.0033004281381126986 | validation loss: 0.0037072470146385854
Epoch: 1539, trainingloss: 0.0034695916369830216 | validation loss: 0.003793663303982045
Epoch: 1540, trainingloss: 0.003855362977537869 | validation loss: 0.004187340379596227
Epoch: 1541, trainingloss: 0.00346308464231167 | validation loss: 0.0038292273905553317
Epoch: 1542, trainingloss: 0.0033829961612830963 | validation loss: 0.0037446957082264837
Epoch: 1543, trainingloss: 0.0036833094523873364 | validation loss: 0.004043979154738855
Epoch: 1544, trainingloss: 0.0037243733620254587 | validation loss: 0.004069372838473543
Epoch: 1545, trainingloss: 0.0035619424281575648 | validation loss: 0.0038966330704361626
Epoch: 1546, trainingloss: 0.0034045451285283504 | validation loss: 0.0037787534717060277
Epoch: 1547, trainingloss: 0.0034574767999066636 | validation loss: 0.003802066100681236
Epoch: 1548, trainingloss: 0.003506135478922195 | validation loss: 0.003847725297818497
Epoch: 1549, trainingloss: 0.0037501573055336848 | validation loss: 0.004055873979334864
Epoch: 1550, trainingloss: 0.0032085605725550672 | validation loss: 0.003598523422631147
Epoch: 1551, trainingloss: 0.00435623978750362 | validation loss: 0.00461766849174971
Epoch: 1552, trainingloss: 0.003218599375547621 | validation loss: 0.0035960560758920204
Epoch: 1553, trainingloss: 0.004497512375778303 | validation loss: 0.004775933721847526
Epoch: 1554, trainingloss: 0.003606430176403159 | validation loss: 0.003972111427537268
Epoch: 1555, trainingloss: 0.0034004539133664757 | validation loss: 0.00378249202027493
Epoch: 1556, trainingloss: 0.0036760096385497405 | validation loss: 0.003969003397888678
Epoch: 1557, trainingloss: 0.0037317660414477316 | validation loss: 0.004055659706706149
Epoch: 1558, trainingloss: 0.0036760640816445845 | validation loss: 0.003992868797118559
Epoch: 1559, trainingloss: 0.0033814118048160866 | validation loss: 0.0037502960394898226
Epoch: 1560, trainingloss: 0.0035660308117515 | validation loss: 0.003922082720766937
Epoch: 1561, trainingloss: 0.003506863311469225 | validation loss: 0.0038467252982486784
Epoch: 1562, trainingloss: 0.003650334010354813 | validation loss: 0.003986635020821909
Epoch: 1563, trainingloss: 0.0035080875514039668 | validation loss: 0.003882530803339067
Epoch: 1564, trainingloss: 0.0035928625776065416 | validation loss: 0.00396253584925485
Epoch: 1565, trainingloss: 0.0033734676425903466 | validation loss: 0.0037433798665583652
Epoch: 1566, trainingloss: 0.003334889982009927 | validation loss: 0.0037222721997844685
Epoch: 1567, trainingloss: 0.003567319243519573 | validation loss: 0.0039024374875917963
Epoch: 1568, trainingloss: 0.0038134949714929553 | validation loss: 0.0041266470387273865
Epoch: 1569, trainingloss: 0.004263329833087656 | validation loss: 0.004510282361287389
Epoch: 1570, trainingloss: 0.0036803493928538535 | validation loss: 0.0040296361847866
Epoch: 1571, trainingloss: 0.0035738375193505433 | validation loss: 0.003889382142970199
Epoch: 1572, trainingloss: 0.0038380648200001 | validation loss: 0.0041714418588955976
Epoch: 1573, trainingloss: 0.0036070961431587277 | validation loss: 0.00395316943666076
Epoch: 1574, trainingloss: 0.003311123066482085 | validation loss: 0.0036657063754603875
Epoch: 1575, trainingloss: 0.003720799650883093 | validation loss: 0.004060472177376893
Epoch: 1576, trainingloss: 0.0035713935550894006 | validation loss: 0.0039387642539513695
Epoch: 1577, trainingloss: 0.0034970022605965594 | validation loss: 0.0038543942687724922
Epoch: 1578, trainingloss: 0.0036127353033313936 | validation loss: 0.003962896147701237
Epoch: 1579, trainingloss: 0.0035453088314472674 | validation loss: 0.0038878099470560728
Epoch: 1580, trainingloss: 0.0038633273188047683 | validation loss: 0.004187011607128256
Epoch: 1581, trainingloss: 0.0034795877928771248 | validation loss: 0.003849522287118654
Epoch: 1582, trainingloss: 0.003399327812334559 | validation loss: 0.0037714104838626936
Epoch: 1583, trainingloss: 0.003421464535056178 | validation loss: 0.0037839239569337465
Epoch: 1584, trainingloss: 0.00350269895988055 | validation loss: 0.00384049274411476
Epoch: 1585, trainingloss: 0.003707672855001965 | validation loss: 0.004059328005139625
Epoch: 1586, trainingloss: 0.0037749511415173464 | validation loss: 0.0040667268463419675
Epoch: 1587, trainingloss: 0.0033580965469971885 | validation loss: 0.0037228269740750513
Epoch: 1588, trainingloss: 0.003924829138900413 | validation loss: 0.0041898286546185855
Epoch: 1589, trainingloss: 0.003262581467827442 | validation loss: 0.003639824060180753
Epoch: 1590, trainingloss: 0.003472444030151227 | validation loss: 0.003834432846717576
Epoch: 1591, trainingloss: 0.0034636675131563114 | validation loss: 0.0038478129441609525
Epoch: 1592, trainingloss: 0.003789315874538284 | validation loss: 0.0041362966198600064
Epoch: 1593, trainingloss: 0.003579236286581957 | validation loss: 0.0039472727250577985
Epoch: 1594, trainingloss: 0.003651800410038729 | validation loss: 0.003999661577188648
Epoch: 1595, trainingloss: 0.0034803352677559075 | validation loss: 0.003818725126466046
Epoch: 1596, trainingloss: 0.0034553828119684702 | validation loss: 0.0038311298868699013
Epoch: 1597, trainingloss: 0.0034008725260608486 | validation loss: 0.0037632054796774015
Epoch: 1598, trainingloss: 0.0032236840739313906 | validation loss: 0.0036128706267758402
Epoch: 1599, trainingloss: 0.0035539380395789564 | validation loss: 0.003926058707742015
Epoch: 1600, trainingloss: 0.003919109664270644 | validation loss: 0.0041998083477516705
Epoch: 1601, trainingloss: 0.00354660818953177 | validation loss: 0.0039053741860347385
Epoch: 1602, trainingloss: 0.003185309454123106 | validation loss: 0.0035759107361004938
Epoch: 1603, trainingloss: 0.0036512254022136423 | validation loss: 0.003997467725397055
Epoch: 1604, trainingloss: 0.0037070399950117627 | validation loss: 0.004041997288994855
Epoch: 1605, trainingloss: 0.0037209086826076637 | validation loss: 0.004035608120370246
Epoch: 1606, trainingloss: 0.0037003475877022624 | validation loss: 0.004001735298850958
Epoch: 1607, trainingloss: 0.0034095643686769903 | validation loss: 0.0037748965595669807
Epoch: 1608, trainingloss: 0.0036285155393756107 | validation loss: 0.003969083313236372
Epoch: 1609, trainingloss: 0.003571685120374285 | validation loss: 0.003906484488006227
Epoch: 1610, trainingloss: 0.0037367719207144334 | validation loss: 0.004098721985966748
Epoch: 1611, trainingloss: 0.003535799419801813 | validation loss: 0.003906684500050989
Epoch: 1612, trainingloss: 0.0038146417497412167 | validation loss: 0.004125191348782569
Epoch: 1613, trainingloss: 0.003411765578473001 | validation loss: 0.0037941249284064197
Epoch: 1614, trainingloss: 0.003426941641470596 | validation loss: 0.00377251699004363
Epoch: 1615, trainingloss: 0.0036740565354897265 | validation loss: 0.003994581826388112
Epoch: 1616, trainingloss: 0.0035476469443770846 | validation loss: 0.003889201980666874
Epoch: 1617, trainingloss: 0.003767111078263018 | validation loss: 0.0040763597246807936
Epoch: 1618, trainingloss: 0.004115378240455765 | validation loss: 0.004408184094432006
Epoch: 1619, trainingloss: 0.0037300924230033927 | validation loss: 0.00404842359375809
Epoch: 1620, trainingloss: 0.00535682010686901 | validation loss: 0.005549404397219239
Epoch: 1621, trainingloss: 0.00346370002604976 | validation loss: 0.0038376375995385487
Epoch: 1622, trainingloss: 0.0036350172230393157 | validation loss: 0.003944019953551621
Epoch: 1623, trainingloss: 0.0034521254974742626 | validation loss: 0.003818758111242958
Epoch: 1624, trainingloss: 0.0038015557795228355 | validation loss: 0.004119371308216586
Epoch: 1625, trainingloss: 0.0037139987750112466 | validation loss: 0.004062376988249839
Epoch: 1626, trainingloss: 0.00337258771230999 | validation loss: 0.0037331745083340963
Epoch: 1627, trainingloss: 0.003555239474943164 | validation loss: 0.003910584513154687
Epoch: 1628, trainingloss: 0.003472551467735012 | validation loss: 0.0038542110542680377
Epoch: 1629, trainingloss: 0.00414806149617112 | validation loss: 0.004459531861724093
Epoch: 1630, trainingloss: 0.0035520736834181187 | validation loss: 0.003884606988892075
Epoch: 1631, trainingloss: 0.0036106915059974172 | validation loss: 0.003944808238085621
Epoch: 1632, trainingloss: 0.0038992792577074256 | validation loss: 0.004201003344739762
Epoch: 1633, trainingloss: 0.0036303492897480907 | validation loss: 0.00400352782531159
Epoch: 1634, trainingloss: 0.003756207033489411 | validation loss: 0.004074434102095762
Epoch: 1635, trainingloss: 0.003965930449760425 | validation loss: 0.004270229144957176
Epoch: 1636, trainingloss: 0.0034179718598637224 | validation loss: 0.0037861912981930054
Epoch: 1637, trainingloss: 0.0035794073462694967 | validation loss: 0.0039120159986920765
Epoch: 1638, trainingloss: 0.003971883886338706 | validation loss: 0.004262971075528076
Epoch: 1639, trainingloss: 0.003690563112455361 | validation loss: 0.004032506339235187
Epoch: 1640, trainingloss: 0.0032902438300139833 | validation loss: 0.003668829426590439
Epoch: 1641, trainingloss: 0.003232189635343886 | validation loss: 0.003593563073636906
Epoch: 1642, trainingloss: 0.0036705972853677054 | validation loss: 0.004051773165024571
Epoch: 1643, trainingloss: 0.003241728028110417 | validation loss: 0.003641310566553382
Epoch: 1644, trainingloss: 0.003518614184491639 | validation loss: 0.003886422029541356
Epoch: 1645, trainingloss: 0.004128649134573834 | validation loss: 0.0044396622653664385
Epoch: 1646, trainingloss: 0.0035450349087822247 | validation loss: 0.003884198774649005
Epoch: 1647, trainingloss: 0.003361078119836297 | validation loss: 0.003713871762268054
Epoch: 1648, trainingloss: 0.003312265718402082 | validation loss: 0.0036689605468986264
Epoch: 1649, trainingloss: 0.003478575126234608 | validation loss: 0.003837516209524211
Epoch: 1650, trainingloss: 0.0037901117924255844 | validation loss: 0.004134973419816471
Epoch: 1651, trainingloss: 0.003695104100196704 | validation loss: 0.004047024001706475
Epoch: 1652, trainingloss: 0.0038892454687850047 | validation loss: 0.00421111671933353
Epoch: 1653, trainingloss: 0.003397199200415561 | validation loss: 0.0037718451754739234
Epoch: 1654, trainingloss: 0.003401189325947037 | validation loss: 0.0037580594705664823
Epoch: 1655, trainingloss: 0.0035249931230439367 | validation loss: 0.003874815475347637
Epoch: 1656, trainingloss: 0.0039725054771399555 | validation loss: 0.004290914641093067
Epoch: 1657, trainingloss: 0.0039585214363842955 | validation loss: 0.004256598418774724
Epoch: 1658, trainingloss: 0.0033130184158868224 | validation loss: 0.0036942685985235043
Epoch: 1659, trainingloss: 0.004038822940786035 | validation loss: 0.004287304799934511
Epoch: 1660, trainingloss: 0.004006651331712948 | validation loss: 0.004338817256126025
Epoch: 1661, trainingloss: 0.0035319694280237725 | validation loss: 0.0038701029404047474
Epoch: 1662, trainingloss: 0.0033734605830966044 | validation loss: 0.003738639692291048
Epoch: 1663, trainingloss: 0.003918235600677703 | validation loss: 0.004232189352919906
Epoch: 1664, trainingloss: 0.0035050633365939533 | validation loss: 0.0038530832934434395
Epoch: 1665, trainingloss: 0.003881986719126202 | validation loss: 0.004191261180614937
Epoch: 1666, trainingloss: 0.0034702318456499327 | validation loss: 0.0038284637998402173
Epoch: 1667, trainingloss: 0.0037783290644504753 | validation loss: 0.004092662006787941
Epoch: 1668, trainingloss: 0.0035002568105462657 | validation loss: 0.003856159390379264
Epoch: 1669, trainingloss: 0.003397244560429853 | validation loss: 0.0037494003999044494
Epoch: 1670, trainingloss: 0.0036160863325070303 | validation loss: 0.0039260703070871745
Epoch: 1671, trainingloss: 0.003460630464454914 | validation loss: 0.0038279538851203284
Epoch: 1672, trainingloss: 0.0038841590219750757 | validation loss: 0.004156684509715627
Epoch: 1673, trainingloss: 0.0039257697933394176 | validation loss: 0.004249621344342705
Epoch: 1674, trainingloss: 0.0035397833021193555 | validation loss: 0.003883487835202483
Epoch: 1675, trainingloss: 0.003751806344626499 | validation loss: 0.004060898545729779
Epoch: 1676, trainingloss: 0.003462747517729069 | validation loss: 0.003810031541862285
Epoch: 1677, trainingloss: 0.0036882922922582694 | validation loss: 0.00402471301026427
Epoch: 1678, trainingloss: 0.0035860241182145416 | validation loss: 0.003960782016521935
Epoch: 1679, trainingloss: 0.0038704875907300718 | validation loss: 0.004184190499656788
Epoch: 1680, trainingloss: 0.003836262623107544 | validation loss: 0.00418952836895571
Epoch: 1681, trainingloss: 0.003473873610396947 | validation loss: 0.003814932405413773
Epoch: 1682, trainingloss: 0.004151840338202712 | validation loss: 0.004426923173860553
Epoch: 1683, trainingloss: 0.003964579670658216 | validation loss: 0.004290084845399995
Epoch: 1684, trainingloss: 0.0037567755622935203 | validation loss: 0.004113272468775717
Epoch: 1685, trainingloss: 0.004259684588233871 | validation loss: 0.0045507621293295105
Epoch: 1686, trainingloss: 0.0032982264542085224 | validation loss: 0.003661074605450049
Epoch: 1687, trainingloss: 0.003531753378899198 | validation loss: 0.0038751225158291307
Epoch: 1688, trainingloss: 0.003918196732916544 | validation loss: 0.004224051188976119
Epoch: 1689, trainingloss: 0.003982572965218414 | validation loss: 0.004302565560735363
Epoch: 1690, trainingloss: 0.0037020630702656546 | validation loss: 0.004052117534313577
Epoch: 1691, trainingloss: 0.0035442140544898566 | validation loss: 0.00390613848611505
Epoch: 1692, trainingloss: 0.003851579446691126 | validation loss: 0.004179801176821642
Epoch: 1693, trainingloss: 0.004087204268412375 | validation loss: 0.004370623274358941
Epoch: 1694, trainingloss: 0.003613350146991587 | validation loss: 0.003953165147214622
Epoch: 1695, trainingloss: 0.0034763148657603877 | validation loss: 0.003833779438723293
Epoch: 1696, trainingloss: 0.0037683861783235394 | validation loss: 0.004135242139752512
Epoch: 1697, trainingloss: 0.003866720057356598 | validation loss: 0.0041848766962850085
Epoch: 1698, trainingloss: 0.004250848513527076 | validation loss: 0.004534889718209951
Epoch: 1699, trainingloss: 0.003598202561526851 | validation loss: 0.00391507001387574
Epoch: 1700, trainingloss: 0.0034509363915281076 | validation loss: 0.0038043888455262724
Epoch: 1701, trainingloss: 0.0035769808164581754 | validation loss: 0.003911562457888526
Epoch: 1702, trainingloss: 0.004849761945894599 | validation loss: 0.005112970456280384
Epoch: 1703, trainingloss: 0.0035850982031266844 | validation loss: 0.003945471414988855
Epoch: 1704, trainingloss: 0.003980416566416057 | validation loss: 0.004240313160717227
Epoch: 1705, trainingloss: 0.0035335091296140367 | validation loss: 0.0038706466966808933
Epoch: 1706, trainingloss: 0.003657555975985146 | validation loss: 0.00402156420470085
Epoch: 1707, trainingloss: 0.0034347816248800414 | validation loss: 0.0037989631596434116
Epoch: 1708, trainingloss: 0.0034051609441043767 | validation loss: 0.003772191982514377
Epoch: 1709, trainingloss: 0.003423731419319124 | validation loss: 0.003790674785492964
Epoch: 1710, trainingloss: 0.003448215334513415 | validation loss: 0.0038188927365236567
Epoch: 1711, trainingloss: 0.0032623884672449443 | validation loss: 0.003635685303077993
Epoch: 1712, trainingloss: 0.003407565558563097 | validation loss: 0.003787170902989269
Epoch: 1713, trainingloss: 0.0045761370148758185 | validation loss: 0.004829797354389286
Epoch: 1714, trainingloss: 0.003713579346582833 | validation loss: 0.004014889099551209
Epoch: 1715, trainingloss: 0.003740839181611569 | validation loss: 0.0040931535404756655
Epoch: 1716, trainingloss: 0.0037521375084809917 | validation loss: 0.004071905247465302
Epoch: 1717, trainingloss: 0.003498768847014023 | validation loss: 0.0038530521396869886
Epoch: 1718, trainingloss: 0.0038345295533437386 | validation loss: 0.004189991977892022
Epoch: 1719, trainingloss: 0.003962238867675162 | validation loss: 0.004259572521723207
Epoch: 1720, trainingloss: 0.004075738692169133 | validation loss: 0.004407848001414472
Epoch: 1721, trainingloss: 0.0037511136111037418 | validation loss: 0.004069443175748734
Epoch: 1722, trainingloss: 0.003361780054357346 | validation loss: 0.003736302011536644
Epoch: 1723, trainingloss: 0.004101360109974909 | validation loss: 0.004367084847891461
Epoch: 1724, trainingloss: 0.003260689276528528 | validation loss: 0.0036047051007338225
Epoch: 1725, trainingloss: 0.0035917343977093182 | validation loss: 0.003918356746370238
Epoch: 1726, trainingloss: 0.003508874676771819 | validation loss: 0.0038418006206218124
Epoch: 1727, trainingloss: 0.00356219855659498 | validation loss: 0.003918262499488054
Epoch: 1728, trainingloss: 0.0037916092590252275 | validation loss: 0.004126716058032396
Epoch: 1729, trainingloss: 0.0036639055827788034 | validation loss: 0.004017631914219152
Epoch: 1730, trainingloss: 0.0032553273877523503 | validation loss: 0.003680159202455048
Epoch: 1731, trainingloss: 0.0034902160039346967 | validation loss: 0.003838983616884148
Epoch: 1732, trainingloss: 0.003838527875226438 | validation loss: 0.004174040283709276
Epoch: 1733, trainingloss: 0.0037521072210504654 | validation loss: 0.0040514856223853625
Epoch: 1734, trainingloss: 0.003916088034718071 | validation loss: 0.004198696570104354
Epoch: 1735, trainingloss: 0.003422901184065401 | validation loss: 0.003776881698376758
Epoch: 1736, trainingloss: 0.0032903781514316784 | validation loss: 0.0036357763594139884
Epoch: 1737, trainingloss: 0.0035365568184782844 | validation loss: 0.003887368131235814
Epoch: 1738, trainingloss: 0.003417978916943327 | validation loss: 0.0037869041869205036
Epoch: 1739, trainingloss: 0.003178793385607178 | validation loss: 0.0035823490462043987
Epoch: 1740, trainingloss: 0.004255591586814014 | validation loss: 0.004524746576978848
Epoch: 1741, trainingloss: 0.004218688787125075 | validation loss: 0.0044746664473335465
Epoch: 1742, trainingloss: 0.0035805916170262774 | validation loss: 0.003927559798407217
Epoch: 1743, trainingloss: 0.003179931571140818 | validation loss: 0.003555736669752902
Epoch: 1744, trainingloss: 0.003544774220051413 | validation loss: 0.0038830165545286023
Epoch: 1745, trainingloss: 0.003731336283228623 | validation loss: 0.00405089173078612
Epoch: 1746, trainingloss: 0.003557357157098572 | validation loss: 0.0038901142788830695
Epoch: 1747, trainingloss: 0.00367235674932332 | validation loss: 0.00400532321593393
Epoch: 1748, trainingloss: 0.003986939032056693 | validation loss: 0.004303590587905861
Epoch: 1749, trainingloss: 0.003705286363668935 | validation loss: 0.004032751849032786
Epoch: 1750, trainingloss: 0.0037922595450345397 | validation loss: 0.0041464446517039295
Epoch: 1751, trainingloss: 0.0034334214963343173 | validation loss: 0.0037725642920680997
Epoch: 1752, trainingloss: 0.003322580577722335 | validation loss: 0.0036964013319900836
Epoch: 1753, trainingloss: 0.003807976325703555 | validation loss: 0.004122253771183732
Epoch: 1754, trainingloss: 0.004039213545274521 | validation loss: 0.0043583639261006125
Epoch: 1755, trainingloss: 0.0034762909425671497 | validation loss: 0.0038120083042482177
Epoch: 1756, trainingloss: 0.0036085658745291065 | validation loss: 0.003971953541979933
Epoch: 1757, trainingloss: 0.0036418513054962518 | validation loss: 0.0039876774726198255
Epoch: 1758, trainingloss: 0.0033112019674512924 | validation loss: 0.0036966401586435035
Epoch: 1759, trainingloss: 0.0033105246517193556 | validation loss: 0.0036908507127464147
Epoch: 1760, trainingloss: 0.0035909555403616325 | validation loss: 0.0039225143770199875
Epoch: 1761, trainingloss: 0.003454970776332772 | validation loss: 0.003807351078145706
Epoch: 1762, trainingloss: 0.00333920731027811 | validation loss: 0.0037169150895376532
Epoch: 1763, trainingloss: 0.003611459295547563 | validation loss: 0.003957730616691623
Epoch: 1764, trainingloss: 0.00337368312272813 | validation loss: 0.0037231990829139803
Epoch: 1765, trainingloss: 0.0032014142499794773 | validation loss: 0.0036051666484084813
Epoch: 1766, trainingloss: 0.003438624785269981 | validation loss: 0.003811981221946591
Epoch: 1767, trainingloss: 0.0035872177349557176 | validation loss: 0.003928827773375502
Epoch: 1768, trainingloss: 0.0035013240682921845 | validation loss: 0.0038429554879121476
Epoch: 1769, trainingloss: 0.0037535542909319843 | validation loss: 0.004066687500608324
Epoch: 1770, trainingloss: 0.004250905554295129 | validation loss: 0.0045197051828810945
Epoch: 1771, trainingloss: 0.00345331228493772 | validation loss: 0.003804724696565796
Epoch: 1772, trainingloss: 0.003666465804993695 | validation loss: 0.003980250928619928
Epoch: 1773, trainingloss: 0.0039026830026234437 | validation loss: 0.004216197683333792
Epoch: 1774, trainingloss: 0.0033059219532511164 | validation loss: 0.0036820582164653003
Epoch: 1775, trainingloss: 0.0042883417742264895 | validation loss: 0.00455038866746204
Epoch: 1776, trainingloss: 0.003705729050919806 | validation loss: 0.004034352930764392
Epoch: 1777, trainingloss: 0.0034874297900559497 | validation loss: 0.0038322475858984318
Epoch: 1778, trainingloss: 0.0036490113190249117 | validation loss: 0.004024640519562078
Epoch: 1779, trainingloss: 0.003788232003015115 | validation loss: 0.004087476206860158
Epoch: 1780, trainingloss: 0.003491920101574917 | validation loss: 0.00380606457107463
Epoch: 1781, trainingloss: 0.0032557573794048692 | validation loss: 0.003631088934480041
Epoch: 1782, trainingloss: 0.004158997467945161 | validation loss: 0.004421143338908831
Epoch: 1783, trainingloss: 0.0038574485206799096 | validation loss: 0.004166594136442166
Epoch: 1784, trainingloss: 0.003289624776869627 | validation loss: 0.003678000684268868
Epoch: 1785, trainingloss: 0.003663379856626374 | validation loss: 0.003990111073087694
Epoch: 1786, trainingloss: 0.003332015930338035 | validation loss: 0.003707088778129756
Epoch: 1787, trainingloss: 0.003442437228057402 | validation loss: 0.003804575089228259
Epoch: 1788, trainingloss: 0.003518923719861347 | validation loss: 0.0038803255146130718
Epoch: 1789, trainingloss: 0.003542203675088365 | validation loss: 0.0038763737512778305
Epoch: 1790, trainingloss: 0.004397188153374762 | validation loss: 0.004678175948103643
Epoch: 1791, trainingloss: 0.003388011448831069 | validation loss: 0.0037562729110624266
Epoch: 1792, trainingloss: 0.0034339545577425474 | validation loss: 0.003811072658499721
Epoch: 1793, trainingloss: 0.0036358602512255233 | validation loss: 0.003943947481273303
Epoch: 1794, trainingloss: 0.004010303424969216 | validation loss: 0.004311394964405479
Epoch: 1795, trainingloss: 0.0034943825671250764 | validation loss: 0.0038424663505502183
Epoch: 1796, trainingloss: 0.004096450911452286 | validation loss: 0.004400182766899887
Epoch: 1797, trainingloss: 0.004500877868513292 | validation loss: 0.004746239791448332
Epoch: 1798, trainingloss: 0.003864995060195693 | validation loss: 0.004185981329412352
Epoch: 1799, trainingloss: 0.0036136030881837415 | validation loss: 0.003923824549082993
Epoch: 1800, trainingloss: 0.00364218137071846 | validation loss: 0.0040011998898513215
Epoch: 1801, trainingloss: 0.004250344596865665 | validation loss: 0.004512791743037569
Epoch: 1802, trainingloss: 0.0035204813401019104 | validation loss: 0.003873191876078362
Epoch: 1803, trainingloss: 0.004152467756441194 | validation loss: 0.004435878563303875
Epoch: 1804, trainingloss: 0.0034891397764651613 | validation loss: 0.003826458305531366
Epoch: 1805, trainingloss: 0.003910877477114293 | validation loss: 0.004186820635564291
Epoch: 1806, trainingloss: 0.003808778227093515 | validation loss: 0.00413212037831936
Epoch: 1807, trainingloss: 0.005070346564784273 | validation loss: 0.00532916206231473
Epoch: 1808, trainingloss: 0.00398115657152977 | validation loss: 0.004265754355047072
Epoch: 1809, trainingloss: 0.004125509121323593 | validation loss: 0.00440761895575464
Epoch: 1810, trainingloss: 0.0036482938101318977 | validation loss: 0.00398825051997643
Epoch: 1811, trainingloss: 0.003550364615988562 | validation loss: 0.0038778044596823663
Epoch: 1812, trainingloss: 0.0037301785306242054 | validation loss: 0.00407640271345098
Epoch: 1813, trainingloss: 0.00338028693597319 | validation loss: 0.0037458301944339333
Epoch: 1814, trainingloss: 0.003298354288281618 | validation loss: 0.0036785829447323563
Epoch: 1815, trainingloss: 0.003365726864959521 | validation loss: 0.003730131681986167
Epoch: 1816, trainingloss: 0.003757382482463067 | validation loss: 0.004106163482171189
Epoch: 1817, trainingloss: 0.003557037044327715 | validation loss: 0.003923930276137142
Epoch: 1818, trainingloss: 0.0034926866110150953 | validation loss: 0.0038447422337369148
Epoch: 1819, trainingloss: 0.003637805351623937 | validation loss: 0.003972564749333876
Epoch: 1820, trainingloss: 0.0037333356766281996 | validation loss: 0.004072555192156725
Epoch: 1821, trainingloss: 0.0032097684952832966 | validation loss: 0.003604113549199885
Epoch: 1822, trainingloss: 0.003988662693677379 | validation loss: 0.00426779970794543
Epoch: 1823, trainingloss: 0.003283219014386033 | validation loss: 0.003683678641920103
Epoch: 1824, trainingloss: 0.0032469078375044307 | validation loss: 0.003627225629143031
Epoch: 1825, trainingloss: 0.004065953943173289 | validation loss: 0.00435990990340856
Epoch: 1826, trainingloss: 0.0032896130376974257 | validation loss: 0.003690181984694948
Epoch: 1827, trainingloss: 0.003752959316428281 | validation loss: 0.004104417608031421
Epoch: 1828, trainingloss: 0.0036431936156910553 | validation loss: 0.004002529960003699
Epoch: 1829, trainingloss: 0.004271413985505514 | validation loss: 0.00453308303459174
Epoch: 1830, trainingloss: 0.003886938754835224 | validation loss: 0.004210494452188715
Epoch: 1831, trainingloss: 0.003275598673275975 | validation loss: 0.003649378204127182
Epoch: 1832, trainingloss: 0.0032378801423445834 | validation loss: 0.0036310924683298227
Epoch: 1833, trainingloss: 0.0033792251495112367 | validation loss: 0.0037096410398469765
Epoch: 1834, trainingloss: 0.003473442104033789 | validation loss: 0.0038501353102374865
Epoch: 1835, trainingloss: 0.00325812540084101 | validation loss: 0.003680848724051564
Epoch: 1836, trainingloss: 0.0036039175719490045 | validation loss: 0.003942714639604665
Epoch: 1837, trainingloss: 0.0042033392117324896 | validation loss: 0.004485854987730387
Epoch: 1838, trainingloss: 0.0036435148840224755 | validation loss: 0.003954248758329948
Epoch: 1839, trainingloss: 0.0036324543899308795 | validation loss: 0.003967172853744283
Epoch: 1840, trainingloss: 0.004171036355786598 | validation loss: 0.0044519385968110154
Epoch: 1841, trainingloss: 0.0036842949156622256 | validation loss: 0.003992395942499122
Epoch: 1842, trainingloss: 0.004213082819484642 | validation loss: 0.004470549153634877
Epoch: 1843, trainingloss: 0.0035423007675726118 | validation loss: 0.0038905123390550033
Epoch: 1844, trainingloss: 0.0036934850218569132 | validation loss: 0.004015022858523687
Epoch: 1845, trainingloss: 0.003478823758514683 | validation loss: 0.003832816153929941
Epoch: 1846, trainingloss: 0.003443049330497176 | validation loss: 0.0038043890319456593
Epoch: 1847, trainingloss: 0.004088651186455701 | validation loss: 0.0044008999501244685
Epoch: 1848, trainingloss: 0.0035661679483830894 | validation loss: 0.003912173813519151
Epoch: 1849, trainingloss: 0.0035540337943849956 | validation loss: 0.0038924453209376706
Epoch: 1850, trainingloss: 0.003390622457063098 | validation loss: 0.00376338341521722
Epoch: 1851, trainingloss: 0.003180658075887397 | validation loss: 0.003586220110380237
Epoch: 1852, trainingloss: 0.0035190990969078627 | validation loss: 0.0038737210007885963
Epoch: 1853, trainingloss: 0.003574194686084364 | validation loss: 0.0039101170535066005
Epoch: 1854, trainingloss: 0.003347426263582123 | validation loss: 0.0037329497229469694
Epoch: 1855, trainingloss: 0.004004508189610689 | validation loss: 0.00428966411442795
Epoch: 1856, trainingloss: 0.003751653205541649 | validation loss: 0.004102210959013078
Epoch: 1857, trainingloss: 0.003978828851096125 | validation loss: 0.004303722560466558
Epoch: 1858, trainingloss: 0.003985346567257125 | validation loss: 0.004304662765434033
Epoch: 1859, trainingloss: 0.003437048084588676 | validation loss: 0.0037957577845850942
Epoch: 1860, trainingloss: 0.003390284299209607 | validation loss: 0.0037719611327798985
Epoch: 1861, trainingloss: 0.003651426948016143 | validation loss: 0.003973689752016251
Epoch: 1862, trainingloss: 0.0040814790852557355 | validation loss: 0.004374872154600328
Epoch: 1863, trainingloss: 0.0034301094842794214 | validation loss: 0.0037833044142620864
Epoch: 1864, trainingloss: 0.004373058150009354 | validation loss: 0.004620727055027352
Epoch: 1865, trainingloss: 0.0036053390005669214 | validation loss: 0.003942555105008245
Epoch: 1866, trainingloss: 0.0035972326621295566 | validation loss: 0.003937107927284596
Epoch: 1867, trainingloss: 0.00405930817873819 | validation loss: 0.004328687438916388
Epoch: 1868, trainingloss: 0.0040148152702125335 | validation loss: 0.004280663626441156
Epoch: 1869, trainingloss: 0.00389211078738365 | validation loss: 0.004214464066183787
Epoch: 1870, trainingloss: 0.003642262064019313 | validation loss: 0.003974045211941812
Epoch: 1871, trainingloss: 0.003462026503209812 | validation loss: 0.0038288815506674952
Epoch: 1872, trainingloss: 0.0039621606318646346 | validation loss: 0.004252414279963673
Epoch: 1873, trainingloss: 0.00381386194145963 | validation loss: 0.004131146641751948
Epoch: 1874, trainingloss: 0.0036443622043458037 | validation loss: 0.00398790594350798
Epoch: 1875, trainingloss: 0.003516875818853478 | validation loss: 0.0038842573404917033
Epoch: 1876, trainingloss: 0.0035541728792465293 | validation loss: 0.003909534818186444
Epoch: 1877, trainingloss: 0.0035394460416684824 | validation loss: 0.003897840977129126
Epoch: 1878, trainingloss: 0.003426504053919943 | validation loss: 0.0037465335376502275
Epoch: 1879, trainingloss: 0.003527409277553105 | validation loss: 0.0038909765046131577
Epoch: 1880, trainingloss: 0.003332999921200101 | validation loss: 0.0037350726655792565
Epoch: 1881, trainingloss: 0.0036677698041169948 | validation loss: 0.004001232715458085
Epoch: 1882, trainingloss: 0.0033795412422647757 | validation loss: 0.003734204967606452
Epoch: 1883, trainingloss: 0.0034897862108498735 | validation loss: 0.0038204093113682275
Epoch: 1884, trainingloss: 0.0035983925466564317 | validation loss: 0.003942209392411879
Epoch: 1885, trainingloss: 0.00368411342069879 | validation loss: 0.004062028390488185
Epoch: 1886, trainingloss: 0.003618722264311012 | validation loss: 0.003978122786035509
Epoch: 1887, trainingloss: 0.0034497815719721175 | validation loss: 0.003820800589929981
Epoch: 1888, trainingloss: 0.0037200749113470016 | validation loss: 0.0040581387639292395
Epoch: 1889, trainingloss: 0.003634678235280606 | validation loss: 0.004000305811158074
Epoch: 1890, trainingloss: 0.0034939624225838123 | validation loss: 0.003869823805992107
Epoch: 1891, trainingloss: 0.0038163634832668386 | validation loss: 0.004143507569829431
Epoch: 1892, trainingloss: 0.004264504725577305 | validation loss: 0.0045593902929358734
Epoch: 1893, trainingloss: 0.003610114845757329 | validation loss: 0.003974074495345639
Epoch: 1894, trainingloss: 0.004493476612423019 | validation loss: 0.004791445482090842
Epoch: 1895, trainingloss: 0.003508572239162699 | validation loss: 0.0038381371852933897
Epoch: 1896, trainingloss: 0.0038755651742512684 | validation loss: 0.004182658256676295
Epoch: 1897, trainingloss: 0.004080665596566686 | validation loss: 0.004382847222937808
Epoch: 1898, trainingloss: 0.0034751547822715525 | validation loss: 0.003846570076117551
Epoch: 1899, trainingloss: 0.00330405503533578 | validation loss: 0.0036910512184673942
Epoch: 1900, trainingloss: 0.004152667792500015 | validation loss: 0.004472344167551834
Epoch: 1901, trainingloss: 0.0034485513963180155 | validation loss: 0.003816698898089937
Epoch: 1902, trainingloss: 0.0035251910055860087 | validation loss: 0.0038738103045844897
Epoch: 1903, trainingloss: 0.0036319216870493764 | validation loss: 0.0039548981675882715
Epoch: 1904, trainingloss: 0.0038998430619200187 | validation loss: 0.004159588643411404
Epoch: 1905, trainingloss: 0.003276116687562903 | validation loss: 0.0036472967802026668
Epoch: 1906, trainingloss: 0.00417939930433529 | validation loss: 0.004489308614445409
Epoch: 1907, trainingloss: 0.0043660971738638385 | validation loss: 0.004652975439050705
Epoch: 1908, trainingloss: 0.0035544740619403944 | validation loss: 0.0039091989066294235
Epoch: 1909, trainingloss: 0.0035843370600483347 | validation loss: 0.003920874165304816
Epoch: 1910, trainingloss: 0.004123888260512714 | validation loss: 0.004400548221198355
Epoch: 1911, trainingloss: 0.0034714874432099636 | validation loss: 0.0038290598432746846
Epoch: 1912, trainingloss: 0.003550711655859827 | validation loss: 0.003910235776163621
Epoch: 1913, trainingloss: 0.0036711944720784744 | validation loss: 0.0040101896424533535
Epoch: 1914, trainingloss: 0.0034012764176646385 | validation loss: 0.0037602290498152434
Epoch: 1915, trainingloss: 0.0037945624640224125 | validation loss: 0.00409396535792847
Epoch: 1916, trainingloss: 0.003940126508607812 | validation loss: 0.004247860445904138
Epoch: 1917, trainingloss: 0.003650619348059258 | validation loss: 0.004037160314177962
Epoch: 1918, trainingloss: 0.004085806713405031 | validation loss: 0.004353307405323251
Epoch: 1919, trainingloss: 0.003753773114726288 | validation loss: 0.004101061336343928
Epoch: 1920, trainingloss: 0.0038372679214118714 | validation loss: 0.004159085952235667
Epoch: 1921, trainingloss: 0.003777872657471942 | validation loss: 0.004107104616701791
Epoch: 1922, trainingloss: 0.0037427575266678064 | validation loss: 0.00405679472024396
Epoch: 1923, trainingloss: 0.0038266535090596813 | validation loss: 0.004116422434618815
Epoch: 1924, trainingloss: 0.004114686650517134 | validation loss: 0.004386863311350629
Epoch: 1925, trainingloss: 0.0037529183968786854 | validation loss: 0.004079810893171256
Epoch: 1926, trainingloss: 0.004052982061579347 | validation loss: 0.004314882187183923
Epoch: 1927, trainingloss: 0.0034595070190929214 | validation loss: 0.0038140640915281685
Epoch: 1928, trainingloss: 0.0036025679676205406 | validation loss: 0.003937769072465334
Epoch: 1929, trainingloss: 0.004168968316722006 | validation loss: 0.0044616750199716415
Epoch: 1930, trainingloss: 0.003162342765779171 | validation loss: 0.003566029018591446
Epoch: 1931, trainingloss: 0.0034514057034088653 | validation loss: 0.003844453565022097
Epoch: 1932, trainingloss: 0.003980422744946438 | validation loss: 0.00426404329230785
Epoch: 1933, trainingloss: 0.003456208806478434 | validation loss: 0.0037779783797599713
Epoch: 1934, trainingloss: 0.003767833337284885 | validation loss: 0.004113136763366307
Epoch: 1935, trainingloss: 0.0035028436464926626 | validation loss: 0.0038641494875515463
Epoch: 1936, trainingloss: 0.003372066615435336 | validation loss: 0.003763822065833053
Epoch: 1937, trainingloss: 0.00377979206410512 | validation loss: 0.004044326786511324
Epoch: 1938, trainingloss: 0.004088150493851985 | validation loss: 0.004353290580525546
Epoch: 1939, trainingloss: 0.004090300927090746 | validation loss: 0.004394735234717237
Epoch: 1940, trainingloss: 0.0034611364481018903 | validation loss: 0.003820996946160153
Epoch: 1941, trainingloss: 0.00427786323693432 | validation loss: 0.004536303564073486
Epoch: 1942, trainingloss: 0.0034588797562611555 | validation loss: 0.003825193665546233
Epoch: 1943, trainingloss: 0.004461579891016388 | validation loss: 0.0047032898246889545
Epoch: 1944, trainingloss: 0.004217841223238354 | validation loss: 0.004544568211204895
Epoch: 1945, trainingloss: 0.0036036395085710937 | validation loss: 0.003925759552733684
Epoch: 1946, trainingloss: 0.003629059992557565 | validation loss: 0.003946407191449194
Epoch: 1947, trainingloss: 0.0038335586519379094 | validation loss: 0.004171361653775638
Epoch: 1948, trainingloss: 0.0033606831006482026 | validation loss: 0.0037388016081224677
Epoch: 1949, trainingloss: 0.003600374125628781 | validation loss: 0.003959774185432346
Epoch: 1950, trainingloss: 0.0034252332188093584 | validation loss: 0.003792500186510561
Epoch: 1951, trainingloss: 0.003533771287084249 | validation loss: 0.003863436712706384
Epoch: 1952, trainingloss: 0.003710049545022001 | validation loss: 0.004040885353476986
Epoch: 1953, trainingloss: 0.0042907264482810676 | validation loss: 0.004567884525179336
Epoch: 1954, trainingloss: 0.003701270829787609 | validation loss: 0.0040184745271782405
Epoch: 1955, trainingloss: 0.0034452619319540346 | validation loss: 0.003803928002845315
Epoch: 1956, trainingloss: 0.00367239930957943 | validation loss: 0.003999546513403845
Epoch: 1957, trainingloss: 0.003547652605515114 | validation loss: 0.0038630999235777152
Epoch: 1958, trainingloss: 0.003896377898717535 | validation loss: 0.0042155304795032595
Epoch: 1959, trainingloss: 0.004107462382288403 | validation loss: 0.004385833497992448
Epoch: 1960, trainingloss: 0.0038396587278607527 | validation loss: 0.004170246559155005
Epoch: 1961, trainingloss: 0.003511599953860499 | validation loss: 0.003883947562343593
Epoch: 1962, trainingloss: 0.003679039184265912 | validation loss: 0.004013637003623289
Epoch: 1963, trainingloss: 0.004131491906830178 | validation loss: 0.004449202147270685
Epoch: 1964, trainingloss: 0.0038711675045682513 | validation loss: 0.004183667566445699
Epoch: 1965, trainingloss: 0.003923588482315681 | validation loss: 0.00425426068082339
Epoch: 1966, trainingloss: 0.0036799394914075654 | validation loss: 0.00400492483031972
Epoch: 1967, trainingloss: 0.003718298907357857 | validation loss: 0.00401941469629829
Epoch: 1968, trainingloss: 0.0035578609389595784 | validation loss: 0.0038998773470183424
Epoch: 1969, trainingloss: 0.0033180916236627525 | validation loss: 0.0036626561454425216
Epoch: 1970, trainingloss: 0.0033845496628290518 | validation loss: 0.0037888337439831426
Epoch: 1971, trainingloss: 0.0037769483023569633 | validation loss: 0.004054084132046655
Epoch: 1972, trainingloss: 0.003308482988280913 | validation loss: 0.003689008830869015
Epoch: 1973, trainingloss: 0.0036034047575645486 | validation loss: 0.003952123124479942
Epoch: 1974, trainingloss: 0.003399696971621558 | validation loss: 0.003764330057739455
Epoch: 1975, trainingloss: 0.004137930900437032 | validation loss: 0.004424766689568355
Epoch: 1976, trainingloss: 0.0032923427405935086 | validation loss: 0.0036780038532027346
Epoch: 1977, trainingloss: 0.0038679875673980953 | validation loss: 0.004181065963527326
Epoch: 1978, trainingloss: 0.0034155531886856175 | validation loss: 0.003785043130908861
Epoch: 1979, trainingloss: 0.0035683536852403443 | validation loss: 0.003893701365597932
Epoch: 1980, trainingloss: 0.003833287611048302 | validation loss: 0.004150815986487611
Epoch: 1981, trainingloss: 0.003465814561459517 | validation loss: 0.003807826904928602
Epoch: 1982, trainingloss: 0.003947526484863917 | validation loss: 0.0042276436682284375
Epoch: 1983, trainingloss: 0.003310405982123537 | validation loss: 0.0036872077226005958
Epoch: 1984, trainingloss: 0.0031508407729890337 | validation loss: 0.0035489180157879004
Epoch: 1985, trainingloss: 0.0034487334608126288 | validation loss: 0.0038040941572630217
Epoch: 1986, trainingloss: 0.0039727026585056335 | validation loss: 0.004284486711099814
Epoch: 1987, trainingloss: 0.0035162106577430892 | validation loss: 0.0038645377664442144
Epoch: 1988, trainingloss: 0.003423297162489483 | validation loss: 0.0038008351498317688
Epoch: 1989, trainingloss: 0.003601084141422054 | validation loss: 0.003951142734103501
Epoch: 1990, trainingloss: 0.003855536134670692 | validation loss: 0.004124691393341808
Epoch: 1991, trainingloss: 0.00330969051095868 | validation loss: 0.0036811328788898374
Epoch: 1992, trainingloss: 0.0036459807354506024 | validation loss: 0.003961152191746376
Epoch: 1993, trainingloss: 0.004099465702712539 | validation loss: 0.004374404321569237
Epoch: 1994, trainingloss: 0.0035801738936647133 | validation loss: 0.0039501603863905796
Epoch: 1995, trainingloss: 0.003978199405077569 | validation loss: 0.004301383580811602
Epoch: 1996, trainingloss: 0.0039830557380979275 | validation loss: 0.004266572608703227
Epoch: 1997, trainingloss: 0.0035293521771134237 | validation loss: 0.003870076137216054
Epoch: 1998, trainingloss: 0.004011894926089593 | validation loss: 0.004313980422372076
Epoch: 1999, trainingloss: 0.0038240331556383326 | validation loss: 0.004134818217353514
Epoch: 2000, trainingloss: 0.0032643294295737774 | validation loss: 0.0036550325076497173
Epoch: 2001, trainingloss: 0.003494256574607577 | validation loss: 0.0038502073915877844
Epoch: 2002, trainingloss: 0.003943734461833603 | validation loss: 0.00427637797052661
Epoch: 2003, trainingloss: 0.003557492027997828 | validation loss: 0.003901001094084448
Epoch: 2004, trainingloss: 0.0033183013836248568 | validation loss: 0.0036836354570351404
Epoch: 2005, trainingloss: 0.00398895963700273 | validation loss: 0.004263766960384062
Epoch: 2006, trainingloss: 0.0036952905922153848 | validation loss: 0.004058713697759999
Epoch: 2007, trainingloss: 0.003807449273202898 | validation loss: 0.004155381567449753
Epoch: 2008, trainingloss: 0.0035821967698785044 | validation loss: 0.003930311655352242
Epoch: 2009, trainingloss: 0.003938139615811428 | validation loss: 0.004226227445507988
Epoch: 2010, trainingloss: 0.0035027674680243935 | validation loss: 0.0038183433601374373
Epoch: 2011, trainingloss: 0.003650608746059332 | validation loss: 0.003957172493866283
Epoch: 2012, trainingloss: 0.0036580150864325843 | validation loss: 0.003961142412674603
Epoch: 2013, trainingloss: 0.0036130960045570007 | validation loss: 0.003955737729592822
Epoch: 2014, trainingloss: 0.003967536742849435 | validation loss: 0.004275053197144192
Epoch: 2015, trainingloss: 0.0035666623077361286 | validation loss: 0.003926970491525678
Epoch: 2016, trainingloss: 0.00313665575866274 | validation loss: 0.0035298213356292764
Epoch: 2017, trainingloss: 0.0036420003836473477 | validation loss: 0.003975186407696892
Epoch: 2018, trainingloss: 0.0038218675274876617 | validation loss: 0.004161865267433063
Epoch: 2019, trainingloss: 0.0037965021216285768 | validation loss: 0.004133061445240676
Epoch: 2020, trainingloss: 0.003416438920731116 | validation loss: 0.0037974688085376635
Epoch: 2021, trainingloss: 0.0036121480400475433 | validation loss: 0.003943273260344665
Epoch: 2022, trainingloss: 0.003759768588939304 | validation loss: 0.004042691364454823
Epoch: 2023, trainingloss: 0.0036014780655061166 | validation loss: 0.003938558216810222
Epoch: 2024, trainingloss: 0.004463242517883655 | validation loss: 0.004706028678467423
Epoch: 2025, trainingloss: 0.003533272295934164 | validation loss: 0.0038923531449527944
Epoch: 2026, trainingloss: 0.0036607533235765316 | validation loss: 0.00401170390079442
Epoch: 2027, trainingloss: 0.00405987383523957 | validation loss: 0.0043804280974482235
Epoch: 2028, trainingloss: 0.004050631472997989 | validation loss: 0.004370065164651151
Epoch: 2029, trainingloss: 0.003453033457260793 | validation loss: 0.0038228482250221275
Epoch: 2030, trainingloss: 0.0035836581216399047 | validation loss: 0.003918321655141035
Epoch: 2031, trainingloss: 0.003786085444596766 | validation loss: 0.004094841365874004
Epoch: 2032, trainingloss: 0.0039269451024499 | validation loss: 0.004221412379020707
Epoch: 2033, trainingloss: 0.003650881966016608 | validation loss: 0.003975775265319843
Epoch: 2034, trainingloss: 0.00362292899302859 | validation loss: 0.003958421443883683
Epoch: 2035, trainingloss: 0.004089759638772573 | validation loss: 0.004379948704127826
Epoch: 2036, trainingloss: 0.003532939823708256 | validation loss: 0.0038990353737908563
Epoch: 2037, trainingloss: 0.003700496037149822 | validation loss: 0.004049144732605611
Epoch: 2038, trainingloss: 0.0036690909911002065 | validation loss: 0.00397036937718539
Epoch: 2039, trainingloss: 0.0039045196072999516 | validation loss: 0.004203658014579854
Epoch: 2040, trainingloss: 0.0035992934658706467 | validation loss: 0.003931644671203352
Epoch: 2041, trainingloss: 0.0036431664617089625 | validation loss: 0.003960355230483065
Epoch: 2042, trainingloss: 0.003713062513110404 | validation loss: 0.004048135401182021
Epoch: 2043, trainingloss: 0.004026824665823864 | validation loss: 0.004335455111533027
Epoch: 2044, trainingloss: 0.0036776180763399514 | validation loss: 0.004017737947365251
Epoch: 2045, trainingloss: 0.0033473565289012866 | validation loss: 0.003706065924936442
Epoch: 2046, trainingloss: 0.0038319686512512533 | validation loss: 0.004124675023277808
Epoch: 2047, trainingloss: 0.003400578380741809 | validation loss: 0.003803002831040289
Epoch: 2048, trainingloss: 0.003394652856611741 | validation loss: 0.0037635395528129423
Epoch: 2049, trainingloss: 0.003524787215146317 | validation loss: 0.003890152287392668
Epoch: 2050, trainingloss: 0.004485699881918866 | validation loss: 0.004725288022023228
Epoch: 2051, trainingloss: 0.004138900474052651 | validation loss: 0.004392933138317299
Epoch: 2052, trainingloss: 0.004007087034423792 | validation loss: 0.004321609597343744
Epoch: 2053, trainingloss: 0.003833893436602425 | validation loss: 0.00414222713716717
Epoch: 2054, trainingloss: 0.004641768774328691 | validation loss: 0.0048750620902663945
Epoch: 2055, trainingloss: 0.0034599518627625586 | validation loss: 0.003832240690232831
Epoch: 2056, trainingloss: 0.004014170386478094 | validation loss: 0.004296475484029278
Epoch: 2057, trainingloss: 0.004024918954373132 | validation loss: 0.004314214751526472
Epoch: 2058, trainingloss: 0.0037586754506267546 | validation loss: 0.00406796804516687
Epoch: 2059, trainingloss: 0.00392596804368139 | validation loss: 0.004252817524149492
Epoch: 2060, trainingloss: 0.003628578608573328 | validation loss: 0.003949191460894805
Epoch: 2061, trainingloss: 0.003351096637892146 | validation loss: 0.003729933526607809
Epoch: 2062, trainingloss: 0.003833962958602285 | validation loss: 0.004167116686159743
Epoch: 2063, trainingloss: 0.003265755101131427 | validation loss: 0.0036502622976081825
Epoch: 2064, trainingloss: 0.0037031781226567894 | validation loss: 0.0040170722801121045
Epoch: 2065, trainingloss: 0.003346144055020106 | validation loss: 0.003721377255849896
Epoch: 2066, trainingloss: 0.003855197571070377 | validation loss: 0.0041459652668621805
Epoch: 2067, trainingloss: 0.003964720084681187 | validation loss: 0.0042069591375060045
Epoch: 2068, trainingloss: 0.0042934183519237525 | validation loss: 0.004597352729685056
Epoch: 2069, trainingloss: 0.003603125992831201 | validation loss: 0.003944586196598181
Epoch: 2070, trainingloss: 0.0032381512303407646 | validation loss: 0.0036292819505732168
Epoch: 2071, trainingloss: 0.0034994552070322215 | validation loss: 0.0038412805919555114
Epoch: 2072, trainingloss: 0.0037012193690804133 | validation loss: 0.004022513573927397
Epoch: 2073, trainingloss: 0.003602256168522318 | validation loss: 0.0039066386034063766
Epoch: 2074, trainingloss: 0.003805876088933548 | validation loss: 0.004130835068884132
Epoch: 2075, trainingloss: 0.003974817138656333 | validation loss: 0.004292316988036302
Epoch: 2076, trainingloss: 0.0035573627347305512 | validation loss: 0.0039271498460857505
Epoch: 2077, trainingloss: 0.0037339508622947376 | validation loss: 0.0040510975759025
Epoch: 2078, trainingloss: 0.003757779606351994 | validation loss: 0.004086236162048827
Epoch: 2079, trainingloss: 0.004179762925136569 | validation loss: 0.00448483721027791
Epoch: 2080, trainingloss: 0.0033714979706063494 | validation loss: 0.0037280783305455997
Epoch: 2081, trainingloss: 0.0032840907837036206 | validation loss: 0.0036695578243404426
Epoch: 2082, trainingloss: 0.0034325068574977842 | validation loss: 0.0037948582144601566
Epoch: 2083, trainingloss: 0.003670396777788531 | validation loss: 0.0040140637509367555
Epoch: 2084, trainingloss: 0.003468048453971366 | validation loss: 0.0038171223750942227
Epoch: 2085, trainingloss: 0.003953152945317937 | validation loss: 0.004256902196365671
Epoch: 2086, trainingloss: 0.0032725273479574015 | validation loss: 0.0036418135614445036
Epoch: 2087, trainingloss: 0.0034289010113998336 | validation loss: 0.003796606036060681
Epoch: 2088, trainingloss: 0.0032488939993119757 | validation loss: 0.003632301603320616
Epoch: 2089, trainingloss: 0.003798326741081735 | validation loss: 0.004117404070926838
Epoch: 2090, trainingloss: 0.003406270524031787 | validation loss: 0.0037729419927668034
Epoch: 2091, trainingloss: 0.003193703905829009 | validation loss: 0.003575552373236491
Epoch: 2092, trainingloss: 0.004166005458443169 | validation loss: 0.004474934047615929
Epoch: 2093, trainingloss: 0.003914094371646266 | validation loss: 0.004267640680228669
Epoch: 2094, trainingloss: 0.0033772544431956816 | validation loss: 0.0037604311048009664
Epoch: 2095, trainingloss: 0.004881786003061284 | validation loss: 0.005131030885342402
Epoch: 2096, trainingloss: 0.003692069483289431 | validation loss: 0.004038534711586908
Epoch: 2097, trainingloss: 0.003756315878194168 | validation loss: 0.004044073451788502
Epoch: 2098, trainingloss: 0.0037301796418993745 | validation loss: 0.004048196564859611
Epoch: 2099, trainingloss: 0.00343770048031584 | validation loss: 0.003787494003923358
Epoch: 2100, trainingloss: 0.004236466914689332 | validation loss: 0.004504233695178908
Epoch: 2101, trainingloss: 0.004034264207390172 | validation loss: 0.00430752009313546
Epoch: 2102, trainingloss: 0.00331044941820173 | validation loss: 0.003666943295660927
Epoch: 2103, trainingloss: 0.0033939296614657593 | validation loss: 0.0037548929721152383
Epoch: 2104, trainingloss: 0.0033716835963687616 | validation loss: 0.0037386524190521184
Epoch: 2105, trainingloss: 0.003392163879425269 | validation loss: 0.0037555419124341164
Epoch: 2106, trainingloss: 0.0036041255049670705 | validation loss: 0.003926575387329665
Epoch: 2107, trainingloss: 0.003819062395520699 | validation loss: 0.004141892703674529
Epoch: 2108, trainingloss: 0.004437376495968024 | validation loss: 0.004713639436799001
Epoch: 2109, trainingloss: 0.004188649030549933 | validation loss: 0.004488828672104444
Epoch: 2110, trainingloss: 0.0036800126037799087 | validation loss: 0.004004008561626153
Epoch: 2111, trainingloss: 0.003899826986505558 | validation loss: 0.0041907639017999005
Epoch: 2112, trainingloss: 0.003258517797950055 | validation loss: 0.0036390280273262475
Epoch: 2113, trainingloss: 0.0033085580543017515 | validation loss: 0.0036667475831446525
Epoch: 2114, trainingloss: 0.003919007594714812 | validation loss: 0.004179714409719159
Epoch: 2115, trainingloss: 0.0037189342131062402 | validation loss: 0.00404104034107298
Epoch: 2116, trainingloss: 0.003987382307710929 | validation loss: 0.004330673951263714
Epoch: 2117, trainingloss: 0.0038103677040488256 | validation loss: 0.00412410122961338
Epoch: 2118, trainingloss: 0.003411233569983377 | validation loss: 0.0037695353240689714
Epoch: 2119, trainingloss: 0.004046908931139979 | validation loss: 0.0043353272531811374
Epoch: 2120, trainingloss: 0.0037092667714125555 | validation loss: 0.004003137004272647
Epoch: 2121, trainingloss: 0.003548725061894521 | validation loss: 0.003924945223343874
Epoch: 2122, trainingloss: 0.003958265930758462 | validation loss: 0.004260392321942701
Epoch: 2123, trainingloss: 0.004119051916510284 | validation loss: 0.004414701776371203
Epoch: 2124, trainingloss: 0.0032448702399450993 | validation loss: 0.003604234609525519
Epoch: 2125, trainingloss: 0.0037057112870978698 | validation loss: 0.004020442508026296
Epoch: 2126, trainingloss: 0.0036554304914367874 | validation loss: 0.003997524658535797
Epoch: 2127, trainingloss: 0.003634828750466488 | validation loss: 0.003953018078771162
Epoch: 2128, trainingloss: 0.0036157745103622004 | validation loss: 0.00393836475721073
Epoch: 2129, trainingloss: 0.0038363286360992162 | validation loss: 0.00416407588705831
Epoch: 2130, trainingloss: 0.004400827924335054 | validation loss: 0.004651376710645455
Epoch: 2131, trainingloss: 0.004482938707340535 | validation loss: 0.00476720813600334
Epoch: 2132, trainingloss: 0.0037743643083868635 | validation loss: 0.00409817857285872
Epoch: 2133, trainingloss: 0.003970677801297868 | validation loss: 0.004258916838969349
Epoch: 2134, trainingloss: 0.0035962295261081395 | validation loss: 0.003927096128201067
Epoch: 2135, trainingloss: 0.003438622294442699 | validation loss: 0.003801555293384196
Epoch: 2136, trainingloss: 0.0037670284547181155 | validation loss: 0.004098898054852974
Epoch: 2137, trainingloss: 0.00420640161296103 | validation loss: 0.004476203446552465
Epoch: 2138, trainingloss: 0.0036990876063702914 | validation loss: 0.004014326823577705
Epoch: 2139, trainingloss: 0.003664415626180606 | validation loss: 0.003987578753628695
Epoch: 2140, trainingloss: 0.0034055192620032686 | validation loss: 0.00379692782476793
Epoch: 2141, trainingloss: 0.003556146480782394 | validation loss: 0.003896721134519055
Epoch: 2142, trainingloss: 0.003532173536421871 | validation loss: 0.003825753245113969
Epoch: 2143, trainingloss: 0.0038097403409101988 | validation loss: 0.004096081310111045
Epoch: 2144, trainingloss: 0.0041370574535272535 | validation loss: 0.004424705665219628
Epoch: 2145, trainingloss: 0.0034240336509087973 | validation loss: 0.0037844828485667547
Epoch: 2146, trainingloss: 0.003431060835741748 | validation loss: 0.0037561577450677375
Epoch: 2147, trainingloss: 0.003916478167174774 | validation loss: 0.004252149379250803
Epoch: 2148, trainingloss: 0.003605437741153348 | validation loss: 0.003924946378810143
Epoch: 2149, trainingloss: 0.003959253764140433 | validation loss: 0.0042804395974352415
Epoch: 2150, trainingloss: 0.0037010730506298268 | validation loss: 0.00401031862285184
Epoch: 2151, trainingloss: 0.00394481564876757 | validation loss: 0.004244245488711908
Epoch: 2152, trainingloss: 0.0035726369143529455 | validation loss: 0.003895476772186746
Epoch: 2153, trainingloss: 0.0036866463136567347 | validation loss: 0.003988805053759384
Epoch: 2154, trainingloss: 0.0035608297444797692 | validation loss: 0.003923430826730252
Epoch: 2155, trainingloss: 0.0036218135272096915 | validation loss: 0.003959237212177768
Epoch: 2156, trainingloss: 0.0033931577419947074 | validation loss: 0.003742920136462858
Epoch: 2157, trainingloss: 0.0033747431207259695 | validation loss: 0.003767119574922627
Epoch: 2158, trainingloss: 0.0035669965132578284 | validation loss: 0.0039003549192330963
Epoch: 2159, trainingloss: 0.0038552384187919577 | validation loss: 0.004174421545009578
Epoch: 2160, trainingloss: 0.003808045867613476 | validation loss: 0.004084432252334362
Epoch: 2161, trainingloss: 0.003703867139135141 | validation loss: 0.0040175121557383345
Epoch: 2162, trainingloss: 0.003982179139191119 | validation loss: 0.004256648411154061
Epoch: 2163, trainingloss: 0.004501537091611782 | validation loss: 0.004763400512319321
Epoch: 2164, trainingloss: 0.003455319355782207 | validation loss: 0.0038475086842277243
Epoch: 2165, trainingloss: 0.003986874679176304 | validation loss: 0.004288157804923783
Epoch: 2166, trainingloss: 0.003711337627401567 | validation loss: 0.003998354898369516
Epoch: 2167, trainingloss: 0.004490698180108433 | validation loss: 0.004712836084426718
Epoch: 2168, trainingloss: 0.003565766469560029 | validation loss: 0.003907842703211344
Epoch: 2169, trainingloss: 0.0035035850239445963 | validation loss: 0.003846934290967718
Epoch: 2170, trainingloss: 0.0036368548977234938 | validation loss: 0.003965509129138417
Epoch: 2171, trainingloss: 0.0034284397434077105 | validation loss: 0.0038109210202285993
Epoch: 2172, trainingloss: 0.003570620488603251 | validation loss: 0.003912681421550012
Epoch: 2173, trainingloss: 0.0042035022975741325 | validation loss: 0.004505957135037917
Epoch: 2174, trainingloss: 0.0035465382332690466 | validation loss: 0.003909708885339466
Epoch: 2175, trainingloss: 0.003418958822460161 | validation loss: 0.0037791079474533804
Epoch: 2176, trainingloss: 0.003947412257899831 | validation loss: 0.0042813173651705715
Epoch: 2177, trainingloss: 0.00388550461680057 | validation loss: 0.004257449887079326
Epoch: 2178, trainingloss: 0.0035221484110295803 | validation loss: 0.003894890669282389
Epoch: 2179, trainingloss: 0.0033891057982890346 | validation loss: 0.003780694486922539
Epoch: 2180, trainingloss: 0.003688121354193425 | validation loss: 0.004012050897507526
Epoch: 2181, trainingloss: 0.0035328377499136807 | validation loss: 0.003862365392773843
Epoch: 2182, trainingloss: 0.0038094104196212284 | validation loss: 0.0041321452540697395
Epoch: 2183, trainingloss: 0.0038968947049583817 | validation loss: 0.004187033554297733
Epoch: 2184, trainingloss: 0.003402436354543786 | validation loss: 0.003786519167454697
Epoch: 2185, trainingloss: 0.0036851210361687143 | validation loss: 0.004026937306047536
Epoch: 2186, trainingloss: 0.0034928697554825064 | validation loss: 0.003843437767964531
Epoch: 2187, trainingloss: 0.0036351558385961753 | validation loss: 0.003972044282900046
Epoch: 2188, trainingloss: 0.00376684383030088 | validation loss: 0.004088400862722726
Epoch: 2189, trainingloss: 0.0034123432056142535 | validation loss: 0.0037980386451072936
Epoch: 2190, trainingloss: 0.004252589358935186 | validation loss: 0.004555606200382195
Epoch: 2191, trainingloss: 0.003534332697584783 | validation loss: 0.003880024194097497
Epoch: 2192, trainingloss: 0.003691233104859161 | validation loss: 0.00403128341248585
Epoch: 2193, trainingloss: 0.003736980630369125 | validation loss: 0.004060849096411024
Epoch: 2194, trainingloss: 0.0040444356505853684 | validation loss: 0.004327423497340277
Epoch: 2195, trainingloss: 0.003828133022490674 | validation loss: 0.004134564052373069
Epoch: 2196, trainingloss: 0.003444721314355081 | validation loss: 0.003792236955086774
Epoch: 2197, trainingloss: 0.0038848715353745848 | validation loss: 0.004184725966246566
Epoch: 2198, trainingloss: 0.003743116498043106 | validation loss: 0.004039435660266406
Epoch: 2199, trainingloss: 0.0036079461468119674 | validation loss: 0.00396100309948137
Epoch: 2200, trainingloss: 0.003475616531026305 | validation loss: 0.003835243610462949
Epoch: 2201, trainingloss: 0.0036458677243456825 | validation loss: 0.004001492739228567
Epoch: 2202, trainingloss: 0.0036318423165286546 | validation loss: 0.003992574853825273
Epoch: 2203, trainingloss: 0.003931294371790742 | validation loss: 0.004252392879208426
Epoch: 2204, trainingloss: 0.003622003551424693 | validation loss: 0.003977274201294941
Epoch: 2205, trainingloss: 0.0037239876805372604 | validation loss: 0.004069161301731114
Epoch: 2206, trainingloss: 0.003694529657779853 | validation loss: 0.004081645180790979
Epoch: 2207, trainingloss: 0.003271081129727159 | validation loss: 0.0036609005274646335
Epoch: 2208, trainingloss: 0.003899060723966322 | validation loss: 0.004226157977051745
Epoch: 2209, trainingloss: 0.004055776692840125 | validation loss: 0.004358975597125531
Epoch: 2210, trainingloss: 0.003527341531266159 | validation loss: 0.003856163479156039
Epoch: 2211, trainingloss: 0.0034416664947846867 | validation loss: 0.0038337875051286945
Epoch: 2212, trainingloss: 0.0034274805100062635 | validation loss: 0.0037709793236857274
Epoch: 2213, trainingloss: 0.0038999461661172632 | validation loss: 0.004239398239099368
Epoch: 2214, trainingloss: 0.0035711176540317454 | validation loss: 0.003941986031852355
Epoch: 2215, trainingloss: 0.004408322168531538 | validation loss: 0.004644598657719293
Epoch: 2216, trainingloss: 0.0036916882648494976 | validation loss: 0.004039765767369
Epoch: 2217, trainingloss: 0.003403397187300399 | validation loss: 0.003782254178471524
Epoch: 2218, trainingloss: 0.00365711725407442 | validation loss: 0.00396859320060462
Epoch: 2219, trainingloss: 0.0033897337531253358 | validation loss: 0.0037828584636627406
Epoch: 2220, trainingloss: 0.0034670713453271063 | validation loss: 0.003848472195573148
Epoch: 2221, trainingloss: 0.0036585357453318076 | validation loss: 0.004003471400241276
Epoch: 2222, trainingloss: 0.003453142443400039 | validation loss: 0.0037983706157519487
Epoch: 2223, trainingloss: 0.0037721070153643316 | validation loss: 0.004113030201937575
Epoch: 2224, trainingloss: 0.003710113580956589 | validation loss: 0.004082925423655523
Epoch: 2225, trainingloss: 0.0035570505404105683 | validation loss: 0.003902893508695634
Epoch: 2226, trainingloss: 0.0034639605073036855 | validation loss: 0.003791537743522629
Epoch: 2227, trainingloss: 0.0033427174558238243 | validation loss: 0.003720179067707908
Epoch: 2228, trainingloss: 0.003483480398612221 | validation loss: 0.003884644716112783
Epoch: 2229, trainingloss: 0.0035376566290243813 | validation loss: 0.003931315105882258
Epoch: 2230, trainingloss: 0.004403974557094719 | validation loss: 0.0046419837418547015
Epoch: 2231, trainingloss: 0.0037997385020429363 | validation loss: 0.004112446469183896
Epoch: 2232, trainingloss: 0.0038747978687078233 | validation loss: 0.004208915972045321
Epoch: 2233, trainingloss: 0.003896678906817856 | validation loss: 0.004245689100275073
Epoch: 2234, trainingloss: 0.003446749233140094 | validation loss: 0.0037953173836260162
Epoch: 2235, trainingloss: 0.003649535492899657 | validation loss: 0.003999277306221121
Epoch: 2236, trainingloss: 0.003791974677323522 | validation loss: 0.004149209217992892
Epoch: 2237, trainingloss: 0.0037898098407100505 | validation loss: 0.0041020042515794684
Epoch: 2238, trainingloss: 0.0038628672597618994 | validation loss: 0.004189509007032707
Epoch: 2239, trainingloss: 0.003446422632030945 | validation loss: 0.003790257762487143
Epoch: 2240, trainingloss: 0.004021696741458719 | validation loss: 0.004324348375714347
Epoch: 2241, trainingloss: 0.0036116703299332114 | validation loss: 0.003955861419235816
Epoch: 2242, trainingloss: 0.003309489124103193 | validation loss: 0.003735475690753472
Epoch: 2243, trainingloss: 0.0031972247071844757 | validation loss: 0.0035998188828423013
Epoch: 2244, trainingloss: 0.003822531778780401 | validation loss: 0.0041636521334447165
Epoch: 2245, trainingloss: 0.0034581527624721418 | validation loss: 0.0038116181014775726
Epoch: 2246, trainingloss: 0.0039756978456563135 | validation loss: 0.00427842573949151
Epoch: 2247, trainingloss: 0.003408060213930408 | validation loss: 0.003770651601685005
Epoch: 2248, trainingloss: 0.003496976016023872 | validation loss: 0.003826441534396612
Epoch: 2249, trainingloss: 0.003348382341185076 | validation loss: 0.003688963713370316
Epoch: 2250, trainingloss: 0.0035227093806165103 | validation loss: 0.0039100754334447175
Epoch: 2251, trainingloss: 0.0033705932357257938 | validation loss: 0.0037320194586089785
Epoch: 2252, trainingloss: 0.0033852865184447268 | validation loss: 0.0037430365468173648
Epoch: 2253, trainingloss: 0.0043826631038311956 | validation loss: 0.004634945150593501
Epoch: 2254, trainingloss: 0.0034934105043041832 | validation loss: 0.003851600946127439
Epoch: 2255, trainingloss: 0.00390819123642504 | validation loss: 0.00417967317037921
Epoch: 2256, trainingloss: 0.004208818326926213 | validation loss: 0.004504974741511495
Epoch: 2257, trainingloss: 0.0036533526479666646 | validation loss: 0.003996016622436155
Epoch: 2258, trainingloss: 0.004302315000395053 | validation loss: 0.004589079321878207
Epoch: 2259, trainingloss: 0.0036839123966398092 | validation loss: 0.004048196515084935
Epoch: 2260, trainingloss: 0.004237485535556267 | validation loss: 0.004536732859893928
Epoch: 2261, trainingloss: 0.004265349226758844 | validation loss: 0.004547850009559293
Epoch: 2262, trainingloss: 0.0037184999711665973 | validation loss: 0.004056568058987995
Epoch: 2263, trainingloss: 0.0033705358230155854 | validation loss: 0.003729530534131226
Epoch: 2264, trainingloss: 0.0032102286817237884 | validation loss: 0.003619358273930996
Epoch: 2265, trainingloss: 0.0035179278103076384 | validation loss: 0.0038801820686092258
Epoch: 2266, trainingloss: 0.004053256981399196 | validation loss: 0.004359228056377021
Epoch: 2267, trainingloss: 0.003982894373380853 | validation loss: 0.00433555182249344
Epoch: 2268, trainingloss: 0.0034899052972207217 | validation loss: 0.003840075122083178
Epoch: 2269, trainingloss: 0.0037572153686228865 | validation loss: 0.004099264871521829
Epoch: 2270, trainingloss: 0.0034950020974735124 | validation loss: 0.0038232857106742664
Epoch: 2271, trainingloss: 0.004082453480114681 | validation loss: 0.004401178720449417
Epoch: 2272, trainingloss: 0.003633696501963959 | validation loss: 0.003965861846022099
Epoch: 2273, trainingloss: 0.003851068727296189 | validation loss: 0.004151321978278991
Epoch: 2274, trainingloss: 0.004446319671242961 | validation loss: 0.004694762432105644
Epoch: 2275, trainingloss: 0.003731413843923532 | validation loss: 0.004051671422053727
Epoch: 2276, trainingloss: 0.0043190304840160666 | validation loss: 0.004593371819272905
Epoch: 2277, trainingloss: 0.003517363710738615 | validation loss: 0.0038551157035122885
Epoch: 2278, trainingloss: 0.003573662357035151 | validation loss: 0.003953761262320088
Epoch: 2279, trainingloss: 0.0034870545041085278 | validation loss: 0.003829415421872041
Epoch: 2280, trainingloss: 0.003805028106966396 | validation loss: 0.004151825288984851
Epoch: 2281, trainingloss: 0.003301192312557809 | validation loss: 0.00366313549631719
Epoch: 2282, trainingloss: 0.0036253637184110914 | validation loss: 0.003965409679525364
Epoch: 2283, trainingloss: 0.003522889971392832 | validation loss: 0.0038576707517981525
Epoch: 2284, trainingloss: 0.0038312828686387136 | validation loss: 0.004124361583940716
Epoch: 2285, trainingloss: 0.00365075973123608 | validation loss: 0.003989993258304676
Epoch: 2286, trainingloss: 0.0033718769171370085 | validation loss: 0.0037301922770405192
Epoch: 2287, trainingloss: 0.0037197631124425727 | validation loss: 0.004046445656048392
Epoch: 2288, trainingloss: 0.0036555885535021707 | validation loss: 0.00397382635336602
Epoch: 2289, trainingloss: 0.004305400777467698 | validation loss: 0.004514881075692658
Epoch: 2290, trainingloss: 0.003937126263200372 | validation loss: 0.004226769307060079
Epoch: 2291, trainingloss: 0.004101450378787941 | validation loss: 0.004385657810769881
Epoch: 2292, trainingloss: 0.0032566831608040617 | validation loss: 0.00362767847260024
Epoch: 2293, trainingloss: 0.00348228710579115 | validation loss: 0.003816634928316925
Epoch: 2294, trainingloss: 0.0037900975292726245 | validation loss: 0.004080832518848561
Epoch: 2295, trainingloss: 0.0036729149493662534 | validation loss: 0.003979711375791256
Epoch: 2296, trainingloss: 0.0034552919551688595 | validation loss: 0.0037844537198060495
Epoch: 2297, trainingloss: 0.003377221452291012 | validation loss: 0.0037066027259660124
Epoch: 2298, trainingloss: 0.0034698671788155914 | validation loss: 0.0038192990971673765
Epoch: 2299, trainingloss: 0.0035476615208833258 | validation loss: 0.003865431657648665
Epoch: 2300, trainingloss: 0.0034279615325187238 | validation loss: 0.0037662777300648542
Epoch: 2301, trainingloss: 0.003205255740646723 | validation loss: 0.0035716710188062563
Epoch: 2302, trainingloss: 0.003864327435939508 | validation loss: 0.004144722081478599
Epoch: 2303, trainingloss: 0.0046208160419168405 | validation loss: 0.0049176097240827416
Epoch: 2304, trainingloss: 0.0034871778661050316 | validation loss: 0.0038304887648936644
Epoch: 2305, trainingloss: 0.00485502814876172 | validation loss: 0.0051155189514203005
Epoch: 2306, trainingloss: 0.004401244278264651 | validation loss: 0.004704235399850951
Epoch: 2307, trainingloss: 0.003777428854178804 | validation loss: 0.004121809338413649
Epoch: 2308, trainingloss: 0.0036918150853212737 | validation loss: 0.0040403251252911
Epoch: 2309, trainingloss: 0.0037523377426098266 | validation loss: 0.00404840939909799
Epoch: 2310, trainingloss: 0.003453042229703935 | validation loss: 0.0038276924258140057
Epoch: 2311, trainingloss: 0.0032955227210360446 | validation loss: 0.003653546103519342
Epoch: 2312, trainingloss: 0.00377933669538981 | validation loss: 0.004105071089251692
Epoch: 2313, trainingloss: 0.003763451498876753 | validation loss: 0.004058076384143564
Epoch: 2314, trainingloss: 0.003605075315967933 | validation loss: 0.0039483905290030345
Epoch: 2315, trainingloss: 0.0038006562123259003 | validation loss: 0.004117180430327714
Epoch: 2316, trainingloss: 0.003325744486071524 | validation loss: 0.0036809583612371186
Epoch: 2317, trainingloss: 0.004252089291308514 | validation loss: 0.004526371065761546
Epoch: 2318, trainingloss: 0.00368953844047588 | validation loss: 0.004020764973619062
Epoch: 2319, trainingloss: 0.0036978181974031367 | validation loss: 0.004008027412433745
Epoch: 2320, trainingloss: 0.0032213613126408644 | validation loss: 0.0036085703589147757
Epoch: 2321, trainingloss: 0.0036097027582996603 | validation loss: 0.0039214484529357975
Epoch: 2322, trainingloss: 0.003484860509365292 | validation loss: 0.003827345714039011
Epoch: 2323, trainingloss: 0.0036491520202738058 | validation loss: 0.0039665832975976255
Epoch: 2324, trainingloss: 0.003694731047367963 | validation loss: 0.003999377167602648
Epoch: 2325, trainingloss: 0.0038428579692581237 | validation loss: 0.004166598872651913
Epoch: 2326, trainingloss: 0.003966275352557412 | validation loss: 0.004253507083730202
Epoch: 2327, trainingloss: 0.003906385498001684 | validation loss: 0.004230430785895247
Epoch: 2328, trainingloss: 0.0035368974211424003 | validation loss: 0.003898329005238292
Epoch: 2329, trainingloss: 0.0039062943621202325 | validation loss: 0.00422382462167902
Epoch: 2330, trainingloss: 0.003509726225177028 | validation loss: 0.0038724868438105033
Epoch: 2331, trainingloss: 0.0034221958115645476 | validation loss: 0.0037702324938079274
Epoch: 2332, trainingloss: 0.003971066916776336 | validation loss: 0.0042479352012476735
Epoch: 2333, trainingloss: 0.004111890639942295 | validation loss: 0.00439321258550096
Epoch: 2334, trainingloss: 0.003358301622412972 | validation loss: 0.003709594555132621
Epoch: 2335, trainingloss: 0.003580095171592495 | validation loss: 0.00393635851569709
Epoch: 2336, trainingloss: 0.00425941430682078 | validation loss: 0.004537017161643344
Epoch: 2337, trainingloss: 0.003935372945204118 | validation loss: 0.004216084261392343
Epoch: 2338, trainingloss: 0.0031497678254899355 | validation loss: 0.003561086778463406
Epoch: 2339, trainingloss: 0.004004841094265888 | validation loss: 0.004291303620377974
Epoch: 2340, trainingloss: 0.0033325009714506187 | validation loss: 0.0036860606731062943
Epoch: 2341, trainingloss: 0.003610897313461483 | validation loss: 0.003946485435350958
Epoch: 2342, trainingloss: 0.003554746477290199 | validation loss: 0.0038818763869413074
Epoch: 2343, trainingloss: 0.0036752788719825857 | validation loss: 0.004001090494728122
Epoch: 2344, trainingloss: 0.003229396194668017 | validation loss: 0.0036244647229145208
Epoch: 2345, trainingloss: 0.003881497099837614 | validation loss: 0.004220229145688408
Epoch: 2346, trainingloss: 0.0038000485695513435 | validation loss: 0.004111134521504444
Epoch: 2347, trainingloss: 0.003307521484547977 | validation loss: 0.0036815848254361286
Epoch: 2348, trainingloss: 0.0034847176598553206 | validation loss: 0.003830531195779966
Epoch: 2349, trainingloss: 0.0034162296102296934 | validation loss: 0.0037794084731401787
Epoch: 2350, trainingloss: 0.0034509709915356056 | validation loss: 0.003827592601071383
Epoch: 2351, trainingloss: 0.003884321764152757 | validation loss: 0.004170898648275388
Epoch: 2352, trainingloss: 0.003972222562999214 | validation loss: 0.004293523785116501
Epoch: 2353, trainingloss: 0.0034501440039585362 | validation loss: 0.0037999090933039255
Epoch: 2354, trainingloss: 0.0037467167538456493 | validation loss: 0.004081536834236765
Epoch: 2355, trainingloss: 0.003371102494103513 | validation loss: 0.0037547511533985124
Epoch: 2356, trainingloss: 0.003729141054209913 | validation loss: 0.004043055562778975
Epoch: 2357, trainingloss: 0.0031186072298408545 | validation loss: 0.0035398889392803815
Epoch: 2358, trainingloss: 0.003854328499117686 | validation loss: 0.004180218074593266
Epoch: 2359, trainingloss: 0.0034344454156085787 | validation loss: 0.003777493196168161
Epoch: 2360, trainingloss: 0.0037545658655842628 | validation loss: 0.0040912852895506275
Epoch: 2361, trainingloss: 0.0039055600252510315 | validation loss: 0.004183403390494964
Epoch: 2362, trainingloss: 0.0035985681328255252 | validation loss: 0.003929029768978768
Epoch: 2363, trainingloss: 0.0037207203351611825 | validation loss: 0.004055890098931044
Epoch: 2364, trainingloss: 0.003617790900302913 | validation loss: 0.003922118668195265
Epoch: 2365, trainingloss: 0.0034805207084349916 | validation loss: 0.003868108833458104
Epoch: 2366, trainingloss: 0.003492990583486246 | validation loss: 0.0038206843199956268
Epoch: 2367, trainingloss: 0.003948889761614941 | validation loss: 0.004253767428048353
Epoch: 2368, trainingloss: 0.0033179247014234305 | validation loss: 0.003694910609867749
Epoch: 2369, trainingloss: 0.004184968581906164 | validation loss: 0.004474162490363367
Epoch: 2370, trainingloss: 0.003759681947846232 | validation loss: 0.004065214423987266
Epoch: 2371, trainingloss: 0.003500176209704974 | validation loss: 0.0038687068912709307
Epoch: 2372, trainingloss: 0.003701865839936478 | validation loss: 0.004027083352555721
Epoch: 2373, trainingloss: 0.0035226841870996473 | validation loss: 0.003863744207336
Epoch: 2374, trainingloss: 0.0033706565265512437 | validation loss: 0.0037265614066998047
Epoch: 2375, trainingloss: 0.0036039367185520164 | validation loss: 0.00396019413022462
Epoch: 2376, trainingloss: 0.0037016591527068462 | validation loss: 0.004034867788065907
Epoch: 2377, trainingloss: 0.0034508250865183283 | validation loss: 0.0038112706401296046
Epoch: 2378, trainingloss: 0.003878045344575351 | validation loss: 0.004180373158396289
Epoch: 2379, trainingloss: 0.00313991628258526 | validation loss: 0.003537473176362927
Epoch: 2380, trainingloss: 0.003842703978692795 | validation loss: 0.004168896865593949
Epoch: 2381, trainingloss: 0.0036072465445628793 | validation loss: 0.003982499890303774
Epoch: 2382, trainingloss: 0.0036489281962610092 | validation loss: 0.003990085511978437
Epoch: 2383, trainingloss: 0.003780785470223183 | validation loss: 0.004116699080218159
Epoch: 2384, trainingloss: 0.004116202338738742 | validation loss: 0.004403723288788543
Epoch: 2385, trainingloss: 0.003321419742477176 | validation loss: 0.003701825312657705
Epoch: 2386, trainingloss: 0.0036322779281962765 | validation loss: 0.003954845110568512
Epoch: 2387, trainingloss: 0.003785309351530792 | validation loss: 0.00409568111132226
Epoch: 2388, trainingloss: 0.0034194453087086317 | validation loss: 0.0037679364240759575
Epoch: 2389, trainingloss: 0.003472810953437971 | validation loss: 0.00384423669024067
Epoch: 2390, trainingloss: 0.003383729865489377 | validation loss: 0.003721756472125152
Epoch: 2391, trainingloss: 0.003540331905797501 | validation loss: 0.00391129767350834
Epoch: 2392, trainingloss: 0.003829289730804846 | validation loss: 0.004173451799865663
Epoch: 2393, trainingloss: 0.0031438196372261325 | validation loss: 0.003552605509333923
Epoch: 2394, trainingloss: 0.003413891840330564 | validation loss: 0.0037641613609577652
Epoch: 2395, trainingloss: 0.0033684010095379447 | validation loss: 0.0037457703538547322
Epoch: 2396, trainingloss: 0.0037527593861183517 | validation loss: 0.004068423511760207
Epoch: 2397, trainingloss: 0.003523098600461043 | validation loss: 0.003882239393807839
Epoch: 2398, trainingloss: 0.0034149245580993473 | validation loss: 0.0037944677918327627
Epoch: 2399, trainingloss: 0.003795589533621715 | validation loss: 0.004110745648407222
Epoch: 2400, trainingloss: 0.0034413572843491743 | validation loss: 0.0038086588655752364
Epoch: 2401, trainingloss: 0.00395426741332548 | validation loss: 0.00424566926759405
Epoch: 2402, trainingloss: 0.0038394779477611564 | validation loss: 0.00414590046636727
Epoch: 2403, trainingloss: 0.004626164771589218 | validation loss: 0.0049143814459068
Epoch: 2404, trainingloss: 0.0033647778714558235 | validation loss: 0.003726925555898307
Epoch: 2405, trainingloss: 0.0032634402697403787 | validation loss: 0.003649033823493113
Epoch: 2406, trainingloss: 0.003394932839188047 | validation loss: 0.003712978974515879
Epoch: 2407, trainingloss: 0.00351920821118915 | validation loss: 0.003858317323704911
Epoch: 2408, trainingloss: 0.003663272102572134 | validation loss: 0.004016066770131184
Epoch: 2409, trainingloss: 0.00344962317170761 | validation loss: 0.0038011256340210763
Epoch: 2410, trainingloss: 0.0032599011550904665 | validation loss: 0.0036590665873691562
Epoch: 2411, trainingloss: 0.0032992205705719996 | validation loss: 0.003690004566206452
Epoch: 2412, trainingloss: 0.003288175675202406 | validation loss: 0.003647858046237095
Epoch: 2413, trainingloss: 0.003696169057189969 | validation loss: 0.004014948291449941
Epoch: 2414, trainingloss: 0.0033797640119112727 | validation loss: 0.0037288035545950627
Epoch: 2415, trainingloss: 0.0035639141502675415 | validation loss: 0.003927721758676273
Epoch: 2416, trainingloss: 0.003383289054221796 | validation loss: 0.0037524501410119344
Epoch: 2417, trainingloss: 0.0035322750634881658 | validation loss: 0.0038514126142373114
Epoch: 2418, trainingloss: 0.0036947796125775772 | validation loss: 0.004030447572246185
Epoch: 2419, trainingloss: 0.0033594849257984846 | validation loss: 0.003700150113894582
Epoch: 2420, trainingloss: 0.003940096447846104 | validation loss: 0.004262975716846057
Epoch: 2421, trainingloss: 0.0035276980975256058 | validation loss: 0.0038591541844249164
Epoch: 2422, trainingloss: 0.003265356450911234 | validation loss: 0.0036695888216448317
Epoch: 2423, trainingloss: 0.0036361012519305724 | validation loss: 0.0039926556792117835
Epoch: 2424, trainingloss: 0.003440588835103469 | validation loss: 0.0038098421408136202
Epoch: 2425, trainingloss: 0.0034031997049518915 | validation loss: 0.0037342059778190787
Epoch: 2426, trainingloss: 0.003691969746002074 | validation loss: 0.004009785007093731
Epoch: 2427, trainingloss: 0.003137142752493213 | validation loss: 0.0035327686108589545
Epoch: 2428, trainingloss: 0.0039882877803477795 | validation loss: 0.004297230969918486
Epoch: 2429, trainingloss: 0.003902798114252978 | validation loss: 0.0042148293894908135
Epoch: 2430, trainingloss: 0.0040809741721412295 | validation loss: 0.004384061205083616
Epoch: 2431, trainingloss: 0.0032151622744226727 | validation loss: 0.0036074522654542746
Epoch: 2432, trainingloss: 0.003693466828176699 | validation loss: 0.004027039565721029
Epoch: 2433, trainingloss: 0.0037028167610207254 | validation loss: 0.00403875853338744
Epoch: 2434, trainingloss: 0.0035938946404304602 | validation loss: 0.003944161574881234
Epoch: 2435, trainingloss: 0.0034496425503378722 | validation loss: 0.00382239689371808
Epoch: 2436, trainingloss: 0.004150148995088922 | validation loss: 0.004425638886402963
Epoch: 2437, trainingloss: 0.003294338024973111 | validation loss: 0.0036690619166728795
Epoch: 2438, trainingloss: 0.004297964284575156 | validation loss: 0.004567516312419627
Epoch: 2439, trainingloss: 0.0034501807603253298 | validation loss: 0.0037844000523609457
Epoch: 2440, trainingloss: 0.0035857906588837763 | validation loss: 0.003910248576441795
Epoch: 2441, trainingloss: 0.004165806887495733 | validation loss: 0.004460170427634307
Epoch: 2442, trainingloss: 0.003287145465328376 | validation loss: 0.0036688651086379267
Epoch: 2443, trainingloss: 0.003413560862349125 | validation loss: 0.003765137010418713
Epoch: 2444, trainingloss: 0.0032729649956382786 | validation loss: 0.003646627321313149
Epoch: 2445, trainingloss: 0.003523976334772267 | validation loss: 0.0038810096236125895
Epoch: 2446, trainingloss: 0.003506782110596104 | validation loss: 0.0038881086714376025
Epoch: 2447, trainingloss: 0.003687651959369667 | validation loss: 0.004026070422696271
Epoch: 2448, trainingloss: 0.003721950779644319 | validation loss: 0.004040970674809765
Epoch: 2449, trainingloss: 0.0038006582930647675 | validation loss: 0.004127752535224298
Epoch: 2450, trainingloss: 0.0032638204621249158 | validation loss: 0.003675977680707493
Epoch: 2451, trainingloss: 0.0036622725174803236 | validation loss: 0.003998491908307387
Epoch: 2452, trainingloss: 0.0038083472554577055 | validation loss: 0.004120340188276359
Epoch: 2453, trainingloss: 0.003418929500974444 | validation loss: 0.003769220026513824
Epoch: 2454, trainingloss: 0.0041520463671463346 | validation loss: 0.00442341792924805
Epoch: 2455, trainingloss: 0.003259518204305991 | validation loss: 0.0036461212095749125
Epoch: 2456, trainingloss: 0.003684125037431126 | validation loss: 0.00404145186882524
Epoch: 2457, trainingloss: 0.0033601388438836183 | validation loss: 0.0037241856878047265
Epoch: 2458, trainingloss: 0.0036772162377309526 | validation loss: 0.004004716145222237
Epoch: 2459, trainingloss: 0.003371372473513675 | validation loss: 0.0037767876244799853
Epoch: 2460, trainingloss: 0.0036796516979028674 | validation loss: 0.004031456829777105
Epoch: 2461, trainingloss: 0.003384775746695582 | validation loss: 0.0037880857608980387
Epoch: 2462, trainingloss: 0.0033665198269462997 | validation loss: 0.0037219756741075807
Epoch: 2463, trainingloss: 0.0034501001654715694 | validation loss: 0.0038303794369574434
Epoch: 2464, trainingloss: 0.0035454173680687204 | validation loss: 0.003889721800784101
Epoch: 2465, trainingloss: 0.003586051722821817 | validation loss: 0.003965856614284777
Epoch: 2466, trainingloss: 0.0038276321123390205 | validation loss: 0.004121494855324687
Epoch: 2467, trainingloss: 0.003309795715448216 | validation loss: 0.003680273896302833
Epoch: 2468, trainingloss: 0.0036875058380785647 | validation loss: 0.004045301527916651
Epoch: 2469, trainingloss: 0.0035916479818392114 | validation loss: 0.003953068827529217
Epoch: 2470, trainingloss: 0.0038202560097820863 | validation loss: 0.004137706194342717
Epoch: 2471, trainingloss: 0.003876630649916157 | validation loss: 0.004174281499412817
Epoch: 2472, trainingloss: 0.0036579861330512556 | validation loss: 0.003999454087708901
Epoch: 2473, trainingloss: 0.0037907264540892067 | validation loss: 0.004111935551418732
Epoch: 2474, trainingloss: 0.003977980469966027 | validation loss: 0.004292915880488689
Epoch: 2475, trainingloss: 0.004006307928173985 | validation loss: 0.00431911240978033
Epoch: 2476, trainingloss: 0.003526134707115581 | validation loss: 0.0038631840683989935
Epoch: 2477, trainingloss: 0.0036879336186153326 | validation loss: 0.004006303677551931
Epoch: 2478, trainingloss: 0.0035906408140113826 | validation loss: 0.0039038040033788418
Epoch: 2479, trainingloss: 0.0034748826271685444 | validation loss: 0.003807364109049058
Epoch: 2480, trainingloss: 0.003955118819021352 | validation loss: 0.0042444498641547755
Epoch: 2481, trainingloss: 0.003802939563967091 | validation loss: 0.00414758934325952
Epoch: 2482, trainingloss: 0.0035039279644112553 | validation loss: 0.0038650570063114595
Epoch: 2483, trainingloss: 0.0043561386963235395 | validation loss: 0.004615117748990824
Epoch: 2484, trainingloss: 0.0034453351033599147 | validation loss: 0.0038114913158308838
Epoch: 2485, trainingloss: 0.0032680707848287078 | validation loss: 0.0036562054692426214
Epoch: 2486, trainingloss: 0.0032741960210419876 | validation loss: 0.003663379201413501
Epoch: 2487, trainingloss: 0.003569074318801415 | validation loss: 0.003918043460012297
Epoch: 2488, trainingloss: 0.0035503179900883354 | validation loss: 0.003940187960452168
Epoch: 2489, trainingloss: 0.003540738125916832 | validation loss: 0.0038889394596452243
Epoch: 2490, trainingloss: 0.003700263007066549 | validation loss: 0.004030173263707499
Epoch: 2491, trainingloss: 0.003399847131661534 | validation loss: 0.003766762341463371
Epoch: 2492, trainingloss: 0.0037472256686123958 | validation loss: 0.004081828911365583
Epoch: 2493, trainingloss: 0.003661321124333814 | validation loss: 0.004017426602778984
Epoch: 2494, trainingloss: 0.003533722893949927 | validation loss: 0.00391171967926004
Epoch: 2495, trainingloss: 0.0036069164465569294 | validation loss: 0.003956105958092557
Epoch: 2496, trainingloss: 0.0042370964669503144 | validation loss: 0.004525106552369882
Epoch: 2497, trainingloss: 0.0036439856641567957 | validation loss: 0.003978876178926254
Epoch: 2498, trainingloss: 0.0037748284442825335 | validation loss: 0.004104305375069477
Epoch: 2499, trainingloss: 0.003383013071806714 | validation loss: 0.0037471494797664887
Epoch: 2500, trainingloss: 0.003547407853636659 | validation loss: 0.003882038075597876
Epoch: 2501, trainingloss: 0.0034569389758706834 | validation loss: 0.0038115635425133776
Epoch: 2502, trainingloss: 0.0037101760933499804 | validation loss: 0.004045901446407831
Epoch: 2503, trainingloss: 0.0032797528912011215 | validation loss: 0.003654117743396425
Epoch: 2504, trainingloss: 0.0032881421666580593 | validation loss: 0.0036665749107010507
Epoch: 2505, trainingloss: 0.0035713857938021788 | validation loss: 0.003933424582696004
Epoch: 2506, trainingloss: 0.0034507643301921347 | validation loss: 0.0038285300728882954
Epoch: 2507, trainingloss: 0.0035142438448310925 | validation loss: 0.0038584525781506242
Epoch: 2508, trainingloss: 0.0037861070894536866 | validation loss: 0.0040979064291517065
Epoch: 2509, trainingloss: 0.003374205545161928 | validation loss: 0.0037447317729252844
Epoch: 2510, trainingloss: 0.0039840935647368885 | validation loss: 0.004300092489045408
Epoch: 2511, trainingloss: 0.003767394970789401 | validation loss: 0.0040701382974726655
Epoch: 2512, trainingloss: 0.003827215155466952 | validation loss: 0.0041604031966281565
Epoch: 2513, trainingloss: 0.0034451157044776224 | validation loss: 0.0038087542184017473
Epoch: 2514, trainingloss: 0.0035617947544092986 | validation loss: 0.0039193155990374096
Epoch: 2515, trainingloss: 0.003811946652112529 | validation loss: 0.004163224500341826
Epoch: 2516, trainingloss: 0.0038321425421676677 | validation loss: 0.004148483973741317
Epoch: 2517, trainingloss: 0.003740571064435137 | validation loss: 0.004052038137443768
Epoch: 2518, trainingloss: 0.0033717086033099248 | validation loss: 0.0037444252831249016
Epoch: 2519, trainingloss: 0.0035384341624219127 | validation loss: 0.0038843460067645827
Epoch: 2520, trainingloss: 0.003590354653432721 | validation loss: 0.003932392822072159
Epoch: 2521, trainingloss: 0.0032725626955453203 | validation loss: 0.0036567890943035595
Epoch: 2522, trainingloss: 0.0034334142620287686 | validation loss: 0.0037786517425003226
Epoch: 2523, trainingloss: 0.004117905314064013 | validation loss: 0.004441031089921932
Epoch: 2524, trainingloss: 0.0037668966547129037 | validation loss: 0.004071317147590904
Epoch: 2525, trainingloss: 0.0034632779451410378 | validation loss: 0.0038273631696222232
Epoch: 2526, trainingloss: 0.0037019951489187263 | validation loss: 0.004057813818604961
Epoch: 2527, trainingloss: 0.003952143186931874 | validation loss: 0.00428668490581314
Epoch: 2528, trainingloss: 0.0034449836831143073 | validation loss: 0.003786233013587625
Epoch: 2529, trainingloss: 0.00329193847475881 | validation loss: 0.0036561475562348986
Epoch: 2530, trainingloss: 0.003809024772908934 | validation loss: 0.004134892491025475
Epoch: 2531, trainingloss: 0.0032976095998833587 | validation loss: 0.0037094737904958207
Epoch: 2532, trainingloss: 0.004324770417479459 | validation loss: 0.004569636744614725
Epoch: 2533, trainingloss: 0.0038057706816975794 | validation loss: 0.004138827199334715
Epoch: 2534, trainingloss: 0.0032517193453338008 | validation loss: 0.003644303054563817
Epoch: 2535, trainingloss: 0.0037242783544038 | validation loss: 0.004080697161470994
Epoch: 2536, trainingloss: 0.003345540775412924 | validation loss: 0.0037074655081116696
Epoch: 2537, trainingloss: 0.003570204074138229 | validation loss: 0.003928278214219425
Epoch: 2538, trainingloss: 0.003344885920678371 | validation loss: 0.003704703421207968
Epoch: 2539, trainingloss: 0.003343313928339147 | validation loss: 0.0037043341453578747
Epoch: 2540, trainingloss: 0.003496365971803958 | validation loss: 0.0038678870274611895
Epoch: 2541, trainingloss: 0.003471401538495843 | validation loss: 0.003823677902352449
Epoch: 2542, trainingloss: 0.0034997747829097463 | validation loss: 0.0038469980020421515
Epoch: 2543, trainingloss: 0.00370553778882893 | validation loss: 0.004057722209555711
Epoch: 2544, trainingloss: 0.003950524056246858 | validation loss: 0.004260489160387663
Epoch: 2545, trainingloss: 0.0035202780166835516 | validation loss: 0.003876773609174896
Epoch: 2546, trainingloss: 0.003478459435473502 | validation loss: 0.003856029532088253
Epoch: 2547, trainingloss: 0.0038014069825905894 | validation loss: 0.004126923278779286
Epoch: 2548, trainingloss: 0.00365808298375923 | validation loss: 0.003986068221771524
Epoch: 2549, trainingloss: 0.003692845818545682 | validation loss: 0.00403682715587762
Epoch: 2550, trainingloss: 0.003238784634919962 | validation loss: 0.0036009690249133057
Epoch: 2551, trainingloss: 0.0034002377231791042 | validation loss: 0.0037664615920348027
Epoch: 2552, trainingloss: 0.0036520476153424973 | validation loss: 0.003985463933583901
Epoch: 2553, trainingloss: 0.0036669609079244226 | validation loss: 0.003983172317304877
Epoch: 2554, trainingloss: 0.003641828923764321 | validation loss: 0.003961311922635379
Epoch: 2555, trainingloss: 0.0036758423008311737 | validation loss: 0.0040207871993071746
Epoch: 2556, trainingloss: 0.0036220119819176757 | validation loss: 0.003984856112276584
Epoch: 2557, trainingloss: 0.003526460069044103 | validation loss: 0.0039041535798555287
Epoch: 2558, trainingloss: 0.0035103825997759622 | validation loss: 0.00388407984034831
Epoch: 2559, trainingloss: 0.003691287483066693 | validation loss: 0.004034450915439541
Epoch: 2560, trainingloss: 0.0033090099814299095 | validation loss: 0.003678288975309826
Epoch: 2561, trainingloss: 0.003796666879829469 | validation loss: 0.004138981220133639
Epoch: 2562, trainingloss: 0.0036539852948641845 | validation loss: 0.004002035129319753
Epoch: 2563, trainingloss: 0.0035715619866522304 | validation loss: 0.003921415499716161
Epoch: 2564, trainingloss: 0.003457610664919115 | validation loss: 0.003825487663654468
Epoch: 2565, trainingloss: 0.0034512455810785697 | validation loss: 0.0038289928470291003
Epoch: 2566, trainingloss: 0.003808112024979387 | validation loss: 0.004111282115155065
Epoch: 2567, trainingloss: 0.003841580396640927 | validation loss: 0.004157340787229597
Epoch: 2568, trainingloss: 0.0036065523222414 | validation loss: 0.00394192212671147
Epoch: 2569, trainingloss: 0.003963427371036748 | validation loss: 0.0042657675741356324
Epoch: 2570, trainingloss: 0.003901946819260381 | validation loss: 0.004233364542534237
Epoch: 2571, trainingloss: 0.003561915730697819 | validation loss: 0.003915795011375738
Epoch: 2572, trainingloss: 0.003474825496381051 | validation loss: 0.0038693023448806707
Epoch: 2573, trainingloss: 0.003415690136641003 | validation loss: 0.003785484178217878
Epoch: 2574, trainingloss: 0.0034640497385636394 | validation loss: 0.003821465485015344
Epoch: 2575, trainingloss: 0.003521902537950686 | validation loss: 0.0038783935685900005
Epoch: 2576, trainingloss: 0.0034123130128752605 | validation loss: 0.00377063411195446
Epoch: 2577, trainingloss: 0.003758008091450984 | validation loss: 0.004099233810583459
Epoch: 2578, trainingloss: 0.003595015761024341 | validation loss: 0.003925441592322558
Epoch: 2579, trainingloss: 0.003610519171739719 | validation loss: 0.003968264321831425
Epoch: 2580, trainingloss: 0.003323628234040764 | validation loss: 0.0036895227353903656
Epoch: 2581, trainingloss: 0.0037258043980890783 | validation loss: 0.0040796335696298225
Epoch: 2582, trainingloss: 0.0038602521646478594 | validation loss: 0.004172125991977958
Epoch: 2583, trainingloss: 0.0032432631266693704 | validation loss: 0.003633152243072063
Epoch: 2584, trainingloss: 0.003584385358292812 | validation loss: 0.0039489449034028285
Epoch: 2585, trainingloss: 0.0036036969454367115 | validation loss: 0.003933438985593932
Epoch: 2586, trainingloss: 0.0037187254550673644 | validation loss: 0.0040723748037066205
Epoch: 2587, trainingloss: 0.003977457415958221 | validation loss: 0.0043117249527370415
Epoch: 2588, trainingloss: 0.0034473763435867747 | validation loss: 0.003802851258401247
Epoch: 2589, trainingloss: 0.0037908435075810756 | validation loss: 0.004099346032540415
Epoch: 2590, trainingloss: 0.0033382672604200083 | validation loss: 0.0037355142620691616
Epoch: 2591, trainingloss: 0.004093587682337601 | validation loss: 0.0043616048778796655
Epoch: 2592, trainingloss: 0.0033982988376674 | validation loss: 0.0037502579839707793
Epoch: 2593, trainingloss: 0.0038174009057724135 | validation loss: 0.004164353550058454
Epoch: 2594, trainingloss: 0.003936936606722138 | validation loss: 0.004221583638743517
Epoch: 2595, trainingloss: 0.004093907975141884 | validation loss: 0.004379754421790758
Epoch: 2596, trainingloss: 0.0034014141127801253 | validation loss: 0.003764891875345097
Epoch: 2597, trainingloss: 0.003325320296692098 | validation loss: 0.0037343088125775777
Epoch: 2598, trainingloss: 0.004231658784604167 | validation loss: 0.004512401155301041
Epoch: 2599, trainingloss: 0.003641893202432242 | validation loss: 0.0039923854635069275
Epoch: 2600, trainingloss: 0.0034789842199760526 | validation loss: 0.0038497426787273996
Epoch: 2601, trainingloss: 0.0036375539255772337 | validation loss: 0.003990662800708735
Epoch: 2602, trainingloss: 0.0035555652374427496 | validation loss: 0.003918738484590233
Epoch: 2603, trainingloss: 0.003890199011477671 | validation loss: 0.0041725127050155466
Epoch: 2604, trainingloss: 0.004155687714243284 | validation loss: 0.004473525590147996
Epoch: 2605, trainingloss: 0.003889420096622834 | validation loss: 0.004206849876067511
Epoch: 2606, trainingloss: 0.0037373834156515435 | validation loss: 0.004061862023639483
Epoch: 2607, trainingloss: 0.0038055485611994157 | validation loss: 0.004133057048330966
Epoch: 2608, trainingloss: 0.003848615512076936 | validation loss: 0.004190322993579539
Epoch: 2609, trainingloss: 0.0038238228490063684 | validation loss: 0.004116260615957935
Epoch: 2610, trainingloss: 0.0033209167699674966 | validation loss: 0.0036885149889588106
Epoch: 2611, trainingloss: 0.0035033386647336153 | validation loss: 0.003864175570102612
Epoch: 2612, trainingloss: 0.003046525492582796 | validation loss: 0.003475020696935937
Epoch: 2613, trainingloss: 0.0038847607697097943 | validation loss: 0.004207286291173567
Epoch: 2614, trainingloss: 0.0034659174020481216 | validation loss: 0.0038340792482916618
Epoch: 2615, trainingloss: 0.004126213213973139 | validation loss: 0.004425528958386312
Epoch: 2616, trainingloss: 0.0034962730707455507 | validation loss: 0.003833321989759436
Epoch: 2617, trainingloss: 0.003499953679868355 | validation loss: 0.0038278390798336475
Epoch: 2618, trainingloss: 0.004091397104927102 | validation loss: 0.00437697458809715
Epoch: 2619, trainingloss: 0.003652562937449845 | validation loss: 0.004013208155124753
Epoch: 2620, trainingloss: 0.0033052711419115552 | validation loss: 0.003692553588996273
Epoch: 2621, trainingloss: 0.0040266881303533154 | validation loss: 0.004323338477231751
Epoch: 2622, trainingloss: 0.0031056601130332933 | validation loss: 0.0035042094589479737
Epoch: 2623, trainingloss: 0.003342196954726704 | validation loss: 0.0037251643762535864
Epoch: 2624, trainingloss: 0.003917888921929583 | validation loss: 0.004244750000142656
Epoch: 2625, trainingloss: 0.00373886212177937 | validation loss: 0.004029321338917751
Epoch: 2626, trainingloss: 0.003393995998842444 | validation loss: 0.0037462478329363335
Epoch: 2627, trainingloss: 0.0040287957482109844 | validation loss: 0.004339171368197421
Epoch: 2628, trainingloss: 0.004126268004689567 | validation loss: 0.004422124454893504
Epoch: 2629, trainingloss: 0.004069968371116491 | validation loss: 0.004370280879833176
Epoch: 2630, trainingloss: 0.0036772173231214233 | validation loss: 0.003986315949738376
Epoch: 2631, trainingloss: 0.003511274630787332 | validation loss: 0.003861640298307808
Epoch: 2632, trainingloss: 0.0037336953202204027 | validation loss: 0.004061318814731719
Epoch: 2633, trainingloss: 0.0034324548609529757 | validation loss: 0.00381734747627671
Epoch: 2634, trainingloss: 0.003570680130202442 | validation loss: 0.0039230645052838195
Epoch: 2635, trainingloss: 0.0036130667731345007 | validation loss: 0.003925555848527012
Epoch: 2636, trainingloss: 0.0038974781523729036 | validation loss: 0.004227032557377328
Epoch: 2637, trainingloss: 0.0034395255437275024 | validation loss: 0.0037986640262030547
Epoch: 2638, trainingloss: 0.003787769774628875 | validation loss: 0.00412764746892057
Epoch: 2639, trainingloss: 0.003850130734615233 | validation loss: 0.004184752683322118
Epoch: 2640, trainingloss: 0.004574036982262219 | validation loss: 0.004868131996012655
Epoch: 2641, trainingloss: 0.003873989133461945 | validation loss: 0.004205299012945081
Epoch: 2642, trainingloss: 0.003382149805154225 | validation loss: 0.0037762394043877115
Epoch: 2643, trainingloss: 0.003540286980501826 | validation loss: 0.0038787371403827377
Epoch: 2644, trainingloss: 0.003961655406200765 | validation loss: 0.004287879959912791
Epoch: 2645, trainingloss: 0.00339181225359638 | validation loss: 0.0037511491181409866
Epoch: 2646, trainingloss: 0.0037488241105691315 | validation loss: 0.004068604353697981
Epoch: 2647, trainingloss: 0.0035761206664960397 | validation loss: 0.003913643808296408
Epoch: 2648, trainingloss: 0.003672220279934477 | validation loss: 0.004004724309138732
Epoch: 2649, trainingloss: 0.004255987749307181 | validation loss: 0.004531745483515932
Epoch: 2650, trainingloss: 0.0035865364442117338 | validation loss: 0.0039253795113537784
Epoch: 2651, trainingloss: 0.003574046386230226 | validation loss: 0.003920616466948165
Epoch: 2652, trainingloss: 0.003311316081090579 | validation loss: 0.003687229245310293
Epoch: 2653, trainingloss: 0.003404317403620759 | validation loss: 0.0037955514977059267
Epoch: 2654, trainingloss: 0.004261835599192345 | validation loss: 0.004556506090957555
Epoch: 2655, trainingloss: 0.003416439849321139 | validation loss: 0.0037679401096031525
Epoch: 2656, trainingloss: 0.0037188139163272793 | validation loss: 0.004021280063135511
Epoch: 2657, trainingloss: 0.003878681359809857 | validation loss: 0.004199053978297832
Epoch: 2658, trainingloss: 0.003572247644646839 | validation loss: 0.0039323020395085565
Epoch: 2659, trainingloss: 0.003396813123660613 | validation loss: 0.0037480474941986378
Epoch: 2660, trainingloss: 0.003042494428124499 | validation loss: 0.003472016114777012
Epoch: 2661, trainingloss: 0.003914430534589347 | validation loss: 0.004228251181192419
Epoch: 2662, trainingloss: 0.003387215113132848 | validation loss: 0.0037654130746384283
Epoch: 2663, trainingloss: 0.0038004135381396282 | validation loss: 0.004121606415277875
Epoch: 2664, trainingloss: 0.0035475282275916455 | validation loss: 0.0038926989285842707
Epoch: 2665, trainingloss: 0.003635862389031624 | validation loss: 0.0039793246286606325
Epoch: 2666, trainingloss: 0.003953947431770837 | validation loss: 0.004232107363255702
Epoch: 2667, trainingloss: 0.0034115748644872623 | validation loss: 0.003752419176715648
Epoch: 2668, trainingloss: 0.003950363531357618 | validation loss: 0.004293041631044562
Epoch: 2669, trainingloss: 0.0033072818343121077 | validation loss: 0.003685204601467734
Epoch: 2670, trainingloss: 0.003964806161499622 | validation loss: 0.004282438292660745
Epoch: 2671, trainingloss: 0.004130425108656718 | validation loss: 0.004399551321324675
Epoch: 2672, trainingloss: 0.003273752137260662 | validation loss: 0.003657854739105666
Epoch: 2673, trainingloss: 0.00355656315370977 | validation loss: 0.0038934720398391648
Epoch: 2674, trainingloss: 0.003753762965882239 | validation loss: 0.004088932665546044
Epoch: 2675, trainingloss: 0.003936060063345232 | validation loss: 0.004242059536705855
Epoch: 2676, trainingloss: 0.0035572863149222513 | validation loss: 0.0039205366851327965
Epoch: 2677, trainingloss: 0.004111575166635383 | validation loss: 0.004398102076851601
Epoch: 2678, trainingloss: 0.003437304309567645 | validation loss: 0.003787932518186991
Epoch: 2679, trainingloss: 0.0035462551038728802 | validation loss: 0.003905925415205262
Epoch: 2680, trainingloss: 0.0038263703478149977 | validation loss: 0.004171289323398629
Epoch: 2681, trainingloss: 0.0036705349631937323 | validation loss: 0.004043197668140698
Epoch: 2682, trainingloss: 0.0035364050393071607 | validation loss: 0.003893563612947312
Epoch: 2683, trainingloss: 0.003997752723953192 | validation loss: 0.004301913191960051
Epoch: 2684, trainingloss: 0.003206483491205644 | validation loss: 0.003607035816175823
Epoch: 2685, trainingloss: 0.0035201138482922594 | validation loss: 0.003874892979231805
Epoch: 2686, trainingloss: 0.0035045221394194455 | validation loss: 0.0039015665609310034
Epoch: 2687, trainingloss: 0.003579772240860275 | validation loss: 0.003917314539452006
Epoch: 2688, trainingloss: 0.0036081070040010757 | validation loss: 0.003981984600868254
Epoch: 2689, trainingloss: 0.0039109769352208236 | validation loss: 0.004231443152789073
Epoch: 2690, trainingloss: 0.0035859789195269317 | validation loss: 0.003951545615977363
Epoch: 2691, trainingloss: 0.0037389138382427404 | validation loss: 0.00408873449653953
Epoch: 2692, trainingloss: 0.0033598261105061917 | validation loss: 0.0037189195394054897
Epoch: 2693, trainingloss: 0.0034254079116777347 | validation loss: 0.003807893961935118
Epoch: 2694, trainingloss: 0.003362061428374108 | validation loss: 0.003714741058159087
Epoch: 2695, trainingloss: 0.0038611284402140377 | validation loss: 0.004171862103854447
Epoch: 2696, trainingloss: 0.004228373391313666 | validation loss: 0.004478746316757791
Epoch: 2697, trainingloss: 0.0033333316794245532 | validation loss: 0.0037110383721286467
Epoch: 2698, trainingloss: 0.003519350314286454 | validation loss: 0.0038716173178446143
Epoch: 2699, trainingloss: 0.0037601949667109224 | validation loss: 0.004096091290145084
Epoch: 2700, trainingloss: 0.0036417248505875095 | validation loss: 0.003973802161584172
Epoch: 2701, trainingloss: 0.0034269310874403104 | validation loss: 0.0038143985550708253
Epoch: 2702, trainingloss: 0.004452044662677035 | validation loss: 0.004686721698262895
Epoch: 2703, trainingloss: 0.0036292115465339334 | validation loss: 0.003955232359017623
Epoch: 2704, trainingloss: 0.0031079034922834132 | validation loss: 0.0034969055346690554
Epoch: 2705, trainingloss: 0.0036104054502836334 | validation loss: 0.003962194985069928
Epoch: 2706, trainingloss: 0.003754095277025564 | validation loss: 0.004078594218514797
Epoch: 2707, trainingloss: 0.0033038327193128615 | validation loss: 0.0036935569075192774
Epoch: 2708, trainingloss: 0.0038672383307002895 | validation loss: 0.004165251911872255
Epoch: 2709, trainingloss: 0.0034535736973072815 | validation loss: 0.0038119142454970272
Epoch: 2710, trainingloss: 0.0032997330074205707 | validation loss: 0.0037042272580652636
Epoch: 2711, trainingloss: 0.004169076479875814 | validation loss: 0.0044894007625726476
Epoch: 2712, trainingloss: 0.0038580798487538766 | validation loss: 0.004205984421954076
Epoch: 2713, trainingloss: 0.0037037080767601408 | validation loss: 0.004048121925165329
Epoch: 2714, trainingloss: 0.004023930417364875 | validation loss: 0.004320488950037873
Epoch: 2715, trainingloss: 0.0035680286402407562 | validation loss: 0.003901504747968666
Epoch: 2716, trainingloss: 0.003737677836516778 | validation loss: 0.0040538599555324396
Epoch: 2717, trainingloss: 0.003429161697790871 | validation loss: 0.0037850821283434044
Epoch: 2718, trainingloss: 0.004029582465274689 | validation loss: 0.004343376528141614
Epoch: 2719, trainingloss: 0.0036260284827589564 | validation loss: 0.003982879913215992
Epoch: 2720, trainingloss: 0.0035469526341401535 | validation loss: 0.0038976214736604277
Epoch: 2721, trainingloss: 0.0032578643400857786 | validation loss: 0.0036324980844635616
Epoch: 2722, trainingloss: 0.0033511439394279465 | validation loss: 0.0037102544006029376
Epoch: 2723, trainingloss: 0.0033502421173354406 | validation loss: 0.00369882614268312
Epoch: 2724, trainingloss: 0.003274392129894777 | validation loss: 0.0036659475571907733
Epoch: 2725, trainingloss: 0.0035320327167338563 | validation loss: 0.003886040601224353
Epoch: 2726, trainingloss: 0.003425088948274555 | validation loss: 0.0037984241031285867
Epoch: 2727, trainingloss: 0.003499562909737979 | validation loss: 0.0038394857318474734
Epoch: 2728, trainingloss: 0.0032837664470073713 | validation loss: 0.003666845224323051
Epoch: 2729, trainingloss: 0.0036670275408459945 | validation loss: 0.004006593140684796
Epoch: 2730, trainingloss: 0.003408530776280992 | validation loss: 0.0037787195744480285
Epoch: 2731, trainingloss: 0.003480862761566898 | validation loss: 0.003848835659651273
Epoch: 2732, trainingloss: 0.003495110049319681 | validation loss: 0.0038444298247625767
Epoch: 2733, trainingloss: 0.0033712035718438975 | validation loss: 0.003752790205014277
Epoch: 2734, trainingloss: 0.003378500073231637 | validation loss: 0.0037517230561875197
Epoch: 2735, trainingloss: 0.0038108608990032335 | validation loss: 0.004182966512589735
Epoch: 2736, trainingloss: 0.003395478015573218 | validation loss: 0.003797733190309414
Epoch: 2737, trainingloss: 0.003344543880487233 | validation loss: 0.0037355125456899714
Epoch: 2738, trainingloss: 0.003565633160950142 | validation loss: 0.00392942321843553
Epoch: 2739, trainingloss: 0.004001092255677087 | validation loss: 0.004323264945261008
Epoch: 2740, trainingloss: 0.004027646011081404 | validation loss: 0.004321295646245533
Epoch: 2741, trainingloss: 0.0038666312287437754 | validation loss: 0.004216874333333424
Epoch: 2742, trainingloss: 0.003792529608339862 | validation loss: 0.004121782317331934
Epoch: 2743, trainingloss: 0.0036067323139526834 | validation loss: 0.003965933621576487
Epoch: 2744, trainingloss: 0.0036038309729882344 | validation loss: 0.003963005206001603
Epoch: 2745, trainingloss: 0.0032268823321895965 | validation loss: 0.0035983968392330782
Epoch: 2746, trainingloss: 0.0038341023441794938 | validation loss: 0.004171171922922812
Epoch: 2747, trainingloss: 0.0036135891528262945 | validation loss: 0.003955506005310182
Epoch: 2748, trainingloss: 0.0035474100375944588 | validation loss: 0.003910378239590517
Epoch: 2749, trainingloss: 0.0035954355474548372 | validation loss: 0.0039601179323044775
Epoch: 2750, trainingloss: 0.003526858239197939 | validation loss: 0.0038959789889082457
Epoch: 2751, trainingloss: 0.00367665565094401 | validation loss: 0.004012617291980419
Epoch: 2752, trainingloss: 0.004097035726386775 | validation loss: 0.004417949153930251
Epoch: 2753, trainingloss: 0.004570391418253163 | validation loss: 0.004820644366178516
Epoch: 2754, trainingloss: 0.0033599588683017 | validation loss: 0.0037433196543728464
Epoch: 2755, trainingloss: 0.0036117943779148134 | validation loss: 0.003936032068450306
Epoch: 2756, trainingloss: 0.0032944208333129834 | validation loss: 0.0036666574603302607
Epoch: 2757, trainingloss: 0.003596355855606314 | validation loss: 0.003951565620295635
Epoch: 2758, trainingloss: 0.004513327585449215 | validation loss: 0.004802327978979942
Epoch: 2759, trainingloss: 0.003261481146894507 | validation loss: 0.003656093524658932
Epoch: 2760, trainingloss: 0.0034998747097899794 | validation loss: 0.0038641173868605477
Epoch: 2761, trainingloss: 0.003441577268461304 | validation loss: 0.0038172958869157826
Epoch: 2762, trainingloss: 0.00423268423262129 | validation loss: 0.004529888712057693
Epoch: 2763, trainingloss: 0.003229108704150834 | validation loss: 0.0036273545388857175
Epoch: 2764, trainingloss: 0.003938096450345749 | validation loss: 0.00425929238036454
Epoch: 2765, trainingloss: 0.0033436734007227706 | validation loss: 0.003719356272505985
Epoch: 2766, trainingloss: 0.0037400150674513524 | validation loss: 0.004087379224065514
Epoch: 2767, trainingloss: 0.0034675338765715806 | validation loss: 0.003821457612423032
Epoch: 2768, trainingloss: 0.0033024490463541846 | validation loss: 0.003709360611165141
Epoch: 2769, trainingloss: 0.0034357683572470905 | validation loss: 0.0038198652133811877
Epoch: 2770, trainingloss: 0.0032165352986185895 | validation loss: 0.0036184579337514007
Epoch: 2771, trainingloss: 0.003448657772216847 | validation loss: 0.0038406421152923564
Epoch: 2772, trainingloss: 0.0035148988227663575 | validation loss: 0.0038604996730807117
Epoch: 2773, trainingloss: 0.0036694633024940593 | validation loss: 0.004016203091005126
Epoch: 2774, trainingloss: 0.003253890379591301 | validation loss: 0.0036494662334490406
Epoch: 2775, trainingloss: 0.003784990108651853 | validation loss: 0.004129217583450796
Epoch: 2776, trainingloss: 0.0033369404919069124 | validation loss: 0.0036997682456255446
Epoch: 2777, trainingloss: 0.0036112470694127695 | validation loss: 0.003922798083321534
Epoch: 2778, trainingloss: 0.0034928854075754385 | validation loss: 0.0038594226150764554
Epoch: 2779, trainingloss: 0.0041748617311862845 | validation loss: 0.004480496511773766
Epoch: 2780, trainingloss: 0.0038484776004822805 | validation loss: 0.004165560320025506
Epoch: 2781, trainingloss: 0.0033371727358345936 | validation loss: 0.0037236573037634346
Epoch: 2782, trainingloss: 0.003553909346299329 | validation loss: 0.00391408727123266
Epoch: 2783, trainingloss: 0.003376786822188334 | validation loss: 0.0037479253939456995
Epoch: 2784, trainingloss: 0.003532153585433143 | validation loss: 0.0038902549060719546
Epoch: 2785, trainingloss: 0.0036263349629221393 | validation loss: 0.00398206340041214
Epoch: 2786, trainingloss: 0.0036097197320011857 | validation loss: 0.003959735768746436
Epoch: 2787, trainingloss: 0.0037736119060578573 | validation loss: 0.004096368183994286
Epoch: 2788, trainingloss: 0.003486648362744998 | validation loss: 0.0038691618932815393
Epoch: 2789, trainingloss: 0.004038870193827965 | validation loss: 0.004334615269262841
Epoch: 2790, trainingloss: 0.0044140979050351125 | validation loss: 0.004688868589798696
Epoch: 2791, trainingloss: 0.0034799828416434047 | validation loss: 0.0038515168504041227
Epoch: 2792, trainingloss: 0.004109674068171688 | validation loss: 0.00442931013580922
Epoch: 2793, trainingloss: 0.0033578623182665664 | validation loss: 0.003740695333747717
Epoch: 2794, trainingloss: 0.0033281820766139334 | validation loss: 0.003693861240804601
Epoch: 2795, trainingloss: 0.003378866638169408 | validation loss: 0.0037693887586341974
Epoch: 2796, trainingloss: 0.003918146206488387 | validation loss: 0.004228979234383694
Epoch: 2797, trainingloss: 0.0035044153747462873 | validation loss: 0.0038844132146165456
Epoch: 2798, trainingloss: 0.004130889585228081 | validation loss: 0.00443958769663285
Epoch: 2799, trainingloss: 0.0034529649321369876 | validation loss: 0.003816758444898161
Epoch: 2800, trainingloss: 0.003606608231565549 | validation loss: 0.003970202220356671
Epoch: 2801, trainingloss: 0.003642655985895614 | validation loss: 0.0039973072308090675
Epoch: 2802, trainingloss: 0.0035118928349216843 | validation loss: 0.003872457524114465
Epoch: 2803, trainingloss: 0.0043104418890726 | validation loss: 0.0045781326562426205
Epoch: 2804, trainingloss: 0.004104750212666076 | validation loss: 0.004400465495795679
Epoch: 2805, trainingloss: 0.0035999422735195127 | validation loss: 0.003963683134667467
Epoch: 2806, trainingloss: 0.003823972945717705 | validation loss: 0.0041949104509601525
Epoch: 2807, trainingloss: 0.0031195563813789496 | validation loss: 0.003523187437771339
Epoch: 2808, trainingloss: 0.003954386867465665 | validation loss: 0.004274147472251221
Epoch: 2809, trainingloss: 0.003622866488944426 | validation loss: 0.003993972054752579
Epoch: 2810, trainingloss: 0.0032825805408691266 | validation loss: 0.003660688182593135
Epoch: 2811, trainingloss: 0.004179115662060605 | validation loss: 0.004491977862809354
Epoch: 2812, trainingloss: 0.003299322316239076 | validation loss: 0.0036886075360644
Epoch: 2813, trainingloss: 0.0037935720421659667 | validation loss: 0.0041645463208095325
Epoch: 2814, trainingloss: 0.003285881342340744 | validation loss: 0.0036663748117095737
Epoch: 2815, trainingloss: 0.003623362149953862 | validation loss: 0.003975023459699412
Epoch: 2816, trainingloss: 0.0034580265708426183 | validation loss: 0.0038223790799968528
Epoch: 2817, trainingloss: 0.0037572548345253397 | validation loss: 0.004087122333662348
Epoch: 2818, trainingloss: 0.0038729257015462466 | validation loss: 0.004211891728210075
Epoch: 2819, trainingloss: 0.0035343643548471602 | validation loss: 0.003902781060172826
Epoch: 2820, trainingloss: 0.0034427549758140018 | validation loss: 0.003817899528977379
Epoch: 2821, trainingloss: 0.003671014743980343 | validation loss: 0.004045138144345143
Epoch: 2822, trainingloss: 0.003763370570845524 | validation loss: 0.004128721800508229
Epoch: 2823, trainingloss: 0.004125714862550738 | validation loss: 0.004430381964003662
Epoch: 2824, trainingloss: 0.003592175934270739 | validation loss: 0.003975712844890404
Epoch: 2825, trainingloss: 0.003714188266060613 | validation loss: 0.004068708111026335
Epoch: 2826, trainingloss: 0.003844500078189431 | validation loss: 0.004148229484999808
Epoch: 2827, trainingloss: 0.00373728474068108 | validation loss: 0.004080614177682171
Epoch: 2828, trainingloss: 0.003536902403181165 | validation loss: 0.003913346143905306
Epoch: 2829, trainingloss: 0.0034125708442247615 | validation loss: 0.0037904302780311446
Epoch: 2830, trainingloss: 0.0036466712223120544 | validation loss: 0.004003143335364164
Epoch: 2831, trainingloss: 0.0035925662097778597 | validation loss: 0.00393547213281586
Epoch: 2832, trainingloss: 0.003999322484808698 | validation loss: 0.004361353577020303
Epoch: 2833, trainingloss: 0.0036613499447285995 | validation loss: 0.004038048998028118
Epoch: 2834, trainingloss: 0.0035417603001451923 | validation loss: 0.0038923848522803084
Epoch: 2835, trainingloss: 0.003670905100406083 | validation loss: 0.003991263159844325
Epoch: 2836, trainingloss: 0.003197432552576228 | validation loss: 0.0036033153973880332
Epoch: 2837, trainingloss: 0.003456114736237069 | validation loss: 0.0038108541194420433
Epoch: 2838, trainingloss: 0.003554854485794558 | validation loss: 0.00390459477404342
Epoch: 2839, trainingloss: 0.0035472347090710374 | validation loss: 0.003881423133770848
Epoch: 2840, trainingloss: 0.003746359594246485 | validation loss: 0.004092804161814454
Epoch: 2841, trainingloss: 0.0033388509279660035 | validation loss: 0.003717690303500261
Epoch: 2842, trainingloss: 0.004083332447950315 | validation loss: 0.004406232297371649
Epoch: 2843, trainingloss: 0.003355702212971704 | validation loss: 0.0037369835832366306
Epoch: 2844, trainingloss: 0.0034518575638316216 | validation loss: 0.0038268645251542475
Epoch: 2845, trainingloss: 0.003335527528485255 | validation loss: 0.0037481899382382712
Epoch: 2846, trainingloss: 0.0036249968388824003 | validation loss: 0.003959521305065006
Epoch: 2847, trainingloss: 0.0032009220577096913 | validation loss: 0.0036163378695838857
Epoch: 2848, trainingloss: 0.0036709495914674676 | validation loss: 0.004034982759441553
Epoch: 2849, trainingloss: 0.0037645390798510263 | validation loss: 0.004105542861406647
Epoch: 2850, trainingloss: 0.003417084029767294 | validation loss: 0.003801481450221169
Epoch: 2851, trainingloss: 0.003564637747254098 | validation loss: 0.003945923986622
Epoch: 2852, trainingloss: 0.0038834055251127865 | validation loss: 0.0042279244973365306
Epoch: 2853, trainingloss: 0.003425386688028705 | validation loss: 0.003794160804007016
Epoch: 2854, trainingloss: 0.003216802446981805 | validation loss: 0.003639053603314521
Epoch: 2855, trainingloss: 0.0036722742111640863 | validation loss: 0.0040082978407644685
Epoch: 2856, trainingloss: 0.0038223565821565914 | validation loss: 0.004138544893788831
Epoch: 2857, trainingloss: 0.004150575927879875 | validation loss: 0.004449333627089718
Epoch: 2858, trainingloss: 0.003756945205758723 | validation loss: 0.004104871144604303
Epoch: 2859, trainingloss: 0.00398371909760357 | validation loss: 0.004294491362821106
Epoch: 2860, trainingloss: 0.004125915217081666 | validation loss: 0.004423115526950237
Epoch: 2861, trainingloss: 0.003989585889765657 | validation loss: 0.004315195801627937
Epoch: 2862, trainingloss: 0.0037612498133781586 | validation loss: 0.0040912581555576566
Epoch: 2863, trainingloss: 0.0035161321902827908 | validation loss: 0.003883002194385748
Epoch: 2864, trainingloss: 0.003896104252848324 | validation loss: 0.004223632204028674
Epoch: 2865, trainingloss: 0.0035638443742975036 | validation loss: 0.003922678145298457
Epoch: 2866, trainingloss: 0.003774744605520243 | validation loss: 0.004144542250646784
Epoch: 2867, trainingloss: 0.0035358358768185 | validation loss: 0.003897557853259045
Epoch: 2868, trainingloss: 0.003789780144967444 | validation loss: 0.004136206992610848
Epoch: 2869, trainingloss: 0.003526565446851072 | validation loss: 0.003905841129880448
Epoch: 2870, trainingloss: 0.003681563358800434 | validation loss: 0.004021329156664746
Epoch: 2871, trainingloss: 0.0037021086440738172 | validation loss: 0.004046987208617932
Epoch: 2872, trainingloss: 0.003427256298226602 | validation loss: 0.003808227294519366
Epoch: 2873, trainingloss: 0.0035215194115563735 | validation loss: 0.003871227042628705
Epoch: 2874, trainingloss: 0.0036763813675247193 | validation loss: 0.004006872228489337
Epoch: 2875, trainingloss: 0.0033826932253212746 | validation loss: 0.0037778994383810215
Epoch: 2876, trainingloss: 0.003812895845515974 | validation loss: 0.004175480323570006
Epoch: 2877, trainingloss: 0.0035522511228995896 | validation loss: 0.003916023844207427
Epoch: 2878, trainingloss: 0.0036893588173691496 | validation loss: 0.004078078222559303
Epoch: 2879, trainingloss: 0.0036868966987851698 | validation loss: 0.00401507641200485
Epoch: 2880, trainingloss: 0.0035518381295353194 | validation loss: 0.003952166562534421
Epoch: 2881, trainingloss: 0.0031239914675280415 | validation loss: 0.0035308945680768006
Epoch: 2882, trainingloss: 0.0042282136343996446 | validation loss: 0.004513970539283287
Epoch: 2883, trainingloss: 0.004376319838469057 | validation loss: 0.0046856929308254185
Epoch: 2884, trainingloss: 0.0039088237518116985 | validation loss: 0.0042535912777278435
Epoch: 2885, trainingloss: 0.0033385153299900537 | validation loss: 0.003718805804802493
Epoch: 2886, trainingloss: 0.0038056022176723354 | validation loss: 0.004143868256679253
Epoch: 2887, trainingloss: 0.0035192954475200097 | validation loss: 0.0038878424557882525
Epoch: 2888, trainingloss: 0.003918432294027507 | validation loss: 0.004219443122148477
Epoch: 2889, trainingloss: 0.0035742229946937897 | validation loss: 0.003930765910015906
Epoch: 2890, trainingloss: 0.0034017874123038042 | validation loss: 0.003780788665445638
Epoch: 2891, trainingloss: 0.003605310452873101 | validation loss: 0.003983989535505507
Epoch: 2892, trainingloss: 0.004129819641974262 | validation loss: 0.004417947066648648
Epoch: 2893, trainingloss: 0.00369095712686114 | validation loss: 0.004063064749488031
Epoch: 2894, trainingloss: 0.003207631208371819 | validation loss: 0.0036157084322308106
Epoch: 2895, trainingloss: 0.003734530927322452 | validation loss: 0.004048441630825395
Epoch: 2896, trainingloss: 0.003866549101433742 | validation loss: 0.00420062265485466
Epoch: 2897, trainingloss: 0.003992143502771249 | validation loss: 0.004296654202416641
Epoch: 2898, trainingloss: 0.0033575676484153406 | validation loss: 0.003729591744164328
Epoch: 2899, trainingloss: 0.0034649593077655133 | validation loss: 0.0037932784886861226
Epoch: 2900, trainingloss: 0.0034819513056841976 | validation loss: 0.0038366963366533056
Epoch: 2901, trainingloss: 0.003488310688570725 | validation loss: 0.00385875553967156
Epoch: 2902, trainingloss: 0.0034315549782029608 | validation loss: 0.0038160992218021312
Epoch: 2903, trainingloss: 0.0039079820071070736 | validation loss: 0.004250054945501719
Epoch: 2904, trainingloss: 0.00337097214831298 | validation loss: 0.00375855311110229
Epoch: 2905, trainingloss: 0.004516555588276901 | validation loss: 0.004801231519891333
Epoch: 2906, trainingloss: 0.0032486639908112366 | validation loss: 0.0036505747587677034
Epoch: 2907, trainingloss: 0.0030880698557695097 | validation loss: 0.003511116957865072
Epoch: 2908, trainingloss: 0.004156165168703776 | validation loss: 0.004487626647545299
Epoch: 2909, trainingloss: 0.004825229102476252 | validation loss: 0.005062449544870253
Epoch: 2910, trainingloss: 0.003976688128666016 | validation loss: 0.0042994102954182975
Epoch: 2911, trainingloss: 0.0038310111004395166 | validation loss: 0.004158222794786735
Epoch: 2912, trainingloss: 0.0035247727251191776 | validation loss: 0.003876015173219616
Epoch: 2913, trainingloss: 0.0036512137215455836 | validation loss: 0.003983125692677899
Epoch: 2914, trainingloss: 0.003939793102478191 | validation loss: 0.004262892203259028
Epoch: 2915, trainingloss: 0.004029607914353272 | validation loss: 0.0043498463354174274
Epoch: 2916, trainingloss: 0.0033862695298230248 | validation loss: 0.0037427875861561918
Epoch: 2917, trainingloss: 0.003746408459093249 | validation loss: 0.0040724573205963436
Epoch: 2918, trainingloss: 0.0032263888533572635 | validation loss: 0.003613802907614124
Epoch: 2919, trainingloss: 0.0037907151078072276 | validation loss: 0.004126655947842954
Epoch: 2920, trainingloss: 0.003709461612232765 | validation loss: 0.0040477499434761425
Epoch: 2921, trainingloss: 0.003295475279220279 | validation loss: 0.003690705504197215
Epoch: 2922, trainingloss: 0.0035319350085054125 | validation loss: 0.0038599786634505575
Epoch: 2923, trainingloss: 0.0035631770153241957 | validation loss: 0.003915852765691328
Epoch: 2924, trainingloss: 0.0032017009883750737 | validation loss: 0.003626593890906234
Epoch: 2925, trainingloss: 0.003552777349421646 | validation loss: 0.00391069910968778
Epoch: 2926, trainingloss: 0.0036316407233584137 | validation loss: 0.004007131471122357
Epoch: 2927, trainingloss: 0.003860412249114087 | validation loss: 0.00420405802720507
Epoch: 2928, trainingloss: 0.004031589023586879 | validation loss: 0.004355753715519873
Epoch: 2929, trainingloss: 0.003764268306952138 | validation loss: 0.0041294598827297125
Epoch: 2930, trainingloss: 0.0037169372554669527 | validation loss: 0.004063924557578217
Epoch: 2931, trainingloss: 0.003644501885628084 | validation loss: 0.004039004525563047
Epoch: 2932, trainingloss: 0.003365223810456554 | validation loss: 0.0037359373407370184
Epoch: 2933, trainingloss: 0.0037591076683245687 | validation loss: 0.004108208204879585
Epoch: 2934, trainingloss: 0.0033078110146496174 | validation loss: 0.0036792021972816857
Epoch: 2935, trainingloss: 0.003577403714861812 | validation loss: 0.003931117069954015
Epoch: 2936, trainingloss: 0.0033235722258861443 | validation loss: 0.003708790446136032
Epoch: 2937, trainingloss: 0.003256246474673011 | validation loss: 0.003663935763290594
Epoch: 2938, trainingloss: 0.003397710821774261 | validation loss: 0.0037519799677251313
Epoch: 2939, trainingloss: 0.0032166792797570765 | validation loss: 0.0036339538771184053
Epoch: 2940, trainingloss: 0.003324809178740059 | validation loss: 0.003702747906800092
Epoch: 2941, trainingloss: 0.003318850069457694 | validation loss: 0.003701118545278313
Epoch: 2942, trainingloss: 0.003437439502371815 | validation loss: 0.003822478293929181
Epoch: 2943, trainingloss: 0.0032432356157431337 | validation loss: 0.0036465219845316296
Epoch: 2944, trainingloss: 0.003732589578891014 | validation loss: 0.004066332316283366
Epoch: 2945, trainingloss: 0.003658451620714144 | validation loss: 0.003988054369371001
Epoch: 2946, trainingloss: 0.003609441104018095 | validation loss: 0.003954816084753177
Epoch: 2947, trainingloss: 0.0042874845532947636 | validation loss: 0.004600415055540269
Epoch: 2948, trainingloss: 0.00357139391075754 | validation loss: 0.0038857220667791346
Epoch: 2949, trainingloss: 0.0037594683076608085 | validation loss: 0.0040931615323594045
Epoch: 2950, trainingloss: 0.003662855291127862 | validation loss: 0.0040249164074177
Epoch: 2951, trainingloss: 0.0037356661434400054 | validation loss: 0.004062263638931883
Epoch: 2952, trainingloss: 0.004164070684789308 | validation loss: 0.004482609091331101
Epoch: 2953, trainingloss: 0.0039058023059173833 | validation loss: 0.004230713899586872
Epoch: 2954, trainingloss: 0.003698496216741142 | validation loss: 0.004025357831160925
Epoch: 2955, trainingloss: 0.004128948349854795 | validation loss: 0.004458694915419885
Epoch: 2956, trainingloss: 0.003608377011432552 | validation loss: 0.003957082177259406
Epoch: 2957, trainingloss: 0.00403581908732066 | validation loss: 0.004360960694163047
Epoch: 2958, trainingloss: 0.003920861119282481 | validation loss: 0.004226174552317323
Epoch: 2959, trainingloss: 0.0032563014529603308 | validation loss: 0.003649768543452727
Epoch: 2960, trainingloss: 0.003680375429441052 | validation loss: 0.003997656057611233
Epoch: 2961, trainingloss: 0.003405461206286974 | validation loss: 0.003766946041496276
Epoch: 2962, trainingloss: 0.0033757993650282243 | validation loss: 0.0037267666779320827
Epoch: 2963, trainingloss: 0.004226706930403206 | validation loss: 0.0045360082167933925
Epoch: 2964, trainingloss: 0.0036071631366334975 | validation loss: 0.003960828795473219
Epoch: 2965, trainingloss: 0.003445470025989576 | validation loss: 0.0037868803570099835
Epoch: 2966, trainingloss: 0.0037139126753020796 | validation loss: 0.004074044348864891
Epoch: 2967, trainingloss: 0.003530007976876904 | validation loss: 0.0039018236849792842
Epoch: 2968, trainingloss: 0.003992004984687854 | validation loss: 0.004301191012453368
Epoch: 2969, trainingloss: 0.003812385472233133 | validation loss: 0.004190337283422619
Epoch: 2970, trainingloss: 0.0034133181439174763 | validation loss: 0.003796970820513295
Epoch: 2971, trainingloss: 0.003526903423185773 | validation loss: 0.003898016822111589
Epoch: 2972, trainingloss: 0.003910544189037725 | validation loss: 0.004248304297851505
Epoch: 2973, trainingloss: 0.003415467984171816 | validation loss: 0.003798150261090868
Epoch: 2974, trainingloss: 0.0034526325874822163 | validation loss: 0.003820605119911082
Epoch: 2975, trainingloss: 0.0037561165401236154 | validation loss: 0.004126466730095114
Epoch: 2976, trainingloss: 0.003613373348330667 | validation loss: 0.00396395705704993
Epoch: 2977, trainingloss: 0.00400001774365994 | validation loss: 0.004313403887656344
Epoch: 2978, trainingloss: 0.003515547657752334 | validation loss: 0.0038677921454234906
Epoch: 2979, trainingloss: 0.004164713675877996 | validation loss: 0.004462633122134743
Epoch: 2980, trainingloss: 0.0037174616048806113 | validation loss: 0.004061497925292841
Epoch: 2981, trainingloss: 0.003743861237283275 | validation loss: 0.0040584273054103445
Epoch: 2982, trainingloss: 0.004027002174039856 | validation loss: 0.0043499938875825395
Epoch: 2983, trainingloss: 0.0034048991738493115 | validation loss: 0.003789933937232594
Epoch: 2984, trainingloss: 0.00356808926372087 | validation loss: 0.003937283037288736
Epoch: 2985, trainingloss: 0.0034921997875780415 | validation loss: 0.003862742346492262
Epoch: 2986, trainingloss: 0.003857937098307319 | validation loss: 0.004177010524206213
Epoch: 2987, trainingloss: 0.003599236137297494 | validation loss: 0.003977370430596194
Epoch: 2988, trainingloss: 0.0035394679196757424 | validation loss: 0.0038710336261795378
Epoch: 2989, trainingloss: 0.003948881412060479 | validation loss: 0.004256189812788901
Epoch: 2990, trainingloss: 0.0036126831921328233 | validation loss: 0.003962811834698391
Epoch: 2991, trainingloss: 0.003286877309523298 | validation loss: 0.003667389318848494
Epoch: 2992, trainingloss: 0.004170007421312443 | validation loss: 0.004488085076419986
Epoch: 2993, trainingloss: 0.003476297502640401 | validation loss: 0.0038614603817905503
Epoch: 2994, trainingloss: 0.0036769358309177557 | validation loss: 0.004069104622526562
Epoch: 2995, trainingloss: 0.003530132395485514 | validation loss: 0.00390834190341346
Epoch: 2996, trainingloss: 0.003377535745168248 | validation loss: 0.003787256327558383
Epoch: 2997, trainingloss: 0.004158538317449151 | validation loss: 0.004436906757817783
Epoch: 2998, trainingloss: 0.003566519799412801 | validation loss: 0.0039136435761499555
Epoch: 2999, trainingloss: 0.003308060532437618 | validation loss: 0.003718846731627856
Epoch: 3000, trainingloss: 0.004104165378265001 | validation loss: 0.004414398504435816
Epoch: 3001, trainingloss: 0.003863935876689675 | validation loss: 0.004174785145754139
Epoch: 3002, trainingloss: 0.0037844082803704473 | validation loss: 0.004129165123177564
Epoch: 3003, trainingloss: 0.003959091097367606 | validation loss: 0.004288711752075422
Epoch: 3004, trainingloss: 0.0036686806434619783 | validation loss: 0.004010300064413677
Epoch: 3005, trainingloss: 0.003478630509459231 | validation loss: 0.0038443892560178824
Epoch: 3006, trainingloss: 0.003742449070084791 | validation loss: 0.0041043695222372605
Epoch: 3007, trainingloss: 0.003093662416737071 | validation loss: 0.003527195590815764
Epoch: 3008, trainingloss: 0.003648519943058018 | validation loss: 0.004021298118105911
Epoch: 3009, trainingloss: 0.00376694475518954 | validation loss: 0.0040929651382307095
Epoch: 3010, trainingloss: 0.0037457519282378684 | validation loss: 0.004075012105759036
Epoch: 3011, trainingloss: 0.003213820569449998 | validation loss: 0.003636515426536963
Epoch: 3012, trainingloss: 0.0036700567917128395 | validation loss: 0.0039855893126007685
Epoch: 3013, trainingloss: 0.0039152209553364814 | validation loss: 0.004248248515916601
Epoch: 3014, trainingloss: 0.004050771063432139 | validation loss: 0.004391518500973219
Epoch: 3015, trainingloss: 0.0037112142670827197 | validation loss: 0.004057767575949698
Epoch: 3016, trainingloss: 0.003389612564573507 | validation loss: 0.0038041705112589258
Epoch: 3017, trainingloss: 0.0041555965990058355 | validation loss: 0.0044618157196258425
Epoch: 3018, trainingloss: 0.003290128637204362 | validation loss: 0.003649617176942229
Epoch: 3019, trainingloss: 0.0034624438862225367 | validation loss: 0.00384769420814802
Epoch: 3020, trainingloss: 0.004091514345359579 | validation loss: 0.004391086171737364
Epoch: 3021, trainingloss: 0.003714359095846101 | validation loss: 0.004053055849749398
Epoch: 3022, trainingloss: 0.0036847574792708074 | validation loss: 0.004012931369744283
Epoch: 3023, trainingloss: 0.003594199620812286 | validation loss: 0.003947772254526543
Epoch: 3024, trainingloss: 0.004026810806023211 | validation loss: 0.00431176304126361
Epoch: 3025, trainingloss: 0.0033225591231685263 | validation loss: 0.003733649427552285
Epoch: 3026, trainingloss: 0.004148085187296389 | validation loss: 0.0044333256702341894
Epoch: 3027, trainingloss: 0.0036539087384742045 | validation loss: 0.004019023436652788
Epoch: 3028, trainingloss: 0.0033911184031244117 | validation loss: 0.003787017731129463
Epoch: 3029, trainingloss: 0.0034652070117380425 | validation loss: 0.003852937216429112
Epoch: 3030, trainingloss: 0.0036393438151476245 | validation loss: 0.0040038774544656165
Epoch: 3031, trainingloss: 0.0037362224562412 | validation loss: 0.004069573783580722
Epoch: 3032, trainingloss: 0.003916018052116155 | validation loss: 0.004285819500235638
Epoch: 3033, trainingloss: 0.004060424051600223 | validation loss: 0.004357192287985289
Epoch: 3034, trainingloss: 0.0035668386152417483 | validation loss: 0.003904167197517877
Epoch: 3035, trainingloss: 0.003541977512889096 | validation loss: 0.00394248441644388
Epoch: 3036, trainingloss: 0.003491576429526701 | validation loss: 0.0038702379514677842
Epoch: 3037, trainingloss: 0.003399213443977734 | validation loss: 0.003776506092967665
Epoch: 3038, trainingloss: 0.0036292740457201226 | validation loss: 0.003984720832419038
Epoch: 3039, trainingloss: 0.0035659959496239587 | validation loss: 0.003937213451912994
Epoch: 3040, trainingloss: 0.0036774778693599423 | validation loss: 0.004029047765857456
Epoch: 3041, trainingloss: 0.003633794031320278 | validation loss: 0.004003978095679286
Epoch: 3042, trainingloss: 0.0037796705982919144 | validation loss: 0.004155215951379517
Epoch: 3043, trainingloss: 0.003869035005183017 | validation loss: 0.0042254378183338055
Epoch: 3044, trainingloss: 0.0037952826938512188 | validation loss: 0.00416486205368853
Epoch: 3045, trainingloss: 0.003543994340785764 | validation loss: 0.003903581303877351
Epoch: 3046, trainingloss: 0.0036742758875270374 | validation loss: 0.004042225318473476
Epoch: 3047, trainingloss: 0.0035286171868029953 | validation loss: 0.003908698581190202
Epoch: 3048, trainingloss: 0.0033802732918879956 | validation loss: 0.003744944200032549
Epoch: 3049, trainingloss: 0.0037631677980602147 | validation loss: 0.004106088988259934
Epoch: 3050, trainingloss: 0.003577598541901503 | validation loss: 0.003942050753873567
Epoch: 3051, trainingloss: 0.0037241414410240695 | validation loss: 0.004074781175323466
Epoch: 3052, trainingloss: 0.0035156243775668022 | validation loss: 0.0039067417057186095
Epoch: 3053, trainingloss: 0.003671335559133061 | validation loss: 0.004024015664646347
Epoch: 3054, trainingloss: 0.003838088765588849 | validation loss: 0.0041809791611746245
Epoch: 3055, trainingloss: 0.0033336989309783 | validation loss: 0.0037129693896068333
Epoch: 3056, trainingloss: 0.0033062912896657097 | validation loss: 0.0036989525775281066
Epoch: 3057, trainingloss: 0.003499585155411164 | validation loss: 0.0038545854117146357
Epoch: 3058, trainingloss: 0.0035270991454696456 | validation loss: 0.003884481215241878
Epoch: 3059, trainingloss: 0.0035891496879126294 | validation loss: 0.003949678901478929
Epoch: 3060, trainingloss: 0.004062824731420107 | validation loss: 0.004399928592382945
Epoch: 3061, trainingloss: 0.00383067056002501 | validation loss: 0.004138669338978168
Epoch: 3062, trainingloss: 0.0038916684634810964 | validation loss: 0.004229935819929382
Epoch: 3063, trainingloss: 0.003760319046273316 | validation loss: 0.004121538463125312
Epoch: 3064, trainingloss: 0.0035157558326884696 | validation loss: 0.003917211827849778
Epoch: 3065, trainingloss: 0.004044761576577341 | validation loss: 0.004399798872525849
Epoch: 3066, trainingloss: 0.0033389033749184754 | validation loss: 0.003736220898571456
Epoch: 3067, trainingloss: 0.00397842453123135 | validation loss: 0.004286665710916286
Epoch: 3068, trainingloss: 0.003396680566017335 | validation loss: 0.0037539549248303077
Epoch: 3069, trainingloss: 0.003246281344096076 | validation loss: 0.0036393012560519394
Epoch: 3070, trainingloss: 0.0036118780420048196 | validation loss: 0.0039863055296723154
Epoch: 3071, trainingloss: 0.0034948208805929935 | validation loss: 0.0038535254857847193
Epoch: 3072, trainingloss: 0.003341252043283898 | validation loss: 0.0037469469753752334
Epoch: 3073, trainingloss: 0.0037158656406253805 | validation loss: 0.004058570492968214
Epoch: 3074, trainingloss: 0.0038303251315451184 | validation loss: 0.004188408159209498
Epoch: 3075, trainingloss: 0.0031848978195053506 | validation loss: 0.003568148265340711
Epoch: 3076, trainingloss: 0.004536858574651219 | validation loss: 0.004835857536302814
Epoch: 3077, trainingloss: 0.0036269022948724056 | validation loss: 0.004001103863596019
Epoch: 3078, trainingloss: 0.0037750596743353045 | validation loss: 0.004137984470142477
Epoch: 3079, trainingloss: 0.003930357052415747 | validation loss: 0.004253939887374344
Epoch: 3080, trainingloss: 0.0032004368968523147 | validation loss: 0.003615051789409934
Epoch: 3081, trainingloss: 0.003945612441711997 | validation loss: 0.0042744251544915
Epoch: 3082, trainingloss: 0.0033159939381913403 | validation loss: 0.00371136016045177
Epoch: 3083, trainingloss: 0.003678668101700974 | validation loss: 0.004064767722819187
Epoch: 3084, trainingloss: 0.0036367162448971498 | validation loss: 0.003986806636302612
Epoch: 3085, trainingloss: 0.004031905387223439 | validation loss: 0.004357907585984138
Epoch: 3086, trainingloss: 0.003645605337095644 | validation loss: 0.003980590083982055
Epoch: 3087, trainingloss: 0.004410015459245204 | validation loss: 0.004742954845101849
Epoch: 3088, trainingloss: 0.00335178033741051 | validation loss: 0.0037373703878470187
Epoch: 3089, trainingloss: 0.003916499062292511 | validation loss: 0.004262250502437649
Epoch: 3090, trainingloss: 0.003256298807942927 | validation loss: 0.0036853756592847373
Epoch: 3091, trainingloss: 0.003787816578832245 | validation loss: 0.0041139901216187096
Epoch: 3092, trainingloss: 0.0041586474150866635 | validation loss: 0.0044340076108653126
Epoch: 3093, trainingloss: 0.0032794847719505257 | validation loss: 0.003668501625352013
Epoch: 3094, trainingloss: 0.0035600227009185657 | validation loss: 0.003918646818081246
Epoch: 3095, trainingloss: 0.003806190872294244 | validation loss: 0.004121866457608055
Epoch: 3096, trainingloss: 0.0033523297536337225 | validation loss: 0.003761086521539673
Epoch: 3097, trainingloss: 0.0037122722029504017 | validation loss: 0.00411291901125375
Epoch: 3098, trainingloss: 0.003701375788530126 | validation loss: 0.004073762502947835
Epoch: 3099, trainingloss: 0.003602082569500979 | validation loss: 0.003958482186092184
Epoch: 3100, trainingloss: 0.0037904847737460527 | validation loss: 0.004116755382213197
Epoch: 3101, trainingloss: 0.003618947954675535 | validation loss: 0.004010654728956175
Epoch: 3102, trainingloss: 0.003378174414403257 | validation loss: 0.0037315785908519587
Epoch: 3103, trainingloss: 0.003862416068149851 | validation loss: 0.0042220709125149565
Epoch: 3104, trainingloss: 0.0034938113936971724 | validation loss: 0.0039026435612553277
Epoch: 3105, trainingloss: 0.004254557389745837 | validation loss: 0.004566060926729
Epoch: 3106, trainingloss: 0.003946057292059504 | validation loss: 0.004287663354320007
Epoch: 3107, trainingloss: 0.0032410372588513978 | validation loss: 0.0036301067654798715
Epoch: 3108, trainingloss: 0.003315136527299478 | validation loss: 0.003725509584419392
Epoch: 3109, trainingloss: 0.00449306848164621 | validation loss: 0.004726462383672876
Epoch: 3110, trainingloss: 0.003532459095561757 | validation loss: 0.003907888449960589
Epoch: 3111, trainingloss: 0.0033850369060531775 | validation loss: 0.003764681402252929
Epoch: 3112, trainingloss: 0.003906662219279363 | validation loss: 0.004225709815585924
Epoch: 3113, trainingloss: 0.003220850644822948 | validation loss: 0.003635919319007324
Epoch: 3114, trainingloss: 0.003424774620984047 | validation loss: 0.003795008972090863
Epoch: 3115, trainingloss: 0.003538908079852639 | validation loss: 0.003920128619667706
Epoch: 3116, trainingloss: 0.004284260824911132 | validation loss: 0.004572723159074513
Epoch: 3117, trainingloss: 0.003372840155174731 | validation loss: 0.0037442215106158147
Epoch: 3118, trainingloss: 0.0036608756346317504 | validation loss: 0.003995438907226635
Epoch: 3119, trainingloss: 0.0034241454352030415 | validation loss: 0.003821724571536093
Epoch: 3120, trainingloss: 0.0037778698172436223 | validation loss: 0.004109886947179798
Epoch: 3121, trainingloss: 0.003841934159429441 | validation loss: 0.004194398669142557
Epoch: 3122, trainingloss: 0.003429467175739549 | validation loss: 0.0038161083025561836
Epoch: 3123, trainingloss: 0.0035392004884489993 | validation loss: 0.0039224355858428536
Epoch: 3124, trainingloss: 0.0038486818335825524 | validation loss: 0.0042093471884288546
Epoch: 3125, trainingloss: 0.003671874912741597 | validation loss: 0.004031662936223294
Epoch: 3126, trainingloss: 0.003613373062774619 | validation loss: 0.003998480463563595
Epoch: 3127, trainingloss: 0.003984290313276702 | validation loss: 0.004309216823685578
Epoch: 3128, trainingloss: 0.003305314993154357 | validation loss: 0.0037008692250814837
Epoch: 3129, trainingloss: 0.003999049108641479 | validation loss: 0.004336622524180327
Epoch: 3130, trainingloss: 0.003529116834839165 | validation loss: 0.003917539544693962
Epoch: 3131, trainingloss: 0.0038321442245243687 | validation loss: 0.004229919172399958
Epoch: 3132, trainingloss: 0.0033206161213228183 | validation loss: 0.003723663635283682
Epoch: 3133, trainingloss: 0.00353636107348853 | validation loss: 0.0039030707917579377
Epoch: 3134, trainingloss: 0.0037940537630825892 | validation loss: 0.004158303991849113
Epoch: 3135, trainingloss: 0.0032333706371997996 | validation loss: 0.0036178105972773465
Epoch: 3136, trainingloss: 0.003856884882695149 | validation loss: 0.004212547040005976
Epoch: 3137, trainingloss: 0.003341724692492517 | validation loss: 0.003755127344104723
Epoch: 3138, trainingloss: 0.003925578757556722 | validation loss: 0.004274603159957645
Epoch: 3139, trainingloss: 0.003602322640184683 | validation loss: 0.003962046305211335
Epoch: 3140, trainingloss: 0.003192244547382552 | validation loss: 0.003630738071623243
Epoch: 3141, trainingloss: 0.004370557268649323 | validation loss: 0.004681698746893349
Epoch: 3142, trainingloss: 0.003244283966010637 | validation loss: 0.003680413113319182
Epoch: 3143, trainingloss: 0.003659250721865687 | validation loss: 0.004020605802735551
Epoch: 3144, trainingloss: 0.003543240945402946 | validation loss: 0.003908223105259309
Epoch: 3145, trainingloss: 0.0036175172396925403 | validation loss: 0.003989392788193102
Epoch: 3146, trainingloss: 0.0037586420260885744 | validation loss: 0.004111491964377625
Epoch: 3147, trainingloss: 0.0034449429915293806 | validation loss: 0.0038285180242642334
Epoch: 3148, trainingloss: 0.00400064690755664 | validation loss: 0.004307994958565907
Epoch: 3149, trainingloss: 0.003843903374082599 | validation loss: 0.004165879804800716
Epoch: 3150, trainingloss: 0.004241154558516313 | validation loss: 0.004541246926710199
Epoch: 3151, trainingloss: 0.003444067827933292 | validation loss: 0.0038406419582430445
Epoch: 3152, trainingloss: 0.00336136455630523 | validation loss: 0.0037486077238606456
Epoch: 3153, trainingloss: 0.004013096001298748 | validation loss: 0.004367981690639504
Epoch: 3154, trainingloss: 0.004197955118375697 | validation loss: 0.004503194387057549
Epoch: 3155, trainingloss: 0.003538823084470931 | validation loss: 0.003920577580618406
Epoch: 3156, trainingloss: 0.0035816036150002313 | validation loss: 0.003981335775890024
Epoch: 3157, trainingloss: 0.0037265492039631654 | validation loss: 0.0040981987451017355
Epoch: 3158, trainingloss: 0.0038584216735972573 | validation loss: 0.004191156649683749
Epoch: 3159, trainingloss: 0.0035799799693105056 | validation loss: 0.003959798942140552
Epoch: 3160, trainingloss: 0.0037807862643838668 | validation loss: 0.0041464408081458405
Epoch: 3161, trainingloss: 0.0034273227052997136 | validation loss: 0.0038136105668952554
Epoch: 3162, trainingloss: 0.0039000006620037 | validation loss: 0.00422968859644361
Epoch: 3163, trainingloss: 0.0033667576618645555 | validation loss: 0.003758554331723647
Epoch: 3164, trainingloss: 0.003788513110638556 | validation loss: 0.004144995481718258
Epoch: 3165, trainingloss: 0.004665177644460609 | validation loss: 0.004944434681538998
Epoch: 3166, trainingloss: 0.0033752226080465235 | validation loss: 0.003741587253336745
Epoch: 3167, trainingloss: 0.0038427366193341337 | validation loss: 0.004206012840722265
Epoch: 3168, trainingloss: 0.004025423232231827 | validation loss: 0.00437828705219235
Epoch: 3169, trainingloss: 0.003989880879690433 | validation loss: 0.004295969639267025
Epoch: 3170, trainingloss: 0.003417505814006397 | validation loss: 0.0038175830018515756
Epoch: 3171, trainingloss: 0.0033838427001689113 | validation loss: 0.0037789949976107877
Epoch: 3172, trainingloss: 0.003471496270904093 | validation loss: 0.0038495132606678217
Epoch: 3173, trainingloss: 0.004186768758490335 | validation loss: 0.00451654120729704
Epoch: 3174, trainingloss: 0.004168359198414147 | validation loss: 0.004455062094514943
Epoch: 3175, trainingloss: 0.003430057849965205 | validation loss: 0.003807057898147072
Epoch: 3176, trainingloss: 0.003831860394384787 | validation loss: 0.004197971301555388
Epoch: 3177, trainingloss: 0.00360426620705702 | validation loss: 0.003973975381727453
Epoch: 3178, trainingloss: 0.0033445887538415034 | validation loss: 0.0037301356607103075
Epoch: 3179, trainingloss: 0.003408322922639112 | validation loss: 0.0037881461811978033
Epoch: 3180, trainingloss: 0.003947737160982692 | validation loss: 0.004274559343746167
Epoch: 3181, trainingloss: 0.0037419917881945943 | validation loss: 0.00409471207764091
Epoch: 3182, trainingloss: 0.0034333512262884375 | validation loss: 0.0038026250849305314
Epoch: 3183, trainingloss: 0.003196835064663373 | validation loss: 0.003587344986902595
Epoch: 3184, trainingloss: 0.0039160261360293375 | validation loss: 0.004271020978248362
Epoch: 3185, trainingloss: 0.003469258353291829 | validation loss: 0.003855722252415066
Epoch: 3186, trainingloss: 0.004165198492145208 | validation loss: 0.004478662371523527
Epoch: 3187, trainingloss: 0.003912500238840777 | validation loss: 0.0042512747344667645
Epoch: 3188, trainingloss: 0.003486361658649709 | validation loss: 0.0038484427160316585
Epoch: 3189, trainingloss: 0.003373495102675353 | validation loss: 0.00376772137030426
Epoch: 3190, trainingloss: 0.0032870045323278732 | validation loss: 0.003679284951903753
Epoch: 3191, trainingloss: 0.003990955945285138 | validation loss: 0.004306183018293785
Epoch: 3192, trainingloss: 0.0036264075927010127 | validation loss: 0.003977378375246525
Epoch: 3193, trainingloss: 0.003375531840009714 | validation loss: 0.0037701750896466705
Epoch: 3194, trainingloss: 0.003680258176555075 | validation loss: 0.004043933516371716
Epoch: 3195, trainingloss: 0.0030429719072055266 | validation loss: 0.003471204188658021
Epoch: 3196, trainingloss: 0.0038417442404483034 | validation loss: 0.004177216644626045
Epoch: 3197, trainingloss: 0.003550966719406135 | validation loss: 0.003913376913722371
Epoch: 3198, trainingloss: 0.003404512542707367 | validation loss: 0.003786147855827649
Epoch: 3199, trainingloss: 0.0032513495596908273 | validation loss: 0.0036398694810418596
Epoch: 3200, trainingloss: 0.0034043827869521984 | validation loss: 0.0037951497665271497
Epoch: 3201, trainingloss: 0.003276194397763594 | validation loss: 0.003659310184359265
Epoch: 3202, trainingloss: 0.0033191067766818435 | validation loss: 0.0037196128144013955
Epoch: 3203, trainingloss: 0.0036272234106597815 | validation loss: 0.0039577196532076765
Epoch: 3204, trainingloss: 0.004062323159056665 | validation loss: 0.004400415094982067
Epoch: 3205, trainingloss: 0.00377798285167053 | validation loss: 0.0041599223605081545
Epoch: 3206, trainingloss: 0.0033068984970848845 | validation loss: 0.003734354523204925
Epoch: 3207, trainingloss: 0.003875469055169499 | validation loss: 0.004187292266931814
Epoch: 3208, trainingloss: 0.0034508237871330215 | validation loss: 0.0038234786407599403
Epoch: 3209, trainingloss: 0.003888173699724163 | validation loss: 0.004216250774410914
Epoch: 3210, trainingloss: 0.0033264665893011007 | validation loss: 0.0037601761589683576
Epoch: 3211, trainingloss: 0.0037158601582997362 | validation loss: 0.004060592874505272
Epoch: 3212, trainingloss: 0.003374407478978742 | validation loss: 0.0037701336107127956
Epoch: 3213, trainingloss: 0.003244195610177159 | validation loss: 0.0036623751364444615
Epoch: 3214, trainingloss: 0.003795487504523092 | validation loss: 0.0041224874582049785
Epoch: 3215, trainingloss: 0.0038365477761646686 | validation loss: 0.004206368469053242
Epoch: 3216, trainingloss: 0.003281982448033444 | validation loss: 0.003687349460385451
Epoch: 3217, trainingloss: 0.004005816517701421 | validation loss: 0.004296380677150549
Epoch: 3218, trainingloss: 0.0036925241169195643 | validation loss: 0.004058438246823718
Epoch: 3219, trainingloss: 0.0038564111667610396 | validation loss: 0.004214133382955755
Epoch: 3220, trainingloss: 0.003966416006023692 | validation loss: 0.004295685993560285
Epoch: 3221, trainingloss: 0.003319704456068973 | validation loss: 0.0036967970763029357
Epoch: 3222, trainingloss: 0.0035940811407599227 | validation loss: 0.003961526617515979
Epoch: 3223, trainingloss: 0.0034266754022032318 | validation loss: 0.003813513503057269
Epoch: 3224, trainingloss: 0.003385352759428337 | validation loss: 0.0037751447559337863
Epoch: 3225, trainingloss: 0.004164911967969494 | validation loss: 0.0044765093463624665
Epoch: 3226, trainingloss: 0.0034053809780089607 | validation loss: 0.0038457816920227485
Epoch: 3227, trainingloss: 0.0033016956857956905 | validation loss: 0.0036916695972195788
Epoch: 3228, trainingloss: 0.0039441539853497555 | validation loss: 0.004286792549918446
Epoch: 3229, trainingloss: 0.003286078595251382 | validation loss: 0.0036848506839781436
Epoch: 3230, trainingloss: 0.004437767602030658 | validation loss: 0.004704066354094955
Epoch: 3231, trainingloss: 0.003438794939728873 | validation loss: 0.003829259516532426
Epoch: 3232, trainingloss: 0.0034248789293972637 | validation loss: 0.0037873752456973036
Epoch: 3233, trainingloss: 0.00377872896377134 | validation loss: 0.0041286465367919465
Epoch: 3234, trainingloss: 0.0036893421330963802 | validation loss: 0.0040435132566607095
Epoch: 3235, trainingloss: 0.004220351466744573 | validation loss: 0.004538000164180212
Epoch: 3236, trainingloss: 0.003964664527407219 | validation loss: 0.004308754410007948
Epoch: 3237, trainingloss: 0.0034829328519382203 | validation loss: 0.0038628324062641686
Epoch: 3238, trainingloss: 0.003964081804852622 | validation loss: 0.0042676127381260556
Epoch: 3239, trainingloss: 0.004147374857692708 | validation loss: 0.004491262984400632
Epoch: 3240, trainingloss: 0.0032993174817472913 | validation loss: 0.003683825472841142
Epoch: 3241, trainingloss: 0.003627767900360044 | validation loss: 0.004016700020287646
Epoch: 3242, trainingloss: 0.004316645008014052 | validation loss: 0.004611005356554769
Epoch: 3243, trainingloss: 0.0037341785232287393 | validation loss: 0.004091788962247635
Epoch: 3244, trainingloss: 0.003649398628200897 | validation loss: 0.004003236179589635
Epoch: 3245, trainingloss: 0.0037218623738074696 | validation loss: 0.004088368944239672
Epoch: 3246, trainingloss: 0.0038607975987030485 | validation loss: 0.004226811946325221
Epoch: 3247, trainingloss: 0.0034962263632147953 | validation loss: 0.003897400818340398
Epoch: 3248, trainingloss: 0.003481817761697823 | validation loss: 0.0038604909897342024
Epoch: 3249, trainingloss: 0.003671621692199912 | validation loss: 0.004007727690891427
Epoch: 3250, trainingloss: 0.003539079473949719 | validation loss: 0.003933486453874619
Epoch: 3251, trainingloss: 0.00414793778409874 | validation loss: 0.004466764199949696
Epoch: 3252, trainingloss: 0.005169983320438854 | validation loss: 0.005452209423651415
Epoch: 3253, trainingloss: 0.003346311509875727 | validation loss: 0.003747279297438047
Epoch: 3254, trainingloss: 0.0040387902501526005 | validation loss: 0.004343770424635433
Epoch: 3255, trainingloss: 0.0040914361891323265 | validation loss: 0.004366735856567011
Epoch: 3256, trainingloss: 0.003380136982659273 | validation loss: 0.003783446211500896
Epoch: 3257, trainingloss: 0.003647011661903467 | validation loss: 0.004026631507194851
Epoch: 3258, trainingloss: 0.003957810195886316 | validation loss: 0.0042776762967017415
Epoch: 3259, trainingloss: 0.0035094091459701078 | validation loss: 0.0038820812607394126
Epoch: 3260, trainingloss: 0.003667101009897608 | validation loss: 0.004018801905077242
Epoch: 3261, trainingloss: 0.003451530995916582 | validation loss: 0.003830302657164731
Epoch: 3262, trainingloss: 0.003561047575237711 | validation loss: 0.003909471389612276
Epoch: 3263, trainingloss: 0.003976442261004172 | validation loss: 0.004291844502778759
Epoch: 3264, trainingloss: 0.003371560727629258 | validation loss: 0.0037895493588921696
Epoch: 3265, trainingloss: 0.0036174264152509295 | validation loss: 0.003986676006348643
Epoch: 3266, trainingloss: 0.003702506487744975 | validation loss: 0.004057071879528631
Epoch: 3267, trainingloss: 0.0037226516949192957 | validation loss: 0.004071505906030546
Epoch: 3268, trainingloss: 0.003425084654855813 | validation loss: 0.0038206489083850753
Epoch: 3269, trainingloss: 0.004027599352562535 | validation loss: 0.004360626029575654
Epoch: 3270, trainingloss: 0.003374155259385499 | validation loss: 0.003754641950453862
Epoch: 3271, trainingloss: 0.003345703349703846 | validation loss: 0.0037532565216142812
Epoch: 3272, trainingloss: 0.003696003953992876 | validation loss: 0.004056320694181558
Epoch: 3273, trainingloss: 0.0037950345026608345 | validation loss: 0.0041476524039372525
Epoch: 3274, trainingloss: 0.0035951802040157395 | validation loss: 0.003969631313128552
Epoch: 3275, trainingloss: 0.0033944370042836786 | validation loss: 0.003758249084135489
Epoch: 3276, trainingloss: 0.0030807942031705663 | validation loss: 0.0034995580267797336
Epoch: 3277, trainingloss: 0.003482242162539274 | validation loss: 0.0038518339744852584
Epoch: 3278, trainingloss: 0.003315080498569335 | validation loss: 0.0037236122297736067
Epoch: 3279, trainingloss: 0.003670830206356265 | validation loss: 0.004013992366114401
Epoch: 3280, trainingloss: 0.003737821296551612 | validation loss: 0.004079344259917117
Epoch: 3281, trainingloss: 0.00330381440580219 | validation loss: 0.003714429921442509
Epoch: 3282, trainingloss: 0.0035187674624144434 | validation loss: 0.003907778286626031
Epoch: 3283, trainingloss: 0.003435222901424268 | validation loss: 0.003823804751445246
Epoch: 3284, trainingloss: 0.0035810231213884193 | validation loss: 0.003951028505251986
Epoch: 3285, trainingloss: 0.0034286820457308308 | validation loss: 0.0038172124876449387
Epoch: 3286, trainingloss: 0.0042486862225844906 | validation loss: 0.00457648880820856
Epoch: 3287, trainingloss: 0.0035332522407007802 | validation loss: 0.003913166662960933
Epoch: 3288, trainingloss: 0.0032216057295827946 | validation loss: 0.0036676271280008904
Epoch: 3289, trainingloss: 0.003556416621026334 | validation loss: 0.003947680942741767
Epoch: 3290, trainingloss: 0.0036286241342815585 | validation loss: 0.0039743258233954125
Epoch: 3291, trainingloss: 0.003341870034131896 | validation loss: 0.0037567795078049214
Epoch: 3292, trainingloss: 0.0041327010301000985 | validation loss: 0.004478896232405913
Epoch: 3293, trainingloss: 0.003170225932295086 | validation loss: 0.0035949249939205034
Epoch: 3294, trainingloss: 0.003198404687209122 | validation loss: 0.003619632938425576
Epoch: 3295, trainingloss: 0.003962920824622266 | validation loss: 0.004316253925410627
Epoch: 3296, trainingloss: 0.0036498980635548185 | validation loss: 0.004032431417054881
Epoch: 3297, trainingloss: 0.0036875898688804717 | validation loss: 0.004013147297159221
Epoch: 3298, trainingloss: 0.0037054093827215894 | validation loss: 0.004083047531005947
Epoch: 3299, trainingloss: 0.0033616273740947984 | validation loss: 0.0037736524731733917
Epoch: 3300, trainingloss: 0.003888550963788589 | validation loss: 0.004264496985987536
Epoch: 3301, trainingloss: 0.003485620424283884 | validation loss: 0.003857027092333344
Epoch: 3302, trainingloss: 0.00386376283787062 | validation loss: 0.004207898337654057
Epoch: 3303, trainingloss: 0.003823394838011612 | validation loss: 0.00419296774021962
Epoch: 3304, trainingloss: 0.0035065178960176978 | validation loss: 0.0038980501894940447
Epoch: 3305, trainingloss: 0.003616952846735346 | validation loss: 0.003970475464692422
Epoch: 3306, trainingloss: 0.0035809531642041863 | validation loss: 0.004001510003764406
Epoch: 3307, trainingloss: 0.003441997358529547 | validation loss: 0.0038204317091372402
Epoch: 3308, trainingloss: 0.003507842677600891 | validation loss: 0.0038733234924564065
Epoch: 3309, trainingloss: 0.0036608161279817566 | validation loss: 0.004034053226832761
Epoch: 3310, trainingloss: 0.0033426556705581974 | validation loss: 0.0037407780894085215
Epoch: 3311, trainingloss: 0.003562199300508704 | validation loss: 0.003961805585539753
Epoch: 3312, trainingloss: 0.003720475314334837 | validation loss: 0.004088019010938449
Epoch: 3313, trainingloss: 0.003399715775067888 | validation loss: 0.0037693855798903927
Epoch: 3314, trainingloss: 0.004030916629656969 | validation loss: 0.004412737862638466
Epoch: 3315, trainingloss: 0.0033155254797017533 | validation loss: 0.0037045873656539386
Epoch: 3316, trainingloss: 0.0038737010895671673 | validation loss: 0.0042445505411800285
Epoch: 3317, trainingloss: 0.004040880816807536 | validation loss: 0.004365444371955486
Epoch: 3318, trainingloss: 0.004434235018669978 | validation loss: 0.00472275295726337
Epoch: 3319, trainingloss: 0.003964771270609069 | validation loss: 0.004316856394395155
Epoch: 3320, trainingloss: 0.0032307607235950784 | validation loss: 0.003647433414363164
Epoch: 3321, trainingloss: 0.003542904243309261 | validation loss: 0.003944619923205677
Epoch: 3322, trainingloss: 0.0033876079536000214 | validation loss: 0.0037841079301972145
Epoch: 3323, trainingloss: 0.0037266844254342977 | validation loss: 0.0040464673721180115
Epoch: 3324, trainingloss: 0.00326528680871818 | validation loss: 0.003694757677971766
Epoch: 3325, trainingloss: 0.003154053073158796 | validation loss: 0.003571779476810656
Epoch: 3326, trainingloss: 0.0035995567455152544 | validation loss: 0.003991020190173652
Epoch: 3327, trainingloss: 0.003360655933647684 | validation loss: 0.0037376937173069953
Epoch: 3328, trainingloss: 0.0037446497065517265 | validation loss: 0.0041155328080755525
Epoch: 3329, trainingloss: 0.0033132018466581394 | validation loss: 0.003726269034666325
Epoch: 3330, trainingloss: 0.004131002330391847 | validation loss: 0.004445423058743018
Epoch: 3331, trainingloss: 0.0039570923948192525 | validation loss: 0.0043061519677204865
Epoch: 3332, trainingloss: 0.0035978364606903362 | validation loss: 0.003978708543930806
Epoch: 3333, trainingloss: 0.003429323349985823 | validation loss: 0.0037965631458616615
Epoch: 3334, trainingloss: 0.0035477619948676804 | validation loss: 0.003918481809500934
Epoch: 3335, trainingloss: 0.003439250956616544 | validation loss: 0.003839606450370299
Epoch: 3336, trainingloss: 0.0038854377161653447 | validation loss: 0.004209148178822219
Epoch: 3337, trainingloss: 0.0036439931661861784 | validation loss: 0.0039991708328354645
Epoch: 3338, trainingloss: 0.0033165720170805976 | validation loss: 0.0037350328195625694
Epoch: 3339, trainingloss: 0.0035654079726765075 | validation loss: 0.003974356071005778
Epoch: 3340, trainingloss: 0.0033342476054638993 | validation loss: 0.0037371496063910484
Epoch: 3341, trainingloss: 0.0033016768074012903 | validation loss: 0.003697470138392807
Epoch: 3342, trainingloss: 0.0035164600380332913 | validation loss: 0.003868346150061116
Epoch: 3343, trainingloss: 0.003466332096040607 | validation loss: 0.003854613787679166
Epoch: 3344, trainingloss: 0.003658564721685255 | validation loss: 0.004034308492047003
Epoch: 3345, trainingloss: 0.003825469704190949 | validation loss: 0.004163780466871209
Epoch: 3346, trainingloss: 0.0036185135435993273 | validation loss: 0.00400524741585012
Epoch: 3347, trainingloss: 0.0036227999264103815 | validation loss: 0.004015102508931143
Epoch: 3348, trainingloss: 0.0037405339876991407 | validation loss: 0.004110765337234442
Epoch: 3349, trainingloss: 0.003397590328306122 | validation loss: 0.0037843746150359858
Epoch: 3350, trainingloss: 0.00328229264212165 | validation loss: 0.003662346591421413
Epoch: 3351, trainingloss: 0.0037518128585442086 | validation loss: 0.0041073482503352875
Epoch: 3352, trainingloss: 0.0037449466967267968 | validation loss: 0.004096846031014838
Epoch: 3353, trainingloss: 0.00419175550601457 | validation loss: 0.004503955148859276
Epoch: 3354, trainingloss: 0.003778255169435024 | validation loss: 0.004130994441611699
Epoch: 3355, trainingloss: 0.0032843414984165464 | validation loss: 0.003708522971554708
Epoch: 3356, trainingloss: 0.003524844737030659 | validation loss: 0.003905233063053602
Epoch: 3357, trainingloss: 0.003946326537231892 | validation loss: 0.0042868236552182455
Epoch: 3358, trainingloss: 0.004150899076696973 | validation loss: 0.004475467736817796
Epoch: 3359, trainingloss: 0.0035059706372234543 | validation loss: 0.0038793541803944136
Epoch: 3360, trainingloss: 0.0035476569338257265 | validation loss: 0.003917781444461595
Epoch: 3361, trainingloss: 0.0037498058609784224 | validation loss: 0.00413613132554153
Epoch: 3362, trainingloss: 0.0035710956417509634 | validation loss: 0.003970112271140615
Epoch: 3363, trainingloss: 0.0035758693032607483 | validation loss: 0.003957673624468885
Epoch: 3364, trainingloss: 0.003570920433626207 | validation loss: 0.003953985312124983
Epoch: 3365, trainingloss: 0.003912832809228257 | validation loss: 0.0043021349031814125
Epoch: 3366, trainingloss: 0.00381695429667697 | validation loss: 0.004155390475539432
Epoch: 3367, trainingloss: 0.003780447306424906 | validation loss: 0.00414394600684226
Epoch: 3368, trainingloss: 0.0036065196724073636 | validation loss: 0.00400585255275417
Epoch: 3369, trainingloss: 0.0036714256665472435 | validation loss: 0.004035600084307547
Epoch: 3370, trainingloss: 0.0035774862316723327 | validation loss: 0.003969256220051862
Epoch: 3371, trainingloss: 0.003533046234031381 | validation loss: 0.003937070410243542
Epoch: 3372, trainingloss: 0.0038803580088563735 | validation loss: 0.004234166719559254
Epoch: 3373, trainingloss: 0.0032535920809682217 | validation loss: 0.003670582577980982
Epoch: 3374, trainingloss: 0.0033595743667026766 | validation loss: 0.0037710069009551143
Epoch: 3375, trainingloss: 0.0034293127686038445 | validation loss: 0.003836756172941508
Epoch: 3376, trainingloss: 0.003416085149420944 | validation loss: 0.0038125767173332746
Epoch: 3377, trainingloss: 0.0034553699362714803 | validation loss: 0.003821793237316358
Epoch: 3378, trainingloss: 0.004250667818698147 | validation loss: 0.004541414102947524
Epoch: 3379, trainingloss: 0.003378684458726929 | validation loss: 0.0037974823392948856
Epoch: 3380, trainingloss: 0.004141114345752747 | validation loss: 0.0044674187556606485
Epoch: 3381, trainingloss: 0.0034824681916768596 | validation loss: 0.003891793983825258
Epoch: 3382, trainingloss: 0.0037032512736305066 | validation loss: 0.004050689850600959
Epoch: 3383, trainingloss: 0.0033267477602213417 | validation loss: 0.003742664530285536
Epoch: 3384, trainingloss: 0.0044375977700899984 | validation loss: 0.004728775234810233
Epoch: 3385, trainingloss: 0.003321393670961821 | validation loss: 0.003719261200915162
Epoch: 3386, trainingloss: 0.0038811176331160413 | validation loss: 0.004208138788583337
Epoch: 3387, trainingloss: 0.003373992624526916 | validation loss: 0.0037768352367222066
Epoch: 3388, trainingloss: 0.004109902017253499 | validation loss: 0.004408466803300748
Epoch: 3389, trainingloss: 0.00402430005181622 | validation loss: 0.0043598763588128695
Epoch: 3390, trainingloss: 0.0035369214654566504 | validation loss: 0.003917316863175587
Epoch: 3391, trainingloss: 0.00404392366553292 | validation loss: 0.004381920545586579
Epoch: 3392, trainingloss: 0.004131520482190154 | validation loss: 0.00451181380226086
Epoch: 3393, trainingloss: 0.0037973922839606056 | validation loss: 0.0041377488122935875
Epoch: 3394, trainingloss: 0.003411474823946267 | validation loss: 0.0038145586898917045
Epoch: 3395, trainingloss: 0.0039901462960056965 | validation loss: 0.004339201838917275
Epoch: 3396, trainingloss: 0.0035719582818862657 | validation loss: 0.003975531221151184
Epoch: 3397, trainingloss: 0.004011397606823681 | validation loss: 0.0043181423844755405
Epoch: 3398, trainingloss: 0.0034759006814658044 | validation loss: 0.003856655501466794
Epoch: 3399, trainingloss: 0.003643081000676662 | validation loss: 0.004010398783211467
Epoch: 3400, trainingloss: 0.004116060951228775 | validation loss: 0.004451195186115086
Epoch: 3401, trainingloss: 0.0032988272827738562 | validation loss: 0.003723049934662303
Epoch: 3402, trainingloss: 0.003673695915122731 | validation loss: 0.004048938782368863
Epoch: 3403, trainingloss: 0.0036109444836709536 | validation loss: 0.0039596134235195726
Epoch: 3404, trainingloss: 0.003548496487557644 | validation loss: 0.003947036221800297
Epoch: 3405, trainingloss: 0.003747114011855591 | validation loss: 0.004088693926248584
Epoch: 3406, trainingloss: 0.0032121966986988462 | validation loss: 0.0036325582844189456
Epoch: 3407, trainingloss: 0.0037000705818892713 | validation loss: 0.004087785054459179
Epoch: 3408, trainingloss: 0.003282602256511091 | validation loss: 0.003661321790593383
Epoch: 3409, trainingloss: 0.004217689120046302 | validation loss: 0.004535849453598551
Epoch: 3410, trainingloss: 0.0035974938018826117 | validation loss: 0.00397776828298162
Epoch: 3411, trainingloss: 0.0037548109287126666 | validation loss: 0.004143133021216691
Epoch: 3412, trainingloss: 0.004038374291157959 | validation loss: 0.004367990104419741
Epoch: 3413, trainingloss: 0.003917701075591528 | validation loss: 0.004236909574136635
Epoch: 3414, trainingloss: 0.0035312012376286584 | validation loss: 0.0039040213635413907
Epoch: 3415, trainingloss: 0.0036344608602260097 | validation loss: 0.004001185046675432
Epoch: 3416, trainingloss: 0.00386618559992414 | validation loss: 0.0042411748709651345
Epoch: 3417, trainingloss: 0.0033039151874937373 | validation loss: 0.0036850121876051745
Epoch: 3418, trainingloss: 0.004039605222465974 | validation loss: 0.004395098096060343
Epoch: 3419, trainingloss: 0.0036369390588009624 | validation loss: 0.004016828107934146
Epoch: 3420, trainingloss: 0.0032456842288235456 | validation loss: 0.0036541365878528767
Epoch: 3421, trainingloss: 0.0032368503579836443 | validation loss: 0.0036731563057367466
Epoch: 3422, trainingloss: 0.0033488782777030737 | validation loss: 0.0037683186220537047
Epoch: 3423, trainingloss: 0.0032920727547729187 | validation loss: 0.003649980198612542
Epoch: 3424, trainingloss: 0.003678382080348966 | validation loss: 0.004067364679684513
Epoch: 3425, trainingloss: 0.003875719863602276 | validation loss: 0.004230267715228596
Epoch: 3426, trainingloss: 0.003507995431884455 | validation loss: 0.0038949657944593553
Epoch: 3427, trainingloss: 0.0033035146867846934 | validation loss: 0.0037194023935842127
Epoch: 3428, trainingloss: 0.0032835357729341127 | validation loss: 0.003676549671273791
Epoch: 3429, trainingloss: 0.003887840275733498 | validation loss: 0.0042578317549638285
Epoch: 3430, trainingloss: 0.0037057268207164058 | validation loss: 0.004083246744893258
Epoch: 3431, trainingloss: 0.0036361843553862436 | validation loss: 0.004014352537528494
Epoch: 3432, trainingloss: 0.004018564236877895 | validation loss: 0.004367567324883117
Epoch: 3433, trainingloss: 0.0037989933560651414 | validation loss: 0.004144843253873659
Epoch: 3434, trainingloss: 0.003611230033697718 | validation loss: 0.003959192156095194
Epoch: 3435, trainingloss: 0.004171474235529024 | validation loss: 0.004524476303594715
Epoch: 3436, trainingloss: 0.0032378028802534245 | validation loss: 0.003662762920574341
Epoch: 3437, trainingloss: 0.003727230087087213 | validation loss: 0.004105008195911123
Epoch: 3438, trainingloss: 0.003928858229079368 | validation loss: 0.004264860023595754
Epoch: 3439, trainingloss: 0.00353619393851574 | validation loss: 0.0039492945159496405
Epoch: 3440, trainingloss: 0.003750546489426311 | validation loss: 0.0040636339920724135
Epoch: 3441, trainingloss: 0.003767962907697303 | validation loss: 0.004136923861656188
Epoch: 3442, trainingloss: 0.0034760379678063897 | validation loss: 0.0038579770079676663
Epoch: 3443, trainingloss: 0.005175397999071745 | validation loss: 0.00547342081715278
Epoch: 3444, trainingloss: 0.003242671112343056 | validation loss: 0.003638774012360915
Epoch: 3445, trainingloss: 0.00412130899410958 | validation loss: 0.004396351583258106
Epoch: 3446, trainingloss: 0.00415642418636234 | validation loss: 0.00447953398777437
Epoch: 3447, trainingloss: 0.0034253656332811247 | validation loss: 0.003793942811312268
Epoch: 3448, trainingloss: 0.004131553102513324 | validation loss: 0.004405122783882361
Epoch: 3449, trainingloss: 0.004281405025685956 | validation loss: 0.0045622853665884325
Epoch: 3450, trainingloss: 0.0037093447813277337 | validation loss: 0.004060657485851147
Epoch: 3451, trainingloss: 0.003770715596612701 | validation loss: 0.004102673276287569
Epoch: 3452, trainingloss: 0.003532121880896988 | validation loss: 0.003920272987177941
Epoch: 3453, trainingloss: 0.003447223439070689 | validation loss: 0.0038607511317858907
Epoch: 3454, trainingloss: 0.003689297624643628 | validation loss: 0.004079552803227306
Epoch: 3455, trainingloss: 0.003384817135155577 | validation loss: 0.003785708894519167
Epoch: 3456, trainingloss: 0.0035729313081623785 | validation loss: 0.003957350744455708
Epoch: 3457, trainingloss: 0.004080541755956105 | validation loss: 0.004373389444347738
Epoch: 3458, trainingloss: 0.004022240461628337 | validation loss: 0.004370610208342435
Epoch: 3459, trainingloss: 0.003732326962022011 | validation loss: 0.004083082600647353
Epoch: 3460, trainingloss: 0.003534891343901623 | validation loss: 0.0039028123937868697
Epoch: 3461, trainingloss: 0.0037973310783879955 | validation loss: 0.00414444481261552
Epoch: 3462, trainingloss: 0.004111544338593675 | validation loss: 0.004430610508285415
Epoch: 3463, trainingloss: 0.004078951518862982 | validation loss: 0.0044210743436045394
Epoch: 3464, trainingloss: 0.003512235000191066 | validation loss: 0.003905502913150437
Epoch: 3465, trainingloss: 0.0035334175674414637 | validation loss: 0.003914916204712752
Epoch: 3466, trainingloss: 0.0033325580241799335 | validation loss: 0.00372345388734349
Epoch: 3467, trainingloss: 0.003413862743714911 | validation loss: 0.0037867532924556685
Epoch: 3468, trainingloss: 0.0036750332789116384 | validation loss: 0.0040492181927363115
Epoch: 3469, trainingloss: 0.0035736560089808917 | validation loss: 0.003944550586854813
Epoch: 3470, trainingloss: 0.0035181711695982357 | validation loss: 0.0038763335782778983
Epoch: 3471, trainingloss: 0.003794995384729232 | validation loss: 0.004133798416147103
Epoch: 3472, trainingloss: 0.0031992155123927715 | validation loss: 0.0036297543909106496
Epoch: 3473, trainingloss: 0.0033684256449181263 | validation loss: 0.0037901851781670395
Epoch: 3474, trainingloss: 0.0034935257716679274 | validation loss: 0.003912250855662988
Epoch: 3475, trainingloss: 0.003327808516508047 | validation loss: 0.003771861272183125
Epoch: 3476, trainingloss: 0.0031604065882036266 | validation loss: 0.0035937768336857657
Epoch: 3477, trainingloss: 0.003968738515261201 | validation loss: 0.0043019606324954975
Epoch: 3478, trainingloss: 0.0033431304250706156 | validation loss: 0.0037491333945041303
Epoch: 3479, trainingloss: 0.003568802189664872 | validation loss: 0.003965040785524887
Epoch: 3480, trainingloss: 0.004056053721819803 | validation loss: 0.004373368586130867
Epoch: 3481, trainingloss: 0.0038545667202980367 | validation loss: 0.004170583998230319
Epoch: 3482, trainingloss: 0.004026956823677579 | validation loss: 0.0043955723891198435
Epoch: 3483, trainingloss: 0.003870050439249451 | validation loss: 0.004196604311447048
Epoch: 3484, trainingloss: 0.003874102625018021 | validation loss: 0.004191712776021182
Epoch: 3485, trainingloss: 0.0035075248159056713 | validation loss: 0.003885568650411635
Epoch: 3486, trainingloss: 0.0033253543548505925 | validation loss: 0.003736825043510538
Epoch: 3487, trainingloss: 0.0035887870955872985 | validation loss: 0.00396298418698029
Epoch: 3488, trainingloss: 0.003215016149473874 | validation loss: 0.003634382084547552
Epoch: 3489, trainingloss: 0.0036406495758947942 | validation loss: 0.003990207317417409
Epoch: 3490, trainingloss: 0.00350602922363503 | validation loss: 0.0038841219874676254
Epoch: 3491, trainingloss: 0.003860361792228028 | validation loss: 0.004221189663642172
Epoch: 3492, trainingloss: 0.003728683147874777 | validation loss: 0.00408005959775999
Epoch: 3493, trainingloss: 0.0033118226794543746 | validation loss: 0.003700902570080214
Epoch: 3494, trainingloss: 0.0037676586577876955 | validation loss: 0.0041164577071397136
Epoch: 3495, trainingloss: 0.0036619648651872866 | validation loss: 0.003999904080239169
Epoch: 3496, trainingloss: 0.004201640734344088 | validation loss: 0.004507760357846668
Epoch: 3497, trainingloss: 0.00509744613457988 | validation loss: 0.00541236757964532
Epoch: 3498, trainingloss: 0.003402607495988995 | validation loss: 0.003799755169836273
Epoch: 3499, trainingloss: 0.003511116793261941 | validation loss: 0.0038873716814718335
Epoch: 3500, trainingloss: 0.0035174083348994754 | validation loss: 0.003928936937894265
Epoch: 3501, trainingloss: 0.003461919504507486 | validation loss: 0.003852692184486625
Epoch: 3502, trainingloss: 0.00445366184177541 | validation loss: 0.00475287699855304
Epoch: 3503, trainingloss: 0.004325996281827435 | validation loss: 0.004683379929072231
Epoch: 3504, trainingloss: 0.003488342291318601 | validation loss: 0.00387509797258106
Epoch: 3505, trainingloss: 0.003910313709588463 | validation loss: 0.0042598054086348145
Epoch: 3506, trainingloss: 0.0033685088277951563 | validation loss: 0.0037542861193628754
Epoch: 3507, trainingloss: 0.00400042872013894 | validation loss: 0.004331489296005432
Epoch: 3508, trainingloss: 0.003815914368758581 | validation loss: 0.004162289262891311
Epoch: 3509, trainingloss: 0.0035255077245360616 | validation loss: 0.003876715895306335
Epoch: 3510, trainingloss: 0.0036366165890483726 | validation loss: 0.004030366582649079
Epoch: 3511, trainingloss: 0.0032584529074335677 | validation loss: 0.0036631554281714566
Epoch: 3512, trainingloss: 0.003474004358324647 | validation loss: 0.003851120385979091
Epoch: 3513, trainingloss: 0.0039004829072004413 | validation loss: 0.004233929634525562
Epoch: 3514, trainingloss: 0.0040434387068721735 | validation loss: 0.0043481683570215516
Epoch: 3515, trainingloss: 0.0035907617440932653 | validation loss: 0.003950444773839365
Epoch: 3516, trainingloss: 0.004101044558203059 | validation loss: 0.004455410491627703
Epoch: 3517, trainingloss: 0.003382207459167136 | validation loss: 0.003811542049043727
Epoch: 3518, trainingloss: 0.003661409323014236 | validation loss: 0.0040395693714989885
Epoch: 3519, trainingloss: 0.003750244532099775 | validation loss: 0.004119112564261981
Epoch: 3520, trainingloss: 0.004339595089991025 | validation loss: 0.0046481717047781234
Epoch: 3521, trainingloss: 0.003944166574814809 | validation loss: 0.004214544029672481
Epoch: 3522, trainingloss: 0.0037219981397790215 | validation loss: 0.0040755854464702675
Epoch: 3523, trainingloss: 0.003470149563716798 | validation loss: 0.0038853165711022213
Epoch: 3524, trainingloss: 0.0034832644153952176 | validation loss: 0.003884513721799111
Epoch: 3525, trainingloss: 0.003363597903565751 | validation loss: 0.0037592376686855352
Epoch: 3526, trainingloss: 0.0036500434784552268 | validation loss: 0.00401986969863637
Epoch: 3527, trainingloss: 0.003819293435942267 | validation loss: 0.004204970730106487
Epoch: 3528, trainingloss: 0.0037388584077936472 | validation loss: 0.004098922659977184
Epoch: 3529, trainingloss: 0.0038567065929917604 | validation loss: 0.004195770530468872
Epoch: 3530, trainingloss: 0.0034386685891295656 | validation loss: 0.0038690661424461608
Epoch: 3531, trainingloss: 0.004708081670576914 | validation loss: 0.005018935384098701
Epoch: 3532, trainingloss: 0.003467977460781766 | validation loss: 0.003873884204143204
Epoch: 3533, trainingloss: 0.0037066934903944313 | validation loss: 0.004070007494747714
Epoch: 3534, trainingloss: 0.003770707935149265 | validation loss: 0.004137560535722085
Epoch: 3535, trainingloss: 0.004273505720956068 | validation loss: 0.004604019778790907
Epoch: 3536, trainingloss: 0.004284792477371569 | validation loss: 0.00459737873612679
Epoch: 3537, trainingloss: 0.003155248085084334 | validation loss: 0.003595310029608238
Epoch: 3538, trainingloss: 0.003673712843490048 | validation loss: 0.004034904241824551
Epoch: 3539, trainingloss: 0.003591119539426673 | validation loss: 0.003968205261331888
Epoch: 3540, trainingloss: 0.0038450828358202707 | validation loss: 0.00423433176396908
Epoch: 3541, trainingloss: 0.003744511139008843 | validation loss: 0.004112169610794966
Epoch: 3542, trainingloss: 0.004112615699321963 | validation loss: 0.004450136578312912
Epoch: 3543, trainingloss: 0.003674477749497816 | validation loss: 0.004017184741354435
Epoch: 3544, trainingloss: 0.00347919740982949 | validation loss: 0.003835318991248357
Epoch: 3545, trainingloss: 0.004140811082354338 | validation loss: 0.004476804091030897
Epoch: 3546, trainingloss: 0.0036230757696200256 | validation loss: 0.00396136035151068
Epoch: 3547, trainingloss: 0.003678792091384301 | validation loss: 0.004051624693598925
Epoch: 3548, trainingloss: 0.0035078517802783326 | validation loss: 0.003895608491108743
Epoch: 3549, trainingloss: 0.003510424968934875 | validation loss: 0.003916858995700788
Epoch: 3550, trainingloss: 0.0036428223027468944 | validation loss: 0.004034585925707522
Epoch: 3551, trainingloss: 0.00376234037740712 | validation loss: 0.004127665161591877
Epoch: 3552, trainingloss: 0.0032056689050204284 | validation loss: 0.0036323473016097382
Epoch: 3553, trainingloss: 0.003968644572428245 | validation loss: 0.004315815552079211
Epoch: 3554, trainingloss: 0.0033881364010922596 | validation loss: 0.0037752895578952632
Epoch: 3555, trainingloss: 0.003546125636198889 | validation loss: 0.003933848836945336
Epoch: 3556, trainingloss: 0.0033559491322825144 | validation loss: 0.00377019458634512
Epoch: 3557, trainingloss: 0.003753454474090637 | validation loss: 0.0041180046343292165
Epoch: 3558, trainingloss: 0.003653252527662963 | validation loss: 0.004008450896349649
Epoch: 3559, trainingloss: 0.0038511467374643432 | validation loss: 0.004179597522747892
Epoch: 3560, trainingloss: 0.003758699918128016 | validation loss: 0.004109183331959479
Epoch: 3561, trainingloss: 0.005070115668858034 | validation loss: 0.005297815174874795
Epoch: 3562, trainingloss: 0.0033531118215058046 | validation loss: 0.0037780750837994644
Epoch: 3563, trainingloss: 0.0037005145205209005 | validation loss: 0.0040491613318588355
Epoch: 3564, trainingloss: 0.003251585673565556 | validation loss: 0.0036893412027801413
Epoch: 3565, trainingloss: 0.0037418802829995556 | validation loss: 0.004079563354188911
Epoch: 3566, trainingloss: 0.003386698337417997 | validation loss: 0.003755208849279393
Epoch: 3567, trainingloss: 0.003909396560534614 | validation loss: 0.004219612999561115
Epoch: 3568, trainingloss: 0.0038803322930400265 | validation loss: 0.004225892868962464
Epoch: 3569, trainingloss: 0.00311037634156456 | validation loss: 0.0035499757110873348
Epoch: 3570, trainingloss: 0.0036448019803799908 | validation loss: 0.004014982333765481
Epoch: 3571, trainingloss: 0.0033948376804463797 | validation loss: 0.0037925361120424435
Epoch: 3572, trainingloss: 0.003559950662202904 | validation loss: 0.003921199651404998
Epoch: 3573, trainingloss: 0.0032071606775904895 | validation loss: 0.003633292699422867
Epoch: 3574, trainingloss: 0.0033559921425558173 | validation loss: 0.003754630970415407
Epoch: 3575, trainingloss: 0.003454215075457829 | validation loss: 0.0038473078292479024
Epoch: 3576, trainingloss: 0.004090560974178082 | validation loss: 0.004465840381211735
Epoch: 3577, trainingloss: 0.003401726805367946 | validation loss: 0.00377271762647503
Epoch: 3578, trainingloss: 0.003370811601864034 | validation loss: 0.0037841313872466957
Epoch: 3579, trainingloss: 0.0032340615680232034 | validation loss: 0.0036329676248343075
Epoch: 3580, trainingloss: 0.00342366999121546 | validation loss: 0.003810186899544491
Epoch: 3581, trainingloss: 0.003122457499773127 | validation loss: 0.0035875589163124884
Epoch: 3582, trainingloss: 0.0033162686211715632 | validation loss: 0.0037111994574289056
Epoch: 3583, trainingloss: 0.0033963397442121532 | validation loss: 0.003810541396848436
Epoch: 3584, trainingloss: 0.004309810494553578 | validation loss: 0.00464543229575713
Epoch: 3585, trainingloss: 0.003742700892688319 | validation loss: 0.004094820155025619
Epoch: 3586, trainingloss: 0.003329991217534328 | validation loss: 0.0037325020363703104
Epoch: 3587, trainingloss: 0.0036402755371748347 | validation loss: 0.003990937889219128
Epoch: 3588, trainingloss: 0.003524826372665656 | validation loss: 0.003940522083343058
Epoch: 3589, trainingloss: 0.00349840246218629 | validation loss: 0.0039095409833350536
Epoch: 3590, trainingloss: 0.003533769204331542 | validation loss: 0.003883579428090353
Epoch: 3591, trainingloss: 0.003413363865051856 | validation loss: 0.003823136132736691
Epoch: 3592, trainingloss: 0.003460116507806572 | validation loss: 0.0038490041957617875
Epoch: 3593, trainingloss: 0.003170504215509667 | validation loss: 0.0036125576734917864
Epoch: 3594, trainingloss: 0.003578003269999958 | validation loss: 0.00393340006382711
Epoch: 3595, trainingloss: 0.0037432322892657225 | validation loss: 0.004059065834402248
Epoch: 3596, trainingloss: 0.003740597889701759 | validation loss: 0.004152076531089686
Epoch: 3597, trainingloss: 0.003433959836575432 | validation loss: 0.003805195240978925
Epoch: 3598, trainingloss: 0.0033765040876633508 | validation loss: 0.0037714588283529137
Epoch: 3599, trainingloss: 0.004230457328025449 | validation loss: 0.004540868840997318
Epoch: 3600, trainingloss: 0.00434881536647827 | validation loss: 0.004663967175644837
Epoch: 3601, trainingloss: 0.0036635167962059626 | validation loss: 0.004027317212611599
Epoch: 3602, trainingloss: 0.0037845546298606154 | validation loss: 0.004160301320244835
Epoch: 3603, trainingloss: 0.003801255171617888 | validation loss: 0.004158994809999189
Epoch: 3604, trainingloss: 0.004280022031776046 | validation loss: 0.004523413791869152
Epoch: 3605, trainingloss: 0.0036871043415080394 | validation loss: 0.004050603561409143
Epoch: 3606, trainingloss: 0.0037541936060041733 | validation loss: 0.004095409553820853
Epoch: 3607, trainingloss: 0.003663645478976855 | validation loss: 0.004045505376815375
Epoch: 3608, trainingloss: 0.003319588836027157 | validation loss: 0.0037287339182024313
Epoch: 3609, trainingloss: 0.003317638510432943 | validation loss: 0.003727748228114706
Epoch: 3610, trainingloss: 0.003462844479711457 | validation loss: 0.0038374044310103095
Epoch: 3611, trainingloss: 0.0033395456504120746 | validation loss: 0.0037467907026207266
Epoch: 3612, trainingloss: 0.0036684132451514713 | validation loss: 0.004060866739575994
Epoch: 3613, trainingloss: 0.0033629653502309353 | validation loss: 0.003765051089487254
Epoch: 3614, trainingloss: 0.003194741730579956 | validation loss: 0.0036279951869650226
Epoch: 3615, trainingloss: 0.0033764434229874127 | validation loss: 0.0037811518798627325
Epoch: 3616, trainingloss: 0.00392521615921143 | validation loss: 0.0042638577040163255
Epoch: 3617, trainingloss: 0.0038008574997086633 | validation loss: 0.004174956670834575
Epoch: 3618, trainingloss: 0.0034989188472702494 | validation loss: 0.0038811347063301797
Epoch: 3619, trainingloss: 0.0037420001417171208 | validation loss: 0.004097989898631581
Epoch: 3620, trainingloss: 0.004017129945822131 | validation loss: 0.0043626493967624524
Epoch: 3621, trainingloss: 0.004217738852492291 | validation loss: 0.004558141107526319
Epoch: 3622, trainingloss: 0.0034833795647518585 | validation loss: 0.003845221150743464
Epoch: 3623, trainingloss: 0.0032659421136025557 | validation loss: 0.0036799823192266673
Epoch: 3624, trainingloss: 0.003385168493623587 | validation loss: 0.003751757587210124
Epoch: 3625, trainingloss: 0.004074233602409377 | validation loss: 0.004424082431421101
Epoch: 3626, trainingloss: 0.0036130466612009117 | validation loss: 0.003976273431588616
Epoch: 3627, trainingloss: 0.0036088070530395614 | validation loss: 0.0040243032009588025
Epoch: 3628, trainingloss: 0.003658877466968162 | validation loss: 0.0040654099132114265
Epoch: 3629, trainingloss: 0.0031993715865001418 | validation loss: 0.0036084901314609587
Epoch: 3630, trainingloss: 0.003839985095151173 | validation loss: 0.004187580091769537
Epoch: 3631, trainingloss: 0.003404918471466818 | validation loss: 0.0038089715813489733
Epoch: 3632, trainingloss: 0.0038637365016814173 | validation loss: 0.004238727680692965
Epoch: 3633, trainingloss: 0.0035610845909810705 | validation loss: 0.003959390993163491
Epoch: 3634, trainingloss: 0.003969640044262367 | validation loss: 0.0043132029860495835
Epoch: 3635, trainingloss: 0.0033533981825721597 | validation loss: 0.0037653305866746974
Epoch: 3636, trainingloss: 0.003764428822985336 | validation loss: 0.004111829532701225
Epoch: 3637, trainingloss: 0.003490090747196976 | validation loss: 0.0038500570801658198
Epoch: 3638, trainingloss: 0.003965460709405996 | validation loss: 0.004308352988889859
Epoch: 3639, trainingloss: 0.00338705575909688 | validation loss: 0.0037713896720663856
Epoch: 3640, trainingloss: 0.0036128238460729077 | validation loss: 0.003974766775800819
Epoch: 3641, trainingloss: 0.0033462503982964334 | validation loss: 0.0037481685160754134
Epoch: 3642, trainingloss: 0.003461862170643663 | validation loss: 0.003863338981885185
Epoch: 3643, trainingloss: 0.0038547952876689484 | validation loss: 0.004223066849667648
Epoch: 3644, trainingloss: 0.0034327036887792624 | validation loss: 0.0038092387729776428
Epoch: 3645, trainingloss: 0.0038966808371736937 | validation loss: 0.004216874780560315
Epoch: 3646, trainingloss: 0.003494632050812996 | validation loss: 0.003906279943144218
Epoch: 3647, trainingloss: 0.003732496344161257 | validation loss: 0.00411464174511353
Epoch: 3648, trainingloss: 0.003909035022339548 | validation loss: 0.0042466483395307494
Epoch: 3649, trainingloss: 0.0032234286513766683 | validation loss: 0.003627297815598631
Epoch: 3650, trainingloss: 0.003246646042497821 | validation loss: 0.00363505987177239
Epoch: 3651, trainingloss: 0.003337785492180106 | validation loss: 0.003740376112919536
Epoch: 3652, trainingloss: 0.0033395637013778397 | validation loss: 0.003725581604755712
Epoch: 3653, trainingloss: 0.0036403903711934283 | validation loss: 0.004019864932905355
Epoch: 3654, trainingloss: 0.004074669053819079 | validation loss: 0.004404789142195721
Epoch: 3655, trainingloss: 0.0038786167099088033 | validation loss: 0.004220381212622688
Epoch: 3656, trainingloss: 0.003558863367364624 | validation loss: 0.003923199266821463
Epoch: 3657, trainingloss: 0.0035205785772404966 | validation loss: 0.0039124827341034275
Epoch: 3658, trainingloss: 0.0033641810852701255 | validation loss: 0.003741138019224027
Epoch: 3659, trainingloss: 0.0038324633070897897 | validation loss: 0.004212250457362757
Epoch: 3660, trainingloss: 0.003695596014477168 | validation loss: 0.004065777311392433
Epoch: 3661, trainingloss: 0.0036391243249319074 | validation loss: 0.0040139524502198825
Epoch: 3662, trainingloss: 0.0037437281966572144 | validation loss: 0.004087753229573896
Epoch: 3663, trainingloss: 0.003965208682429689 | validation loss: 0.004362973989973555
Epoch: 3664, trainingloss: 0.0033504374366649927 | validation loss: 0.003745167167556637
Epoch: 3665, trainingloss: 0.003968361777491243 | validation loss: 0.004330408434949877
Epoch: 3666, trainingloss: 0.0032829403513194343 | validation loss: 0.003706521420244973
Epoch: 3667, trainingloss: 0.003638134867475914 | validation loss: 0.004026498638982518
Epoch: 3668, trainingloss: 0.003915197464109529 | validation loss: 0.004254345230275568
Epoch: 3669, trainingloss: 0.0033311025634153494 | validation loss: 0.003776792133710484
Epoch: 3670, trainingloss: 0.003384037207662561 | validation loss: 0.003806169536387518
Epoch: 3671, trainingloss: 0.003600108801488676 | validation loss: 0.003969607417353285
Epoch: 3672, trainingloss: 0.004099028723353092 | validation loss: 0.004428878718141215
Epoch: 3673, trainingloss: 0.003758622429523278 | validation loss: 0.004107319566920759
Epoch: 3674, trainingloss: 0.003467823369372839 | validation loss: 0.0038678738540139563
Epoch: 3675, trainingloss: 0.0036242578789627273 | validation loss: 0.00401446261901933
Epoch: 3676, trainingloss: 0.0032534184659018593 | validation loss: 0.0036560350702388982
Epoch: 3677, trainingloss: 0.0033084032963524323 | validation loss: 0.003703485283782412
Epoch: 3678, trainingloss: 0.0035577960036771218 | validation loss: 0.0039241782936321
Epoch: 3679, trainingloss: 0.0032550915413350565 | validation loss: 0.0036353017341609365
Epoch: 3680, trainingloss: 0.003736611747978084 | validation loss: 0.0040983879217187024
Epoch: 3681, trainingloss: 0.0035953133411460725 | validation loss: 0.003941557147664729
Epoch: 3682, trainingloss: 0.003317374488934293 | validation loss: 0.0037117289218346334
Epoch: 3683, trainingloss: 0.003971165452802804 | validation loss: 0.004269858241390925
Epoch: 3684, trainingloss: 0.004186196975383347 | validation loss: 0.004486079171620131
Epoch: 3685, trainingloss: 0.0038113072747191423 | validation loss: 0.004145631717652486
Epoch: 3686, trainingloss: 0.003361176745413529 | validation loss: 0.0037761739460624414
Epoch: 3687, trainingloss: 0.0037924524704622264 | validation loss: 0.00415272260365447
Epoch: 3688, trainingloss: 0.003620723852201938 | validation loss: 0.003997461528325111
Epoch: 3689, trainingloss: 0.0038301553871288503 | validation loss: 0.004177949250272759
Epoch: 3690, trainingloss: 0.0036390009637864763 | validation loss: 0.003990942340784744
Epoch: 3691, trainingloss: 0.0038898086328915667 | validation loss: 0.004225395770687192
Epoch: 3692, trainingloss: 0.0034465990716941067 | validation loss: 0.003859225233352374
Epoch: 3693, trainingloss: 0.003770305134349018 | validation loss: 0.004102105626598556
Epoch: 3694, trainingloss: 0.0035921535361979656 | validation loss: 0.003965028796969991
Epoch: 3695, trainingloss: 0.00358450600573249 | validation loss: 0.003963779106392054
Epoch: 3696, trainingloss: 0.0037253376681836824 | validation loss: 0.00409506906954921
Epoch: 3697, trainingloss: 0.004359518148171985 | validation loss: 0.004613930443599529
Epoch: 3698, trainingloss: 0.0034344191606624393 | validation loss: 0.0038369882907080596
Epoch: 3699, trainingloss: 0.003845401576922497 | validation loss: 0.004165212940029141
Epoch: 3700, trainingloss: 0.0035319694623409874 | validation loss: 0.0038865777044182264
Epoch: 3701, trainingloss: 0.0036222757744257036 | validation loss: 0.003983329676874621
Epoch: 3702, trainingloss: 0.0037116296253301316 | validation loss: 0.0040842111727870355
Epoch: 3703, trainingloss: 0.0031470727774784908 | validation loss: 0.0035457959699154488
Epoch: 3704, trainingloss: 0.0035914970924705103 | validation loss: 0.004013563988814727
Epoch: 3705, trainingloss: 0.0035005780723492675 | validation loss: 0.003914583709498002
Epoch: 3706, trainingloss: 0.00436242141788355 | validation loss: 0.004664623686164753
Epoch: 3707, trainingloss: 0.00346571722071584 | validation loss: 0.0038447092127821365
Epoch: 3708, trainingloss: 0.004272898115247971 | validation loss: 0.004619193274882268
Epoch: 3709, trainingloss: 0.003867613607921116 | validation loss: 0.004204924692537965
Epoch: 3710, trainingloss: 0.003229509849087722 | validation loss: 0.00362627065282051
Epoch: 3711, trainingloss: 0.003351503742645693 | validation loss: 0.0037486458561755342
Epoch: 3712, trainingloss: 0.003483982410325642 | validation loss: 0.003843458922236962
Epoch: 3713, trainingloss: 0.0043578103513268315 | validation loss: 0.004671188085563493
Epoch: 3714, trainingloss: 0.0035427686499526503 | validation loss: 0.003894440726595338
Epoch: 3715, trainingloss: 0.0037079147007612503 | validation loss: 0.004078960130556706
Epoch: 3716, trainingloss: 0.0039900869925991525 | validation loss: 0.004350090656807216
Epoch: 3717, trainingloss: 0.0034791913499988576 | validation loss: 0.0038589679056269424
Epoch: 3718, trainingloss: 0.0037930007889252536 | validation loss: 0.004114501624558214
Epoch: 3719, trainingloss: 0.003647571454077395 | validation loss: 0.003989566392706098
Epoch: 3720, trainingloss: 0.00389436902615426 | validation loss: 0.004258465983909541
Epoch: 3721, trainingloss: 0.004023481827009634 | validation loss: 0.004369125671167976
Epoch: 3722, trainingloss: 0.003676894082960618 | validation loss: 0.0040257574288773655
Epoch: 3723, trainingloss: 0.003422716740034383 | validation loss: 0.003808348037069726
Epoch: 3724, trainingloss: 0.0036993685888476614 | validation loss: 0.004063181313213
Epoch: 3725, trainingloss: 0.003560423179716806 | validation loss: 0.003949984832119229
Epoch: 3726, trainingloss: 0.0033135525020537558 | validation loss: 0.0037089125215264388
Epoch: 3727, trainingloss: 0.0034059553206941557 | validation loss: 0.0037833064820298134
Epoch: 3728, trainingloss: 0.0034608858523262525 | validation loss: 0.0038516826260342283
Epoch: 3729, trainingloss: 0.003951419149986462 | validation loss: 0.004294346101797586
Epoch: 3730, trainingloss: 0.003370362356323315 | validation loss: 0.0037710962667919963
Epoch: 3731, trainingloss: 0.003887008762478966 | validation loss: 0.004218715057055564
Epoch: 3732, trainingloss: 0.0038798764915551416 | validation loss: 0.004214775451012166
Epoch: 3733, trainingloss: 0.0038893065972560436 | validation loss: 0.004223286090283576
Epoch: 3734, trainingloss: 0.0032707827501597137 | validation loss: 0.0036992574577332064
Epoch: 3735, trainingloss: 0.0033554740579520093 | validation loss: 0.00376887153792657
Epoch: 3736, trainingloss: 0.003914652115338846 | validation loss: 0.004282498047541466
Epoch: 3737, trainingloss: 0.003486262624414617 | validation loss: 0.0038732499923925657
Epoch: 3738, trainingloss: 0.003782360152470033 | validation loss: 0.004188357822400326
Epoch: 3739, trainingloss: 0.0035897515850333646 | validation loss: 0.003989676290150776
Epoch: 3740, trainingloss: 0.00328851715331396 | validation loss: 0.0036802102861711247
Epoch: 3741, trainingloss: 0.0034199902924850747 | validation loss: 0.0038052532594175076
Epoch: 3742, trainingloss: 0.003288674264455169 | validation loss: 0.0036925017482452305
Epoch: 3743, trainingloss: 0.003179452353420359 | validation loss: 0.0036133433432771625
Epoch: 3744, trainingloss: 0.004079534494159878 | validation loss: 0.004391337181205539
Epoch: 3745, trainingloss: 0.0034234673168544406 | validation loss: 0.0038053007469726102
Epoch: 3746, trainingloss: 0.004387080536393314 | validation loss: 0.004742145500781859
Epoch: 3747, trainingloss: 0.00352272817199581 | validation loss: 0.0038867449359670857
Epoch: 3748, trainingloss: 0.003590351258920317 | validation loss: 0.0040317785394937125
Epoch: 3749, trainingloss: 0.003337107054993627 | validation loss: 0.00374271555733214
Epoch: 3750, trainingloss: 0.004164057001173898 | validation loss: 0.0045020319933925705
Epoch: 3751, trainingloss: 0.003458230602846207 | validation loss: 0.0038695437648872443
Epoch: 3752, trainingloss: 0.004084447864239437 | validation loss: 0.004436750427242728
Epoch: 3753, trainingloss: 0.003674975851894611 | validation loss: 0.004041433660076848
Epoch: 3754, trainingloss: 0.0033966013906653147 | validation loss: 0.003789140544088277
Epoch: 3755, trainingloss: 0.004237779114176564 | validation loss: 0.004538602049081875
Epoch: 3756, trainingloss: 0.003350515736308763 | validation loss: 0.003747197746134303
Epoch: 3757, trainingloss: 0.0037776794033053266 | validation loss: 0.004097175129894236
Epoch: 3758, trainingloss: 0.0034390821374772557 | validation loss: 0.0038555824087194088
Epoch: 3759, trainingloss: 0.0036234473255519623 | validation loss: 0.003990108779253181
Epoch: 3760, trainingloss: 0.003213008700486776 | validation loss: 0.0036284526250932956
Epoch: 3761, trainingloss: 0.003826597004397398 | validation loss: 0.00418045287952477
Epoch: 3762, trainingloss: 0.0032291401805623976 | validation loss: 0.003634333839386106
Epoch: 3763, trainingloss: 0.004242329019953941 | validation loss: 0.004556528204940714
Epoch: 3764, trainingloss: 0.0037748717042794936 | validation loss: 0.004104545504789699
Epoch: 3765, trainingloss: 0.003507474973182324 | validation loss: 0.003926845643252117
Epoch: 3766, trainingloss: 0.00352930549048732 | validation loss: 0.003909118808368285
Epoch: 3767, trainingloss: 0.0032305660373499003 | validation loss: 0.003648457453545009
Epoch: 3768, trainingloss: 0.0036782845570983496 | validation loss: 0.004020814734598771
Epoch: 3769, trainingloss: 0.004118211946151368 | validation loss: 0.0044482627883833704
Epoch: 3770, trainingloss: 0.0036218156174538125 | validation loss: 0.004000902432515578
Epoch: 3771, trainingloss: 0.0035944547656579146 | validation loss: 0.003953187996231835
Epoch: 3772, trainingloss: 0.0037581142293403027 | validation loss: 0.004117358050163079
Epoch: 3773, trainingloss: 0.003514928936861574 | validation loss: 0.003907003389423134
Epoch: 3774, trainingloss: 0.0039959480750587275 | validation loss: 0.004298713782231878
Epoch: 3775, trainingloss: 0.003728913466828628 | validation loss: 0.004052622880026164
Epoch: 3776, trainingloss: 0.003623051091063347 | validation loss: 0.004030615167825799
Epoch: 3777, trainingloss: 0.0035901264935581222 | validation loss: 0.003951079108326506
Epoch: 3778, trainingloss: 0.003743360333750436 | validation loss: 0.004129701143678896
Epoch: 3779, trainingloss: 0.004548696573222053 | validation loss: 0.004845765540902256
Epoch: 3780, trainingloss: 0.0033802259400311217 | validation loss: 0.0037652062376400805
Epoch: 3781, trainingloss: 0.003709326576391539 | validation loss: 0.004085504803946151
Epoch: 3782, trainingloss: 0.003438696395284101 | validation loss: 0.0038088162688574264
Epoch: 3783, trainingloss: 0.0033701135138353494 | validation loss: 0.0037931099220050455
Epoch: 3784, trainingloss: 0.0032208359300093135 | validation loss: 0.0036290901130794423
Epoch: 3785, trainingloss: 0.0038017946559145387 | validation loss: 0.004186470621276509
Epoch: 3786, trainingloss: 0.004014276170796178 | validation loss: 0.0043316039852204545
Epoch: 3787, trainingloss: 0.0034595972295477957 | validation loss: 0.0038517298344134033
Epoch: 3788, trainingloss: 0.003974062480669953 | validation loss: 0.004295312871315625
Epoch: 3789, trainingloss: 0.0034006573537533696 | validation loss: 0.0037814238947871544
Epoch: 3790, trainingloss: 0.003275800554544071 | validation loss: 0.003699660731694954
Epoch: 3791, trainingloss: 0.003678007275448455 | validation loss: 0.004031555248851966
Epoch: 3792, trainingloss: 0.003443312135383428 | validation loss: 0.0038009527642884947
Epoch: 3793, trainingloss: 0.0034679391947417784 | validation loss: 0.0038405522044820486
Epoch: 3794, trainingloss: 0.003818076749145469 | validation loss: 0.004183946276577822
Epoch: 3795, trainingloss: 0.0039663626950166755 | validation loss: 0.004301802633655848
Epoch: 3796, trainingloss: 0.003825351304277029 | validation loss: 0.0041493985268616996
Epoch: 3797, trainingloss: 0.003829852448084051 | validation loss: 0.0041812721192927725
Epoch: 3798, trainingloss: 0.003639759571665404 | validation loss: 0.0039967142131646085
Epoch: 3799, trainingloss: 0.0036473974481191903 | validation loss: 0.004000630559508748
Epoch: 3800, trainingloss: 0.003272129375375158 | validation loss: 0.0036440652198761604
Epoch: 3801, trainingloss: 0.0035358230280757197 | validation loss: 0.003935794075334374
Epoch: 3802, trainingloss: 0.0034968896690217334 | validation loss: 0.0038585514265833767
Epoch: 3803, trainingloss: 0.003828443554740831 | validation loss: 0.0042010974066577144
Epoch: 3804, trainingloss: 0.0036423096828182297 | validation loss: 0.004006144794838761
Epoch: 3805, trainingloss: 0.0032239894036890904 | validation loss: 0.003618870830981031
Epoch: 3806, trainingloss: 0.004233725035320511 | validation loss: 0.004594065176895861
Epoch: 3807, trainingloss: 0.00359416944470065 | validation loss: 0.003950388547169234
Epoch: 3808, trainingloss: 0.0035546682117116473 | validation loss: 0.003950490246340444
Epoch: 3809, trainingloss: 0.003991404783143332 | validation loss: 0.004348388333856142
Epoch: 3810, trainingloss: 0.00330600066893429 | validation loss: 0.0037006519753969487
Epoch: 3811, trainingloss: 0.004360066192128496 | validation loss: 0.004669809344916327
Epoch: 3812, trainingloss: 0.0037077580458626776 | validation loss: 0.004062654230119634
Epoch: 3813, trainingloss: 0.003885307293476126 | validation loss: 0.00419390896004688
Epoch: 3814, trainingloss: 0.0036192860859837516 | validation loss: 0.003993954650693491
Epoch: 3815, trainingloss: 0.0034844601664540797 | validation loss: 0.003869114790957072
Epoch: 3816, trainingloss: 0.0040062943044194416 | validation loss: 0.004359112024451449
Epoch: 3817, trainingloss: 0.0034123614503116166 | validation loss: 0.003802927718683155
Epoch: 3818, trainingloss: 0.003552437357358577 | validation loss: 0.0039053739476442558
Epoch: 3819, trainingloss: 0.0036476748649755053 | validation loss: 0.004042211659981105
Epoch: 3820, trainingloss: 0.0038887508510090526 | validation loss: 0.00424428263455515
Epoch: 3821, trainingloss: 0.0036937038203912692 | validation loss: 0.004090347521935311
Epoch: 3822, trainingloss: 0.004098814938100618 | validation loss: 0.004424774285309089
Epoch: 3823, trainingloss: 0.003464238943489388 | validation loss: 0.0038370940842946304
Epoch: 3824, trainingloss: 0.004724882555155675 | validation loss: 0.005057456071079814
Epoch: 3825, trainingloss: 0.00344866536424282 | validation loss: 0.0038532867807741893
Epoch: 3826, trainingloss: 0.004014750528591655 | validation loss: 0.004359558931834754
Epoch: 3827, trainingloss: 0.003704883183453755 | validation loss: 0.004040656474189573
Epoch: 3828, trainingloss: 0.003545887964638633 | validation loss: 0.003944096254524104
Epoch: 3829, trainingloss: 0.0037744609876500263 | validation loss: 0.004145159481320668
Epoch: 3830, trainingloss: 0.0037778581000219246 | validation loss: 0.004167965947678756
Epoch: 3831, trainingloss: 0.0035863258806285115 | validation loss: 0.003919082218106891
Epoch: 3832, trainingloss: 0.0035577166403714003 | validation loss: 0.003938266017090863
Epoch: 3833, trainingloss: 0.0034830615365906703 | validation loss: 0.0038673886405064506
Epoch: 3834, trainingloss: 0.0036969086397164526 | validation loss: 0.004066782862373881
Epoch: 3835, trainingloss: 0.0039881852138984415 | validation loss: 0.0043571241105885275
Epoch: 3836, trainingloss: 0.003409594440307006 | validation loss: 0.0037899998893076658
Epoch: 3837, trainingloss: 0.0037057380114198595 | validation loss: 0.004083318127634563
Epoch: 3838, trainingloss: 0.003594315919506592 | validation loss: 0.003943317623565504
Epoch: 3839, trainingloss: 0.0037399049351606053 | validation loss: 0.004089654248091716
Epoch: 3840, trainingloss: 0.0035418226973233814 | validation loss: 0.003925871138299363
Epoch: 3841, trainingloss: 0.003903737653750201 | validation loss: 0.004223444271569994
Epoch: 3842, trainingloss: 0.003463081736149781 | validation loss: 0.003822562717451203
Epoch: 3843, trainingloss: 0.00341065985694146 | validation loss: 0.0037889065413560844
Epoch: 3844, trainingloss: 0.0036352159412374957 | validation loss: 0.00404353735033987
Epoch: 3845, trainingloss: 0.0037711624125947494 | validation loss: 0.004124693064578479
Epoch: 3846, trainingloss: 0.0034122537806853446 | validation loss: 0.0038068043881178994
Epoch: 3847, trainingloss: 0.004387292095015223 | validation loss: 0.004673439141437977
Epoch: 3848, trainingloss: 0.004148772398556196 | validation loss: 0.004440344895550895
Epoch: 3849, trainingloss: 0.003951749922065867 | validation loss: 0.004276271721405187
Epoch: 3850, trainingloss: 0.0038052706708026746 | validation loss: 0.004196544423332725
Epoch: 3851, trainingloss: 0.003438647263013999 | validation loss: 0.003809900677831306
Epoch: 3852, trainingloss: 0.0034873144588454573 | validation loss: 0.0038530341964725223
Epoch: 3853, trainingloss: 0.0036655701339591154 | validation loss: 0.0040065082430474006
Epoch: 3854, trainingloss: 0.0037920687180871297 | validation loss: 0.0041476249825535836
Epoch: 3855, trainingloss: 0.004319097408421167 | validation loss: 0.004605635149392511
Epoch: 3856, trainingloss: 0.003536706620491894 | validation loss: 0.003941596732383426
Epoch: 3857, trainingloss: 0.003698338253572064 | validation loss: 0.004088235579357667
Epoch: 3858, trainingloss: 0.003471614080794292 | validation loss: 0.0038306857777160104
Epoch: 3859, trainingloss: 0.0040481280528735465 | validation loss: 0.004366031982216188
Epoch: 3860, trainingloss: 0.003742607745525592 | validation loss: 0.004127265354194045
Epoch: 3861, trainingloss: 0.0035471129165529675 | validation loss: 0.003946488170888347
Epoch: 3862, trainingloss: 0.003392134938915027 | validation loss: 0.0037625900422089847
Epoch: 3863, trainingloss: 0.003450314530507073 | validation loss: 0.0038815860314983667
Epoch: 3864, trainingloss: 0.00320948340380544 | validation loss: 0.0036309163301683363
Epoch: 3865, trainingloss: 0.0034676716900139937 | validation loss: 0.0038286345243005544
Epoch: 3866, trainingloss: 0.003928894335319559 | validation loss: 0.0042181190513691695
Epoch: 3867, trainingloss: 0.004000648777762705 | validation loss: 0.004371655063035973
Epoch: 3868, trainingloss: 0.003224837002554846 | validation loss: 0.003654349491048899
Epoch: 3869, trainingloss: 0.0035364098204311977 | validation loss: 0.003917607741051883
Epoch: 3870, trainingloss: 0.0038733885157405906 | validation loss: 0.004273469984978982
Epoch: 3871, trainingloss: 0.004099323983957039 | validation loss: 0.004432198826053426
Epoch: 3872, trainingloss: 0.00332146325048093 | validation loss: 0.0037342145176423947
Epoch: 3873, trainingloss: 0.0033873654233917932 | validation loss: 0.003814788674864534
Epoch: 3874, trainingloss: 0.0035977422006786995 | validation loss: 0.003971909697494894
Epoch: 3875, trainingloss: 0.003312935697297314 | validation loss: 0.003722493086167732
Epoch: 3876, trainingloss: 0.004157305791618123 | validation loss: 0.004497815227216211
Epoch: 3877, trainingloss: 0.0038447057389503344 | validation loss: 0.004185903021153439
Epoch: 3878, trainingloss: 0.004035861866908086 | validation loss: 0.004351941484896633
Epoch: 3879, trainingloss: 0.0038261372849547476 | validation loss: 0.004192135240500769
Epoch: 3880, trainingloss: 0.0035301540202326374 | validation loss: 0.0038824885243615953
Epoch: 3881, trainingloss: 0.003933398094385737 | validation loss: 0.004245770729358383
Epoch: 3882, trainingloss: 0.003605302373659769 | validation loss: 0.00396045124777429
Epoch: 3883, trainingloss: 0.004597187344146259 | validation loss: 0.004841100638950814
Epoch: 3884, trainingloss: 0.0036765945707803666 | validation loss: 0.004027685389828972
Epoch: 3885, trainingloss: 0.0034188429118284886 | validation loss: 0.00381550651747165
Epoch: 3886, trainingloss: 0.00373994922516113 | validation loss: 0.004114907407768207
Epoch: 3887, trainingloss: 0.004078874957432648 | validation loss: 0.004457065834209484
Epoch: 3888, trainingloss: 0.0036449564345076312 | validation loss: 0.0040276386377618
Epoch: 3889, trainingloss: 0.003908489468736549 | validation loss: 0.004247104977488094
Epoch: 3890, trainingloss: 0.003626267083271815 | validation loss: 0.003962905417699244
Epoch: 3891, trainingloss: 0.0033082235870281517 | validation loss: 0.0036827907937893654
Epoch: 3892, trainingloss: 0.003673265063867251 | validation loss: 0.004031981330048414
Epoch: 3893, trainingloss: 0.003558180079294641 | validation loss: 0.0039441475922713815
Epoch: 3894, trainingloss: 0.0032866272876103417 | validation loss: 0.003686648064330673
Epoch: 3895, trainingloss: 0.003943310604033772 | validation loss: 0.004255286831451263
Epoch: 3896, trainingloss: 0.003462964625900142 | validation loss: 0.0038789081507557568
Epoch: 3897, trainingloss: 0.003776928682143285 | validation loss: 0.004127028456952461
Epoch: 3898, trainingloss: 0.0033168762439760896 | validation loss: 0.0037321968326570663
Epoch: 3899, trainingloss: 0.0031245459272323584 | validation loss: 0.003542025310704248
Epoch: 3900, trainingloss: 0.003846665855004693 | validation loss: 0.004206748503852147
Epoch: 3901, trainingloss: 0.003686774519083086 | validation loss: 0.004072971900541265
Epoch: 3902, trainingloss: 0.003360099231317001 | validation loss: 0.0037461984387873286
Epoch: 3903, trainingloss: 0.0037232667150275418 | validation loss: 0.004078302837610616
Epoch: 3904, trainingloss: 0.0038332380305902817 | validation loss: 0.0041785082179657635
Epoch: 3905, trainingloss: 0.0033336281452665717 | validation loss: 0.0037463431141997916
Epoch: 3906, trainingloss: 0.0036696870105093126 | validation loss: 0.004028987051660407
Epoch: 3907, trainingloss: 0.003426087013265192 | validation loss: 0.003805609803081602
Epoch: 3908, trainingloss: 0.004053763195446775 | validation loss: 0.004371168571662112
Epoch: 3909, trainingloss: 0.003903109213671992 | validation loss: 0.004222070098966806
Epoch: 3910, trainingloss: 0.0034101509839587337 | validation loss: 0.0037776880726947595
Epoch: 3911, trainingloss: 0.0037112610290359156 | validation loss: 0.004069143536076008
Epoch: 3912, trainingloss: 0.003738668791414429 | validation loss: 0.004113515698751485
Epoch: 3913, trainingloss: 0.003542140246216449 | validation loss: 0.0039356108240753375
Epoch: 3914, trainingloss: 0.003305510866411031 | validation loss: 0.0037154452387105122
Epoch: 3915, trainingloss: 0.0033316511475230087 | validation loss: 0.0037265289689648214
Epoch: 3916, trainingloss: 0.003147876975622358 | validation loss: 0.0035703833720593615
Epoch: 3917, trainingloss: 0.0036560906633849974 | validation loss: 0.004016441246437106
Epoch: 3918, trainingloss: 0.0032485352008800135 | validation loss: 0.0036454484203961115
Epoch: 3919, trainingloss: 0.003327026831686642 | validation loss: 0.003713124885814642
Epoch: 3920, trainingloss: 0.003560528458885186 | validation loss: 0.00394940124202836
Epoch: 3921, trainingloss: 0.0033090275382249563 | validation loss: 0.0036964509727877974
Epoch: 3922, trainingloss: 0.00374538079506801 | validation loss: 0.004101443252007282
Epoch: 3923, trainingloss: 0.003548459204994265 | validation loss: 0.003928640638357634
Epoch: 3924, trainingloss: 0.003495201950835736 | validation loss: 0.0038962097692072937
Epoch: 3925, trainingloss: 0.003087100235088986 | validation loss: 0.003496315266104231
Epoch: 3926, trainingloss: 0.0032217824564153568 | validation loss: 0.003652775925850095
Epoch: 3927, trainingloss: 0.003806685121848357 | validation loss: 0.004190005694702249
Epoch: 3928, trainingloss: 0.00369307449182419 | validation loss: 0.004069582384499846
Epoch: 3929, trainingloss: 0.003674239534802779 | validation loss: 0.004059422600725469
Epoch: 3930, trainingloss: 0.003921175603853084 | validation loss: 0.004269451448386997
Epoch: 3931, trainingloss: 0.00355166330012511 | validation loss: 0.003926864935618758
Epoch: 3932, trainingloss: 0.003846571957680379 | validation loss: 0.004219182515666469
Epoch: 3933, trainingloss: 0.003455785092414146 | validation loss: 0.0038184810198055997
Epoch: 3934, trainingloss: 0.003401745004495698 | validation loss: 0.0037968925380149786
Epoch: 3935, trainingloss: 0.0032757507150129855 | validation loss: 0.003673213709127141
Epoch: 3936, trainingloss: 0.0038422159877726505 | validation loss: 0.004135609010075494
Epoch: 3937, trainingloss: 0.0036967129904566165 | validation loss: 0.00404274002637935
Epoch: 3938, trainingloss: 0.004047117391283911 | validation loss: 0.00440817337311262
Epoch: 3939, trainingloss: 0.0033787354825901283 | validation loss: 0.003757841377585363
Epoch: 3940, trainingloss: 0.0034415628077572448 | validation loss: 0.0038207385129044005
Epoch: 3941, trainingloss: 0.003271348056782746 | validation loss: 0.0036190228636191948
Epoch: 3942, trainingloss: 0.0035024766877524436 | validation loss: 0.0038871588337667574
Epoch: 3943, trainingloss: 0.0034398546632202157 | validation loss: 0.0038476511344518356
Epoch: 3944, trainingloss: 0.0034195336924430593 | validation loss: 0.0037905468400327167
Epoch: 3945, trainingloss: 0.003499418492533774 | validation loss: 0.0038615889775495673
Epoch: 3946, trainingloss: 0.0036693673328589142 | validation loss: 0.004003410442612181
Epoch: 3947, trainingloss: 0.0035716537071936016 | validation loss: 0.003937344809114979
Epoch: 3948, trainingloss: 0.003785083307147383 | validation loss: 0.004165375484239348
Epoch: 3949, trainingloss: 0.0031688006043005374 | validation loss: 0.00357978885859103
Epoch: 3950, trainingloss: 0.003389774556573726 | validation loss: 0.003784809217050268
Epoch: 3951, trainingloss: 0.0041583978801555885 | validation loss: 0.004483269850088696
Epoch: 3952, trainingloss: 0.0034804352869162586 | validation loss: 0.0038899650560608777
Epoch: 3953, trainingloss: 0.0036817224081399248 | validation loss: 0.004069025128780529
Epoch: 3954, trainingloss: 0.0032018751631482786 | validation loss: 0.003638110635319194
Epoch: 3955, trainingloss: 0.0032832067120606603 | validation loss: 0.0036765103137912872
Epoch: 3956, trainingloss: 0.0038986380469761537 | validation loss: 0.004268071648898089
Epoch: 3957, trainingloss: 0.0035514751782073687 | validation loss: 0.003918795680367576
Epoch: 3958, trainingloss: 0.0036208717175607225 | validation loss: 0.004003668439310031
Epoch: 3959, trainingloss: 0.003463390518011741 | validation loss: 0.0038450239732937376
Epoch: 3960, trainingloss: 0.0034090747545264775 | validation loss: 0.003817158938253194
Epoch: 3961, trainingloss: 0.0036965497009779015 | validation loss: 0.004052027985191949
Epoch: 3962, trainingloss: 0.003618416882608078 | validation loss: 0.003969475323823264
Epoch: 3963, trainingloss: 0.0036872563056842894 | validation loss: 0.004027389758872879
Epoch: 3964, trainingloss: 0.003526550888037757 | validation loss: 0.003929580524124396
Epoch: 3965, trainingloss: 0.0036395114941239477 | validation loss: 0.0039761570776069245
Epoch: 3966, trainingloss: 0.0037780014085779215 | validation loss: 0.004118218785524135
Epoch: 3967, trainingloss: 0.00397457023064823 | validation loss: 0.00431374386876288
Epoch: 3968, trainingloss: 0.003496333813914936 | validation loss: 0.003862577153022319
Epoch: 3969, trainingloss: 0.0034211283913166456 | validation loss: 0.003780838508425488
Epoch: 3970, trainingloss: 0.0036581165051895437 | validation loss: 0.004024951822179554
Epoch: 3971, trainingloss: 0.003990491699414831 | validation loss: 0.004328638097134061
Epoch: 3972, trainingloss: 0.003505118133961655 | validation loss: 0.003865141880401802
Epoch: 3973, trainingloss: 0.003915231592650055 | validation loss: 0.004272249932686655
Epoch: 3974, trainingloss: 0.004019648607987564 | validation loss: 0.004351542231699392
Epoch: 3975, trainingloss: 0.0034853715594907867 | validation loss: 0.0038332171979352453
Epoch: 3976, trainingloss: 0.0034222898964161117 | validation loss: 0.003823941351019116
Epoch: 3977, trainingloss: 0.0035720391110569123 | validation loss: 0.003928755007911933
Epoch: 3978, trainingloss: 0.0032898606858401797 | validation loss: 0.003689263840515588
Epoch: 3979, trainingloss: 0.003429294282611572 | validation loss: 0.0038288039583551053
Epoch: 3980, trainingloss: 0.0037316987721732757 | validation loss: 0.004072949799092035
Epoch: 3981, trainingloss: 0.004262920991982599 | validation loss: 0.004579680363101876
Epoch: 3982, trainingloss: 0.00330244330133189 | validation loss: 0.0037035523559318584
Epoch: 3983, trainingloss: 0.0032906080793227593 | validation loss: 0.0037069884746233697
Epoch: 3984, trainingloss: 0.003287191450614428 | validation loss: 0.0036676816069373813
Epoch: 3985, trainingloss: 0.003904226726228642 | validation loss: 0.0042476798622114245
Epoch: 3986, trainingloss: 0.0034660920619225257 | validation loss: 0.0038518806559924785
Epoch: 3987, trainingloss: 0.0035901160467321598 | validation loss: 0.00397703701115901
Epoch: 3988, trainingloss: 0.004022117767628392 | validation loss: 0.004400894047766275
Epoch: 3989, trainingloss: 0.00395486436540708 | validation loss: 0.004345946313177021
Epoch: 3990, trainingloss: 0.004076464939083914 | validation loss: 0.004407330454948668
Epoch: 3991, trainingloss: 0.0035856742237520608 | validation loss: 0.003959527598855718
Epoch: 3992, trainingloss: 0.0034402726746439087 | validation loss: 0.0038306774961608483
Epoch: 3993, trainingloss: 0.003497755294797918 | validation loss: 0.00391519707897494
Epoch: 3994, trainingloss: 0.004601932812666755 | validation loss: 0.004893456626180904
Epoch: 3995, trainingloss: 0.0034914149510825907 | validation loss: 0.0038339630904800034
Epoch: 3996, trainingloss: 0.003699074000182911 | validation loss: 0.00409483536945512
Epoch: 3997, trainingloss: 0.0035544142820991133 | validation loss: 0.003933053356368464
Epoch: 3998, trainingloss: 0.0034168475980551035 | validation loss: 0.003803306944382787
Epoch: 3999, trainingloss: 0.0038398534681141996 | validation loss: 0.004181648210736296
Epoch: 4000, trainingloss: 0.0037086017296173524 | validation loss: 0.004086046154887158
Epoch: 4001, trainingloss: 0.0033657757404224947 | validation loss: 0.0037610206161121525
Epoch: 4002, trainingloss: 0.003251115307698778 | validation loss: 0.0036521974613907856
Epoch: 4003, trainingloss: 0.003571667199712314 | validation loss: 0.003933603122231379
Epoch: 4004, trainingloss: 0.00356035445471576 | validation loss: 0.0039314451534671925
Epoch: 4005, trainingloss: 0.0033786207849373765 | validation loss: 0.0037639955706521774
Epoch: 4006, trainingloss: 0.00388249291110478 | validation loss: 0.004226732107767155
Epoch: 4007, trainingloss: 0.00400409885613363 | validation loss: 0.004357999435073286
Epoch: 4008, trainingloss: 0.004003318229480647 | validation loss: 0.00429914840257214
Epoch: 4009, trainingloss: 0.003796055286588964 | validation loss: 0.004164470604155611
Epoch: 4010, trainingloss: 0.0036502206242471588 | validation loss: 0.004032064800241325
Epoch: 4011, trainingloss: 0.0032950752593949475 | validation loss: 0.003690199037541835
Epoch: 4012, trainingloss: 0.0036181060257583623 | validation loss: 0.00399709098803579
Epoch: 4013, trainingloss: 0.003513896786941906 | validation loss: 0.003922032451607685
Epoch: 4014, trainingloss: 0.00380496178999578 | validation loss: 0.004177684580409452
Epoch: 4015, trainingloss: 0.0035772336390693616 | validation loss: 0.00394549575048362
Epoch: 4016, trainingloss: 0.0034734989478386 | validation loss: 0.0038494166900440896
Epoch: 4017, trainingloss: 0.0032249197112676257 | validation loss: 0.003631031731520393
Epoch: 4018, trainingloss: 0.003909244399085401 | validation loss: 0.00424889380946657
Epoch: 4019, trainingloss: 0.003349084140654393 | validation loss: 0.0037412371075798163
Epoch: 4020, trainingloss: 0.003530583131351709 | validation loss: 0.0039039167716544243
Epoch: 4021, trainingloss: 0.0038786831663598833 | validation loss: 0.0042382895045358394
Epoch: 4022, trainingloss: 0.0037454374002185865 | validation loss: 0.004105542932533689
Epoch: 4023, trainingloss: 0.0033314237637863163 | validation loss: 0.0037375176543419236
Epoch: 4024, trainingloss: 0.0032959703931982887 | validation loss: 0.0036980560887291914
Epoch: 4025, trainingloss: 0.0034376392433949163 | validation loss: 0.003831493066902049
Epoch: 4026, trainingloss: 0.0037838778571459685 | validation loss: 0.004152396556895697
Epoch: 4027, trainingloss: 0.003699219461187552 | validation loss: 0.004046132490537163
Epoch: 4028, trainingloss: 0.0035632696738679558 | validation loss: 0.003958604194271935
Epoch: 4029, trainingloss: 0.0036728709249608292 | validation loss: 0.004058002519981436
Epoch: 4030, trainingloss: 0.0034698924352251524 | validation loss: 0.003873180284023477
Epoch: 4031, trainingloss: 0.003724369403573023 | validation loss: 0.004084379995598422
Epoch: 4032, trainingloss: 0.003518523696932567 | validation loss: 0.003895788848989917
Epoch: 4033, trainingloss: 0.0037758794556070514 | validation loss: 0.004132184369374143
Epoch: 4034, trainingloss: 0.0035493894786959475 | validation loss: 0.003923018213191835
Epoch: 4035, trainingloss: 0.003946221577777952 | validation loss: 0.004281576950731185
Epoch: 4036, trainingloss: 0.00358361049763022 | validation loss: 0.003957916696058874
Epoch: 4037, trainingloss: 0.0036745853626470953 | validation loss: 0.004039044059042376
Epoch: 4038, trainingloss: 0.0034024503250321544 | validation loss: 0.003805544931202522
Epoch: 4039, trainingloss: 0.0035845324766059137 | validation loss: 0.003973949805824388
Epoch: 4040, trainingloss: 0.004079837742709395 | validation loss: 0.004414520650997827
Epoch: 4041, trainingloss: 0.0031223155504228528 | validation loss: 0.0035572959532554093
Epoch: 4042, trainingloss: 0.0033016133550627337 | validation loss: 0.0037107646497164365
Epoch: 4043, trainingloss: 0.0038847908399410104 | validation loss: 0.004245552208312116
Epoch: 4044, trainingloss: 0.004177339938891194 | validation loss: 0.004523949493845332
Epoch: 4045, trainingloss: 0.0034922859979962893 | validation loss: 0.0038994472557895023
Epoch: 4046, trainingloss: 0.00338215759325289 | validation loss: 0.0037873654888770742
Epoch: 4047, trainingloss: 0.003787349882632018 | validation loss: 0.004146596421945594
Epoch: 4048, trainingloss: 0.003312282628682614 | validation loss: 0.003751796180885829
Epoch: 4049, trainingloss: 0.003686314790588422 | validation loss: 0.0040350732954945985
Epoch: 4050, trainingloss: 0.0033350354032008426 | validation loss: 0.0037092064184129627
Epoch: 4051, trainingloss: 0.003325111960057435 | validation loss: 0.003728503140400595
Epoch: 4052, trainingloss: 0.0035521351027975215 | validation loss: 0.003943048419043072
Epoch: 4053, trainingloss: 0.004303771042919071 | validation loss: 0.004590454650700494
Epoch: 4054, trainingloss: 0.003759171600483051 | validation loss: 0.004108252202140396
Epoch: 4055, trainingloss: 0.0034504856915816553 | validation loss: 0.00387507377826109
Epoch: 4056, trainingloss: 0.003400340094059683 | validation loss: 0.003776067707556288
Epoch: 4057, trainingloss: 0.0033160992622123914 | validation loss: 0.003727600356124452
Epoch: 4058, trainingloss: 0.0036946891729708695 | validation loss: 0.004034384275049052
Epoch: 4059, trainingloss: 0.0032579877370034426 | validation loss: 0.0036602596546009124
Epoch: 4060, trainingloss: 0.0035608143989238755 | validation loss: 0.003923248596907724
Epoch: 4061, trainingloss: 0.0038347777175202994 | validation loss: 0.00415418248525498
Epoch: 4062, trainingloss: 0.003772072587391383 | validation loss: 0.004113851463199304
Epoch: 4063, trainingloss: 0.003911608608905123 | validation loss: 0.004249323835623405
Epoch: 4064, trainingloss: 0.003442521570038606 | validation loss: 0.0037986679864551254
Epoch: 4065, trainingloss: 0.003132577757322833 | validation loss: 0.0035706793154178127
Epoch: 4066, trainingloss: 0.0038897654599510845 | validation loss: 0.004223374789048524
Epoch: 4067, trainingloss: 0.003139830993404948 | validation loss: 0.0035572266204559853
Epoch: 4068, trainingloss: 0.0034987602805969416 | validation loss: 0.003893960875495462
Epoch: 4069, trainingloss: 0.003394411528699432 | validation loss: 0.0038060147506978055
Epoch: 4070, trainingloss: 0.0034510670888850668 | validation loss: 0.0038192639240972283
Epoch: 4071, trainingloss: 0.003944052731600866 | validation loss: 0.00426543986751279
Epoch: 4072, trainingloss: 0.003493915334147927 | validation loss: 0.003881264042040226
Epoch: 4073, trainingloss: 0.0035021397846280566 | validation loss: 0.003866578468949632
Epoch: 4074, trainingloss: 0.003488783141392277 | validation loss: 0.0038675157309477626
Epoch: 4075, trainingloss: 0.0037546121215309876 | validation loss: 0.004146531910638956
Epoch: 4076, trainingloss: 0.0032873861082572367 | validation loss: 0.0036840184202639975
Epoch: 4077, trainingloss: 0.003341224866954636 | validation loss: 0.003731261840392116
Epoch: 4078, trainingloss: 0.0033350984093728072 | validation loss: 0.0037392039615833737
Epoch: 4079, trainingloss: 0.003861248448792985 | validation loss: 0.00417637221239533
Epoch: 4080, trainingloss: 0.003824874456788358 | validation loss: 0.004140568211571785
Epoch: 4081, trainingloss: 0.0036119675728956808 | validation loss: 0.004006595881902419
Epoch: 4082, trainingloss: 0.003537667851609686 | validation loss: 0.0039057963176470705
Epoch: 4083, trainingloss: 0.003465306687226675 | validation loss: 0.003849507366549938
Epoch: 4084, trainingloss: 0.003291311034657421 | validation loss: 0.0036975103008796595
Epoch: 4085, trainingloss: 0.0031816617510884116 | validation loss: 0.0036232962264333038
Epoch: 4086, trainingloss: 0.0034880274285475537 | validation loss: 0.0038572241515946438
Epoch: 4087, trainingloss: 0.003467694926326405 | validation loss: 0.0038258083821644143
Epoch: 4088, trainingloss: 0.0038620626832216714 | validation loss: 0.004178556481883444
Epoch: 4089, trainingloss: 0.0035917766657053143 | validation loss: 0.003940579186386502
Epoch: 4090, trainingloss: 0.0038325272627354437 | validation loss: 0.004212937015760963
Epoch: 4091, trainingloss: 0.0035955165798253375 | validation loss: 0.003968943397509375
Epoch: 4092, trainingloss: 0.004024331696353772 | validation loss: 0.004353987028508429
Epoch: 4093, trainingloss: 0.003507405427285042 | validation loss: 0.00387425232263671
Epoch: 4094, trainingloss: 0.0034463888340863563 | validation loss: 0.003853082004791875
Epoch: 4095, trainingloss: 0.003647606639293802 | validation loss: 0.004021409930727671
Epoch: 4096, trainingloss: 0.003374016978717272 | validation loss: 0.0037746972029073234
Epoch: 4097, trainingloss: 0.0035154587275046233 | validation loss: 0.003900929050715166
Epoch: 4098, trainingloss: 0.003188393684003334 | validation loss: 0.0035807430979440907
Epoch: 4099, trainingloss: 0.0033950611158524327 | validation loss: 0.0038163292725849063
Epoch: 4100, trainingloss: 0.0030840444119584268 | validation loss: 0.003540723498657006
Epoch: 4101, trainingloss: 0.003785429654440827 | validation loss: 0.004136241781480517
Epoch: 4102, trainingloss: 0.003476415546964776 | validation loss: 0.0038693887213265897
Epoch: 4103, trainingloss: 0.0034243707442959312 | validation loss: 0.0038287723958216916
Epoch: 4104, trainingloss: 0.003352232921376233 | validation loss: 0.0037348355452650034
Epoch: 4105, trainingloss: 0.003473584082191983 | validation loss: 0.0038394492688457837
Epoch: 4106, trainingloss: 0.003411473245997935 | validation loss: 0.0037656983119618466
Epoch: 4107, trainingloss: 0.0036394994823413847 | validation loss: 0.004022661302169986
Epoch: 4108, trainingloss: 0.003459659009341371 | validation loss: 0.003826132468547459
Epoch: 4109, trainingloss: 0.0033245740146635996 | validation loss: 0.0037320570139260083
Epoch: 4110, trainingloss: 0.0032556356643918334 | validation loss: 0.003648121850352371
Epoch: 4111, trainingloss: 0.0035348517985751234 | validation loss: 0.00395980625351211
Epoch: 4112, trainingloss: 0.003297912410406559 | validation loss: 0.0036953234024008365
Epoch: 4113, trainingloss: 0.0032048283833954016 | validation loss: 0.0036503024455226424
Epoch: 4114, trainingloss: 0.003994933580064391 | validation loss: 0.004308681767774969
Epoch: 4115, trainingloss: 0.0036074997951236584 | validation loss: 0.003961716370830653
Epoch: 4116, trainingloss: 0.003405217188039262 | validation loss: 0.003807114624068214
Epoch: 4117, trainingloss: 0.00378501680878247 | validation loss: 0.004172847407773273
Epoch: 4118, trainingloss: 0.0033946546673952844 | validation loss: 0.003760896376990196
Epoch: 4119, trainingloss: 0.0034532024167140806 | validation loss: 0.0038309404828402536
Epoch: 4120, trainingloss: 0.0032511815443923963 | validation loss: 0.0036415003712068467
Epoch: 4121, trainingloss: 0.0035856869632087465 | validation loss: 0.00394318997857895
Epoch: 4122, trainingloss: 0.0036531961864969104 | validation loss: 0.00401401449072475
Epoch: 4123, trainingloss: 0.004544518213318224 | validation loss: 0.004790562696378885
Epoch: 4124, trainingloss: 0.003490313146543425 | validation loss: 0.003861479902721341
Epoch: 4125, trainingloss: 0.004534360436438698 | validation loss: 0.004864167281026079
Epoch: 4126, trainingloss: 0.003423547125190686 | validation loss: 0.0038300047738142567
Epoch: 4127, trainingloss: 0.0038151467363610296 | validation loss: 0.004158479754485853
Epoch: 4128, trainingloss: 0.0037662596441758118 | validation loss: 0.004113833509513151
Epoch: 4129, trainingloss: 0.003811400631048743 | validation loss: 0.004187817443744938
Epoch: 4130, trainingloss: 0.003549881964104166 | validation loss: 0.003939416343628369
Epoch: 4131, trainingloss: 0.0036427499235945093 | validation loss: 0.0040024407773871186
Epoch: 4132, trainingloss: 0.0033054311930215178 | validation loss: 0.003737815671096648
Epoch: 4133, trainingloss: 0.0037333849276036217 | validation loss: 0.0040549584231231815
Epoch: 4134, trainingloss: 0.003769919085330492 | validation loss: 0.004115175543601583
Epoch: 4135, trainingloss: 0.0034567944612387534 | validation loss: 0.003847022790422824
Epoch: 4136, trainingloss: 0.0035977560932776527 | validation loss: 0.003957294548238661
Epoch: 4137, trainingloss: 0.003435821540602119 | validation loss: 0.003846849673160343
Epoch: 4138, trainingloss: 0.003427171605641577 | validation loss: 0.0038093681367218253
Epoch: 4139, trainingloss: 0.0034901493303336013 | validation loss: 0.0039021459062514906
Epoch: 4140, trainingloss: 0.0034181193072217882 | validation loss: 0.0038010892900713486
Epoch: 4141, trainingloss: 0.0032770316483034163 | validation loss: 0.0036885005485328463
Epoch: 4142, trainingloss: 0.0033097306732869326 | validation loss: 0.003678027557355491
Epoch: 4143, trainingloss: 0.0036139842502887092 | validation loss: 0.003962064154979129
Epoch: 4144, trainingloss: 0.004001383887494528 | validation loss: 0.004306967248787428
Epoch: 4145, trainingloss: 0.0032439244923023395 | validation loss: 0.003643990390901292
Epoch: 4146, trainingloss: 0.004125161261863873 | validation loss: 0.004406098055350112
Epoch: 4147, trainingloss: 0.003445218404915012 | validation loss: 0.003812984353851046
Epoch: 4148, trainingloss: 0.0034937416082202193 | validation loss: 0.0038976862469787548
Epoch: 4149, trainingloss: 0.0038904172686299475 | validation loss: 0.0042229209799916545
Epoch: 4150, trainingloss: 0.003674332779757702 | validation loss: 0.004044108339256178
Epoch: 4151, trainingloss: 0.003979187648927806 | validation loss: 0.004294287123437705
Epoch: 4152, trainingloss: 0.003488523564887317 | validation loss: 0.003909260338123664
Epoch: 4153, trainingloss: 0.0032172119928001175 | validation loss: 0.0036139920888362234
Epoch: 4154, trainingloss: 0.0032546515498691024 | validation loss: 0.0036701197822416203
Epoch: 4155, trainingloss: 0.003672577682698767 | validation loss: 0.004042062401032025
Epoch: 4156, trainingloss: 0.0032715400067724032 | validation loss: 0.0036938574174951904
Epoch: 4157, trainingloss: 0.0036149477425630196 | validation loss: 0.0039648176105576355
Epoch: 4158, trainingloss: 0.004133087061896927 | validation loss: 0.004457401749771472
Epoch: 4159, trainingloss: 0.00403874819311506 | validation loss: 0.004360933951513038
Epoch: 4160, trainingloss: 0.0035598516968458737 | validation loss: 0.003978972469763884
Epoch: 4161, trainingloss: 0.0035302870455434024 | validation loss: 0.0039008235429299504
Epoch: 4162, trainingloss: 0.003264946151035217 | validation loss: 0.0036834920745640984
Epoch: 4163, trainingloss: 0.0035124867490632867 | validation loss: 0.0038488152150338564
Epoch: 4164, trainingloss: 0.0034162173597289403 | validation loss: 0.0038095649631559973
Epoch: 4165, trainingloss: 0.00356657575614215 | validation loss: 0.003965130541663375
Epoch: 4166, trainingloss: 0.0040103610163996755 | validation loss: 0.004306177688689332
Epoch: 4167, trainingloss: 0.004179907192760969 | validation loss: 0.004448703479267939
Epoch: 4168, trainingloss: 0.003837935978657251 | validation loss: 0.004225345198537901
Epoch: 4169, trainingloss: 0.003649585957228799 | validation loss: 0.0039832410372754815
Epoch: 4170, trainingloss: 0.0033283135666737885 | validation loss: 0.003715317269101929
Epoch: 4171, trainingloss: 0.004059839250927915 | validation loss: 0.0043860195769711615
Epoch: 4172, trainingloss: 0.0032590229694940864 | validation loss: 0.003653037641398442
Epoch: 4173, trainingloss: 0.0033797719700880357 | validation loss: 0.003756440590085842
Epoch: 4174, trainingloss: 0.003467136351090336 | validation loss: 0.0038593276745948826
Epoch: 4175, trainingloss: 0.0037895096355214392 | validation loss: 0.004106412390057558
Epoch: 4176, trainingloss: 0.003660388315187535 | validation loss: 0.00401526972971913
Epoch: 4177, trainingloss: 0.00420936434596754 | validation loss: 0.004573697883267627
Epoch: 4178, trainingloss: 0.0035460120282609395 | validation loss: 0.003919492257210205
Epoch: 4179, trainingloss: 0.0036354786994522706 | validation loss: 0.004003912038620206
Epoch: 4180, trainingloss: 0.00357619615999838 | validation loss: 0.003973037637606393
Epoch: 4181, trainingloss: 0.003831886700124609 | validation loss: 0.004174933572699719
Epoch: 4182, trainingloss: 0.003519555318675338 | validation loss: 0.003858844157903138
Epoch: 4183, trainingloss: 0.0037728056778759895 | validation loss: 0.004126331399540739
Epoch: 4184, trainingloss: 0.003869379028584697 | validation loss: 0.0041821598783896175
Epoch: 4185, trainingloss: 0.003277548773619812 | validation loss: 0.0036931866245030706
Epoch: 4186, trainingloss: 0.0036257854412461783 | validation loss: 0.003971855793670883
Epoch: 4187, trainingloss: 0.0034289493051611695 | validation loss: 0.0038472509865745716
Epoch: 4188, trainingloss: 0.004171243918525703 | validation loss: 0.004481730257916706
Epoch: 4189, trainingloss: 0.003979993902055469 | validation loss: 0.004297534624575733
Epoch: 4190, trainingloss: 0.003413913399509444 | validation loss: 0.0037905831755026234
Epoch: 4191, trainingloss: 0.003672998502787999 | validation loss: 0.00403697938508422
Epoch: 4192, trainingloss: 0.0035545030064342066 | validation loss: 0.003921557900239542
Epoch: 4193, trainingloss: 0.0038092926111650952 | validation loss: 0.004163450795678287
Epoch: 4194, trainingloss: 0.003716173059831567 | validation loss: 0.004081491406760651
Epoch: 4195, trainingloss: 0.003273077171560603 | validation loss: 0.0036603035899003358
Epoch: 4196, trainingloss: 0.0035094581078108943 | validation loss: 0.003875595042726732
Epoch: 4197, trainingloss: 0.0033224164322673234 | validation loss: 0.0037149474463904738
Epoch: 4198, trainingloss: 0.0035959488625033663 | validation loss: 0.003919210848992121
Epoch: 4199, trainingloss: 0.0034608208980281352 | validation loss: 0.0038775832627080944
Epoch: 4200, trainingloss: 0.0034410346718649295 | validation loss: 0.0038003641858423286
Epoch: 4201, trainingloss: 0.0037493220480692173 | validation loss: 0.004169717734049943
Epoch: 4202, trainingloss: 0.0038715773246003776 | validation loss: 0.004234435469778299
Epoch: 4203, trainingloss: 0.0036447061223043873 | validation loss: 0.003980147765190328
Epoch: 4204, trainingloss: 0.003312041245593714 | validation loss: 0.0037305605002430162
Epoch: 4205, trainingloss: 0.0037922684468663335 | validation loss: 0.004130614518720856
Epoch: 4206, trainingloss: 0.0033208928895875132 | validation loss: 0.003726365536212036
Epoch: 4207, trainingloss: 0.0033211541154139624 | validation loss: 0.0037276117013631755
Epoch: 4208, trainingloss: 0.003686322830938914 | validation loss: 0.004006412612119487
Epoch: 4209, trainingloss: 0.0036781580809594596 | validation loss: 0.00401661615549462
Epoch: 4210, trainingloss: 0.003933252127221788 | validation loss: 0.0042622736131376
Epoch: 4211, trainingloss: 0.0033866361744015294 | validation loss: 0.0037709781870151884
Epoch: 4212, trainingloss: 0.0032118645755936336 | validation loss: 0.00363055688942066
Epoch: 4213, trainingloss: 0.003624163476493367 | validation loss: 0.003982378364273415
Epoch: 4214, trainingloss: 0.0037711619980372547 | validation loss: 0.004098344624108543
Epoch: 4215, trainingloss: 0.0034489924000908035 | validation loss: 0.0038552868338903607
Epoch: 4216, trainingloss: 0.0033387351212272685 | validation loss: 0.0037475590827915207
Epoch: 4217, trainingloss: 0.0034907141090594193 | validation loss: 0.0038249316981578117
Epoch: 4218, trainingloss: 0.0033955878461577817 | validation loss: 0.003782434949281669
Epoch: 4219, trainingloss: 0.003677625589721201 | validation loss: 0.0040854388643459414
Epoch: 4220, trainingloss: 0.0033301415767858474 | validation loss: 0.0037543700299260173
Epoch: 4221, trainingloss: 0.0034543328825093326 | validation loss: 0.0038631161420873625
Epoch: 4222, trainingloss: 0.004116971729058763 | validation loss: 0.004487736656485218
Epoch: 4223, trainingloss: 0.0037605745568049585 | validation loss: 0.004126776646466955
Epoch: 4224, trainingloss: 0.0034689013193337894 | validation loss: 0.0038398913501789932
Epoch: 4225, trainingloss: 0.0033003063821616793 | validation loss: 0.003726535423121726
Epoch: 4226, trainingloss: 0.0037340525306313564 | validation loss: 0.00408880692767433
Epoch: 4227, trainingloss: 0.0035736363066534707 | validation loss: 0.003975487751113768
Epoch: 4228, trainingloss: 0.003206511387416461 | validation loss: 0.00361692813133591
Epoch: 4229, trainingloss: 0.0034607613615485846 | validation loss: 0.0038476568967728574
Epoch: 4230, trainingloss: 0.0034577205286678092 | validation loss: 0.0038159301359060476
Epoch: 4231, trainingloss: 0.0035598340197006565 | validation loss: 0.003926156842553989
Epoch: 4232, trainingloss: 0.00408294416738358 | validation loss: 0.0043663198556474665
Epoch: 4233, trainingloss: 0.0034806045642248747 | validation loss: 0.0038564875972600214
Epoch: 4234, trainingloss: 0.003198490983183111 | validation loss: 0.003607928928337128
Epoch: 4235, trainingloss: 0.0035410033385772687 | validation loss: 0.0038949765675743756
Epoch: 4236, trainingloss: 0.003304653133488199 | validation loss: 0.0037335750797701556
Epoch: 4237, trainingloss: 0.003632243868289537 | validation loss: 0.003976554483069999
Epoch: 4238, trainingloss: 0.003194151595108045 | validation loss: 0.0036219753459587225
Epoch: 4239, trainingloss: 0.003229516075348795 | validation loss: 0.0036446584135560486
Epoch: 4240, trainingloss: 0.0033116647008569816 | validation loss: 0.003708264939796632
Epoch: 4241, trainingloss: 0.003791851849557153 | validation loss: 0.004152346567422336
Epoch: 4242, trainingloss: 0.003229002570045096 | validation loss: 0.003688691705299163
Epoch: 4243, trainingloss: 0.004200181915104102 | validation loss: 0.0044976968623495145
Epoch: 4244, trainingloss: 0.003351804003759849 | validation loss: 0.0037528931257597045
Epoch: 4245, trainingloss: 0.0037491938296030512 | validation loss: 0.004082727950491403
Epoch: 4246, trainingloss: 0.003284911448668049 | validation loss: 0.003651492799287246
Epoch: 4247, trainingloss: 0.003664359148192358 | validation loss: 0.003991553514896029
Epoch: 4248, trainingloss: 0.004139096951818724 | validation loss: 0.0044189482672117265
Epoch: 4249, trainingloss: 0.0035309965786990477 | validation loss: 0.003912977075884691
Epoch: 4250, trainingloss: 0.0034755865625466526 | validation loss: 0.0038354808944000033
Epoch: 4251, trainingloss: 0.003338484942056079 | validation loss: 0.0037177221465013633
Epoch: 4252, trainingloss: 0.0035576195876011966 | validation loss: 0.0039123225217479385
Epoch: 4253, trainingloss: 0.0038846150453279906 | validation loss: 0.004216559847572502
Epoch: 4254, trainingloss: 0.003233786780356565 | validation loss: 0.003592286890829459
Epoch: 4255, trainingloss: 0.0034001841988752285 | validation loss: 0.0037695046379010266
Epoch: 4256, trainingloss: 0.003462891457353483 | validation loss: 0.003858374346788075
Epoch: 4257, trainingloss: 0.003447021515061385 | validation loss: 0.0038156077852662916
Epoch: 4258, trainingloss: 0.0036910220894055493 | validation loss: 0.004031576314269163
Epoch: 4259, trainingloss: 0.003926735680380365 | validation loss: 0.00425859189431027
Epoch: 4260, trainingloss: 0.0036861547392701764 | validation loss: 0.004060100682395985
Epoch: 4261, trainingloss: 0.003544483016857869 | validation loss: 0.003933578296459708
Epoch: 4262, trainingloss: 0.0036009243753795813 | validation loss: 0.0039471120258916005
Epoch: 4263, trainingloss: 0.003293294518182614 | validation loss: 0.00368094099076075
Epoch: 4264, trainingloss: 0.0037840738094386587 | validation loss: 0.004098234655230051
Epoch: 4265, trainingloss: 0.0034500693807818514 | validation loss: 0.003858039655570454
Epoch: 4266, trainingloss: 0.003694898716279479 | validation loss: 0.004021234154942239
Epoch: 4267, trainingloss: 0.003424185679374252 | validation loss: 0.0037928313309246596
Epoch: 4268, trainingloss: 0.003975476402917132 | validation loss: 0.004331509975756376
Epoch: 4269, trainingloss: 0.0037444856719743543 | validation loss: 0.004077948286880524
Epoch: 4270, trainingloss: 0.0036671199452027593 | validation loss: 0.003998071257646423
Epoch: 4271, trainingloss: 0.003748265815678465 | validation loss: 0.0041402206871846235
Epoch: 4272, trainingloss: 0.00388508455455528 | validation loss: 0.004229865521301167
Epoch: 4273, trainingloss: 0.0037234340475227994 | validation loss: 0.004102587867367029
Epoch: 4274, trainingloss: 0.0034705965986235833 | validation loss: 0.0038707791586526314
Epoch: 4275, trainingloss: 0.0036340872707240138 | validation loss: 0.003991973978894764
Epoch: 4276, trainingloss: 0.0033473842599319047 | validation loss: 0.0037302427906348713
Epoch: 4277, trainingloss: 0.003732791707970337 | validation loss: 0.004072640556842603
Epoch: 4278, trainingloss: 0.0036734726314112715 | validation loss: 0.004030832548092387
Epoch: 4279, trainingloss: 0.0035821852236103185 | validation loss: 0.00399033011939137
Epoch: 4280, trainingloss: 0.003600307875981666 | validation loss: 0.003980955637077179
Epoch: 4281, trainingloss: 0.0032815045831798622 | validation loss: 0.0036855570431120603
Epoch: 4282, trainingloss: 0.003587238336705201 | validation loss: 0.003934332971394916
Epoch: 4283, trainingloss: 0.004157364108351547 | validation loss: 0.00447250260553477
Epoch: 4284, trainingloss: 0.003598711442682483 | validation loss: 0.003969812938279182
Epoch: 4285, trainingloss: 0.004089336568375145 | validation loss: 0.0043821231309033575
Epoch: 4286, trainingloss: 0.0037424367738161835 | validation loss: 0.004060164447867645
Epoch: 4287, trainingloss: 0.004141376299010673 | validation loss: 0.004444637791040964
Epoch: 4288, trainingloss: 0.0033675698673047796 | validation loss: 0.0037529291965217853
Epoch: 4289, trainingloss: 0.003891876345990997 | validation loss: 0.004234539289399291
Epoch: 4290, trainingloss: 0.0034602056532703385 | validation loss: 0.003854706006379793
Epoch: 4291, trainingloss: 0.003864043139703536 | validation loss: 0.004198852998647347
Epoch: 4292, trainingloss: 0.004137336529155746 | validation loss: 0.004405829504544785
Epoch: 4293, trainingloss: 0.003653581186824117 | validation loss: 0.004042602207765465
Epoch: 4294, trainingloss: 0.0036008290862965765 | validation loss: 0.003984030307649716
Epoch: 4295, trainingloss: 0.0036857738221168944 | validation loss: 0.004043895779683224
Epoch: 4296, trainingloss: 0.0034649606534601775 | validation loss: 0.003869482484699423
Epoch: 4297, trainingloss: 0.0033357210553662127 | validation loss: 0.0037292131116418987
Epoch: 4298, trainingloss: 0.0035470470390086034 | validation loss: 0.003922778246673371
Epoch: 4299, trainingloss: 0.003945205769985999 | validation loss: 0.004265019075470093
Epoch: 4300, trainingloss: 0.003999640097401756 | validation loss: 0.004367478746471125
Epoch: 4301, trainingloss: 0.003232549782779458 | validation loss: 0.0036259269938080365
Epoch: 4302, trainingloss: 0.0036735301881415574 | validation loss: 0.00403000915282329
Epoch: 4303, trainingloss: 0.0034417564766646507 | validation loss: 0.003818929139059571
Epoch: 4304, trainingloss: 0.0033165895306211416 | validation loss: 0.0037209677749808095
Epoch: 4305, trainingloss: 0.0035306028152005467 | validation loss: 0.00393387548790596
Epoch: 4306, trainingloss: 0.003292442681123511 | validation loss: 0.003691432231274731
Epoch: 4307, trainingloss: 0.0034327938571052014 | validation loss: 0.003834083143429575
Epoch: 4308, trainingloss: 0.003208430740755445 | validation loss: 0.003633905809013446
Epoch: 4309, trainingloss: 0.0035867048398076193 | validation loss: 0.003925833301377469
Epoch: 4310, trainingloss: 0.0037691770738078503 | validation loss: 0.004125875158511569
Epoch: 4311, trainingloss: 0.004059685639316565 | validation loss: 0.004383102973727506
Epoch: 4312, trainingloss: 0.0033500258712925047 | validation loss: 0.003703338427563948
Epoch: 4313, trainingloss: 0.0032527388554988777 | validation loss: 0.003657721171345659
Epoch: 4314, trainingloss: 0.0034211533774206166 | validation loss: 0.003830369741435183
Epoch: 4315, trainingloss: 0.0034263403401010506 | validation loss: 0.0038039072443140838
Epoch: 4316, trainingloss: 0.00365189528330994 | validation loss: 0.003976517902901584
Epoch: 4317, trainingloss: 0.003509131944370392 | validation loss: 0.003836637762957406
Epoch: 4318, trainingloss: 0.0035856681559894837 | validation loss: 0.003957283224581979
Epoch: 4319, trainingloss: 0.003915073248331781 | validation loss: 0.004257684308271035
Epoch: 4320, trainingloss: 0.0038625848448389974 | validation loss: 0.004212710363696026
Epoch: 4321, trainingloss: 0.0033049172332398286 | validation loss: 0.0037107320142025814
Epoch: 4322, trainingloss: 0.00421611922716461 | validation loss: 0.004587086563222628
Epoch: 4323, trainingloss: 0.0040340271656924675 | validation loss: 0.004348735277266358
Epoch: 4324, trainingloss: 0.0032998070582875728 | validation loss: 0.0037125652542598303
Epoch: 4325, trainingloss: 0.003932604347230248 | validation loss: 0.00424409946837137
Epoch: 4326, trainingloss: 0.0033223808862892015 | validation loss: 0.003700932284290291
Epoch: 4327, trainingloss: 0.004208368674517594 | validation loss: 0.004501828438207683
Epoch: 4328, trainingloss: 0.003378238580647819 | validation loss: 0.003745525879308262
Epoch: 4329, trainingloss: 0.0036121312459991275 | validation loss: 0.0039931443939295
Epoch: 4330, trainingloss: 0.003883534055468269 | validation loss: 0.004236590229681225
Epoch: 4331, trainingloss: 0.0031413208584678116 | validation loss: 0.003566307024300528
Epoch: 4332, trainingloss: 0.003574484645014725 | validation loss: 0.0039299253212417016
Epoch: 4333, trainingloss: 0.0031756270175312823 | validation loss: 0.003573612205539947
Epoch: 4334, trainingloss: 0.003484551342861465 | validation loss: 0.0038380009701311983
Epoch: 4335, trainingloss: 0.0031593349594272596 | validation loss: 0.0035619854007027853
Epoch: 4336, trainingloss: 0.003752959350356506 | validation loss: 0.004125896510564974
Epoch: 4337, trainingloss: 0.0032869741328444024 | validation loss: 0.003697673460604821
Epoch: 4338, trainingloss: 0.004228422550241727 | validation loss: 0.0045160485229189425
Epoch: 4339, trainingloss: 0.003387703779130178 | validation loss: 0.0037972386676555147
Epoch: 4340, trainingloss: 0.0032365505104922925 | validation loss: 0.003653400108581112
Epoch: 4341, trainingloss: 0.00343512788403403 | validation loss: 0.003795104664451876
Epoch: 4342, trainingloss: 0.0032600965931602614 | validation loss: 0.003665887859898159
Epoch: 4343, trainingloss: 0.0037100852824538022 | validation loss: 0.004069291160026298
Epoch: 4344, trainingloss: 0.0032779576643695153 | validation loss: 0.0036754977734296786
Epoch: 4345, trainingloss: 0.004289723282545814 | validation loss: 0.004605132565182459
Epoch: 4346, trainingloss: 0.003986494292875667 | validation loss: 0.004257957360878347
Epoch: 4347, trainingloss: 0.0033402009878583144 | validation loss: 0.0037688433560761425
Epoch: 4348, trainingloss: 0.003610670943714132 | validation loss: 0.003958002767860974
Epoch: 4349, trainingloss: 0.0035938228632197465 | validation loss: 0.003943987352309105
Epoch: 4350, trainingloss: 0.0036875960378425837 | validation loss: 0.004042065504321791
Epoch: 4351, trainingloss: 0.003906901309899903 | validation loss: 0.004246221792240248
Epoch: 4352, trainingloss: 0.003500438925696674 | validation loss: 0.0038271567975611005
Epoch: 4353, trainingloss: 0.0036431573913417226 | validation loss: 0.004024920430445724
Epoch: 4354, trainingloss: 0.003610916707256206 | validation loss: 0.004035299254487907
Epoch: 4355, trainingloss: 0.0033886927890749105 | validation loss: 0.003777516935782173
Epoch: 4356, trainingloss: 0.003772254532493904 | validation loss: 0.004141402261308039
Epoch: 4357, trainingloss: 0.0034350888985380003 | validation loss: 0.0038070639937758657
Epoch: 4358, trainingloss: 0.003443538214342663 | validation loss: 0.0038298870848493495
Epoch: 4359, trainingloss: 0.003616143071296765 | validation loss: 0.003971094938038614
Epoch: 4360, trainingloss: 0.003473041195948234 | validation loss: 0.003845912960159503
Epoch: 4361, trainingloss: 0.004072669127108858 | validation loss: 0.004395828315010839
Epoch: 4362, trainingloss: 0.003301741227554137 | validation loss: 0.0037246412257081443
Epoch: 4363, trainingloss: 0.0035142876477877267 | validation loss: 0.003916713725837518
Epoch: 4364, trainingloss: 0.0033374241993095384 | validation loss: 0.0037490693746216196
Epoch: 4365, trainingloss: 0.003438299071700903 | validation loss: 0.0038096157390470637
Epoch: 4366, trainingloss: 0.0034544275117331905 | validation loss: 0.003823052514595682
Epoch: 4367, trainingloss: 0.003706865254482422 | validation loss: 0.0040679287184590225
Epoch: 4368, trainingloss: 0.0034901382321776858 | validation loss: 0.0038570132558845708
Epoch: 4369, trainingloss: 0.003472338362592652 | validation loss: 0.003886662383498386
Epoch: 4370, trainingloss: 0.0034419481305480687 | validation loss: 0.0038250142862745504
Epoch: 4371, trainingloss: 0.003756553773298738 | validation loss: 0.004112316613760118
Epoch: 4372, trainingloss: 0.004215512035599464 | validation loss: 0.004545579938975098
Epoch: 4373, trainingloss: 0.0036039969431567735 | validation loss: 0.0039357050105805836
Epoch: 4374, trainingloss: 0.0031635712448272488 | validation loss: 0.0035857754528635724
Epoch: 4375, trainingloss: 0.0036961279048099696 | validation loss: 0.0040406424296121
Epoch: 4376, trainingloss: 0.004673869374734311 | validation loss: 0.004955261709199692
Epoch: 4377, trainingloss: 0.0036654584797996635 | validation loss: 0.004037936925140163
Epoch: 4378, trainingloss: 0.003699352481894982 | validation loss: 0.004052773508884524
Epoch: 4379, trainingloss: 0.0031178658181977748 | validation loss: 0.0035470752531447133
Epoch: 4380, trainingloss: 0.0038349280478277847 | validation loss: 0.004189497664962566
Epoch: 4381, trainingloss: 0.003212763395606631 | validation loss: 0.0036266378305873587
Epoch: 4382, trainingloss: 0.0033793523533608935 | validation loss: 0.0037867600702705248
Epoch: 4383, trainingloss: 0.0035635076737221476 | validation loss: 0.003914189558190237
Epoch: 4384, trainingloss: 0.003174162539534243 | validation loss: 0.003598225812290816
Epoch: 4385, trainingloss: 0.003320200091519756 | validation loss: 0.0037185081285825007
Epoch: 4386, trainingloss: 0.004359748475897643 | validation loss: 0.004630809363103848
Epoch: 4387, trainingloss: 0.00369283073743744 | validation loss: 0.004011880083915871
Epoch: 4388, trainingloss: 0.0034427760252647103 | validation loss: 0.003847009514237274
Epoch: 4389, trainingloss: 0.0033188429991292453 | validation loss: 0.003730558420023496
Epoch: 4390, trainingloss: 0.003228610756147255 | validation loss: 0.003646370101307562
Epoch: 4391, trainingloss: 0.0036452506396112624 | validation loss: 0.0039977822348362165
Epoch: 4392, trainingloss: 0.0035768798064003426 | validation loss: 0.003943280115346502
Epoch: 4393, trainingloss: 0.003866849029038761 | validation loss: 0.004247109791397026
Epoch: 4394, trainingloss: 0.0032062160041183498 | validation loss: 0.003621958815204308
Epoch: 4395, trainingloss: 0.0032705351107716056 | validation loss: 0.003703988895202839
Epoch: 4396, trainingloss: 0.003574834892991457 | validation loss: 0.00394849853792268
Epoch: 4397, trainingloss: 0.0034648115743956672 | validation loss: 0.003889690219492276
Epoch: 4398, trainingloss: 0.0034232020749594013 | validation loss: 0.003827246873415649
Epoch: 4399, trainingloss: 0.0033461438452557467 | validation loss: 0.003752631724927822
Epoch: 4400, trainingloss: 0.0036448357123979092 | validation loss: 0.0040100057293359645
Epoch: 4401, trainingloss: 0.003995253176226626 | validation loss: 0.004355223938539843
Epoch: 4402, trainingloss: 0.0036868429997303693 | validation loss: 0.004031235486090797
Epoch: 4403, trainingloss: 0.0035373782540453957 | validation loss: 0.003891789215571049
Epoch: 4404, trainingloss: 0.004216745568376654 | validation loss: 0.004518324401822578
Epoch: 4405, trainingloss: 0.0035514257501870206 | validation loss: 0.003945332625628265
Epoch: 4406, trainingloss: 0.0037218792677149713 | validation loss: 0.004076371732849591
Epoch: 4407, trainingloss: 0.004293042464630506 | validation loss: 0.00459346747824974
Epoch: 4408, trainingloss: 0.003805996629485561 | validation loss: 0.004166655034277246
Epoch: 4409, trainingloss: 0.004027442652787909 | validation loss: 0.004349888914388491
Epoch: 4410, trainingloss: 0.003627058223446812 | validation loss: 0.0039782890485296025
Epoch: 4411, trainingloss: 0.003911075261120234 | validation loss: 0.0042645355464653095
Epoch: 4412, trainingloss: 0.0036146198769187853 | validation loss: 0.0039913278156389655
Epoch: 4413, trainingloss: 0.0033631284051350656 | validation loss: 0.003751736938288267
Epoch: 4414, trainingloss: 0.004012801817905989 | validation loss: 0.004317557257728634
Epoch: 4415, trainingloss: 0.004098615590308239 | validation loss: 0.00444603219067685
Epoch: 4416, trainingloss: 0.003345985339731719 | validation loss: 0.0037287547806853527
Epoch: 4417, trainingloss: 0.003218116569639918 | validation loss: 0.0036363221526066213
Epoch: 4418, trainingloss: 0.003324917645554082 | validation loss: 0.00374414895515631
Epoch: 4419, trainingloss: 0.0035656816611461545 | validation loss: 0.0039035763264224812
Epoch: 4420, trainingloss: 0.003746120191271904 | validation loss: 0.004112507569672715
Epoch: 4421, trainingloss: 0.003930231116022493 | validation loss: 0.004253704552686791
Epoch: 4422, trainingloss: 0.003628231375828414 | validation loss: 0.0039690116604935224
Epoch: 4423, trainingloss: 0.0033866463310683152 | validation loss: 0.0037564936688641607
Epoch: 4424, trainingloss: 0.0035491649139039487 | validation loss: 0.00395005292487239
Epoch: 4425, trainingloss: 0.0034826834350396426 | validation loss: 0.0038734868734117177
Epoch: 4426, trainingloss: 0.0036362415674257476 | validation loss: 0.003995872810580141
Epoch: 4427, trainingloss: 0.0032361008712763306 | validation loss: 0.003631841614373824
Epoch: 4428, trainingloss: 0.003462119945688004 | validation loss: 0.003849193642128526
Epoch: 4429, trainingloss: 0.0033020479769118568 | validation loss: 0.0037242251264167905
Epoch: 4430, trainingloss: 0.0034033867721077653 | validation loss: 0.003797663591328427
Epoch: 4431, trainingloss: 0.003614223127344003 | validation loss: 0.003992654579567184
Epoch: 4432, trainingloss: 0.0033821843973974417 | validation loss: 0.003770639322522016
Epoch: 4433, trainingloss: 0.003254746169909959 | validation loss: 0.003656407834793808
Epoch: 4434, trainingloss: 0.0034356166801561045 | validation loss: 0.0037977490133347253
Epoch: 4435, trainingloss: 0.0037412524825655978 | validation loss: 0.004066543674097218
Epoch: 4436, trainingloss: 0.0033285373210850877 | validation loss: 0.0037254533076227885
Epoch: 4437, trainingloss: 0.0034025776183871526 | validation loss: 0.003788248521699075
Epoch: 4438, trainingloss: 0.0032957109429479522 | validation loss: 0.0036949465768234746
Epoch: 4439, trainingloss: 0.0033626246959767704 | validation loss: 0.0037546018386107605
Epoch: 4440, trainingloss: 0.003938402235068278 | validation loss: 0.004255707039284523
Epoch: 4441, trainingloss: 0.0034373086231581098 | validation loss: 0.0038435236100562717
Epoch: 4442, trainingloss: 0.003744308306656461 | validation loss: 0.004064651286379614
Epoch: 4443, trainingloss: 0.003186636369107844 | validation loss: 0.003613444378249173
Epoch: 4444, trainingloss: 0.0037702259574422413 | validation loss: 0.00410982081941945
Epoch: 4445, trainingloss: 0.0038416033132087756 | validation loss: 0.004198777132988544
Epoch: 4446, trainingloss: 0.003334207927439579 | validation loss: 0.0037209024157296143
Epoch: 4447, trainingloss: 0.0034210962808486293 | validation loss: 0.0037991875300730556
Epoch: 4448, trainingloss: 0.0034523750541605117 | validation loss: 0.003817482656284519
Epoch: 4449, trainingloss: 0.0031970770642366134 | validation loss: 0.003601543763243434
Epoch: 4450, trainingloss: 0.0036982435963393416 | validation loss: 0.004068098779401629
Epoch: 4451, trainingloss: 0.003384331883088665 | validation loss: 0.003783308438611071
Epoch: 4452, trainingloss: 0.0037616749397470194 | validation loss: 0.004118095759467352
Epoch: 4453, trainingloss: 0.0034810010863077444 | validation loss: 0.003855957477537163
Epoch: 4454, trainingloss: 0.003129141194634785 | validation loss: 0.0035654905009886947
Epoch: 4455, trainingloss: 0.003503822576199255 | validation loss: 0.0038677113693387347
Epoch: 4456, trainingloss: 0.0033796809577531684 | validation loss: 0.003778154548282784
Epoch: 4457, trainingloss: 0.003411405885994768 | validation loss: 0.003800623842223557
Epoch: 4458, trainingloss: 0.0031476427210964213 | validation loss: 0.003525234533081418
Epoch: 4459, trainingloss: 0.0035251954851005488 | validation loss: 0.0039065705937872215
Epoch: 4460, trainingloss: 0.003503481029792326 | validation loss: 0.003872789460011012
Epoch: 4461, trainingloss: 0.0035107312388962058 | validation loss: 0.003879578445255058
Epoch: 4462, trainingloss: 0.003712659556793867 | validation loss: 0.004069865985530485
Epoch: 4463, trainingloss: 0.003893003100837227 | validation loss: 0.004209460284364076
Epoch: 4464, trainingloss: 0.0035065687273512936 | validation loss: 0.0038610437722951772
Epoch: 4465, trainingloss: 0.0035846382879544253 | validation loss: 0.00395685769213261
Epoch: 4466, trainingloss: 0.0035665475006913566 | validation loss: 0.003941198040776104
Epoch: 4467, trainingloss: 0.0033025685197735108 | validation loss: 0.0036767163507594545
Epoch: 4468, trainingloss: 0.003422086052450133 | validation loss: 0.003813380905031389
Epoch: 4469, trainingloss: 0.0031710522270229076 | validation loss: 0.0035531173395416857
Epoch: 4470, trainingloss: 0.0032986109959177133 | validation loss: 0.003704862282359614
Epoch: 4471, trainingloss: 0.003833456557763597 | validation loss: 0.00418014718455135
Epoch: 4472, trainingloss: 0.0030694851298280687 | validation loss: 0.00350731706621297
Epoch: 4473, trainingloss: 0.004159495582701252 | validation loss: 0.0044555164639854565
Epoch: 4474, trainingloss: 0.003795600145866659 | validation loss: 0.004160394936806199
Epoch: 4475, trainingloss: 0.0038963697989061116 | validation loss: 0.00423780935959131
Epoch: 4476, trainingloss: 0.0035416514044319366 | validation loss: 0.003918531963685919
Epoch: 4477, trainingloss: 0.0035737870479267513 | validation loss: 0.003975438555804887
Epoch: 4478, trainingloss: 0.0033986529103953956 | validation loss: 0.003771117465674307
Epoch: 4479, trainingloss: 0.003290696328930501 | validation loss: 0.0036467233727132246
Epoch: 4480, trainingloss: 0.0031625506774736445 | validation loss: 0.003578606143491109
Epoch: 4481, trainingloss: 0.0034209032368177077 | validation loss: 0.0038143871417482857
Epoch: 4482, trainingloss: 0.0034445255374306485 | validation loss: 0.003794030180432153
Epoch: 4483, trainingloss: 0.0035266434229443123 | validation loss: 0.003946226433391886
Epoch: 4484, trainingloss: 0.004283825440067848 | validation loss: 0.00457557857480897
Epoch: 4485, trainingloss: 0.0033390219863400163 | validation loss: 0.003737770081874465
Epoch: 4486, trainingloss: 0.0037789445414257764 | validation loss: 0.004118844205120281
Epoch: 4487, trainingloss: 0.004343783905353828 | validation loss: 0.004656364898782411
Epoch: 4488, trainingloss: 0.004208248107585733 | validation loss: 0.004500717204632069
Epoch: 4489, trainingloss: 0.0036196454226281277 | validation loss: 0.003980850414546124
Epoch: 4490, trainingloss: 0.0037265342513158146 | validation loss: 0.004102014792884549
Epoch: 4491, trainingloss: 0.0036488899674067014 | validation loss: 0.004001783107135418
Epoch: 4492, trainingloss: 0.0033383116557487865 | validation loss: 0.003718916406627665
Epoch: 4493, trainingloss: 0.0039338983065318085 | validation loss: 0.004308552540607318
Epoch: 4494, trainingloss: 0.0035284162083782933 | validation loss: 0.003919542780524551
Epoch: 4495, trainingloss: 0.0035530513208849065 | validation loss: 0.003936478642567652
Epoch: 4496, trainingloss: 0.003722939641071763 | validation loss: 0.0040568189608201945
Epoch: 4497, trainingloss: 0.003475549410472403 | validation loss: 0.0038643333810063096
Epoch: 4498, trainingloss: 0.0036212684370609954 | validation loss: 0.003993341810178158
Epoch: 4499, trainingloss: 0.0033281944871506367 | validation loss: 0.00372206439922996
Epoch: 4500, trainingloss: 0.0036310170698181763 | validation loss: 0.003970626013290368
Epoch: 4501, trainingloss: 0.004224672259247663 | validation loss: 0.0045425620642474155
Epoch: 4502, trainingloss: 0.003407527711752654 | validation loss: 0.003784122480831651
Epoch: 4503, trainingloss: 0.0031039950632564214 | validation loss: 0.0035459624009326375
Epoch: 4504, trainingloss: 0.0034179083245160784 | validation loss: 0.003823129271551887
Epoch: 4505, trainingloss: 0.004088378550523994 | validation loss: 0.004415144510555237
Epoch: 4506, trainingloss: 0.0034904573736330414 | validation loss: 0.003839372970409728
Epoch: 4507, trainingloss: 0.0035701844843496204 | validation loss: 0.003950561295264943
Epoch: 4508, trainingloss: 0.0035235681515497544 | validation loss: 0.0039003134431149773
Epoch: 4509, trainingloss: 0.0034738271108217126 | validation loss: 0.0038238052279780596
Epoch: 4510, trainingloss: 0.0034829915161430323 | validation loss: 0.0038365393856381828
Epoch: 4511, trainingloss: 0.003249919399738883 | validation loss: 0.003622109003000017
Epoch: 4512, trainingloss: 0.0034646078915381196 | validation loss: 0.0038789946428983684
Epoch: 4513, trainingloss: 0.0034795745960471427 | validation loss: 0.0038604638165738218
Epoch: 4514, trainingloss: 0.0037335840752743066 | validation loss: 0.004096498176793494
Epoch: 4515, trainingloss: 0.004024906343729917 | validation loss: 0.004336358290645258
Epoch: 4516, trainingloss: 0.003923836746418726 | validation loss: 0.004279864153589732
Epoch: 4517, trainingloss: 0.003775823523774437 | validation loss: 0.004139829756028152
Epoch: 4518, trainingloss: 0.004286937152728656 | validation loss: 0.004598618386036851
Epoch: 4519, trainingloss: 0.0034725588403742135 | validation loss: 0.003862106962043964
Epoch: 4520, trainingloss: 0.0031810970108916477 | validation loss: 0.003618892753942035
Epoch: 4521, trainingloss: 0.003648346269627029 | validation loss: 0.004028067828831182
Epoch: 4522, trainingloss: 0.003950241718173467 | validation loss: 0.004260427119393737
Epoch: 4523, trainingloss: 0.0037920736654093318 | validation loss: 0.004147891604790155
Epoch: 4524, trainingloss: 0.003229902305867833 | validation loss: 0.003652004135638663
Epoch: 4525, trainingloss: 0.0036262635283009414 | validation loss: 0.003997421935069973
Epoch: 4526, trainingloss: 0.00322793510953219 | validation loss: 0.003619426169243714
Epoch: 4527, trainingloss: 0.003946537472927662 | validation loss: 0.004264561512762337
Epoch: 4528, trainingloss: 0.003794008227202001 | validation loss: 0.004146319931543772
Epoch: 4529, trainingloss: 0.004144852905215388 | validation loss: 0.004440302939444115
Epoch: 4530, trainingloss: 0.0035542274852281685 | validation loss: 0.003932849694287556
Epoch: 4531, trainingloss: 0.003316397497532725 | validation loss: 0.003729349678037261
Epoch: 4532, trainingloss: 0.0034128297961982584 | validation loss: 0.0037885572731499876
Epoch: 4533, trainingloss: 0.003814445598450316 | validation loss: 0.004131711569852803
Epoch: 4534, trainingloss: 0.0033681359700662456 | validation loss: 0.003759365999985107
Epoch: 4535, trainingloss: 0.0033598037764742046 | validation loss: 0.00377701137466861
Epoch: 4536, trainingloss: 0.0033258194153898578 | validation loss: 0.0037228512216808413
Epoch: 4537, trainingloss: 0.0032934637949551928 | validation loss: 0.0037042156160216697
Epoch: 4538, trainingloss: 0.0033722365735242483 | validation loss: 0.0037882571623467447
Epoch: 4539, trainingloss: 0.003260446988906634 | validation loss: 0.0036716736394126754
Epoch: 4540, trainingloss: 0.003688764987856269 | validation loss: 0.004037453905778479
Epoch: 4541, trainingloss: 0.003743679507966127 | validation loss: 0.004034433749641257
Epoch: 4542, trainingloss: 0.003433695360546471 | validation loss: 0.0038169028469440015
Epoch: 4543, trainingloss: 0.004343359578799668 | validation loss: 0.004647299026018165
Epoch: 4544, trainingloss: 0.003450348073740773 | validation loss: 0.0038450797054023576
Epoch: 4545, trainingloss: 0.003478600461119943 | validation loss: 0.003883334342175284
Epoch: 4546, trainingloss: 0.003453370586267043 | validation loss: 0.003830016096907529
Epoch: 4547, trainingloss: 0.003433971040722296 | validation loss: 0.0038639901476908364
Epoch: 4548, trainingloss: 0.003701744010420782 | validation loss: 0.004045404952952834
Epoch: 4549, trainingloss: 0.0038840200045520148 | validation loss: 0.004229338899813279
Epoch: 4550, trainingloss: 0.0033499434739905657 | validation loss: 0.00375867440510757
Epoch: 4551, trainingloss: 0.0036864253374987955 | validation loss: 0.004062795288989073
Epoch: 4552, trainingloss: 0.003407432232852704 | validation loss: 0.003835689957261863
Epoch: 4553, trainingloss: 0.003868878169163375 | validation loss: 0.0041968650055821816
Epoch: 4554, trainingloss: 0.0037223822128467773 | validation loss: 0.0040682768514750285
Epoch: 4555, trainingloss: 0.003860432847623919 | validation loss: 0.0042366943272213135
Epoch: 4556, trainingloss: 0.003413587732943243 | validation loss: 0.003807922429752067
Epoch: 4557, trainingloss: 0.003869808650521814 | validation loss: 0.004218766942826083
Epoch: 4558, trainingloss: 0.003423778972452725 | validation loss: 0.0038138216797676478
Epoch: 4559, trainingloss: 0.004164614239628878 | validation loss: 0.004463329406013451
Epoch: 4560, trainingloss: 0.003669722970131192 | validation loss: 0.004018052263719902
Epoch: 4561, trainingloss: 0.003225889128786318 | validation loss: 0.003668743445452659
Epoch: 4562, trainingloss: 0.0036340260254396086 | validation loss: 0.003989600215989485
Epoch: 4563, trainingloss: 0.003716237112080129 | validation loss: 0.004057866883336047
Epoch: 4564, trainingloss: 0.0037029740834471254 | validation loss: 0.004077616784518284
Epoch: 4565, trainingloss: 0.004032654345009536 | validation loss: 0.004363207374761564
Epoch: 4566, trainingloss: 0.004151771533175453 | validation loss: 0.004452613767068114
Epoch: 4567, trainingloss: 0.0033231815252997903 | validation loss: 0.003717757521688995
Epoch: 4568, trainingloss: 0.003452868211728137 | validation loss: 0.0038308356062686792
Epoch: 4569, trainingloss: 0.003683045884428758 | validation loss: 0.004055863278751925
Epoch: 4570, trainingloss: 0.0035137140485379838 | validation loss: 0.0038799601609775776
Epoch: 4571, trainingloss: 0.003780898682703655 | validation loss: 0.004112895176128486
Epoch: 4572, trainingloss: 0.003558557473680071 | validation loss: 0.003933791451657437
Epoch: 4573, trainingloss: 0.004156764761090657 | validation loss: 0.004472574572518455
Epoch: 4574, trainingloss: 0.0035003853278110482 | validation loss: 0.003876429721486558
Epoch: 4575, trainingloss: 0.003475683301803723 | validation loss: 0.0038763198310269075
Epoch: 4576, trainingloss: 0.003130780707717605 | validation loss: 0.0035429540867101296
Epoch: 4577, trainingloss: 0.0035628522139471586 | validation loss: 0.003963157147812801
Epoch: 4578, trainingloss: 0.003950051046446969 | validation loss: 0.004287583431836656
Epoch: 4579, trainingloss: 0.003986863935370062 | validation loss: 0.0043645473626905485
Epoch: 4580, trainingloss: 0.0035880080969776557 | validation loss: 0.003973349766701027
Epoch: 4581, trainingloss: 0.0038580270707662123 | validation loss: 0.00419855883746731
Epoch: 4582, trainingloss: 0.0032480113864112197 | validation loss: 0.0036660671805071572
Epoch: 4583, trainingloss: 0.003756592542490354 | validation loss: 0.004121972124910883
Epoch: 4584, trainingloss: 0.003489593261315227 | validation loss: 0.003873207335390992
Epoch: 4585, trainingloss: 0.0037520622370993805 | validation loss: 0.004118788386790728
Epoch: 4586, trainingloss: 0.0037777429351321637 | validation loss: 0.0041172732425135816
Epoch: 4587, trainingloss: 0.0040022308270567936 | validation loss: 0.004314765776769739
Epoch: 4588, trainingloss: 0.0036775598957540295 | validation loss: 0.003999587233100126
Epoch: 4589, trainingloss: 0.003798765683266837 | validation loss: 0.004138627671874707
Epoch: 4590, trainingloss: 0.0037342369409024117 | validation loss: 0.004092269895922206
Epoch: 4591, trainingloss: 0.0035297101580095587 | validation loss: 0.0038915201423720463
Epoch: 4592, trainingloss: 0.0034755610593324823 | validation loss: 0.0038762157631467573
Epoch: 4593, trainingloss: 0.0036736461703271487 | validation loss: 0.00402371520785185
Epoch: 4594, trainingloss: 0.0035932697975367555 | validation loss: 0.003966746075368412
Epoch: 4595, trainingloss: 0.003308384038960976 | validation loss: 0.003697339122300514
Epoch: 4596, trainingloss: 0.003551355493964919 | validation loss: 0.003900696141147668
Epoch: 4597, trainingloss: 0.0036361929864564013 | validation loss: 0.0039772031994330884
Epoch: 4598, trainingloss: 0.003486103117132183 | validation loss: 0.003853554523702298
Epoch: 4599, trainingloss: 0.003499959362067037 | validation loss: 0.003887802180642666
Epoch: 4600, trainingloss: 0.004001136013080281 | validation loss: 0.0043368797748263195
Epoch: 4601, trainingloss: 0.003702148892216732 | validation loss: 0.004068699125408125
Epoch: 4602, trainingloss: 0.0035444641308938186 | validation loss: 0.003944676925470447
Epoch: 4603, trainingloss: 0.00331241197673769 | validation loss: 0.003675132119142883
Epoch: 4604, trainingloss: 0.0040071561052557585 | validation loss: 0.004319499684103495
Epoch: 4605, trainingloss: 0.0031756829754225665 | validation loss: 0.0035815592784872257
Epoch: 4606, trainingloss: 0.003950864530258722 | validation loss: 0.00430188852375355
Epoch: 4607, trainingloss: 0.0034136200227815466 | validation loss: 0.0037672530225249276
Epoch: 4608, trainingloss: 0.003503356385165637 | validation loss: 0.00386370414170392
Epoch: 4609, trainingloss: 0.0034524120552787366 | validation loss: 0.003814667464001461
Epoch: 4610, trainingloss: 0.003450176014289744 | validation loss: 0.0038452439260755556
Epoch: 4611, trainingloss: 0.003786482657144134 | validation loss: 0.0041477307228459945
Epoch: 4612, trainingloss: 0.0034882624477716798 | validation loss: 0.003883532436534516
Epoch: 4613, trainingloss: 0.0034884680584589965 | validation loss: 0.0038611520252569095
Epoch: 4614, trainingloss: 0.0037544640625306216 | validation loss: 0.004115625782922905
Epoch: 4615, trainingloss: 0.003878900567192062 | validation loss: 0.004184267236664684
Epoch: 4616, trainingloss: 0.0031635256644255106 | validation loss: 0.0035829224532646043
Epoch: 4617, trainingloss: 0.003286960866664591 | validation loss: 0.003681490444401038
Epoch: 4618, trainingloss: 0.003488772711087442 | validation loss: 0.0038539478913302097
Epoch: 4619, trainingloss: 0.0034782263909548376 | validation loss: 0.0038412813283558236
Epoch: 4620, trainingloss: 0.003363593274115777 | validation loss: 0.0037571533509241964
Epoch: 4621, trainingloss: 0.0036222209120443196 | validation loss: 0.0040237272790486864
Epoch: 4622, trainingloss: 0.0041699396088956025 | validation loss: 0.004482257493528604
Epoch: 4623, trainingloss: 0.003168806011023883 | validation loss: 0.0035897170304610214
Epoch: 4624, trainingloss: 0.004167997734185131 | validation loss: 0.0044722075591954675
Epoch: 4625, trainingloss: 0.003733554175037982 | validation loss: 0.004080956429598216
Epoch: 4626, trainingloss: 0.003873918330967397 | validation loss: 0.0041890279838462195
Epoch: 4627, trainingloss: 0.0032682392443344525 | validation loss: 0.003672360298138236
Epoch: 4628, trainingloss: 0.0032163968130077742 | validation loss: 0.003650318099783204
Epoch: 4629, trainingloss: 0.003339632073924794 | validation loss: 0.0037417789985419126
Epoch: 4630, trainingloss: 0.003942508217705965 | validation loss: 0.004265752845422325
Epoch: 4631, trainingloss: 0.0034943686501007023 | validation loss: 0.003839399790929184
Epoch: 4632, trainingloss: 0.003361357563865836 | validation loss: 0.003768395936690443
Epoch: 4633, trainingloss: 0.0038068749936784555 | validation loss: 0.0041485869825978626
Epoch: 4634, trainingloss: 0.003182488309749541 | validation loss: 0.003586517219928316
Epoch: 4635, trainingloss: 0.003204899260420701 | validation loss: 0.003591273038003689
Epoch: 4636, trainingloss: 0.0033158148062635263 | validation loss: 0.003677118229219367
Epoch: 4637, trainingloss: 0.003176387128577122 | validation loss: 0.0036007841786154697
Epoch: 4638, trainingloss: 0.003413841195429309 | validation loss: 0.0038012940312392987
Epoch: 4639, trainingloss: 0.003222349980913333 | validation loss: 0.0036536944929682355
Epoch: 4640, trainingloss: 0.0034598579776853873 | validation loss: 0.0038435048117659875
Epoch: 4641, trainingloss: 0.0034567341073942414 | validation loss: 0.0038279175531289083
Epoch: 4642, trainingloss: 0.003969404146658075 | validation loss: 0.0042862317235935294
Epoch: 4643, trainingloss: 0.003421595961457018 | validation loss: 0.0038059067380837126
Epoch: 4644, trainingloss: 0.003265379568875477 | validation loss: 0.0036782338399391945
Epoch: 4645, trainingloss: 0.003602972398175805 | validation loss: 0.003983760951526748
Epoch: 4646, trainingloss: 0.0033189105664489602 | validation loss: 0.0037162706447184815
Epoch: 4647, trainingloss: 0.003088341566532134 | validation loss: 0.0035128739972702916
Epoch: 4648, trainingloss: 0.003313386528063211 | validation loss: 0.003738486677168494
Epoch: 4649, trainingloss: 0.004056106536261642 | validation loss: 0.004364711991790584
Epoch: 4650, trainingloss: 0.003585161131410448 | validation loss: 0.0039499031640779555
Epoch: 4651, trainingloss: 0.0036914808663923103 | validation loss: 0.004039179010344286
Epoch: 4652, trainingloss: 0.003529814818687582 | validation loss: 0.003908062375938865
Epoch: 4653, trainingloss: 0.0031904629236642616 | validation loss: 0.0035811540962314894
Epoch: 4654, trainingloss: 0.003464366852692683 | validation loss: 0.0038429270560860376
Epoch: 4655, trainingloss: 0.0035951763695882314 | validation loss: 0.003976868849927602
Epoch: 4656, trainingloss: 0.003200115393350853 | validation loss: 0.003612376858228204
Epoch: 4657, trainingloss: 0.0037155122466692673 | validation loss: 0.004083414858215852
Epoch: 4658, trainingloss: 0.003440561016262515 | validation loss: 0.003814009481087953
Epoch: 4659, trainingloss: 0.003985297137934986 | validation loss: 0.004341079697575771
Epoch: 4660, trainingloss: 0.0033959926135375957 | validation loss: 0.0037793304863601657
Epoch: 4661, trainingloss: 0.003528077061624871 | validation loss: 0.003904872905497704
Epoch: 4662, trainingloss: 0.0034964731860760295 | validation loss: 0.00390533386666623
Epoch: 4663, trainingloss: 0.004103064552984033 | validation loss: 0.004420013551167164
Epoch: 4664, trainingloss: 0.003960741411263029 | validation loss: 0.004312434046029239
Epoch: 4665, trainingloss: 0.0032888830683618776 | validation loss: 0.0036892059287401743
Epoch: 4666, trainingloss: 0.004254046249112083 | validation loss: 0.0045549780041692625
Epoch: 4667, trainingloss: 0.0036090733662819774 | validation loss: 0.003992721428998843
Epoch: 4668, trainingloss: 0.003585012006661259 | validation loss: 0.003939142698949864
Epoch: 4669, trainingloss: 0.003312037969991258 | validation loss: 0.003750495264191589
Epoch: 4670, trainingloss: 0.0035214598433122575 | validation loss: 0.0039048064004329106
Epoch: 4671, trainingloss: 0.0035173311951124395 | validation loss: 0.003918259126446358
Epoch: 4672, trainingloss: 0.0035275530562631522 | validation loss: 0.0038904438856267676
Epoch: 4673, trainingloss: 0.0038621830834319653 | validation loss: 0.00419439089674665
Epoch: 4674, trainingloss: 0.003904122917791291 | validation loss: 0.004249182289572966
Epoch: 4675, trainingloss: 0.003716518323324539 | validation loss: 0.004087423235582163
Epoch: 4676, trainingloss: 0.0032684436839467567 | validation loss: 0.0036842540261994186
Epoch: 4677, trainingloss: 0.003938188845182757 | validation loss: 0.004274994826222624
Epoch: 4678, trainingloss: 0.003476903607120165 | validation loss: 0.0038884813816312943
Epoch: 4679, trainingloss: 0.0032582461108115394 | validation loss: 0.003678388318660767
Epoch: 4680, trainingloss: 0.0033386463613660758 | validation loss: 0.0037325688887566485
Epoch: 4681, trainingloss: 0.003665481448069033 | validation loss: 0.004031554843055596
Epoch: 4682, trainingloss: 0.0034804926909604724 | validation loss: 0.0038730486963230904
Epoch: 4683, trainingloss: 0.0035125033967924302 | validation loss: 0.003918955594233317
Epoch: 4684, trainingloss: 0.0038998134470360156 | validation loss: 0.004217089856488464
Epoch: 4685, trainingloss: 0.003525795520888673 | validation loss: 0.003922459993390645
Epoch: 4686, trainingloss: 0.0036614629058841124 | validation loss: 0.004002992809192658
Epoch: 4687, trainingloss: 0.00355245617861557 | validation loss: 0.0039082274246616975
Epoch: 4688, trainingloss: 0.004301201571827329 | validation loss: 0.00459171757313122
Epoch: 4689, trainingloss: 0.0034190823109992784 | validation loss: 0.0037811301508457198
Epoch: 4690, trainingloss: 0.0033773662449996245 | validation loss: 0.003773924932831485
Epoch: 4691, trainingloss: 0.004133008181797459 | validation loss: 0.004479481094775311
Epoch: 4692, trainingloss: 0.0035379059417109298 | validation loss: 0.003911317644356072
Epoch: 4693, trainingloss: 0.0035949920056792643 | validation loss: 0.003975598840548422
Epoch: 4694, trainingloss: 0.0032158516796254844 | validation loss: 0.0036495668153336907
Epoch: 4695, trainingloss: 0.003959884668757997 | validation loss: 0.004260451120707126
Epoch: 4696, trainingloss: 0.003414612562622938 | validation loss: 0.0038296344171584442
Epoch: 4697, trainingloss: 0.003364836389954877 | validation loss: 0.003776359516214414
Epoch: 4698, trainingloss: 0.004669012697384643 | validation loss: 0.004926512654468538
Epoch: 4699, trainingloss: 0.0036183473003336786 | validation loss: 0.003985672745622167
Epoch: 4700, trainingloss: 0.003144375344604467 | validation loss: 0.003544219588852036
Epoch: 4701, trainingloss: 0.0033173365769406504 | validation loss: 0.003712852655419331
Epoch: 4702, trainingloss: 0.0038049323727788803 | validation loss: 0.004176454776668574
Epoch: 4703, trainingloss: 0.003806560295247091 | validation loss: 0.004156689373083434
Epoch: 4704, trainingloss: 0.0036943529984906315 | validation loss: 0.004048106509985174
Epoch: 4705, trainingloss: 0.003850815852530978 | validation loss: 0.004170712877181687
Epoch: 4706, trainingloss: 0.003362983569868143 | validation loss: 0.0037357717808453386
Epoch: 4707, trainingloss: 0.0034171212080266757 | validation loss: 0.0038209626643600915
Epoch: 4708, trainingloss: 0.003377397298234659 | validation loss: 0.003760762025293849
Epoch: 4709, trainingloss: 0.0033720553299395844 | validation loss: 0.0037364745923429
Epoch: 4710, trainingloss: 0.003992632176314406 | validation loss: 0.004314290742670892
Epoch: 4711, trainingloss: 0.00370002398548785 | validation loss: 0.004053477539123847
Epoch: 4712, trainingloss: 0.003310953125494841 | validation loss: 0.0037189131295871265
Epoch: 4713, trainingloss: 0.0036916303823365665 | validation loss: 0.004042301764126952
Epoch: 4714, trainingloss: 0.003499632578511516 | validation loss: 0.0038720964350948024
Epoch: 4715, trainingloss: 0.003533634414757669 | validation loss: 0.0038686795182685287
Epoch: 4716, trainingloss: 0.0035410879198154357 | validation loss: 0.003899736361514568
Epoch: 4717, trainingloss: 0.00316387986788055 | validation loss: 0.003600540246106811
Epoch: 4718, trainingloss: 0.0031215973333482356 | validation loss: 0.0035409492988452756
Epoch: 4719, trainingloss: 0.0034734807534417002 | validation loss: 0.0038767304661593053
Epoch: 4720, trainingloss: 0.00357333033371212 | validation loss: 0.0039743268306562905
Epoch: 4721, trainingloss: 0.0033804340187692595 | validation loss: 0.0037567338608694074
Epoch: 4722, trainingloss: 0.0032490815214270526 | validation loss: 0.0036157417115652655
Epoch: 4723, trainingloss: 0.0034318481595007086 | validation loss: 0.003791477213888087
Epoch: 4724, trainingloss: 0.003339141755486832 | validation loss: 0.0037244729484274624
Epoch: 4725, trainingloss: 0.0034734964429198284 | validation loss: 0.0038644912042794673
Epoch: 4726, trainingloss: 0.0033842488284880233 | validation loss: 0.0038105632053936503
Epoch: 4727, trainingloss: 0.003138032496013478 | validation loss: 0.0035107578261775957
Epoch: 4728, trainingloss: 0.003276874160015604 | validation loss: 0.003712479644700361
Epoch: 4729, trainingloss: 0.0035129509182635446 | validation loss: 0.0038784980300410154
Epoch: 4730, trainingloss: 0.004120022324861127 | validation loss: 0.0044683251141995756
Epoch: 4731, trainingloss: 0.0032500365785593445 | validation loss: 0.0036501852381537092
Epoch: 4732, trainingloss: 0.003557389002667993 | validation loss: 0.0038903580522420727
Epoch: 4733, trainingloss: 0.0034018314126488605 | validation loss: 0.00376038796898482
Epoch: 4734, trainingloss: 0.003434877009247795 | validation loss: 0.0038304338371837263
Epoch: 4735, trainingloss: 0.0043301710470423985 | validation loss: 0.004615464983932224
Epoch: 4736, trainingloss: 0.0033267977422623517 | validation loss: 0.0037062959783228573
Epoch: 4737, trainingloss: 0.003953789990153275 | validation loss: 0.004293310203272629
Epoch: 4738, trainingloss: 0.003201461235336214 | validation loss: 0.0035768875665195396
Epoch: 4739, trainingloss: 0.003872213518315249 | validation loss: 0.00423712191260718
Epoch: 4740, trainingloss: 0.004197831730964904 | validation loss: 0.0044980216206138976
Epoch: 4741, trainingloss: 0.00412832485550414 | validation loss: 0.004397248880198551
Epoch: 4742, trainingloss: 0.003434506785620371 | validation loss: 0.0037930577290478888
Epoch: 4743, trainingloss: 0.003412656951215669 | validation loss: 0.0037802849867532742
Epoch: 4744, trainingloss: 0.004532890286486873 | validation loss: 0.004804388679570909
Epoch: 4745, trainingloss: 0.0037241935862698766 | validation loss: 0.0040723084630181735
Epoch: 4746, trainingloss: 0.003346535707789357 | validation loss: 0.0037460229372190475
Epoch: 4747, trainingloss: 0.0032879156325588367 | validation loss: 0.0036925251060543106
Epoch: 4748, trainingloss: 0.0033538099377920672 | validation loss: 0.0037609313340724085
Epoch: 4749, trainingloss: 0.003735340460850636 | validation loss: 0.004064303893041602
Epoch: 4750, trainingloss: 0.0035393099769738634 | validation loss: 0.0039215856020153265
Epoch: 4751, trainingloss: 0.0035352611162410255 | validation loss: 0.0039248080513960264
Epoch: 4752, trainingloss: 0.003494048300329365 | validation loss: 0.0039002774924134856
Epoch: 4753, trainingloss: 0.00391360502619025 | validation loss: 0.00425521061435173
Epoch: 4754, trainingloss: 0.0038935549278623647 | validation loss: 0.004239567599040068
Epoch: 4755, trainingloss: 0.0035463684310454496 | validation loss: 0.00389794863257494
Epoch: 4756, trainingloss: 0.004055097818689123 | validation loss: 0.004412367551461246
Epoch: 4757, trainingloss: 0.003227402737779194 | validation loss: 0.0036256133521523296
Epoch: 4758, trainingloss: 0.0031939127745724636 | validation loss: 0.0036194789079707513
Epoch: 4759, trainingloss: 0.0033348506492899156 | validation loss: 0.0037416502648873837
Epoch: 4760, trainingloss: 0.003158824624308775 | validation loss: 0.003543113229211085
Epoch: 4761, trainingloss: 0.004037269089646391 | validation loss: 0.004333880375451363
Epoch: 4762, trainingloss: 0.003941530920446398 | validation loss: 0.004259646795922204
Epoch: 4763, trainingloss: 0.003665053346714116 | validation loss: 0.0040394024530663415
Epoch: 4764, trainingloss: 0.0033416623616860717 | validation loss: 0.0037432065263802968
Epoch: 4765, trainingloss: 0.0037143737546536785 | validation loss: 0.004052901659452363
Epoch: 4766, trainingloss: 0.003903295534299123 | validation loss: 0.004256817575954911
Epoch: 4767, trainingloss: 0.003549987666257296 | validation loss: 0.003932138930195974
Epoch: 4768, trainingloss: 0.0034518528205261054 | validation loss: 0.0038450101785006082
Epoch: 4769, trainingloss: 0.0031569556131547066 | validation loss: 0.0035775345189456454
Epoch: 4770, trainingloss: 0.003632979346803149 | validation loss: 0.003982391699350653
Epoch: 4771, trainingloss: 0.003609955200684724 | validation loss: 0.0039697907606317815
Epoch: 4772, trainingloss: 0.003939628866573939 | validation loss: 0.0042641538334951615
Epoch: 4773, trainingloss: 0.004031615755435163 | validation loss: 0.004361272350090762
Epoch: 4774, trainingloss: 0.0036443366661555255 | validation loss: 0.004009925080194837
Epoch: 4775, trainingloss: 0.0038133820567569274 | validation loss: 0.004139058037764688
Epoch: 4776, trainingloss: 0.003479532878198378 | validation loss: 0.003869683978748246
Epoch: 4777, trainingloss: 0.0037439908565324188 | validation loss: 0.004108266695677781
Epoch: 4778, trainingloss: 0.0035799002508086816 | validation loss: 0.003956523065379566
Epoch: 4779, trainingloss: 0.003979300962179002 | validation loss: 0.004347281816238153
Epoch: 4780, trainingloss: 0.0033472091810230844 | validation loss: 0.0037325260199239756
Epoch: 4781, trainingloss: 0.004567638771450744 | validation loss: 0.004807566272852082
Epoch: 4782, trainingloss: 0.003477559191870844 | validation loss: 0.0038424323392410656
Epoch: 4783, trainingloss: 0.0034682821989634903 | validation loss: 0.003850139646033011
Epoch: 4784, trainingloss: 0.003339398555745977 | validation loss: 0.003730726514580052
Epoch: 4785, trainingloss: 0.003636309057159093 | validation loss: 0.004031086275485849
Epoch: 4786, trainingloss: 0.004762137446983841 | validation loss: 0.005045146914736871
Epoch: 4787, trainingloss: 0.003764604629654127 | validation loss: 0.004152304802865814
Epoch: 4788, trainingloss: 0.0038370697036780683 | validation loss: 0.004178210044829754
Epoch: 4789, trainingloss: 0.003248183086924942 | validation loss: 0.0036418863662097912
Epoch: 4790, trainingloss: 0.004018832964426357 | validation loss: 0.004403238530581743
Epoch: 4791, trainingloss: 0.0036491759817281924 | validation loss: 0.004024188633829859
Epoch: 4792, trainingloss: 0.0035214788140283046 | validation loss: 0.003916263876476983
Epoch: 4793, trainingloss: 0.0036634329713772004 | validation loss: 0.004026920225968009
Epoch: 4794, trainingloss: 0.0036448866890366645 | validation loss: 0.003979568537377408
Epoch: 4795, trainingloss: 0.004326818737847085 | validation loss: 0.004640614680262269
Epoch: 4796, trainingloss: 0.0037342228167207806 | validation loss: 0.004073699452043167
Epoch: 4797, trainingloss: 0.004185981463390049 | validation loss: 0.004494044563655849
Epoch: 4798, trainingloss: 0.0034813015896829292 | validation loss: 0.0038436945938240042
Epoch: 4799, trainingloss: 0.0031155289502004806 | validation loss: 0.003552765724105351
Epoch: 4800, trainingloss: 0.0034644521397278545 | validation loss: 0.0038384524488322925
Epoch: 4801, trainingloss: 0.0031509313467425193 | validation loss: 0.0035463720135842564
Epoch: 4802, trainingloss: 0.0038847751741806578 | validation loss: 0.00424161812918258
Epoch: 4803, trainingloss: 0.0034758967044967335 | validation loss: 0.00382794739091619
Epoch: 4804, trainingloss: 0.003794556208973691 | validation loss: 0.0041470514027569325
Epoch: 4805, trainingloss: 0.003405307240549773 | validation loss: 0.0038016485501216764
Epoch: 4806, trainingloss: 0.0034344094639419545 | validation loss: 0.0038220832797922397
Epoch: 4807, trainingloss: 0.003419326988992585 | validation loss: 0.003815646611242334
Epoch: 4808, trainingloss: 0.0036524288632473526 | validation loss: 0.004036285402384285
Epoch: 4809, trainingloss: 0.004205227084196623 | validation loss: 0.004508512255629922
Epoch: 4810, trainingloss: 0.0033729766462822367 | validation loss: 0.003792011059790585
Epoch: 4811, trainingloss: 0.0033796918697984913 | validation loss: 0.0037628581541435586
Epoch: 4812, trainingloss: 0.003796519010431109 | validation loss: 0.0041441965442196825
Epoch: 4813, trainingloss: 0.0034507463667947827 | validation loss: 0.0038185620809561612
Epoch: 4814, trainingloss: 0.0032909036077343936 | validation loss: 0.0036962795814532235
Epoch: 4815, trainingloss: 0.003331068427440043 | validation loss: 0.0037255431544566805
Epoch: 4816, trainingloss: 0.003979942104053022 | validation loss: 0.004286787344664861
Epoch: 4817, trainingloss: 0.003757732004809836 | validation loss: 0.004146765062596094
Epoch: 4818, trainingloss: 0.0035808990230847167 | validation loss: 0.003975880109019053
Epoch: 4819, trainingloss: 0.0031971099435726836 | validation loss: 0.0036175955131492765
Epoch: 4820, trainingloss: 0.003483358815309377 | validation loss: 0.003900884877002544
Epoch: 4821, trainingloss: 0.0035756428845271616 | validation loss: 0.003981470844163455
Epoch: 4822, trainingloss: 0.0035775422756079097 | validation loss: 0.0039442573350423615
Epoch: 4823, trainingloss: 0.003252271083829577 | validation loss: 0.0036442829433479787
Epoch: 4824, trainingloss: 0.003597380612234565 | validation loss: 0.0039670153859690405
Epoch: 4825, trainingloss: 0.0039028811898809287 | validation loss: 0.004218071412247467
Epoch: 4826, trainingloss: 0.0033918455314259108 | validation loss: 0.003751328368356901
Epoch: 4827, trainingloss: 0.0037821571389367735 | validation loss: 0.004099383551135842
Epoch: 4828, trainingloss: 0.0034188069781044953 | validation loss: 0.0037730955298369865
Epoch: 4829, trainingloss: 0.003748398050373185 | validation loss: 0.0040902041220219326
Epoch: 4830, trainingloss: 0.0032887214673086545 | validation loss: 0.0036779302571966275
Epoch: 4831, trainingloss: 0.003737082871621554 | validation loss: 0.004070419756645065
Epoch: 4832, trainingloss: 0.0032994510716406623 | validation loss: 0.003698612500722256
Epoch: 4833, trainingloss: 0.003344676399081112 | validation loss: 0.0037528718979359765
Epoch: 4834, trainingloss: 0.003771808198694014 | validation loss: 0.00413315754593504
Epoch: 4835, trainingloss: 0.003159727143004311 | validation loss: 0.0035833236978718972
Epoch: 4836, trainingloss: 0.0031270799947429526 | validation loss: 0.003533027855724137
Epoch: 4837, trainingloss: 0.0035243614776627376 | validation loss: 0.0038982895972413203
Epoch: 4838, trainingloss: 0.003784711527159508 | validation loss: 0.00409578235101767
Epoch: 4839, trainingloss: 0.003021752504708196 | validation loss: 0.0034315229141228115
Epoch: 4840, trainingloss: 0.003347515612263461 | validation loss: 0.003705328530600736
Epoch: 4841, trainingloss: 0.003346304986632204 | validation loss: 0.003749959023639203
Epoch: 4842, trainingloss: 0.003322726424109558 | validation loss: 0.003730201509782001
Epoch: 4843, trainingloss: 0.003519318042993873 | validation loss: 0.0038806530622763945
Epoch: 4844, trainingloss: 0.004127048447368758 | validation loss: 0.004447784233465642
Epoch: 4845, trainingloss: 0.003674530323189277 | validation loss: 0.004042610146249655
Epoch: 4846, trainingloss: 0.003481560423068461 | validation loss: 0.0038688198359076794
Epoch: 4847, trainingloss: 0.003529360463051509 | validation loss: 0.003905525672507835
Epoch: 4848, trainingloss: 0.003307198385050716 | validation loss: 0.0037008825143756093
Epoch: 4849, trainingloss: 0.0034411344305801416 | validation loss: 0.003854234115610258
Epoch: 4850, trainingloss: 0.0033284679511335256 | validation loss: 0.003714584572695092
Epoch: 4851, trainingloss: 0.0032858203153004807 | validation loss: 0.0036740095659538825
Epoch: 4852, trainingloss: 0.0034316938738572873 | validation loss: 0.0038023143725931675
Epoch: 4853, trainingloss: 0.003425683122869063 | validation loss: 0.003851543701051915
Epoch: 4854, trainingloss: 0.0035677409741427944 | validation loss: 0.003916138469425057
Epoch: 4855, trainingloss: 0.003662796478419687 | validation loss: 0.004001478698231522
Epoch: 4856, trainingloss: 0.0037362303457112007 | validation loss: 0.004085162789727085
Epoch: 4857, trainingloss: 0.0038735729573534583 | validation loss: 0.00422521799091325
Epoch: 4858, trainingloss: 0.003494530160102711 | validation loss: 0.0038755433228294324
Epoch: 4859, trainingloss: 0.0033737302573207555 | validation loss: 0.0037723703936556417
Epoch: 4860, trainingloss: 0.003819778873401445 | validation loss: 0.004198161085301745
Epoch: 4861, trainingloss: 0.003359798409918062 | validation loss: 0.003750758949260991
Epoch: 4862, trainingloss: 0.0034810607776141326 | validation loss: 0.0038581021319541576
Epoch: 4863, trainingloss: 0.003545540837083887 | validation loss: 0.003893352624335148
Epoch: 4864, trainingloss: 0.004403790303989012 | validation loss: 0.0046783951601470615
Epoch: 4865, trainingloss: 0.0035584371044404795 | validation loss: 0.003946472541380221
Epoch: 4866, trainingloss: 0.0032981291779456603 | validation loss: 0.003692292262782486
Epoch: 4867, trainingloss: 0.0031987485178443563 | validation loss: 0.003628318278359107
Epoch: 4868, trainingloss: 0.003592222705458201 | validation loss: 0.003963561883900644
Epoch: 4869, trainingloss: 0.003481149599046924 | validation loss: 0.0038640099938955365
Epoch: 4870, trainingloss: 0.0031220084562785795 | validation loss: 0.0035409154663886967
Epoch: 4871, trainingloss: 0.0034498305835389403 | validation loss: 0.0038048876254353397
Epoch: 4872, trainingloss: 0.0033155766885165135 | validation loss: 0.0037125512033840424
Epoch: 4873, trainingloss: 0.0034845091010607234 | validation loss: 0.003873930770349686
Epoch: 4874, trainingloss: 0.0033529688716004247 | validation loss: 0.003738381369606757
Epoch: 4875, trainingloss: 0.003746473121255994 | validation loss: 0.004091259252798335
Epoch: 4876, trainingloss: 0.0037387988695654316 | validation loss: 0.004092221226472109
Epoch: 4877, trainingloss: 0.0032888527806502936 | validation loss: 0.003701662319534742
Epoch: 4878, trainingloss: 0.0035941047582968622 | validation loss: 0.003934210466459881
Epoch: 4879, trainingloss: 0.003613130305483246 | validation loss: 0.003966170047239484
Epoch: 4880, trainingloss: 0.0033521613475023635 | validation loss: 0.0037413073428370454
Epoch: 4881, trainingloss: 0.0034872765744004227 | validation loss: 0.003855496813256434
Epoch: 4882, trainingloss: 0.003694540379138244 | validation loss: 0.004027019038758399
Epoch: 4883, trainingloss: 0.0033835841118749627 | validation loss: 0.0037678100459287707
Epoch: 4884, trainingloss: 0.0038237516413596267 | validation loss: 0.004170715563137392
Epoch: 4885, trainingloss: 0.0040345799919762155 | validation loss: 0.004371012817834759
Epoch: 4886, trainingloss: 0.0031960928239525457 | validation loss: 0.0036233731506508803
Epoch: 4887, trainingloss: 0.0034308109113236696 | validation loss: 0.0038145229113002318
Epoch: 4888, trainingloss: 0.003519544605532171 | validation loss: 0.003903815613527928
Epoch: 4889, trainingloss: 0.0039629480853743924 | validation loss: 0.004276360081915098
Epoch: 4890, trainingloss: 0.004403777445050383 | validation loss: 0.004724731665264077
Epoch: 4891, trainingloss: 0.003996968547285563 | validation loss: 0.004326160363616554
Epoch: 4892, trainingloss: 0.003634448529888013 | validation loss: 0.0039613071135170186
Epoch: 4893, trainingloss: 0.003986248294126861 | validation loss: 0.004311688962470495
Epoch: 4894, trainingloss: 0.003267816838821993 | validation loss: 0.003671542516598822
Epoch: 4895, trainingloss: 0.00339218295266916 | validation loss: 0.0037755768023381604
Epoch: 4896, trainingloss: 0.003753424062284516 | validation loss: 0.004095877115795587
Epoch: 4897, trainingloss: 0.003907681050669486 | validation loss: 0.0042462758001402725
Epoch: 4898, trainingloss: 0.0034880582487409177 | validation loss: 0.003865767221517052
Epoch: 4899, trainingloss: 0.0036934237212928552 | validation loss: 0.004060154554053823
Epoch: 4900, trainingloss: 0.0034357732021505867 | validation loss: 0.0038347444751804347
Epoch: 4901, trainingloss: 0.0035810275676901745 | validation loss: 0.003934508432555953
Epoch: 4902, trainingloss: 0.0032269222911066775 | validation loss: 0.0036249801399974445
Epoch: 4903, trainingloss: 0.003525406669625926 | validation loss: 0.0038882939520035707
Epoch: 4904, trainingloss: 0.003423857138528703 | validation loss: 0.003783412081146624
Epoch: 4905, trainingloss: 0.003564885369136448 | validation loss: 0.003938347496331706
Epoch: 4906, trainingloss: 0.0033326254543386 | validation loss: 0.003712890105973348
Epoch: 4907, trainingloss: 0.0033935441292709634 | validation loss: 0.0037927386466249866
Epoch: 4908, trainingloss: 0.003484834642199816 | validation loss: 0.0038697811450747167
Epoch: 4909, trainingloss: 0.004259541876192615 | validation loss: 0.004551717108283947
Epoch: 4910, trainingloss: 0.00363713941634505 | validation loss: 0.0039678520757920254
Epoch: 4911, trainingloss: 0.004116569709882042 | validation loss: 0.0044666810400605115
Epoch: 4912, trainingloss: 0.0032513236782944384 | validation loss: 0.003671082401041644
Epoch: 4913, trainingloss: 0.0033216058233659844 | validation loss: 0.003724312244172039
Epoch: 4914, trainingloss: 0.003463906487365577 | validation loss: 0.003808760904586127
Epoch: 4915, trainingloss: 0.0032608207007846254 | validation loss: 0.0036188699514213304
Epoch: 4916, trainingloss: 0.003164625713214475 | validation loss: 0.0035605363941680606
Epoch: 4917, trainingloss: 0.0038403218717818575 | validation loss: 0.004199280883406207
Epoch: 4918, trainingloss: 0.0034504707671463236 | validation loss: 0.0038346706741778282
Epoch: 4919, trainingloss: 0.003449301270005671 | validation loss: 0.0038301844760961993
Epoch: 4920, trainingloss: 0.002997151273291488 | validation loss: 0.003453333256394767
Epoch: 4921, trainingloss: 0.0036379343098321983 | validation loss: 0.00401462375332402
Epoch: 4922, trainingloss: 0.004109240754030152 | validation loss: 0.004405197966920938
Epoch: 4923, trainingloss: 0.003826057792927712 | validation loss: 0.004181550155947757
Epoch: 4924, trainingloss: 0.004060014296298636 | validation loss: 0.004365716475014372
Epoch: 4925, trainingloss: 0.0032897922603987288 | validation loss: 0.003682269584889153
Epoch: 4926, trainingloss: 0.003554307375000484 | validation loss: 0.00393275117706448
Epoch: 4927, trainingloss: 0.004055025145367032 | validation loss: 0.004352004241338406
Epoch: 4928, trainingloss: 0.0038464284166171516 | validation loss: 0.004208540495524937
Epoch: 4929, trainingloss: 0.003446050856066887 | validation loss: 0.003838357466526318
Epoch: 4930, trainingloss: 0.0036015069185047566 | validation loss: 0.003993281309983384
Epoch: 4931, trainingloss: 0.003971408934225623 | validation loss: 0.004279905993565048
Epoch: 4932, trainingloss: 0.003148899886522226 | validation loss: 0.0035777683120477577
Epoch: 4933, trainingloss: 0.0032648974579573193 | validation loss: 0.003645975527334712
Epoch: 4934, trainingloss: 0.0038965281103886568 | validation loss: 0.004254206427717026
Epoch: 4935, trainingloss: 0.00404102807863909 | validation loss: 0.004363989355132857
Epoch: 4936, trainingloss: 0.003378520217824173 | validation loss: 0.0037775183804247404
Epoch: 4937, trainingloss: 0.0031424189276366243 | validation loss: 0.0035760041690036113
Epoch: 4938, trainingloss: 0.003971576562369855 | validation loss: 0.004292950102314199
Epoch: 4939, trainingloss: 0.003582752890166425 | validation loss: 0.0039744140479348634
Epoch: 4940, trainingloss: 0.0034175298872981628 | validation loss: 0.0038098611335980487
Epoch: 4941, trainingloss: 0.003990735622302547 | validation loss: 0.004355039641176857
Epoch: 4942, trainingloss: 0.003157280376760658 | validation loss: 0.0035811414663266795
Epoch: 4943, trainingloss: 0.0036643975819034324 | validation loss: 0.004034029749280426
Epoch: 4944, trainingloss: 0.0030700575324150207 | validation loss: 0.00347424262951087
Epoch: 4945, trainingloss: 0.003790710257429322 | validation loss: 0.004145783337419164
Epoch: 4946, trainingloss: 0.003907834221065743 | validation loss: 0.004239258808802291
Epoch: 4947, trainingloss: 0.00408617885296589 | validation loss: 0.00439188506463589
Epoch: 4948, trainingloss: 0.0033040941349862236 | validation loss: 0.0037332360775336583
Epoch: 4949, trainingloss: 0.00333591103127938 | validation loss: 0.0037182156202081886
Epoch: 4950, trainingloss: 0.0032754561687327885 | validation loss: 0.00366541715036033
Epoch: 4951, trainingloss: 0.004201061813181995 | validation loss: 0.004542862425964311
Epoch: 4952, trainingloss: 0.003354597259171419 | validation loss: 0.0037327326706470486
Epoch: 4953, trainingloss: 0.0031529200147619374 | validation loss: 0.0035770059277983905
Epoch: 4954, trainingloss: 0.003244899956427568 | validation loss: 0.0036768258769326037
Epoch: 4955, trainingloss: 0.0032542782225734967 | validation loss: 0.0036767337256572645
Epoch: 4956, trainingloss: 0.00353873204704624 | validation loss: 0.003994159908168011
Epoch: 4957, trainingloss: 0.00421646397935866 | validation loss: 0.004518382924033069
Epoch: 4958, trainingloss: 0.003436052489412543 | validation loss: 0.003822762869553381
Epoch: 4959, trainingloss: 0.0033791305759258775 | validation loss: 0.0037672444842515346
Epoch: 4960, trainingloss: 0.0032521360773984987 | validation loss: 0.003657240716278951
Epoch: 4961, trainingloss: 0.0038626233870969343 | validation loss: 0.0041850755907504094
Epoch: 4962, trainingloss: 0.003276523297329483 | validation loss: 0.0036826206638155994
Epoch: 4963, trainingloss: 0.0038967769847707027 | validation loss: 0.004248057013757673
Epoch: 4964, trainingloss: 0.003799396272800797 | validation loss: 0.004160811852785675
Epoch: 4965, trainingloss: 0.0034931640814105003 | validation loss: 0.0038435057937221268
Epoch: 4966, trainingloss: 0.003582830305020982 | validation loss: 0.003940604180501037
Epoch: 4967, trainingloss: 0.003473015145950024 | validation loss: 0.0038445771245719206
Epoch: 4968, trainingloss: 0.0029963526718452763 | validation loss: 0.003440756966413157
Epoch: 4969, trainingloss: 0.0033823883357597226 | validation loss: 0.0037456797098078354
Epoch: 4970, trainingloss: 0.0033688801844001803 | validation loss: 0.003715838603852346
Epoch: 4971, trainingloss: 0.0037850086079916855 | validation loss: 0.004099093657667926
Epoch: 4972, trainingloss: 0.0034865451279219853 | validation loss: 0.0038586382517310854
Epoch: 4973, trainingloss: 0.0038388962060437663 | validation loss: 0.004185522646283714
Epoch: 4974, trainingloss: 0.003725271383136649 | validation loss: 0.004099645460863657
Epoch: 4975, trainingloss: 0.0034371685057935524 | validation loss: 0.003836402712825796
Epoch: 4976, trainingloss: 0.003198408318999124 | validation loss: 0.003629168955760602
Epoch: 4977, trainingloss: 0.003695444570201274 | validation loss: 0.004084829771111448
Epoch: 4978, trainingloss: 0.0031958659448247675 | validation loss: 0.0036163020402622203
Epoch: 4979, trainingloss: 0.003387354679249876 | validation loss: 0.0038138106836411376
Epoch: 4980, trainingloss: 0.003675512979049289 | validation loss: 0.0040035671828093766
Epoch: 4981, trainingloss: 0.0036462648659500788 | validation loss: 0.0039910917988376015
Epoch: 4982, trainingloss: 0.0038060896920020467 | validation loss: 0.004169288492844976
Epoch: 4983, trainingloss: 0.003825807320240117 | validation loss: 0.004197157424541222
Epoch: 4984, trainingloss: 0.0034721932367877506 | validation loss: 0.0038365428234500344
Epoch: 4985, trainingloss: 0.0037788148691368646 | validation loss: 0.00414981900795386
Epoch: 4986, trainingloss: 0.003865182426388497 | validation loss: 0.004210311184540889
Epoch: 4987, trainingloss: 0.003266781650470074 | validation loss: 0.003668469199359383
Epoch: 4988, trainingloss: 0.003534382624015045 | validation loss: 0.0039122485676779065
Epoch: 4989, trainingloss: 0.0036560904475654906 | validation loss: 0.004028563902225862
Epoch: 4990, trainingloss: 0.0031372211121844726 | validation loss: 0.0035899562809992205
Epoch: 4991, trainingloss: 0.0037358995850270064 | validation loss: 0.004075436314145583
Epoch: 4992, trainingloss: 0.004001231397808583 | validation loss: 0.004338013822016381
Epoch: 4993, trainingloss: 0.0030346957804915997 | validation loss: 0.0034696172813385205
Epoch: 4994, trainingloss: 0.0036402493215207435 | validation loss: 0.004016178083603462
Epoch: 4995, trainingloss: 0.003654234612096592 | validation loss: 0.003989623076036088
Epoch: 4996, trainingloss: 0.003975710476798639 | validation loss: 0.004299029909888281
Epoch: 4997, trainingloss: 0.003295089509394455 | validation loss: 0.0037201283337252996
Epoch: 4998, trainingloss: 0.0035483563023679067 | validation loss: 0.0038996001949521343
Epoch: 4999, trainingloss: 0.003201728064240042 | validation loss: 0.0036223700250884432
Epoch: 5000, trainingloss: 0.0036572171907756287 | validation loss: 0.004053894196142821