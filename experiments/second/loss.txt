Smallest SV
Epoch: 0, trainingloss: 0.20162990887824708 | validation loss: 0.20076073539854028
Epoch: 1, trainingloss: 0.05595057486958578 | validation loss: 0.05582662376669428
Epoch: 2, trainingloss: 0.03917085732125989 | validation loss: 0.03943053912429872
Epoch: 3, trainingloss: 0.03320155975649454 | validation loss: 0.033722322241814026
Epoch: 4, trainingloss: 0.02930869212946551 | validation loss: 0.02966338946121292
Epoch: 5, trainingloss: 0.02793457261264025 | validation loss: 0.02826903359476063
Epoch: 6, trainingloss: 0.022774771512469524 | validation loss: 0.023230710230894198
Epoch: 7, trainingloss: 0.022962709193449584 | validation loss: 0.02333259909699554
Epoch: 8, trainingloss: 0.022516740118773214 | validation loss: 0.022916727089425055
Epoch: 9, trainingloss: 0.02183752135106674 | validation loss: 0.022236497976960652
Epoch: 10, trainingloss: 0.01717628995737505 | validation loss: 0.017399469770775746
Epoch: 11, trainingloss: 0.018561850279970118 | validation loss: 0.018921660299947907
Epoch: 12, trainingloss: 0.01687137828386978 | validation loss: 0.01714843766741326
Epoch: 13, trainingloss: 0.01493637873592103 | validation loss: 0.015416267875693961
Epoch: 14, trainingloss: 0.016200079955667725 | validation loss: 0.01659437461201299
Epoch: 15, trainingloss: 0.013492134488320352 | validation loss: 0.013875614929273854
Epoch: 16, trainingloss: 0.014364799322621007 | validation loss: 0.014686091154612387
Epoch: 17, trainingloss: 0.0130919152803045 | validation loss: 0.013492392039831071
Epoch: 18, trainingloss: 0.012878979165200576 | validation loss: 0.013230780157831128
Epoch: 19, trainingloss: 0.013852324919240927 | validation loss: 0.014265172792530128
Epoch: 20, trainingloss: 0.012383767049485855 | validation loss: 0.012762191912721705
Epoch: 21, trainingloss: 0.012418387758467368 | validation loss: 0.012881949571798848
Epoch: 22, trainingloss: 0.012192239384372437 | validation loss: 0.012598130881186994
Epoch: 23, trainingloss: 0.011240696105875463 | validation loss: 0.011590315247241995
Epoch: 24, trainingloss: 0.012577804042539787 | validation loss: 0.012854143727536254
Epoch: 25, trainingloss: 0.012293302405510654 | validation loss: 0.012690708859263692
Epoch: 26, trainingloss: 0.011368207921164242 | validation loss: 0.011611822437603057
Epoch: 27, trainingloss: 0.011689465881377018 | validation loss: 0.01197042544498288
Epoch: 28, trainingloss: 0.012636418305460029 | validation loss: 0.012925216384909746
Epoch: 29, trainingloss: 0.01077940238667743 | validation loss: 0.011212730673197155
Epoch: 30, trainingloss: 0.010328814828328673 | validation loss: 0.010721133106203968
Epoch: 31, trainingloss: 0.010586478287156581 | validation loss: 0.010876097172386414
Epoch: 32, trainingloss: 0.010338056594828912 | validation loss: 0.010717512320747068
Epoch: 33, trainingloss: 0.010521921613740845 | validation loss: 0.010902101402013215
Epoch: 34, trainingloss: 0.011145983930407785 | validation loss: 0.011484546710711828
Epoch: 35, trainingloss: 0.010231417409602227 | validation loss: 0.010592629556797243
Epoch: 36, trainingloss: 0.009853842998368148 | validation loss: 0.010213601912577605
Epoch: 37, trainingloss: 0.009101283716663829 | validation loss: 0.009423087259518615
Epoch: 38, trainingloss: 0.009280766650755936 | validation loss: 0.009669513039431647
Epoch: 39, trainingloss: 0.008976283380631058 | validation loss: 0.00944640581144304
Epoch: 40, trainingloss: 0.009414158808046191 | validation loss: 0.009704393245681196
Epoch: 41, trainingloss: 0.01079051626075574 | validation loss: 0.011127253498470461
Epoch: 42, trainingloss: 0.01027026798856487 | validation loss: 0.010605803298148078
Epoch: 43, trainingloss: 0.009050561308173338 | validation loss: 0.00953667801011701
Epoch: 44, trainingloss: 0.009535768115880628 | validation loss: 0.009978558120640591
Epoch: 45, trainingloss: 0.009170681753787357 | validation loss: 0.00949804264549593
Epoch: 46, trainingloss: 0.009916609300181397 | validation loss: 0.010301682749946835
Epoch: 47, trainingloss: 0.008790823885459025 | validation loss: 0.009246032033819912
Epoch: 48, trainingloss: 0.009008313052362717 | validation loss: 0.009419971738972334
Epoch: 49, trainingloss: 0.009105265684630168 | validation loss: 0.009467093174454386
Epoch: 50, trainingloss: 0.009772043544741683 | validation loss: 0.010197799043099854
Epoch: 51, trainingloss: 0.009931745591826939 | validation loss: 0.010347367517729062
Epoch: 52, trainingloss: 0.008459172461723943 | validation loss: 0.008915868717349371
Epoch: 53, trainingloss: 0.008750154175147486 | validation loss: 0.009241669005644717
Epoch: 54, trainingloss: 0.009077765602823827 | validation loss: 0.009613395349603237
Epoch: 55, trainingloss: 0.008949039654813548 | validation loss: 0.009345331214127065
Epoch: 56, trainingloss: 0.008533652878569942 | validation loss: 0.009030477575287825
Epoch: 57, trainingloss: 0.008734795396359499 | validation loss: 0.009100605282205845
Epoch: 58, trainingloss: 0.007933743793931263 | validation loss: 0.008454549119602375
Epoch: 59, trainingloss: 0.008548747085907166 | validation loss: 0.008990327301802605
Epoch: 60, trainingloss: 0.008177632494281446 | validation loss: 0.008645887684939707
Epoch: 61, trainingloss: 0.008301412915325644 | validation loss: 0.008819383101008788
Epoch: 62, trainingloss: 0.008313450788513895 | validation loss: 0.008707637967955567
Epoch: 63, trainingloss: 0.008845481477180669 | validation loss: 0.009342263261366193
Epoch: 64, trainingloss: 0.00912916888958882 | validation loss: 0.009617948463927018
Epoch: 65, trainingloss: 0.007859977094548987 | validation loss: 0.008341478725883644
Epoch: 66, trainingloss: 0.008170148080598676 | validation loss: 0.008605409117046728
Epoch: 67, trainingloss: 0.008200363506699294 | validation loss: 0.008616650183811334
Epoch: 68, trainingloss: 0.008410006298862351 | validation loss: 0.008869256370251079
Epoch: 69, trainingloss: 0.008528643220509885 | validation loss: 0.008907355056566089
Epoch: 70, trainingloss: 0.008184168597628386 | validation loss: 0.008616275759261601
Epoch: 71, trainingloss: 0.007380773791028413 | validation loss: 0.007851867000549797
Epoch: 72, trainingloss: 0.007325609627273238 | validation loss: 0.007858927534518861
Epoch: 73, trainingloss: 0.007623530444710107 | validation loss: 0.008063401879192121
Epoch: 74, trainingloss: 0.007987024177990083 | validation loss: 0.008396295344782864
Epoch: 75, trainingloss: 0.007994074541847857 | validation loss: 0.008421769031004457
Epoch: 76, trainingloss: 0.007409140976494813 | validation loss: 0.007844174088761391
Epoch: 77, trainingloss: 0.00795771830303446 | validation loss: 0.008355993347757298
Epoch: 78, trainingloss: 0.008439394657740804 | validation loss: 0.008832577865600762
Epoch: 79, trainingloss: 0.008103606834668802 | validation loss: 0.008478587657771826
Epoch: 80, trainingloss: 0.007575362347589752 | validation loss: 0.008061336847255702
Epoch: 81, trainingloss: 0.00688919205779683 | validation loss: 0.007389519539632488
Epoch: 82, trainingloss: 0.007602689238026738 | validation loss: 0.008027890020112267
Epoch: 83, trainingloss: 0.007325403011309263 | validation loss: 0.007772503869039029
Epoch: 84, trainingloss: 0.007810535714200762 | validation loss: 0.008208248678982307
Epoch: 85, trainingloss: 0.008374086735697284 | validation loss: 0.008864969996404596
Epoch: 86, trainingloss: 0.00752144164446199 | validation loss: 0.007950112167207661
Epoch: 87, trainingloss: 0.006933240669502682 | validation loss: 0.007422798864615697
Epoch: 88, trainingloss: 0.007587655726334503 | validation loss: 0.008041668642942805
Epoch: 89, trainingloss: 0.007142206561957838 | validation loss: 0.007588288617092479
Epoch: 90, trainingloss: 0.0075040524836590084 | validation loss: 0.00796035571489071
Epoch: 91, trainingloss: 0.0069530182478737485 | validation loss: 0.007431127847046517
Epoch: 92, trainingloss: 0.008484451303073747 | validation loss: 0.008972958088853589
Epoch: 93, trainingloss: 0.0074622703906604216 | validation loss: 0.00794899408264504
Epoch: 94, trainingloss: 0.0073769289371211815 | validation loss: 0.007858692902646817
Epoch: 95, trainingloss: 0.007680460403907723 | validation loss: 0.008111061549176108
Epoch: 96, trainingloss: 0.006535843522598887 | validation loss: 0.007081006117154977
Epoch: 97, trainingloss: 0.007203022662943531 | validation loss: 0.007638942859954331
Epoch: 98, trainingloss: 0.006647294220185249 | validation loss: 0.0071791035164072755
Epoch: 99, trainingloss: 0.008164483737189462 | validation loss: 0.008567533896018751
Epoch: 100, trainingloss: 0.007336578499436118 | validation loss: 0.0077943845822063505
Epoch: 101, trainingloss: 0.007701212816284535 | validation loss: 0.008080702848450735
Epoch: 102, trainingloss: 0.0066614569671750385 | validation loss: 0.007156246401210342
Epoch: 103, trainingloss: 0.006922238933383869 | validation loss: 0.0074009489473756684
Epoch: 104, trainingloss: 0.006616239095802473 | validation loss: 0.007072836916439826
Epoch: 105, trainingloss: 0.006283867859877233 | validation loss: 0.006781454450992439
Epoch: 106, trainingloss: 0.006343434692578489 | validation loss: 0.006812913493882732
Epoch: 107, trainingloss: 0.0064816434622149725 | validation loss: 0.006962912465123469
Epoch: 108, trainingloss: 0.007154427605022157 | validation loss: 0.007544689025434544
Epoch: 109, trainingloss: 0.007142439161361818 | validation loss: 0.0076035461832287665
Epoch: 110, trainingloss: 0.006688270482245334 | validation loss: 0.007135715829937579
Epoch: 111, trainingloss: 0.006461331554473452 | validation loss: 0.006924906080130586
Epoch: 112, trainingloss: 0.006777156773851359 | validation loss: 0.0071990715132023535
Epoch: 113, trainingloss: 0.006578688089124603 | validation loss: 0.0070291895891258435
Epoch: 114, trainingloss: 0.006910014138875484 | validation loss: 0.0073254547758987995
Epoch: 115, trainingloss: 0.007003125191832552 | validation loss: 0.007417132348099456
Epoch: 116, trainingloss: 0.006508348759798794 | validation loss: 0.006976916768864007
Epoch: 117, trainingloss: 0.006225316601713586 | validation loss: 0.006658117991203913
Epoch: 118, trainingloss: 0.006982348907182996 | validation loss: 0.007437334978051486
Epoch: 119, trainingloss: 0.006562468986037547 | validation loss: 0.006989502425276833
Epoch: 120, trainingloss: 0.006566551302333508 | validation loss: 0.007041279232314551
Epoch: 121, trainingloss: 0.006381476113044698 | validation loss: 0.006855700361743789
Epoch: 122, trainingloss: 0.006348758535330797 | validation loss: 0.0068010624128488385
Epoch: 123, trainingloss: 0.006569097269107817 | validation loss: 0.007000321666876783
Epoch: 124, trainingloss: 0.006196069659644389 | validation loss: 0.006653936185080866
Epoch: 125, trainingloss: 0.0063200228545022465 | validation loss: 0.0067583587045791605
Epoch: 126, trainingloss: 0.006500177044008862 | validation loss: 0.006951923021533131
Epoch: 127, trainingloss: 0.006236315734072754 | validation loss: 0.006708174546747054
Epoch: 128, trainingloss: 0.006049627603673515 | validation loss: 0.006462514904114844
Epoch: 129, trainingloss: 0.006169748351413904 | validation loss: 0.006694616423716438
Epoch: 130, trainingloss: 0.00646171349185481 | validation loss: 0.006923076688346834
Epoch: 131, trainingloss: 0.0064077175037406875 | validation loss: 0.006814945106066372
Epoch: 132, trainingloss: 0.006441593891578128 | validation loss: 0.006880244455630724
Epoch: 133, trainingloss: 0.006286820052854345 | validation loss: 0.006758892076091055
Epoch: 134, trainingloss: 0.006005619327168736 | validation loss: 0.006501666850998852
Epoch: 135, trainingloss: 0.005989343312320386 | validation loss: 0.006516936607846594
Epoch: 136, trainingloss: 0.005876486747825873 | validation loss: 0.0064103823426452265
Epoch: 137, trainingloss: 0.006488966259526487 | validation loss: 0.006882132762584117
Epoch: 138, trainingloss: 0.006186091864120845 | validation loss: 0.006619244082411601
Epoch: 139, trainingloss: 0.00659097709316038 | validation loss: 0.007061402857492757
Epoch: 140, trainingloss: 0.006137588800280893 | validation loss: 0.00661938352884791
Epoch: 141, trainingloss: 0.007007857057535154 | validation loss: 0.007496074782100491
Epoch: 142, trainingloss: 0.006410676589671023 | validation loss: 0.006842414308975019
Epoch: 143, trainingloss: 0.006199694334266095 | validation loss: 0.006670760095694953
Epoch: 144, trainingloss: 0.006962206249142099 | validation loss: 0.007404864371338392
Epoch: 145, trainingloss: 0.006246824790466108 | validation loss: 0.006742858505319829
Epoch: 146, trainingloss: 0.0061093782055300265 | validation loss: 0.006591045427315229
Epoch: 147, trainingloss: 0.006253598979054955 | validation loss: 0.006707613991541359
Epoch: 148, trainingloss: 0.005930214680555464 | validation loss: 0.006407017655885275
Epoch: 149, trainingloss: 0.005970383291242073 | validation loss: 0.0064560180892740335
Epoch: 150, trainingloss: 0.006020110606778051 | validation loss: 0.006483614859756912
Epoch: 151, trainingloss: 0.0062002361792918926 | validation loss: 0.006631358077963225
Epoch: 152, trainingloss: 0.005628856724487463 | validation loss: 0.006117838823831908
Epoch: 153, trainingloss: 0.005907081261229296 | validation loss: 0.006421057429953217
Epoch: 154, trainingloss: 0.005944092987131594 | validation loss: 0.006439094879744391
Epoch: 155, trainingloss: 0.00581448615745146 | validation loss: 0.006328283328158659
Epoch: 156, trainingloss: 0.005720474012326212 | validation loss: 0.00619456748635067
Epoch: 157, trainingloss: 0.0070073081184341465 | validation loss: 0.00744434030740128
Epoch: 158, trainingloss: 0.00594628144376286 | validation loss: 0.006425420887255532
Epoch: 159, trainingloss: 0.0057223205338130115 | validation loss: 0.006168693401957294
Epoch: 160, trainingloss: 0.005790749894251601 | validation loss: 0.006271225599691826
Epoch: 161, trainingloss: 0.006221692934313225 | validation loss: 0.006705461127590044
Epoch: 162, trainingloss: 0.0060032353425615356 | validation loss: 0.0064267575350981775
Epoch: 163, trainingloss: 0.005937461601083617 | validation loss: 0.0064174521938829285
Epoch: 164, trainingloss: 0.005629454786204262 | validation loss: 0.0061126697565539075
Epoch: 165, trainingloss: 0.00596918606988541 | validation loss: 0.006413019564921539
Epoch: 166, trainingloss: 0.005948517999170649 | validation loss: 0.0064403951432765606
Epoch: 167, trainingloss: 0.00589193273587492 | validation loss: 0.006384746912734307
Epoch: 168, trainingloss: 0.00535277826552304 | validation loss: 0.005896574248851936
Epoch: 169, trainingloss: 0.006186882561633726 | validation loss: 0.006603122817814119
Epoch: 170, trainingloss: 0.006305031517947141 | validation loss: 0.006757336485542967
Epoch: 171, trainingloss: 0.005918583030743478 | validation loss: 0.006413652797166691
Epoch: 172, trainingloss: 0.0057947543351343 | validation loss: 0.00624505924511066
Epoch: 173, trainingloss: 0.005506149436419037 | validation loss: 0.00600717229883952
Epoch: 174, trainingloss: 0.005960334719694513 | validation loss: 0.006415881613027881
Epoch: 175, trainingloss: 0.006142786921291938 | validation loss: 0.006595466490630414
Epoch: 176, trainingloss: 0.006063192621368873 | validation loss: 0.006553061433314717
Epoch: 177, trainingloss: 0.005951052916806014 | validation loss: 0.0063723168099405585
Epoch: 178, trainingloss: 0.005618863577801149 | validation loss: 0.006113667266882743
Epoch: 179, trainingloss: 0.005872731606408294 | validation loss: 0.006345739346704458
Epoch: 180, trainingloss: 0.005667901094763367 | validation loss: 0.006184142568709106
Epoch: 181, trainingloss: 0.005900382650366444 | validation loss: 0.0063572813322307145
Epoch: 182, trainingloss: 0.006209542734303776 | validation loss: 0.006642254463986934
Epoch: 183, trainingloss: 0.005796375980982117 | validation loss: 0.00629540730061436
Epoch: 184, trainingloss: 0.006190683786089509 | validation loss: 0.006625219721668677
Epoch: 185, trainingloss: 0.0054886833889465836 | validation loss: 0.005961236505430835
Epoch: 186, trainingloss: 0.006136379302040426 | validation loss: 0.006536219414443994
Epoch: 187, trainingloss: 0.006581923000661336 | validation loss: 0.0069649484720948705
Epoch: 188, trainingloss: 0.0057492588330194565 | validation loss: 0.00616170064758411
Epoch: 189, trainingloss: 0.005636287168820107 | validation loss: 0.006137221957352158
Epoch: 190, trainingloss: 0.0059206201874054685 | validation loss: 0.006347921895867509
Epoch: 191, trainingloss: 0.005709368307312807 | validation loss: 0.006209211254680361
Epoch: 192, trainingloss: 0.006001516647842049 | validation loss: 0.006433453104390071
Epoch: 193, trainingloss: 0.005964438434428229 | validation loss: 0.006434289692853702
Epoch: 194, trainingloss: 0.006143111805200183 | validation loss: 0.006575643785733037
Epoch: 195, trainingloss: 0.0056196762238106554 | validation loss: 0.006093935535062718
Epoch: 196, trainingloss: 0.005276456763079614 | validation loss: 0.005769128935468616
Epoch: 197, trainingloss: 0.00590552110037365 | validation loss: 0.00634029532781722
Epoch: 198, trainingloss: 0.006243679476187587 | validation loss: 0.006646450711400233
Epoch: 199, trainingloss: 0.005381626829212513 | validation loss: 0.005850347024293855
Epoch: 200, trainingloss: 0.0064783483449080866 | validation loss: 0.006913763370861213
Epoch: 201, trainingloss: 0.006007130221199397 | validation loss: 0.0064567273349479155
Epoch: 202, trainingloss: 0.006033201825711394 | validation loss: 0.006498780743710566
Epoch: 203, trainingloss: 0.005769582009168063 | validation loss: 0.006240365277599021
Epoch: 204, trainingloss: 0.006574598383111234 | validation loss: 0.006992383082250737
Epoch: 205, trainingloss: 0.005628682140190463 | validation loss: 0.006095830366501188
Epoch: 206, trainingloss: 0.005319464107894552 | validation loss: 0.005804983923915136
Epoch: 207, trainingloss: 0.005879360571929374 | validation loss: 0.006323968075559888
Epoch: 208, trainingloss: 0.00523021576269233 | validation loss: 0.0056984593943163065
Epoch: 209, trainingloss: 0.0057569997365214875 | validation loss: 0.006181092145942229
Epoch: 210, trainingloss: 0.0059313207849498685 | validation loss: 0.006367605320325379
Epoch: 211, trainingloss: 0.006527083464304539 | validation loss: 0.006934361231704908
Epoch: 212, trainingloss: 0.005403043326132266 | validation loss: 0.0058689100327598285
Epoch: 213, trainingloss: 0.006163499095514312 | validation loss: 0.006565084736783703
Epoch: 214, trainingloss: 0.005175756364578956 | validation loss: 0.005693916402007617
Epoch: 215, trainingloss: 0.00572876136686405 | validation loss: 0.006176162619760686
Epoch: 216, trainingloss: 0.005974967440662454 | validation loss: 0.006398507557986414
Epoch: 217, trainingloss: 0.006148945775538713 | validation loss: 0.006596893251957226
Epoch: 218, trainingloss: 0.005496220371887321 | validation loss: 0.0059628845615677505
Epoch: 219, trainingloss: 0.005568413026687807 | validation loss: 0.006011639916672142
Epoch: 220, trainingloss: 0.005258215545124325 | validation loss: 0.005748198280907922
Epoch: 221, trainingloss: 0.005900507115317431 | validation loss: 0.0063627437100606315
Epoch: 222, trainingloss: 0.005491703086856078 | validation loss: 0.005996903262345066
Epoch: 223, trainingloss: 0.006011630200134681 | validation loss: 0.006476784465240874
Epoch: 224, trainingloss: 0.005328466920141132 | validation loss: 0.005802746614148645
Epoch: 225, trainingloss: 0.005869480860255218 | validation loss: 0.0063327256545764226
Epoch: 226, trainingloss: 0.0060775230401627295 | validation loss: 0.0065487767438405
Epoch: 227, trainingloss: 0.005495351056906659 | validation loss: 0.005966252391499278
Epoch: 228, trainingloss: 0.005872178415667146 | validation loss: 0.0063481170720884805
Epoch: 229, trainingloss: 0.006093211288708804 | validation loss: 0.006562306960041238
Epoch: 230, trainingloss: 0.0062728507876840985 | validation loss: 0.006701407171558534
Epoch: 231, trainingloss: 0.00610073374615653 | validation loss: 0.0065376198282373595
Epoch: 232, trainingloss: 0.006370302389834287 | validation loss: 0.006827319168077631
Epoch: 233, trainingloss: 0.005775721123179974 | validation loss: 0.006260187014434545
Epoch: 234, trainingloss: 0.005483851075599101 | validation loss: 0.005959331722776049
Epoch: 235, trainingloss: 0.005601812074980884 | validation loss: 0.0060657814353912935
Epoch: 236, trainingloss: 0.005426062421024747 | validation loss: 0.0059132901332454154
Epoch: 237, trainingloss: 0.004997360878255382 | validation loss: 0.005496486234466994
Epoch: 238, trainingloss: 0.005978752449440959 | validation loss: 0.006428974243696372
Epoch: 239, trainingloss: 0.005350891691255832 | validation loss: 0.0058527165030443015
Epoch: 240, trainingloss: 0.006031481414777674 | validation loss: 0.0064742846508662666
Epoch: 241, trainingloss: 0.00641406873501451 | validation loss: 0.00685350170459013
Epoch: 242, trainingloss: 0.005670272955165009 | validation loss: 0.006090860100095485
Epoch: 243, trainingloss: 0.005067041817995996 | validation loss: 0.005571801524783015
Epoch: 244, trainingloss: 0.005460737770717334 | validation loss: 0.005926810275715232
Epoch: 245, trainingloss: 0.005301085149115525 | validation loss: 0.00580191220830404
Epoch: 246, trainingloss: 0.005112005920629884 | validation loss: 0.005631103844298998
Epoch: 247, trainingloss: 0.0054099823558712195 | validation loss: 0.005918203669996774
Epoch: 248, trainingloss: 0.005301676881984697 | validation loss: 0.005807442398487005
Epoch: 249, trainingloss: 0.006058210114604256 | validation loss: 0.006515899604473936
Epoch: 250, trainingloss: 0.0052576608911623504 | validation loss: 0.005761885370268226
Epoch: 251, trainingloss: 0.005309654117619828 | validation loss: 0.0058008700838735
Epoch: 252, trainingloss: 0.005452830663937956 | validation loss: 0.005936027706144682
Epoch: 253, trainingloss: 0.0052303664713898345 | validation loss: 0.005733193194657237
Epoch: 254, trainingloss: 0.005816347700738236 | validation loss: 0.006290039809279451
Epoch: 255, trainingloss: 0.005482910560318954 | validation loss: 0.0059760293869038535
Epoch: 256, trainingloss: 0.0058358726035900995 | validation loss: 0.006323983753571782
Epoch: 257, trainingloss: 0.0054882453268247314 | validation loss: 0.005959838630817185
Epoch: 258, trainingloss: 0.0051720737359402715 | validation loss: 0.0056530729257187745
Epoch: 259, trainingloss: 0.005795773001150346 | validation loss: 0.006260210519069888
Epoch: 260, trainingloss: 0.006580519888341982 | validation loss: 0.0070218428259003485
Epoch: 261, trainingloss: 0.005483938329230985 | validation loss: 0.0059539804412499136
Epoch: 262, trainingloss: 0.005410500174783795 | validation loss: 0.005902234441132744
Epoch: 263, trainingloss: 0.00526580828970081 | validation loss: 0.00574354714039495
Epoch: 264, trainingloss: 0.00572733357082925 | validation loss: 0.006169598659004516
Epoch: 265, trainingloss: 0.005546807296739621 | validation loss: 0.006014470654915111
Epoch: 266, trainingloss: 0.005990441998436995 | validation loss: 0.006402255609843941
Epoch: 267, trainingloss: 0.005480525000484653 | validation loss: 0.005924932228258427
Epoch: 268, trainingloss: 0.005297573882809277 | validation loss: 0.005775232893456165
Epoch: 269, trainingloss: 0.005185760798334318 | validation loss: 0.0056088749560434135
Epoch: 270, trainingloss: 0.005190326056689213 | validation loss: 0.005720567733886078
Epoch: 271, trainingloss: 0.005111036099531061 | validation loss: 0.0056345458615644954
Epoch: 272, trainingloss: 0.005442038489509947 | validation loss: 0.005904387974811172
Epoch: 273, trainingloss: 0.00532812214006007 | validation loss: 0.005793032227144532
Epoch: 274, trainingloss: 0.005841144783001932 | validation loss: 0.006298953575333025
Epoch: 275, trainingloss: 0.005343623513949199 | validation loss: 0.005819248434530901
Epoch: 276, trainingloss: 0.005214795825741785 | validation loss: 0.005687463827636917
Epoch: 277, trainingloss: 0.006498438937743614 | validation loss: 0.006924979649342497
Epoch: 278, trainingloss: 0.00557446169654385 | validation loss: 0.0060299121727847745
Epoch: 279, trainingloss: 0.005244812836978251 | validation loss: 0.0057202781489424466
Epoch: 280, trainingloss: 0.005320291371117671 | validation loss: 0.0058298987764625184
Epoch: 281, trainingloss: 0.0056519707399711695 | validation loss: 0.0061242269856518735
Epoch: 282, trainingloss: 0.00569080133767515 | validation loss: 0.006105941046784194
Epoch: 283, trainingloss: 0.005165398474070943 | validation loss: 0.005703182942664971
Epoch: 284, trainingloss: 0.005490534072848562 | validation loss: 0.005978246328848346
Epoch: 285, trainingloss: 0.005388887725748614 | validation loss: 0.0058640306895717245
Epoch: 286, trainingloss: 0.005911251183712834 | validation loss: 0.00635251882784562
Epoch: 287, trainingloss: 0.005004896596162405 | validation loss: 0.005492555600768995
Epoch: 288, trainingloss: 0.005845053452780004 | validation loss: 0.006290176516284271
Epoch: 289, trainingloss: 0.0055817843426267544 | validation loss: 0.006003232485363413
Epoch: 290, trainingloss: 0.005281606777669771 | validation loss: 0.005759479105009953
Epoch: 291, trainingloss: 0.005776717161231846 | validation loss: 0.006212502854339189
Epoch: 292, trainingloss: 0.005320135579078622 | validation loss: 0.0058009580436979066
Epoch: 293, trainingloss: 0.005464003138376293 | validation loss: 0.005898373878857065
Epoch: 294, trainingloss: 0.004992235788551987 | validation loss: 0.005480053386340307
Epoch: 295, trainingloss: 0.005183189142743517 | validation loss: 0.005692725633551064
Epoch: 296, trainingloss: 0.00585591003453557 | validation loss: 0.0062612599565489615
Epoch: 297, trainingloss: 0.005484995654682962 | validation loss: 0.005890697557286089
Epoch: 298, trainingloss: 0.005293527430845471 | validation loss: 0.005729059068472687
Epoch: 299, trainingloss: 0.0055227845243450095 | validation loss: 0.00598283388913492
Epoch: 300, trainingloss: 0.005567474936590837 | validation loss: 0.005995243613816115
Epoch: 301, trainingloss: 0.005336901723754597 | validation loss: 0.005802535484847469
Epoch: 302, trainingloss: 0.005827878898119488 | validation loss: 0.006251670163702327
Epoch: 303, trainingloss: 0.0050527608966052144 | validation loss: 0.00554300494018154
Epoch: 304, trainingloss: 0.0051407840221865935 | validation loss: 0.005610435022809363
Epoch: 305, trainingloss: 0.004672940022094514 | validation loss: 0.005139196990228625
Epoch: 306, trainingloss: 0.00517664547670436 | validation loss: 0.005636420173733653
Epoch: 307, trainingloss: 0.005073562096659955 | validation loss: 0.0055204469006586675
Epoch: 308, trainingloss: 0.005276738277857828 | validation loss: 0.005662849020508586
Epoch: 309, trainingloss: 0.00460325705080705 | validation loss: 0.0051313642104470975
Epoch: 310, trainingloss: 0.00546034815404951 | validation loss: 0.005899909401424399
Epoch: 311, trainingloss: 0.004710129983282312 | validation loss: 0.005223031979545793
Epoch: 312, trainingloss: 0.004881121457873973 | validation loss: 0.00536190789784606
Epoch: 313, trainingloss: 0.005035490269257201 | validation loss: 0.005524446169260905
Epoch: 314, trainingloss: 0.004530014038639984 | validation loss: 0.005078383369470358
Epoch: 315, trainingloss: 0.005680438025728525 | validation loss: 0.006117558749262973
Epoch: 316, trainingloss: 0.0047858310515687605 | validation loss: 0.005311036548850521
Epoch: 317, trainingloss: 0.0054310759412238094 | validation loss: 0.005886723122953022
Epoch: 318, trainingloss: 0.006340735934042984 | validation loss: 0.00669341376380757
Epoch: 319, trainingloss: 0.005239848994347267 | validation loss: 0.005675143509890739
Epoch: 320, trainingloss: 0.00541329860207233 | validation loss: 0.005855203644916977
Epoch: 321, trainingloss: 0.004967870651573509 | validation loss: 0.00543652117847097
Epoch: 322, trainingloss: 0.005980148926320635 | validation loss: 0.006418768952672327
Epoch: 323, trainingloss: 0.0048572455922750194 | validation loss: 0.0053841877953234585
Epoch: 324, trainingloss: 0.004870623341390715 | validation loss: 0.0053325661099348776
Epoch: 325, trainingloss: 0.005285282893061715 | validation loss: 0.005753437617638911
Epoch: 326, trainingloss: 0.00474415808134708 | validation loss: 0.0052438235152153
Epoch: 327, trainingloss: 0.005076895106031137 | validation loss: 0.005530330045071666
Epoch: 328, trainingloss: 0.005256127127386023 | validation loss: 0.0056950544815307464
Epoch: 329, trainingloss: 0.004775574014286774 | validation loss: 0.0052647221034582085
Epoch: 330, trainingloss: 0.004863017193170059 | validation loss: 0.005374302413237278
Epoch: 331, trainingloss: 0.005173805650973507 | validation loss: 0.005669414896344464
Epoch: 332, trainingloss: 0.004782783399062403 | validation loss: 0.005253248045280356
Epoch: 333, trainingloss: 0.0052206707487706975 | validation loss: 0.005639846088192593
Epoch: 334, trainingloss: 0.0051947239699271465 | validation loss: 0.005630467962279793
Epoch: 335, trainingloss: 0.004898652937198828 | validation loss: 0.005389713706938382
Epoch: 336, trainingloss: 0.005484201556912431 | validation loss: 0.005934594846187431
Epoch: 337, trainingloss: 0.006121150219725579 | validation loss: 0.006532286058475113
Epoch: 338, trainingloss: 0.004983076216608248 | validation loss: 0.0054687954553269864
Epoch: 339, trainingloss: 0.0053709380469440906 | validation loss: 0.005820884449186334
Epoch: 340, trainingloss: 0.005156201721269056 | validation loss: 0.005605199227649128
Epoch: 341, trainingloss: 0.005579837114164069 | validation loss: 0.005998425815012182
Epoch: 342, trainingloss: 0.005463920368842428 | validation loss: 0.00592647827511432
Epoch: 343, trainingloss: 0.005413270089904151 | validation loss: 0.005821312130465432
Epoch: 344, trainingloss: 0.005290999058258848 | validation loss: 0.005756019579679978
Epoch: 345, trainingloss: 0.004842911535257589 | validation loss: 0.00532820678559965
Epoch: 346, trainingloss: 0.004849197672362863 | validation loss: 0.005276514610942964
Epoch: 347, trainingloss: 0.005534231294414087 | validation loss: 0.005966381285253739
Epoch: 348, trainingloss: 0.0052369573458863694 | validation loss: 0.005631074976887125
Epoch: 349, trainingloss: 0.005407854576804785 | validation loss: 0.0058530913454872355
Epoch: 350, trainingloss: 0.004992060850620455 | validation loss: 0.005447535610768358
Epoch: 351, trainingloss: 0.005334470106878792 | validation loss: 0.0057783273964219
Epoch: 352, trainingloss: 0.005019387897798186 | validation loss: 0.005480988264610636
Epoch: 353, trainingloss: 0.005299920166080332 | validation loss: 0.005728360486021455
Epoch: 354, trainingloss: 0.00486125846125572 | validation loss: 0.005327798200604982
Epoch: 355, trainingloss: 0.005076489757927443 | validation loss: 0.005576702144038278
Epoch: 356, trainingloss: 0.0051375630160955385 | validation loss: 0.005565194203217385
Epoch: 357, trainingloss: 0.004891752744800663 | validation loss: 0.005353272999640974
Epoch: 358, trainingloss: 0.005255047529537222 | validation loss: 0.005701166654610573
Epoch: 359, trainingloss: 0.004672944644903724 | validation loss: 0.005124115046652495
Epoch: 360, trainingloss: 0.004822868030756017 | validation loss: 0.005279358798462415
Epoch: 361, trainingloss: 0.004675867597233044 | validation loss: 0.005176129242485975
Epoch: 362, trainingloss: 0.004999090533901064 | validation loss: 0.005456986402465466
Epoch: 363, trainingloss: 0.004892527931732404 | validation loss: 0.005351124581370454
Epoch: 364, trainingloss: 0.005054904149468459 | validation loss: 0.005495137466783506
Epoch: 365, trainingloss: 0.0051544054157246465 | validation loss: 0.005607905919497626
Epoch: 366, trainingloss: 0.004737572505425876 | validation loss: 0.005226093085745656
Epoch: 367, trainingloss: 0.004974005735962143 | validation loss: 0.0054160966137119645
Epoch: 368, trainingloss: 0.004916424616709852 | validation loss: 0.005381204467974434
Epoch: 369, trainingloss: 0.005126045219638695 | validation loss: 0.005583912732872632
Epoch: 370, trainingloss: 0.004966458074992211 | validation loss: 0.005423863662693633
Epoch: 371, trainingloss: 0.00446534592162136 | validation loss: 0.005010343615031448
Epoch: 372, trainingloss: 0.005254129133295631 | validation loss: 0.0057060794702620075
Epoch: 373, trainingloss: 0.005154012820152722 | validation loss: 0.0055868976106549185
Epoch: 374, trainingloss: 0.005504377158962442 | validation loss: 0.005874289684696309
Epoch: 375, trainingloss: 0.005832651817745282 | validation loss: 0.006188988245348368
Epoch: 376, trainingloss: 0.004974046106582656 | validation loss: 0.005380444916658598
Epoch: 377, trainingloss: 0.004650847110470044 | validation loss: 0.00513448563503886
Epoch: 378, trainingloss: 0.0054769191508692505 | validation loss: 0.0059194268077708955
Epoch: 379, trainingloss: 0.005631956782618432 | validation loss: 0.006060903298715131
Epoch: 380, trainingloss: 0.005224694920499271 | validation loss: 0.005623987546307095
Epoch: 381, trainingloss: 0.005220129994431888 | validation loss: 0.005638811507654428
Epoch: 382, trainingloss: 0.005209201453591359 | validation loss: 0.005679884040504851
Epoch: 383, trainingloss: 0.0047473645743928705 | validation loss: 0.00523629732198085
Epoch: 384, trainingloss: 0.0049307719805471 | validation loss: 0.00539135329197837
Epoch: 385, trainingloss: 0.0050335451299339026 | validation loss: 0.00549561849316933
Epoch: 386, trainingloss: 0.0048901038407194305 | validation loss: 0.005353075499945673
Epoch: 387, trainingloss: 0.004835314777066124 | validation loss: 0.005304936727989613
Epoch: 388, trainingloss: 0.005162698389234932 | validation loss: 0.005602545276260149
Epoch: 389, trainingloss: 0.005135120060679855 | validation loss: 0.0055908187549611995
Epoch: 390, trainingloss: 0.004655860262133751 | validation loss: 0.00510706592249648
Epoch: 391, trainingloss: 0.004640164103506525 | validation loss: 0.005119718628335411
Epoch: 392, trainingloss: 0.004654697453988867 | validation loss: 0.005134002255911393
Epoch: 393, trainingloss: 0.005189222818851659 | validation loss: 0.005638844721352589
Epoch: 394, trainingloss: 0.0048947419670134305 | validation loss: 0.005364032164793929
Epoch: 395, trainingloss: 0.005178358525434925 | validation loss: 0.0056011860399771225
Epoch: 396, trainingloss: 0.005502667882976941 | validation loss: 0.005941777281919787
Epoch: 397, trainingloss: 0.005012951732116012 | validation loss: 0.005452977603022741
Epoch: 398, trainingloss: 0.005036059291436155 | validation loss: 0.005466480613702904
Epoch: 399, trainingloss: 0.004565842470526869 | validation loss: 0.00505916249629269
Epoch: 400, trainingloss: 0.004614070241501854 | validation loss: 0.00507413914516895
Epoch: 401, trainingloss: 0.004503563551233159 | validation loss: 0.0050050847863580515
Epoch: 402, trainingloss: 0.004946031471543847 | validation loss: 0.005418287152952509
Epoch: 403, trainingloss: 0.0048855125092216465 | validation loss: 0.005382605192262244
Epoch: 404, trainingloss: 0.005179811982972843 | validation loss: 0.005598046826228498
Epoch: 405, trainingloss: 0.0045982479369192095 | validation loss: 0.005087974967405235
Epoch: 406, trainingloss: 0.004615822150019352 | validation loss: 0.005109881091116791
Epoch: 407, trainingloss: 0.005589989191518403 | validation loss: 0.006025600402583278
Epoch: 408, trainingloss: 0.005455737942027163 | validation loss: 0.005893208811706815
Epoch: 409, trainingloss: 0.004695434697026668 | validation loss: 0.00514105709873553
Epoch: 410, trainingloss: 0.005017624183610335 | validation loss: 0.00544384607737962
Epoch: 411, trainingloss: 0.00492813285183917 | validation loss: 0.005372482682972669
Epoch: 412, trainingloss: 0.004743303781233685 | validation loss: 0.005178818488351173
Epoch: 413, trainingloss: 0.004717090525662063 | validation loss: 0.005163145215582753
Epoch: 414, trainingloss: 0.00489048338757463 | validation loss: 0.005320484816454311
Epoch: 415, trainingloss: 0.004840887737793855 | validation loss: 0.005292156871045318
Epoch: 416, trainingloss: 0.005453524920761667 | validation loss: 0.005866518106381815
Epoch: 417, trainingloss: 0.004740634167016672 | validation loss: 0.005197292966558647
Epoch: 418, trainingloss: 0.00475631472604955 | validation loss: 0.005224667786785202
Epoch: 419, trainingloss: 0.004886348626411114 | validation loss: 0.0053329679791022724
Epoch: 420, trainingloss: 0.004648079972335846 | validation loss: 0.0051521008491583215
Epoch: 421, trainingloss: 0.0049016961239131615 | validation loss: 0.00537047103354379
Epoch: 422, trainingloss: 0.004624617193887373 | validation loss: 0.0050750949894339745
Epoch: 423, trainingloss: 0.004954482836312951 | validation loss: 0.00538884141313347
Epoch: 424, trainingloss: 0.004901516094056555 | validation loss: 0.00529444942057695
Epoch: 425, trainingloss: 0.005424206089293428 | validation loss: 0.005822736068323924
Epoch: 426, trainingloss: 0.005009218644239121 | validation loss: 0.005423452381188596
Epoch: 427, trainingloss: 0.005067629743261811 | validation loss: 0.005461229203026912
Epoch: 428, trainingloss: 0.004820737896334256 | validation loss: 0.005264439281179611
Epoch: 429, trainingloss: 0.004830919169599227 | validation loss: 0.005268776213463059
Epoch: 430, trainingloss: 0.004529945877818531 | validation loss: 0.0049930662131572245
Epoch: 431, trainingloss: 0.00512342809002176 | validation loss: 0.005520232618040273
Epoch: 432, trainingloss: 0.004641192197170877 | validation loss: 0.005096569938972869
Epoch: 433, trainingloss: 0.004784079680577183 | validation loss: 0.005215592275236
Epoch: 434, trainingloss: 0.004632799229342357 | validation loss: 0.005098426257164661
Epoch: 435, trainingloss: 0.0044362876962052485 | validation loss: 0.004938220071803774
Epoch: 436, trainingloss: 0.005263439012301294 | validation loss: 0.005695021792355989
Epoch: 437, trainingloss: 0.0051768912514010505 | validation loss: 0.0056262631716202036
Epoch: 438, trainingloss: 0.005224876720152723 | validation loss: 0.00562590713005294
Epoch: 439, trainingloss: 0.004910987053653019 | validation loss: 0.005373437011445021
Epoch: 440, trainingloss: 0.004912289399232996 | validation loss: 0.005355534427100256
Epoch: 441, trainingloss: 0.0050261794627917255 | validation loss: 0.005486368069345298
Epoch: 442, trainingloss: 0.004359061752676191 | validation loss: 0.004852715827766888
Epoch: 443, trainingloss: 0.005032773606653961 | validation loss: 0.005475574138764355
Epoch: 444, trainingloss: 0.005153995904044842 | validation loss: 0.005582146150811125
Epoch: 445, trainingloss: 0.004626351338928797 | validation loss: 0.005065904198606377
Epoch: 446, trainingloss: 0.005152345040183252 | validation loss: 0.005602976618627923
Epoch: 447, trainingloss: 0.004565277338932569 | validation loss: 0.00503094525413827
Epoch: 448, trainingloss: 0.004393533262101942 | validation loss: 0.004842713961379382
Epoch: 449, trainingloss: 0.005072413238465093 | validation loss: 0.005487738485891427
Epoch: 450, trainingloss: 0.004646649036416626 | validation loss: 0.0051395448617082
Epoch: 451, trainingloss: 0.0046502451250791 | validation loss: 0.0051171120820470645
Epoch: 452, trainingloss: 0.004366459121848301 | validation loss: 0.004899435815422028
Epoch: 453, trainingloss: 0.004951007830562293 | validation loss: 0.0054031031141949515
Epoch: 454, trainingloss: 0.004596718968629912 | validation loss: 0.005056759479585027
Epoch: 455, trainingloss: 0.00541078441358842 | validation loss: 0.0058227003949316465
Epoch: 456, trainingloss: 0.004554119275029862 | validation loss: 0.0050302654259646385
Epoch: 457, trainingloss: 0.005339783949289034 | validation loss: 0.005729951872872234
Epoch: 458, trainingloss: 0.0051273556920608575 | validation loss: 0.005567695542829992
Epoch: 459, trainingloss: 0.0044579307479405555 | validation loss: 0.004922689685487584
Epoch: 460, trainingloss: 0.004588645016123843 | validation loss: 0.005055972908344718
Epoch: 461, trainingloss: 0.004698142961793404 | validation loss: 0.005159141787349599
Epoch: 462, trainingloss: 0.00501664637961576 | validation loss: 0.0054523948677017925
Epoch: 463, trainingloss: 0.004664148617860197 | validation loss: 0.005120323965354924
Epoch: 464, trainingloss: 0.004606837710061275 | validation loss: 0.0050859756295328976
Epoch: 465, trainingloss: 0.004737503601025961 | validation loss: 0.005214270618122363
Epoch: 466, trainingloss: 0.004640748900974653 | validation loss: 0.005097667453111612
Epoch: 467, trainingloss: 0.0045524637301509446 | validation loss: 0.005002270594720369
Epoch: 468, trainingloss: 0.005146291393863592 | validation loss: 0.005592031260630394
Epoch: 469, trainingloss: 0.00467540386502266 | validation loss: 0.005156301634960552
Epoch: 470, trainingloss: 0.004604117134225355 | validation loss: 0.005067964698505766
Epoch: 471, trainingloss: 0.004603094433702834 | validation loss: 0.005110855885552933
Epoch: 472, trainingloss: 0.005169552781153003 | validation loss: 0.005596782913265065
Epoch: 473, trainingloss: 0.0048913214815160715 | validation loss: 0.005287487099891728
Epoch: 474, trainingloss: 0.004941648041750381 | validation loss: 0.005386803849880678
Epoch: 475, trainingloss: 0.004596628180658811 | validation loss: 0.005045926834064971
Epoch: 476, trainingloss: 0.004705233946082653 | validation loss: 0.005144612628584865
Epoch: 477, trainingloss: 0.00496814187968259 | validation loss: 0.005349969216245946
Epoch: 478, trainingloss: 0.004575127317682562 | validation loss: 0.00503559345358337
Epoch: 479, trainingloss: 0.004706725187354609 | validation loss: 0.005171936940043744
Epoch: 480, trainingloss: 0.00509715721651222 | validation loss: 0.005491507360183816
Epoch: 481, trainingloss: 0.004722178381390883 | validation loss: 0.005173439868175476
Epoch: 482, trainingloss: 0.004836470251389586 | validation loss: 0.005272452759112649
Epoch: 483, trainingloss: 0.004387111185833114 | validation loss: 0.00483924621666364
Epoch: 484, trainingloss: 0.004780311734910638 | validation loss: 0.005209564524768534
Epoch: 485, trainingloss: 0.004353644231562161 | validation loss: 0.004856176193459395
Epoch: 486, trainingloss: 0.004611540769623717 | validation loss: 0.005079511946348838
Epoch: 487, trainingloss: 0.004732072147053327 | validation loss: 0.005159989150733336
Epoch: 488, trainingloss: 0.0047583038341070735 | validation loss: 0.005235306309116287
Epoch: 489, trainingloss: 0.0045785819918626874 | validation loss: 0.005019429922219206
Epoch: 490, trainingloss: 0.004910372147693179 | validation loss: 0.005311911318761019
Epoch: 491, trainingloss: 0.004740695921742789 | validation loss: 0.005185655264064734
Epoch: 492, trainingloss: 0.004476014874616947 | validation loss: 0.004944182542799567
Epoch: 493, trainingloss: 0.004702665945792818 | validation loss: 0.005139118173027714
Epoch: 494, trainingloss: 0.004740126509058443 | validation loss: 0.005193319620791398
Epoch: 495, trainingloss: 0.004875379448543229 | validation loss: 0.005332386271671029
Epoch: 496, trainingloss: 0.0047818416756447045 | validation loss: 0.005256604514192961
Epoch: 497, trainingloss: 0.00473293850402332 | validation loss: 0.005190442867002487
Epoch: 498, trainingloss: 0.004693375693968926 | validation loss: 0.005163824835403927
Epoch: 499, trainingloss: 0.004434542945005787 | validation loss: 0.004898597977643681
Epoch: 500, trainingloss: 0.004644266770468414 | validation loss: 0.005123848437238226
Epoch: 501, trainingloss: 0.004772943083708449 | validation loss: 0.0052274203913271955
Epoch: 502, trainingloss: 0.005000391781005559 | validation loss: 0.005449114326464175
Epoch: 503, trainingloss: 0.004690824652374984 | validation loss: 0.005132997869416215
Epoch: 504, trainingloss: 0.004463746107604582 | validation loss: 0.004911106340145703
Epoch: 505, trainingloss: 0.0046419502043680725 | validation loss: 0.005054542168169001
Epoch: 506, trainingloss: 0.00496211718432681 | validation loss: 0.005401795503858532
Epoch: 507, trainingloss: 0.004355967877621509 | validation loss: 0.004864442023711697
Epoch: 508, trainingloss: 0.005328204856293235 | validation loss: 0.0057119354609863
Epoch: 509, trainingloss: 0.0046301671572195864 | validation loss: 0.005064899359619345
Epoch: 510, trainingloss: 0.004709699913741971 | validation loss: 0.005163357781759382
Epoch: 511, trainingloss: 0.0044124687515902684 | validation loss: 0.004899710440177178
Epoch: 512, trainingloss: 0.0048639183056330085 | validation loss: 0.005281888630017717