All SV
Epoch: 0, trainingloss: 1.7562293881121427 | validation loss: 1.7520427667608514
Epoch: 1, trainingloss: 0.19790008834436615 | validation loss: 0.19663048345553338
Epoch: 2, trainingloss: 0.1552976486995082 | validation loss: 0.15519117698720536
Epoch: 3, trainingloss: 0.14003006177247715 | validation loss: 0.13964429901225453
Epoch: 4, trainingloss: 0.12738607810402455 | validation loss: 0.12721333421627581
Epoch: 5, trainingloss: 0.11872302051856609 | validation loss: 0.11880324072213434
Epoch: 6, trainingloss: 0.09854741724324863 | validation loss: 0.09931440721614657
Epoch: 7, trainingloss: 0.09824815109776762 | validation loss: 0.09917480684966413
Epoch: 8, trainingloss: 0.09102549636571713 | validation loss: 0.0918374553250124
Epoch: 9, trainingloss: 0.08539480477461801 | validation loss: 0.08660064142144323
Epoch: 10, trainingloss: 0.07914800032278217 | validation loss: 0.08033645246400929
Epoch: 11, trainingloss: 0.07484708603577259 | validation loss: 0.07603118438932145
Epoch: 12, trainingloss: 0.07571897501769485 | validation loss: 0.07661613159109427
Epoch: 13, trainingloss: 0.07040946679178212 | validation loss: 0.0713344329931527
Epoch: 14, trainingloss: 0.07032810622883547 | validation loss: 0.07114375668110577
Epoch: 15, trainingloss: 0.06082108958215922 | validation loss: 0.061738747175571734
Epoch: 16, trainingloss: 0.05697921631508584 | validation loss: 0.05786343967705169
Epoch: 17, trainingloss: 0.05772562363908119 | validation loss: 0.058419778150872535
Epoch: 18, trainingloss: 0.057184354842063544 | validation loss: 0.05796819954247419
Epoch: 19, trainingloss: 0.055921075029820806 | validation loss: 0.05671958667347742
Epoch: 20, trainingloss: 0.05025620050097093 | validation loss: 0.05101476926167594
Epoch: 21, trainingloss: 0.05178041308338441 | validation loss: 0.05259300789980589
Epoch: 22, trainingloss: 0.054260475392368675 | validation loss: 0.054958376024617
Epoch: 23, trainingloss: 0.04654872132341585 | validation loss: 0.047558604302509654
Epoch: 24, trainingloss: 0.04665450523046476 | validation loss: 0.0473494117882943
Epoch: 25, trainingloss: 0.04464618980169332 | validation loss: 0.0452899450498728
Epoch: 26, trainingloss: 0.04588772287725492 | validation loss: 0.04644126300394281
Epoch: 27, trainingloss: 0.04300104105310347 | validation loss: 0.043820694568816265
Epoch: 28, trainingloss: 0.04782161192104205 | validation loss: 0.04845174726914685
Epoch: 29, trainingloss: 0.04199136508507038 | validation loss: 0.04266203983221656
Epoch: 30, trainingloss: 0.04245605154828362 | validation loss: 0.04322983652700519
Epoch: 31, trainingloss: 0.041773580896367506 | validation loss: 0.042560898653784957
Epoch: 32, trainingloss: 0.03925530930508889 | validation loss: 0.03985132196722067
Epoch: 33, trainingloss: 0.03915146324296798 | validation loss: 0.0397905998792883
Epoch: 34, trainingloss: 0.03828023621425702 | validation loss: 0.038832729552019205
Epoch: 35, trainingloss: 0.04371707427359114 | validation loss: 0.04409406115372184
Epoch: 36, trainingloss: 0.04110906238029977 | validation loss: 0.04175660870771081
Epoch: 37, trainingloss: 0.03711160564840512 | validation loss: 0.037950335802596234
Epoch: 38, trainingloss: 0.038417302209304796 | validation loss: 0.039250206547998184
Epoch: 39, trainingloss: 0.03451273705914957 | validation loss: 0.03531562035614544
Epoch: 40, trainingloss: 0.038384098207431626 | validation loss: 0.03882921636908625
Epoch: 41, trainingloss: 0.03555212684321929 | validation loss: 0.03626453781482258
Epoch: 42, trainingloss: 0.035852553808939425 | validation loss: 0.03669999333279535
Epoch: 43, trainingloss: 0.03682283780307973 | validation loss: 0.03730814485175037
Epoch: 44, trainingloss: 0.035824111851641 | validation loss: 0.03645431168980594
Epoch: 45, trainingloss: 0.03602723232584203 | validation loss: 0.03663468234201528
Epoch: 46, trainingloss: 0.03346796926422838 | validation loss: 0.034113890150583595
Epoch: 47, trainingloss: 0.03774410699410752 | validation loss: 0.038304865490654524
Epoch: 48, trainingloss: 0.03204060800721752 | validation loss: 0.03286431138168427
Epoch: 49, trainingloss: 0.03422392735659028 | validation loss: 0.03483571490365322
Epoch: 50, trainingloss: 0.032812880864143995 | validation loss: 0.03349163000848266
Epoch: 51, trainingloss: 0.031198403807397277 | validation loss: 0.03185252976805397
Epoch: 52, trainingloss: 0.031206026636238993 | validation loss: 0.03177070488255025
Epoch: 53, trainingloss: 0.03251854089536622 | validation loss: 0.0332022641965144
Epoch: 54, trainingloss: 0.02900504162977071 | validation loss: 0.029712988606205887
Epoch: 55, trainingloss: 0.03494915297689689 | validation loss: 0.03554950141795892
Epoch: 56, trainingloss: 0.028926660775012044 | validation loss: 0.029789882947966372
Epoch: 57, trainingloss: 0.029856776674754792 | validation loss: 0.03052227207783535
Epoch: 58, trainingloss: 0.03397912671603879 | validation loss: 0.034592920774646506
Epoch: 59, trainingloss: 0.030521237353988602 | validation loss: 0.03108720148539038
Epoch: 60, trainingloss: 0.029769947234041593 | validation loss: 0.03029753563004714
Epoch: 61, trainingloss: 0.03157116901877951 | validation loss: 0.03214293237505778
Epoch: 62, trainingloss: 0.02860109831656566 | validation loss: 0.02926675254962969
Epoch: 63, trainingloss: 0.029950563996637605 | validation loss: 0.030585114091219317
Epoch: 64, trainingloss: 0.02877402912412753 | validation loss: 0.02932388318823834
Epoch: 65, trainingloss: 0.03210687707095936 | validation loss: 0.03271046881404608
Epoch: 66, trainingloss: 0.029214207183622627 | validation loss: 0.02984707777213669
Epoch: 67, trainingloss: 0.028137570649318423 | validation loss: 0.02886616780696164
Epoch: 68, trainingloss: 0.028305374807312683 | validation loss: 0.028915748740484703
Epoch: 69, trainingloss: 0.02681748709492171 | validation loss: 0.027510204945118237
Epoch: 70, trainingloss: 0.030964482144010565 | validation loss: 0.03129120957289086
Epoch: 71, trainingloss: 0.03542417228512199 | validation loss: 0.03583775484861385
Epoch: 72, trainingloss: 0.03218156712997844 | validation loss: 0.03254726148200233
Epoch: 73, trainingloss: 0.028369527935940254 | validation loss: 0.029016306100552787
Epoch: 74, trainingloss: 0.027067349105657963 | validation loss: 0.027618448342410364
Epoch: 75, trainingloss: 0.029536024685886456 | validation loss: 0.029876637959658496
Epoch: 76, trainingloss: 0.026751501511076994 | validation loss: 0.02727103187540721
Epoch: 77, trainingloss: 0.02984606135533784 | validation loss: 0.03020006389619755
Epoch: 78, trainingloss: 0.026305091628660376 | validation loss: 0.02688125287121099
Epoch: 79, trainingloss: 0.02664417095433219 | validation loss: 0.027185599955100555
Epoch: 80, trainingloss: 0.025303013222145516 | validation loss: 0.02583288460228623
Epoch: 81, trainingloss: 0.027603180464530863 | validation loss: 0.028101040549926255
Epoch: 82, trainingloss: 0.028064868630966588 | validation loss: 0.028493093129801948
Epoch: 83, trainingloss: 0.035354100206944725 | validation loss: 0.03559480824171499
Epoch: 84, trainingloss: 0.027228824160799987 | validation loss: 0.02767336062248496
Epoch: 85, trainingloss: 0.02819394792916279 | validation loss: 0.028531073235026447
Epoch: 86, trainingloss: 0.028245569651212485 | validation loss: 0.02871165187716956
Epoch: 87, trainingloss: 0.0287306799733528 | validation loss: 0.02915646981461174
Epoch: 88, trainingloss: 0.025551594783041646 | validation loss: 0.02588965877845359
Epoch: 89, trainingloss: 0.02630439840216467 | validation loss: 0.026700611692522126
Epoch: 90, trainingloss: 0.026213542250998183 | validation loss: 0.02661607753186838
Epoch: 91, trainingloss: 0.027512627925357146 | validation loss: 0.027836074960701705
Epoch: 92, trainingloss: 0.024359725058658604 | validation loss: 0.024719522422379625
Epoch: 93, trainingloss: 0.026168963158309397 | validation loss: 0.026520405238217637
Epoch: 94, trainingloss: 0.027026004545358865 | validation loss: 0.0274871025389269
Epoch: 95, trainingloss: 0.024680115665075903 | validation loss: 0.025065681318927217
Epoch: 96, trainingloss: 0.029807835832035893 | validation loss: 0.030203231746061692
Epoch: 97, trainingloss: 0.023342221279050376 | validation loss: 0.023755087207515464
Epoch: 98, trainingloss: 0.028233578403804013 | validation loss: 0.02866270253208571
Epoch: 99, trainingloss: 0.02477267915781211 | validation loss: 0.025230243830314435
Epoch: 100, trainingloss: 0.02586431828939647 | validation loss: 0.02628615053727417
Epoch: 101, trainingloss: 0.02490175788550245 | validation loss: 0.02531179081970865
Epoch: 102, trainingloss: 0.02539964496957796 | validation loss: 0.025724824322813856
Epoch: 103, trainingloss: 0.023878806759140572 | validation loss: 0.02424353375681043
Epoch: 104, trainingloss: 0.029389681818914177 | validation loss: 0.02977678682661408
Epoch: 105, trainingloss: 0.02471089127370232 | validation loss: 0.025195641456282662
Epoch: 106, trainingloss: 0.027918992677078598 | validation loss: 0.028260148199463493
Epoch: 107, trainingloss: 0.024297978460842144 | validation loss: 0.024797528499738243
Epoch: 108, trainingloss: 0.025565110625359527 | validation loss: 0.025956141198528543
Epoch: 109, trainingloss: 0.024509824002303823 | validation loss: 0.02488075232458656
Epoch: 110, trainingloss: 0.030744076324815624 | validation loss: 0.031179726824228714
Epoch: 111, trainingloss: 0.027944260532924915 | validation loss: 0.02833984946337296
Epoch: 112, trainingloss: 0.028418216839823783 | validation loss: 0.028798445267936876
Epoch: 113, trainingloss: 0.02730482866265877 | validation loss: 0.027680397922540283
Epoch: 114, trainingloss: 0.021200817340445936 | validation loss: 0.02167444873644819
Epoch: 115, trainingloss: 0.026682809806554447 | validation loss: 0.026973195442847764
Epoch: 116, trainingloss: 0.026645904838554488 | validation loss: 0.027094853514073026
Epoch: 117, trainingloss: 0.025049601867314048 | validation loss: 0.02536626476755862
Epoch: 118, trainingloss: 0.02522895554374728 | validation loss: 0.025731635245077995
Epoch: 119, trainingloss: 0.023821781663509144 | validation loss: 0.024253818600456965
Epoch: 120, trainingloss: 0.02471458380862232 | validation loss: 0.02520861323194203
Epoch: 121, trainingloss: 0.025480438806876886 | validation loss: 0.025941781969313602
Epoch: 122, trainingloss: 0.024216241062870927 | validation loss: 0.02463188954258574
Epoch: 123, trainingloss: 0.022657530237204456 | validation loss: 0.02311468095748387
Epoch: 124, trainingloss: 0.022801765687558317 | validation loss: 0.023180529129468424
Epoch: 125, trainingloss: 0.021259891474920734 | validation loss: 0.02165951315782528
Epoch: 126, trainingloss: 0.021855323499307997 | validation loss: 0.022348121448158717
Epoch: 127, trainingloss: 0.024612312679304766 | validation loss: 0.024884962725451945
Epoch: 128, trainingloss: 0.02697121840168804 | validation loss: 0.027256728227380733
Epoch: 129, trainingloss: 0.025321281197445235 | validation loss: 0.02571876718613282
Epoch: 130, trainingloss: 0.024347440819897412 | validation loss: 0.02463009413699691
Epoch: 131, trainingloss: 0.025128123219184277 | validation loss: 0.025487629712539716
Epoch: 132, trainingloss: 0.026816221796446882 | validation loss: 0.027203368515360114
Epoch: 133, trainingloss: 0.02303962499223246 | validation loss: 0.02341717478627689
Epoch: 134, trainingloss: 0.023956374244887682 | validation loss: 0.024259353220952837
Epoch: 135, trainingloss: 0.02415758120052135 | validation loss: 0.024498274516809894
Epoch: 136, trainingloss: 0.02283433902283519 | validation loss: 0.0232842142967389
Epoch: 137, trainingloss: 0.02333451453594013 | validation loss: 0.023728556570221503
Epoch: 138, trainingloss: 0.024092949806343127 | validation loss: 0.02449496339712011
Epoch: 139, trainingloss: 0.023967651430881004 | validation loss: 0.02445696380976109
Epoch: 140, trainingloss: 0.02564730041409691 | validation loss: 0.0259206186780735
Epoch: 141, trainingloss: 0.025694336692999236 | validation loss: 0.026025857479381666
Epoch: 142, trainingloss: 0.02107385059710526 | validation loss: 0.021637678368489087
Epoch: 143, trainingloss: 0.024480561501929406 | validation loss: 0.02486696875065343
Epoch: 144, trainingloss: 0.02499677058425848 | validation loss: 0.02536893920126327
Epoch: 145, trainingloss: 0.02425846611851676 | validation loss: 0.024662265318265486
Epoch: 146, trainingloss: 0.02638711554815291 | validation loss: 0.026607536955965225
Epoch: 147, trainingloss: 0.021879414538691373 | validation loss: 0.02226207644192579
Epoch: 148, trainingloss: 0.02267515887741305 | validation loss: 0.02301389532275506
Epoch: 149, trainingloss: 0.023156200239459874 | validation loss: 0.023543964769056923
Epoch: 150, trainingloss: 0.022172160858902095 | validation loss: 0.022539467619271402
Epoch: 151, trainingloss: 0.023219466767864672 | validation loss: 0.023634105713343376
Epoch: 152, trainingloss: 0.02337096819715627 | validation loss: 0.023719401599780532
Epoch: 153, trainingloss: 0.024454263695739067 | validation loss: 0.024712528431065122
Epoch: 154, trainingloss: 0.023756902393196697 | validation loss: 0.0241182050446539
Epoch: 155, trainingloss: 0.022101102847139294 | validation loss: 0.022477323922262746
Epoch: 156, trainingloss: 0.02379297272210082 | validation loss: 0.024195333306027755
Epoch: 157, trainingloss: 0.023780195130807914 | validation loss: 0.024232694829264413
Epoch: 158, trainingloss: 0.021938195635234387 | validation loss: 0.02234079986830682
Epoch: 159, trainingloss: 0.02260235191749975 | validation loss: 0.0230803242747507
Epoch: 160, trainingloss: 0.02306842525641816 | validation loss: 0.023464667100048155
Epoch: 161, trainingloss: 0.02112292879112036 | validation loss: 0.021558304935650124
Epoch: 162, trainingloss: 0.024211637097172153 | validation loss: 0.024594277738521027
Epoch: 163, trainingloss: 0.02417649368604026 | validation loss: 0.024543896045503045
Epoch: 164, trainingloss: 0.03167860090950581 | validation loss: 0.031953731464917576
Epoch: 165, trainingloss: 0.02425036552280239 | validation loss: 0.02454744922668275
Epoch: 166, trainingloss: 0.022619455409294192 | validation loss: 0.023045402408189055
Epoch: 167, trainingloss: 0.02353526010180945 | validation loss: 0.023811483902892092
Epoch: 168, trainingloss: 0.022932848786388477 | validation loss: 0.023336704767137475
Epoch: 169, trainingloss: 0.02408321057316187 | validation loss: 0.02438724541120332
Epoch: 170, trainingloss: 0.024240423138800683 | validation loss: 0.024551872251061705
Epoch: 171, trainingloss: 0.02118191839747367 | validation loss: 0.021642268165104023
Epoch: 172, trainingloss: 0.02250522113868534 | validation loss: 0.022878337693485934
Epoch: 173, trainingloss: 0.023775857066292084 | validation loss: 0.02412798574457743
Epoch: 174, trainingloss: 0.02472823777236711 | validation loss: 0.02512686065773843
Epoch: 175, trainingloss: 0.02715011194858882 | validation loss: 0.027568152628602263
Epoch: 176, trainingloss: 0.023073658800304788 | validation loss: 0.02343452662414316
Epoch: 177, trainingloss: 0.023825390367054566 | validation loss: 0.02428135135411436
Epoch: 178, trainingloss: 0.020584094159798994 | validation loss: 0.02108945617417533
Epoch: 179, trainingloss: 0.02317073596584531 | validation loss: 0.0235429773207631
Epoch: 180, trainingloss: 0.027560825611868456 | validation loss: 0.027865141152010005
Epoch: 181, trainingloss: 0.022717726780349976 | validation loss: 0.02301200429865945
Epoch: 182, trainingloss: 0.023740272504270108 | validation loss: 0.024169855845164585
Epoch: 183, trainingloss: 0.023834485365638487 | validation loss: 0.024212002006113773
Epoch: 184, trainingloss: 0.024765165217760052 | validation loss: 0.02513207100744621
Epoch: 185, trainingloss: 0.022658209304999677 | validation loss: 0.023067645792405774
Epoch: 186, trainingloss: 0.02392958384263573 | validation loss: 0.024298343689125323
Epoch: 187, trainingloss: 0.02395921658733937 | validation loss: 0.024308010602714616
Epoch: 188, trainingloss: 0.030028815877834292 | validation loss: 0.030321589229912117
Epoch: 189, trainingloss: 0.02232776165694695 | validation loss: 0.022771256629571027
Epoch: 190, trainingloss: 0.020578953354181462 | validation loss: 0.0209123974840006
Epoch: 191, trainingloss: 0.026115511476208702 | validation loss: 0.02648065186557806
Epoch: 192, trainingloss: 0.02313079835827549 | validation loss: 0.023497235894193964
Epoch: 193, trainingloss: 0.024538948026369734 | validation loss: 0.024857094516318675
Epoch: 194, trainingloss: 0.023142139291965003 | validation loss: 0.02343310323145109
Epoch: 195, trainingloss: 0.023951292501076357 | validation loss: 0.02421153423251998
Epoch: 196, trainingloss: 0.021326164281927063 | validation loss: 0.021674483730038902
Epoch: 197, trainingloss: 0.024840359779190385 | validation loss: 0.025009158090756104
Epoch: 198, trainingloss: 0.0255414943612094 | validation loss: 0.02584080309736152
Epoch: 199, trainingloss: 0.02551789448881811 | validation loss: 0.02577210786015925
Epoch: 200, trainingloss: 0.022050504106124497 | validation loss: 0.022474965324624428
Epoch: 201, trainingloss: 0.020674368500260977 | validation loss: 0.02109431285144313
Epoch: 202, trainingloss: 0.02282986395794381 | validation loss: 0.023191472050206483
Epoch: 203, trainingloss: 0.02354942412954484 | validation loss: 0.023939537213961064
Epoch: 204, trainingloss: 0.023637078829915482 | validation loss: 0.0239074180359239
Epoch: 205, trainingloss: 0.02376201802685942 | validation loss: 0.024108926989728035
Epoch: 206, trainingloss: 0.021830932810728645 | validation loss: 0.02211215358099775
Epoch: 207, trainingloss: 0.022336962756236874 | validation loss: 0.0227685951130004
Epoch: 208, trainingloss: 0.023393673980544406 | validation loss: 0.02373231030638297
Epoch: 209, trainingloss: 0.023878812195616418 | validation loss: 0.024244427562384856
Epoch: 210, trainingloss: 0.022999921884669844 | validation loss: 0.02322577242217238
Epoch: 211, trainingloss: 0.020728046960365672 | validation loss: 0.0211707213958151
Epoch: 212, trainingloss: 0.020954813375438995 | validation loss: 0.021261004271118586
Epoch: 213, trainingloss: 0.02625345070090998 | validation loss: 0.026543316020070592
Epoch: 214, trainingloss: 0.021286646020026865 | validation loss: 0.021717219941151607
Epoch: 215, trainingloss: 0.025235424553583744 | validation loss: 0.025480984427531817
Epoch: 216, trainingloss: 0.025730311593288525 | validation loss: 0.02608429143043535
Epoch: 217, trainingloss: 0.02143502631901621 | validation loss: 0.021837732686243283
Epoch: 218, trainingloss: 0.01924595588719875 | validation loss: 0.01975908457132586
Epoch: 219, trainingloss: 0.023890854445115663 | validation loss: 0.02420285021603267
Epoch: 220, trainingloss: 0.02575734118855736 | validation loss: 0.02607677116165647
Epoch: 221, trainingloss: 0.020588430665578132 | validation loss: 0.020989246193860465
Epoch: 222, trainingloss: 0.025369206845438506 | validation loss: 0.02576076352444303
Epoch: 223, trainingloss: 0.023138967352585336 | validation loss: 0.023507503093748338
Epoch: 224, trainingloss: 0.02191290087778385 | validation loss: 0.02232442358898868
Epoch: 225, trainingloss: 0.022294755847535225 | validation loss: 0.022645480762373615
Epoch: 226, trainingloss: 0.02062642219539587 | validation loss: 0.021060184680926075
Epoch: 227, trainingloss: 0.0237819204162667 | validation loss: 0.024094619843976855
Epoch: 228, trainingloss: 0.021210269042512043 | validation loss: 0.0216396474930258
Epoch: 229, trainingloss: 0.027389188612759244 | validation loss: 0.027775260622134784
Epoch: 230, trainingloss: 0.024615658991916343 | validation loss: 0.024990588782506627
Epoch: 231, trainingloss: 0.0221175142791029 | validation loss: 0.022486899865293647
Epoch: 232, trainingloss: 0.021778166587852418 | validation loss: 0.02216311556278738
Epoch: 233, trainingloss: 0.02210746708970774 | validation loss: 0.022453978305568098
Epoch: 234, trainingloss: 0.023499520689694436 | validation loss: 0.023874811663501617
Epoch: 235, trainingloss: 0.02595627775285211 | validation loss: 0.02628694903269677
Epoch: 236, trainingloss: 0.02048767990346306 | validation loss: 0.020841037268246296
Epoch: 237, trainingloss: 0.02285126377758832 | validation loss: 0.023214122841265443
Epoch: 238, trainingloss: 0.01952159609149415 | validation loss: 0.019943118097227205
Epoch: 239, trainingloss: 0.02215356598793574 | validation loss: 0.022515937703121183
Epoch: 240, trainingloss: 0.02338270424955282 | validation loss: 0.023812122092014845
Epoch: 241, trainingloss: 0.022569279658761057 | validation loss: 0.022906454898040836
Epoch: 242, trainingloss: 0.027620561394775426 | validation loss: 0.027909095194136466
Epoch: 243, trainingloss: 0.021579822074416763 | validation loss: 0.022000838473302572
Epoch: 244, trainingloss: 0.02079498349091073 | validation loss: 0.02119510421340788
Epoch: 245, trainingloss: 0.019853331676499372 | validation loss: 0.02017354181985065
Epoch: 246, trainingloss: 0.0241270047182111 | validation loss: 0.024493212670555563
Epoch: 247, trainingloss: 0.021236475144715942 | validation loss: 0.02168655481437684
Epoch: 248, trainingloss: 0.0221438579721084 | validation loss: 0.022501245974435903
Epoch: 249, trainingloss: 0.02484954632780139 | validation loss: 0.02511186266005686
Epoch: 250, trainingloss: 0.02063511408249114 | validation loss: 0.021012713067522094
Epoch: 251, trainingloss: 0.01985425486785414 | validation loss: 0.020212049601784493
Epoch: 252, trainingloss: 0.02390360814515684 | validation loss: 0.0242448338794484
Epoch: 253, trainingloss: 0.02041009294074681 | validation loss: 0.020852804607678077
Epoch: 254, trainingloss: 0.020441301191998253 | validation loss: 0.020784905130436643
Epoch: 255, trainingloss: 0.02026099110463329 | validation loss: 0.020666475414737977
Epoch: 256, trainingloss: 0.02148270751615678 | validation loss: 0.021783473000758377
Epoch: 257, trainingloss: 0.020631419607427936 | validation loss: 0.02095518293152537
Epoch: 258, trainingloss: 0.02013600510057227 | validation loss: 0.020516706974395442
Epoch: 259, trainingloss: 0.024059517093664193 | validation loss: 0.02444820252206718
Epoch: 260, trainingloss: 0.024526158246836408 | validation loss: 0.024908007909494535
Epoch: 261, trainingloss: 0.02224758531723818 | validation loss: 0.02259505266042499
Epoch: 262, trainingloss: 0.0193182521969988 | validation loss: 0.019797773025339343
Epoch: 263, trainingloss: 0.01832100382755322 | validation loss: 0.018762552864926646
Epoch: 264, trainingloss: 0.02313146106837152 | validation loss: 0.023485344925337204
Epoch: 265, trainingloss: 0.021629597761417495 | validation loss: 0.021987217189483578
Epoch: 266, trainingloss: 0.023273653532260734 | validation loss: 0.02365096006060527
Epoch: 267, trainingloss: 0.021090253957502633 | validation loss: 0.021413788865167722
Epoch: 268, trainingloss: 0.022544257708431065 | validation loss: 0.022916032758948636
Epoch: 269, trainingloss: 0.02036311486692143 | validation loss: 0.02069739862741716
Epoch: 270, trainingloss: 0.02031506674844588 | validation loss: 0.020696363503581654
Epoch: 271, trainingloss: 0.01838993971035281 | validation loss: 0.01877300700895226
Epoch: 272, trainingloss: 0.022880042306502313 | validation loss: 0.023309270799172093
Epoch: 273, trainingloss: 0.023021735162369758 | validation loss: 0.02340385684869024
Epoch: 274, trainingloss: 0.024194059914662343 | validation loss: 0.02460763581159782
Epoch: 275, trainingloss: 0.022905945953309297 | validation loss: 0.02328277373417759
Epoch: 276, trainingloss: 0.02020963018571766 | validation loss: 0.020518300549404175
Epoch: 277, trainingloss: 0.0254269933689154 | validation loss: 0.02570659074123052
Epoch: 278, trainingloss: 0.023176817737838768 | validation loss: 0.02359133361206343
Epoch: 279, trainingloss: 0.02221900453048792 | validation loss: 0.02257372766415945
Epoch: 280, trainingloss: 0.021498154687102346 | validation loss: 0.021759402381595266
Epoch: 281, trainingloss: 0.02706807713526425 | validation loss: 0.0273431902236274
Epoch: 282, trainingloss: 0.01808763859328184 | validation loss: 0.018595905690208615
Epoch: 283, trainingloss: 0.021313086565230434 | validation loss: 0.021632477944986857
Epoch: 284, trainingloss: 0.02310944907319819 | validation loss: 0.02340265836848915
Epoch: 285, trainingloss: 0.022724983362323866 | validation loss: 0.02300169714586033
Epoch: 286, trainingloss: 0.02177807922654182 | validation loss: 0.022130113068360335
Epoch: 287, trainingloss: 0.026596162511472524 | validation loss: 0.026959706596388213
Epoch: 288, trainingloss: 0.023221962560979206 | validation loss: 0.023524520856944252
Epoch: 289, trainingloss: 0.02535865718458467 | validation loss: 0.025704938823629495
Epoch: 290, trainingloss: 0.020647615964419337 | validation loss: 0.020901708220682585
Epoch: 291, trainingloss: 0.023602344677880957 | validation loss: 0.023977884139365677
Epoch: 292, trainingloss: 0.018208097978482725 | validation loss: 0.01860373000135601
Epoch: 293, trainingloss: 0.028536066046663724 | validation loss: 0.028895986511467867
Epoch: 294, trainingloss: 0.022088234883211946 | validation loss: 0.022486461213088706
Epoch: 295, trainingloss: 0.021941485551702243 | validation loss: 0.0223022836917174
Epoch: 296, trainingloss: 0.01995493442915851 | validation loss: 0.02026468446662456
Epoch: 297, trainingloss: 0.025600041260257365 | validation loss: 0.026004419009782016
Epoch: 298, trainingloss: 0.022406953195703086 | validation loss: 0.022725728780806923
Epoch: 299, trainingloss: 0.019953146962268294 | validation loss: 0.020333682946776965
Epoch: 300, trainingloss: 0.018850252955572227 | validation loss: 0.019249931115904947
Epoch: 301, trainingloss: 0.024095754818155193 | validation loss: 0.024444607989520497
Epoch: 302, trainingloss: 0.028782344462598565 | validation loss: 0.02902827648773984
Epoch: 303, trainingloss: 0.02076728786608918 | validation loss: 0.021070574595910614
Epoch: 304, trainingloss: 0.01844570279440161 | validation loss: 0.018779555275013873
Epoch: 305, trainingloss: 0.03133038660317137 | validation loss: 0.03153194629109545
Epoch: 306, trainingloss: 0.02840482329380294 | validation loss: 0.02866235650853361
Epoch: 307, trainingloss: 0.024289055459891032 | validation loss: 0.024598461046370278
Epoch: 308, trainingloss: 0.022386730338369045 | validation loss: 0.022744256542311006
Epoch: 309, trainingloss: 0.01946111966725204 | validation loss: 0.01976803496470784
Epoch: 310, trainingloss: 0.01944337539844616 | validation loss: 0.019821979186111827
Epoch: 311, trainingloss: 0.02703838740696119 | validation loss: 0.0272606688591372
Epoch: 312, trainingloss: 0.02004395337063205 | validation loss: 0.020318568660177627
Epoch: 313, trainingloss: 0.024736894783162374 | validation loss: 0.025086284875180376
Epoch: 314, trainingloss: 0.025123849693206215 | validation loss: 0.02540977945542261
Epoch: 315, trainingloss: 0.01974870732117167 | validation loss: 0.02010584484772038
Epoch: 316, trainingloss: 0.019612324227309175 | validation loss: 0.01995842785270485
Epoch: 317, trainingloss: 0.019114183804642325 | validation loss: 0.019504964419366357
Epoch: 318, trainingloss: 0.019817305641222544 | validation loss: 0.020197137102899106
Epoch: 319, trainingloss: 0.023125317301768207 | validation loss: 0.023400179227228132
Epoch: 320, trainingloss: 0.01874892169313217 | validation loss: 0.019190123715745622
Epoch: 321, trainingloss: 0.01834846311086729 | validation loss: 0.018673294235987476
Epoch: 322, trainingloss: 0.032204925257056746 | validation loss: 0.03242241566277848
Epoch: 323, trainingloss: 0.019022930085877982 | validation loss: 0.01944889533678589
Epoch: 324, trainingloss: 0.02132274696314861 | validation loss: 0.021603967966790275
Epoch: 325, trainingloss: 0.020085561648453275 | validation loss: 0.020373571063198762
Epoch: 326, trainingloss: 0.01792730372973137 | validation loss: 0.018324743434266197
Epoch: 327, trainingloss: 0.021827887024683468 | validation loss: 0.022189792829825222
Epoch: 328, trainingloss: 0.026267836429186172 | validation loss: 0.026625154615117778
Epoch: 329, trainingloss: 0.022552865676197364 | validation loss: 0.022832368220793525
Epoch: 330, trainingloss: 0.022797762123723447 | validation loss: 0.023061756936625637
Epoch: 331, trainingloss: 0.020290224351360412 | validation loss: 0.020753143769610908
Epoch: 332, trainingloss: 0.02154764917686788 | validation loss: 0.021909335825065837
Epoch: 333, trainingloss: 0.020220599128480864 | validation loss: 0.02049496645614136
Epoch: 334, trainingloss: 0.020888002354618046 | validation loss: 0.021255972081393855
Epoch: 335, trainingloss: 0.019107437663559552 | validation loss: 0.01941205189596356
Epoch: 336, trainingloss: 0.020644868422122254 | validation loss: 0.02103330513018379
Epoch: 337, trainingloss: 0.023556211695750926 | validation loss: 0.023937692256578453
Epoch: 338, trainingloss: 0.022154011862274774 | validation loss: 0.022495666785195198
Epoch: 339, trainingloss: 0.019787542220584514 | validation loss: 0.02018289530268115
Epoch: 340, trainingloss: 0.024949594869497896 | validation loss: 0.025222999081057067
Epoch: 341, trainingloss: 0.01922738207470188 | validation loss: 0.01963624901438797
Epoch: 342, trainingloss: 0.026251767729340306 | validation loss: 0.026488862109638727
Epoch: 343, trainingloss: 0.022116751859085338 | validation loss: 0.022490784535243728
Epoch: 344, trainingloss: 0.022000368115408894 | validation loss: 0.022317465587417946
Epoch: 345, trainingloss: 0.01844812229010744 | validation loss: 0.01880687398949569
Epoch: 346, trainingloss: 0.01938408038181716 | validation loss: 0.01968370327616543
Epoch: 347, trainingloss: 0.021652093682881783 | validation loss: 0.021915979508193947
Epoch: 348, trainingloss: 0.027423983937490265 | validation loss: 0.027561149963750843
Epoch: 349, trainingloss: 0.02098328901917511 | validation loss: 0.021328072259640403
Epoch: 350, trainingloss: 0.01937182281474491 | validation loss: 0.019666519440864935
Epoch: 351, trainingloss: 0.02017795724099221 | validation loss: 0.020581973994332176
Epoch: 352, trainingloss: 0.02299334113525399 | validation loss: 0.023186061032592853
Epoch: 353, trainingloss: 0.023707690865120836 | validation loss: 0.023978824515630447
Epoch: 354, trainingloss: 0.023795787073320616 | validation loss: 0.024055275590206596
Epoch: 355, trainingloss: 0.021669906556634453 | validation loss: 0.021901077039289476
Epoch: 356, trainingloss: 0.02019168417011164 | validation loss: 0.020500856972136564
Epoch: 357, trainingloss: 0.020633953629081287 | validation loss: 0.021013728182269632
Epoch: 358, trainingloss: 0.019230797650092998 | validation loss: 0.01959592843529182
Epoch: 359, trainingloss: 0.0199204903502121 | validation loss: 0.020245229047444663
Epoch: 360, trainingloss: 0.017835574724749777 | validation loss: 0.018230030250363613
Epoch: 361, trainingloss: 0.021435449964184415 | validation loss: 0.021822916908220132
Epoch: 362, trainingloss: 0.0231400225323664 | validation loss: 0.023427903906906185
Epoch: 363, trainingloss: 0.01941126572226246 | validation loss: 0.019729547822355222
Epoch: 364, trainingloss: 0.01918469158071491 | validation loss: 0.019448410146283446
Epoch: 365, trainingloss: 0.02281731100319197 | validation loss: 0.02311626837633426
Epoch: 366, trainingloss: 0.02154551658679301 | validation loss: 0.021913113952319256
Epoch: 367, trainingloss: 0.018301814407548876 | validation loss: 0.018582846152740463
Epoch: 368, trainingloss: 0.02069523058842775 | validation loss: 0.02104245319185352
Epoch: 369, trainingloss: 0.017944807228602127 | validation loss: 0.01830716135996829
Epoch: 370, trainingloss: 0.024314551397467167 | validation loss: 0.024652184053306242
Epoch: 371, trainingloss: 0.0218838076467827 | validation loss: 0.022218955611446718
Epoch: 372, trainingloss: 0.022603059564157105 | validation loss: 0.022962273983359014
Epoch: 373, trainingloss: 0.021002219582658948 | validation loss: 0.021332287785217518
Epoch: 374, trainingloss: 0.021923788770907966 | validation loss: 0.022224419583116273
Epoch: 375, trainingloss: 0.023298027765393803 | validation loss: 0.023604745390713985
Epoch: 376, trainingloss: 0.017121668758451614 | validation loss: 0.01746951175179807
Epoch: 377, trainingloss: 0.02209151146722753 | validation loss: 0.02239281959834674
Epoch: 378, trainingloss: 0.02203921834493567 | validation loss: 0.022270266965258214
Epoch: 379, trainingloss: 0.020374352556912046 | validation loss: 0.020637920378919417
Epoch: 380, trainingloss: 0.022974364820552536 | validation loss: 0.023292517778015946
Epoch: 381, trainingloss: 0.01796328840925767 | validation loss: 0.018328153115328646
Epoch: 382, trainingloss: 0.01736843042404182 | validation loss: 0.017773181084131853
Epoch: 383, trainingloss: 0.02330977365552903 | validation loss: 0.023619197792844295
Epoch: 384, trainingloss: 0.018855498607344822 | validation loss: 0.019149193131474625
Epoch: 385, trainingloss: 0.01963717166170319 | validation loss: 0.02003252545984261
Epoch: 386, trainingloss: 0.02184683871906459 | validation loss: 0.022121225530523918
Epoch: 387, trainingloss: 0.02492734019446692 | validation loss: 0.025291726965265014
Epoch: 388, trainingloss: 0.018669715348042314 | validation loss: 0.018998786401787485
Epoch: 389, trainingloss: 0.018973854827586154 | validation loss: 0.01939363779199887
Epoch: 390, trainingloss: 0.02547192572514628 | validation loss: 0.02591982410329773
Epoch: 391, trainingloss: 0.0258653420022708 | validation loss: 0.026141291229219894
Epoch: 392, trainingloss: 0.01898485049468908 | validation loss: 0.01934792250333748
Epoch: 393, trainingloss: 0.019682872507596205 | validation loss: 0.019997925411557198
Epoch: 394, trainingloss: 0.02212227093297257 | validation loss: 0.022345200206734462
Epoch: 395, trainingloss: 0.019767796862243062 | validation loss: 0.020020026114882284
Epoch: 396, trainingloss: 0.02055861113579898 | validation loss: 0.02094521964626291
Epoch: 397, trainingloss: 0.019199483465590545 | validation loss: 0.019472740139667297
Epoch: 398, trainingloss: 0.022120331443217962 | validation loss: 0.0224583078256333
Epoch: 399, trainingloss: 0.01913234439835687 | validation loss: 0.019409193217468798
Epoch: 400, trainingloss: 0.020621903929008048 | validation loss: 0.020971471492820158
Epoch: 401, trainingloss: 0.019219911109839373 | validation loss: 0.019425469106053316
Epoch: 402, trainingloss: 0.019004243047704837 | validation loss: 0.019343407110522855
Epoch: 403, trainingloss: 0.022043381521418506 | validation loss: 0.022392564889317897
Epoch: 404, trainingloss: 0.022587462172137255 | validation loss: 0.022944844184802277
Epoch: 405, trainingloss: 0.019509183106933784 | validation loss: 0.019879477914623807
Epoch: 406, trainingloss: 0.019688801668691438 | validation loss: 0.019928279305573487
Epoch: 407, trainingloss: 0.017595197928121767 | validation loss: 0.017857417593979016
Epoch: 408, trainingloss: 0.017181574775435443 | validation loss: 0.0175171587704276
Epoch: 409, trainingloss: 0.020461024082055662 | validation loss: 0.020671286798136016
Epoch: 410, trainingloss: 0.018521017721312347 | validation loss: 0.018902026628723787
Epoch: 411, trainingloss: 0.024787211455846853 | validation loss: 0.025028915468496213
Epoch: 412, trainingloss: 0.022273304800025387 | validation loss: 0.022548613322215978
Epoch: 413, trainingloss: 0.03066432221283325 | validation loss: 0.0309801272155532
Epoch: 414, trainingloss: 0.022373327945786427 | validation loss: 0.02270112073082637
Epoch: 415, trainingloss: 0.01878471315487591 | validation loss: 0.019162178942882736
Epoch: 416, trainingloss: 0.019703921335413845 | validation loss: 0.019992261542181942
Epoch: 417, trainingloss: 0.020550956542466896 | validation loss: 0.02078589005742195
Epoch: 418, trainingloss: 0.02024804940515531 | validation loss: 0.020585920875462245
Epoch: 419, trainingloss: 0.019967202926799994 | validation loss: 0.02028873882523974
Epoch: 420, trainingloss: 0.01723332580885998 | validation loss: 0.01757696916367226
Epoch: 421, trainingloss: 0.01790042762550992 | validation loss: 0.018248798537668445
Epoch: 422, trainingloss: 0.01996580466679903 | validation loss: 0.02023614892696042
Epoch: 423, trainingloss: 0.019266115142568225 | validation loss: 0.019562193138317554
Epoch: 424, trainingloss: 0.02049012757638354 | validation loss: 0.02084573208100169
Epoch: 425, trainingloss: 0.017126337448271207 | validation loss: 0.017510623289536436
Epoch: 426, trainingloss: 0.0220882929404069 | validation loss: 0.02240885696369881
Epoch: 427, trainingloss: 0.022762291443990883 | validation loss: 0.02298519725546999
Epoch: 428, trainingloss: 0.019354526259840913 | validation loss: 0.019582570216390503
Epoch: 429, trainingloss: 0.01830492006046354 | validation loss: 0.018667092853574492
Epoch: 430, trainingloss: 0.01869808379786401 | validation loss: 0.019089357734043258
Epoch: 431, trainingloss: 0.024646957331466636 | validation loss: 0.0248928898265087
Epoch: 432, trainingloss: 0.01721658480066503 | validation loss: 0.017726597031900444
Epoch: 433, trainingloss: 0.02237122189838249 | validation loss: 0.022676298286784368
Epoch: 434, trainingloss: 0.021183854298364845 | validation loss: 0.021522900771795507
Epoch: 435, trainingloss: 0.017378726172877754 | validation loss: 0.017688080756263498
Epoch: 436, trainingloss: 0.018697219939041835 | validation loss: 0.0190881805058545
Epoch: 437, trainingloss: 0.02285331183368405 | validation loss: 0.02314415119585211
Epoch: 438, trainingloss: 0.01934295329833802 | validation loss: 0.019643225591696286
Epoch: 439, trainingloss: 0.017409461456155385 | validation loss: 0.017738201240826076
Epoch: 440, trainingloss: 0.023019347398931675 | validation loss: 0.02331975074355525
Epoch: 441, trainingloss: 0.017615951555448164 | validation loss: 0.017986530510943594
Epoch: 442, trainingloss: 0.020077126247221407 | validation loss: 0.020335859146860612
Epoch: 443, trainingloss: 0.019310921390781954 | validation loss: 0.019688522352539668
Epoch: 444, trainingloss: 0.020042660875625763 | validation loss: 0.020348997896263637
Epoch: 445, trainingloss: 0.019151388229210333 | validation loss: 0.019523697959227586
Epoch: 446, trainingloss: 0.01884451555105483 | validation loss: 0.019150137931682524
Epoch: 447, trainingloss: 0.018299685506973053 | validation loss: 0.018669674275635505
Epoch: 448, trainingloss: 0.01831862366918217 | validation loss: 0.018738944980008627
Epoch: 449, trainingloss: 0.018024701731457832 | validation loss: 0.01841983574078704
Epoch: 450, trainingloss: 0.020163317883868426 | validation loss: 0.020523793686727385
Epoch: 451, trainingloss: 0.020834091400624175 | validation loss: 0.02122350650327153
Epoch: 452, trainingloss: 0.021787431410971402 | validation loss: 0.022091408775753656
Epoch: 453, trainingloss: 0.02180353450182458 | validation loss: 0.02188802809708745
Epoch: 454, trainingloss: 0.022947410984054308 | validation loss: 0.023195242978337877
Epoch: 455, trainingloss: 0.02435250580476346 | validation loss: 0.024670305530101685
Epoch: 456, trainingloss: 0.020603614827145497 | validation loss: 0.02083529217006142
Epoch: 457, trainingloss: 0.020681917422689555 | validation loss: 0.02093322037878974
Epoch: 458, trainingloss: 0.02324250461100827 | validation loss: 0.02350103457694456
Epoch: 459, trainingloss: 0.020657449096375194 | validation loss: 0.020960200380540705
Epoch: 460, trainingloss: 0.01989085864366638 | validation loss: 0.020191314731141535
Epoch: 461, trainingloss: 0.016989942793295642 | validation loss: 0.017344224948293054
Epoch: 462, trainingloss: 0.018994373567075416 | validation loss: 0.019272555250730745
Epoch: 463, trainingloss: 0.021979273852803682 | validation loss: 0.022370887343730977
Epoch: 464, trainingloss: 0.017652986699211958 | validation loss: 0.018057544198051455
Epoch: 465, trainingloss: 0.020131685237599613 | validation loss: 0.020374296028317456
Epoch: 466, trainingloss: 0.018486936251935714 | validation loss: 0.018845231523424964
Epoch: 467, trainingloss: 0.018034622653140996 | validation loss: 0.01833916504754486
Epoch: 468, trainingloss: 0.02028225931957198 | validation loss: 0.020530287941345923
Epoch: 469, trainingloss: 0.023409366566878625 | validation loss: 0.023636052707020013
Epoch: 470, trainingloss: 0.02161127202864617 | validation loss: 0.021984076629776098
Epoch: 471, trainingloss: 0.02077067681082451 | validation loss: 0.021015144292489327
Epoch: 472, trainingloss: 0.02131927467947 | validation loss: 0.021672871827248967
Epoch: 473, trainingloss: 0.02036992458503202 | validation loss: 0.020699373841139793
Epoch: 474, trainingloss: 0.02033980618779672 | validation loss: 0.020682687869449976
Epoch: 475, trainingloss: 0.018412473877267372 | validation loss: 0.018828350232513943
Epoch: 476, trainingloss: 0.02011329960914721 | validation loss: 0.0204942166452876
Epoch: 477, trainingloss: 0.01768100007295637 | validation loss: 0.018043109955511484
Epoch: 478, trainingloss: 0.024835475612208103 | validation loss: 0.025069379169200944
Epoch: 479, trainingloss: 0.018692046358443497 | validation loss: 0.018969031579191137
Epoch: 480, trainingloss: 0.020072604215130324 | validation loss: 0.02040153913945869
Epoch: 481, trainingloss: 0.01968366689849151 | validation loss: 0.019880898200911424
Epoch: 482, trainingloss: 0.02043620460673864 | validation loss: 0.020753826814045893
Epoch: 483, trainingloss: 0.017461337859708027 | validation loss: 0.017803088563445573
Epoch: 484, trainingloss: 0.02153813593545725 | validation loss: 0.021878047251598212
Epoch: 485, trainingloss: 0.01887672467921422 | validation loss: 0.01917761942082381
Epoch: 486, trainingloss: 0.018772911216979396 | validation loss: 0.019142001918422007
Epoch: 487, trainingloss: 0.019064713889626647 | validation loss: 0.019379849014822755
Epoch: 488, trainingloss: 0.019676150205357318 | validation loss: 0.019946746844691894
Epoch: 489, trainingloss: 0.023660326168652508 | validation loss: 0.02396268457822046
Epoch: 490, trainingloss: 0.01822295108393081 | validation loss: 0.018596928936697905
Epoch: 491, trainingloss: 0.020016294063221425 | validation loss: 0.020419782453492227
Epoch: 492, trainingloss: 0.016918163545861942 | validation loss: 0.01726955998578336
Epoch: 493, trainingloss: 0.017647690801028414 | validation loss: 0.017992418894172614
Epoch: 494, trainingloss: 0.016651690637797464 | validation loss: 0.017002647541619675
Epoch: 495, trainingloss: 0.021948930242358576 | validation loss: 0.02207123643364589
Epoch: 496, trainingloss: 0.01624462716406418 | validation loss: 0.016587521476885844
Epoch: 497, trainingloss: 0.018222023454303588 | validation loss: 0.01854295532005391
Epoch: 498, trainingloss: 0.020823728612245646 | validation loss: 0.021086396593231894
Epoch: 499, trainingloss: 0.017696968481446067 | validation loss: 0.018052461317039463
Epoch: 500, trainingloss: 0.018688357256678948 | validation loss: 0.01908346324108193
Epoch: 501, trainingloss: 0.020601413053254008 | validation loss: 0.020935434166921865
Epoch: 502, trainingloss: 0.02238967605907138 | validation loss: 0.02266563876018551
Epoch: 503, trainingloss: 0.019979814977932078 | validation loss: 0.020291982888370676
Epoch: 504, trainingloss: 0.01924066298797301 | validation loss: 0.019468613662080192
Epoch: 505, trainingloss: 0.01899384333492914 | validation loss: 0.019267855444337578
Epoch: 506, trainingloss: 0.02059364407592056 | validation loss: 0.020879193583158213
Epoch: 507, trainingloss: 0.0182752649550783 | validation loss: 0.018526030717432695
Epoch: 508, trainingloss: 0.016599266143314313 | validation loss: 0.017029527441173913
Epoch: 509, trainingloss: 0.018297801989935226 | validation loss: 0.01865789292382002
Epoch: 510, trainingloss: 0.01959750788074382 | validation loss: 0.01990626956244766
Epoch: 511, trainingloss: 0.021207389352438343 | validation loss: 0.02139778656293826
Epoch: 512, trainingloss: 0.020046172366166275 | validation loss: 0.020348489556662425

Smallest SV
Epoch: 0, trainingloss: 0.19652274183416443 | validation loss: 0.19596893646497276
Epoch: 1, trainingloss: 0.10922797675879702 | validation loss: 0.1091403346274516
Epoch: 2, trainingloss: 0.07256774429429305 | validation loss: 0.07207226691055536
Epoch: 3, trainingloss: 0.06092809156736049 | validation loss: 0.06024387385690136
Epoch: 4, trainingloss: 0.048044391180815466 | validation loss: 0.048004332666028895
Epoch: 5, trainingloss: 0.03772212267521142 | validation loss: 0.03780666397910093
Epoch: 6, trainingloss: 0.03139562770054227 | validation loss: 0.031792373403381535
Epoch: 7, trainingloss: 0.02808071174119318 | validation loss: 0.028566856163180398
Epoch: 8, trainingloss: 0.027640511832267657 | validation loss: 0.02816556571793251
Epoch: 9, trainingloss: 0.023556958590873905 | validation loss: 0.02401106273423914
Epoch: 10, trainingloss: 0.02380915114094141 | validation loss: 0.024328363907599473
Epoch: 11, trainingloss: 0.0228623689695339 | validation loss: 0.02332858241761706
Epoch: 12, trainingloss: 0.020065270263978256 | validation loss: 0.020618903581001918
Epoch: 13, trainingloss: 0.020584873055926847 | validation loss: 0.02111414928057855
Epoch: 14, trainingloss: 0.019193054921350563 | validation loss: 0.0197909270596172
Epoch: 15, trainingloss: 0.018491306934805003 | validation loss: 0.01902765613259842
Epoch: 16, trainingloss: 0.01791324475673452 | validation loss: 0.01850123594809621
Epoch: 17, trainingloss: 0.017557239961973194 | validation loss: 0.018059620781559694
Epoch: 18, trainingloss: 0.017321571343768875 | validation loss: 0.01776363829186019
Epoch: 19, trainingloss: 0.017142358207994986 | validation loss: 0.017510667416559444
Epoch: 20, trainingloss: 0.016032539560632796 | validation loss: 0.01658841968879833
Epoch: 21, trainingloss: 0.015485991520294083 | validation loss: 0.015966261845126336
Epoch: 22, trainingloss: 0.015535472424417458 | validation loss: 0.015962738509631494
Epoch: 23, trainingloss: 0.014434579902854528 | validation loss: 0.01492045248665573
Epoch: 24, trainingloss: 0.014090119349604533 | validation loss: 0.014555684261352288
Epoch: 25, trainingloss: 0.014689698063196152 | validation loss: 0.015236959491856859
Epoch: 26, trainingloss: 0.013772805141226018 | validation loss: 0.01430443268125831
Epoch: 27, trainingloss: 0.013502469728168497 | validation loss: 0.013994742709139009
Epoch: 28, trainingloss: 0.012715378919205282 | validation loss: 0.013323241071801667
Epoch: 29, trainingloss: 0.013389408104768338 | validation loss: 0.013903686782622089
Epoch: 30, trainingloss: 0.012622487225281467 | validation loss: 0.013197689717087235
Epoch: 31, trainingloss: 0.012322475189333465 | validation loss: 0.012914114097226556
Epoch: 32, trainingloss: 0.012440320235999943 | validation loss: 0.01295398441429017
Epoch: 33, trainingloss: 0.012422324676784753 | validation loss: 0.012935845290036526
Epoch: 34, trainingloss: 0.012645667924772081 | validation loss: 0.013222985664524867
Epoch: 35, trainingloss: 0.011834447723988506 | validation loss: 0.012352473579377405
Epoch: 36, trainingloss: 0.011814902562316971 | validation loss: 0.012358272199798542
Epoch: 37, trainingloss: 0.011984273293409736 | validation loss: 0.01251473819919237
Epoch: 38, trainingloss: 0.012261706488582774 | validation loss: 0.012771834175527913
Epoch: 39, trainingloss: 0.011733656203969114 | validation loss: 0.012245230911670374
Epoch: 40, trainingloss: 0.012465802724123284 | validation loss: 0.012914866288340135
Epoch: 41, trainingloss: 0.011725136553460769 | validation loss: 0.012250365060612892
Epoch: 42, trainingloss: 0.011895340864479078 | validation loss: 0.01235385166532232
Epoch: 43, trainingloss: 0.011173846583330661 | validation loss: 0.011707107715237195
Epoch: 44, trainingloss: 0.011002560994258507 | validation loss: 0.011517931086803438
Epoch: 45, trainingloss: 0.011162528966044659 | validation loss: 0.011667869332906984
Epoch: 46, trainingloss: 0.010492146256871235 | validation loss: 0.011020895333215845
Epoch: 47, trainingloss: 0.010915081860584163 | validation loss: 0.011406558792931454
Epoch: 48, trainingloss: 0.010185932109372228 | validation loss: 0.010687487732918706
Epoch: 49, trainingloss: 0.011165870881880724 | validation loss: 0.01165218877947308
Epoch: 50, trainingloss: 0.010225942143089512 | validation loss: 0.010754602962261032
Epoch: 51, trainingloss: 0.010073149713135566 | validation loss: 0.01061951077100077
Epoch: 52, trainingloss: 0.010790239052846916 | validation loss: 0.011253417006247463
Epoch: 53, trainingloss: 0.010653402487463345 | validation loss: 0.011112342750609041
Epoch: 54, trainingloss: 0.010095981975553576 | validation loss: 0.010610442266264014
Epoch: 55, trainingloss: 0.010264206165319928 | validation loss: 0.010800182057964331
Epoch: 56, trainingloss: 0.010494284393786657 | validation loss: 0.01101879993993162
Epoch: 57, trainingloss: 0.010421299455921205 | validation loss: 0.010934549561845294
Epoch: 58, trainingloss: 0.009919732785346837 | validation loss: 0.0104371517082448
Epoch: 59, trainingloss: 0.009965162844750153 | validation loss: 0.0104691488427751
Epoch: 60, trainingloss: 0.00996254010980092 | validation loss: 0.010466907183924599
Epoch: 61, trainingloss: 0.009947142978483512 | validation loss: 0.01044937111593569
Epoch: 62, trainingloss: 0.010070278625847664 | validation loss: 0.010545984362003945
Epoch: 63, trainingloss: 0.010032379619279448 | validation loss: 0.010544113410775855
Epoch: 64, trainingloss: 0.009638542342326256 | validation loss: 0.010188731511114366
Epoch: 65, trainingloss: 0.009496904807678107 | validation loss: 0.01006429003337132
Epoch: 66, trainingloss: 0.009673175247398127 | validation loss: 0.010179127240631787
Epoch: 67, trainingloss: 0.010151860979467702 | validation loss: 0.010715361293468567
Epoch: 68, trainingloss: 0.009805571938321392 | validation loss: 0.010360923091445864
Epoch: 69, trainingloss: 0.009495363415107198 | validation loss: 0.010078028960218614
Epoch: 70, trainingloss: 0.009827429257243375 | validation loss: 0.010371733166837337
Epoch: 71, trainingloss: 0.010307840483642234 | validation loss: 0.010872937433646597
Epoch: 72, trainingloss: 0.009811711036335586 | validation loss: 0.010396264144726015
Epoch: 73, trainingloss: 0.009905099887544655 | validation loss: 0.010416150499687232
Epoch: 74, trainingloss: 0.010092698030855071 | validation loss: 0.010613832912353243
Epoch: 75, trainingloss: 0.00969991556402691 | validation loss: 0.01021886892671556
Epoch: 76, trainingloss: 0.009882358836714683 | validation loss: 0.010431157310544325
Epoch: 77, trainingloss: 0.010700892812236858 | validation loss: 0.011182792633395722
Epoch: 78, trainingloss: 0.010561226788486476 | validation loss: 0.011059206370610395
Epoch: 79, trainingloss: 0.010769996544303228 | validation loss: 0.011224356460176155
Epoch: 80, trainingloss: 0.009802485847962972 | validation loss: 0.010296274851165067
Epoch: 81, trainingloss: 0.008880603080954032 | validation loss: 0.009461113704454639
Epoch: 82, trainingloss: 0.00915132852132166 | validation loss: 0.009729295725382992
Epoch: 83, trainingloss: 0.00919279155887011 | validation loss: 0.009769832916473053
Epoch: 84, trainingloss: 0.009165665024841695 | validation loss: 0.009741409694974421
Epoch: 85, trainingloss: 0.009192964562693744 | validation loss: 0.009781321534541492
Epoch: 86, trainingloss: 0.009626871923123576 | validation loss: 0.010221336627917316
Epoch: 87, trainingloss: 0.010273815310948049 | validation loss: 0.01078480430561224
Epoch: 88, trainingloss: 0.010550587717608247 | validation loss: 0.011028511829779009
Epoch: 89, trainingloss: 0.009195739189696866 | validation loss: 0.0097829180561196
Epoch: 90, trainingloss: 0.009581020490102685 | validation loss: 0.01011925677487193
Epoch: 91, trainingloss: 0.009021932050333581 | validation loss: 0.009621465279812893
Epoch: 92, trainingloss: 0.009561690151200584 | validation loss: 0.01011731154506266
Epoch: 93, trainingloss: 0.009104786988808658 | validation loss: 0.009717773241705738
Epoch: 94, trainingloss: 0.010854789396358063 | validation loss: 0.011354860241707865
Epoch: 95, trainingloss: 0.008949553300086982 | validation loss: 0.009570523719232744
Epoch: 96, trainingloss: 0.010348721458795831 | validation loss: 0.010814990170857224
Epoch: 97, trainingloss: 0.009615289794156863 | validation loss: 0.010178793928648518
Epoch: 98, trainingloss: 0.009914375033485794 | validation loss: 0.01044691685309458
Epoch: 99, trainingloss: 0.009584215219462771 | validation loss: 0.01015269788565525
Epoch: 100, trainingloss: 0.01093973418811128 | validation loss: 0.011460643167161
Epoch: 101, trainingloss: 0.0094011518646931 | validation loss: 0.009960848435051704
Epoch: 102, trainingloss: 0.010363213378118031 | validation loss: 0.010868590441325932
Epoch: 103, trainingloss: 0.01001266869243035 | validation loss: 0.01052111776900822
Epoch: 104, trainingloss: 0.008435396296628279 | validation loss: 0.009023705393422165
Epoch: 105, trainingloss: 0.009643057705913925 | validation loss: 0.010120559687593763
Epoch: 106, trainingloss: 0.010406587520461006 | validation loss: 0.0109052652501156
Epoch: 107, trainingloss: 0.008677662524880355 | validation loss: 0.009272061025509438
Epoch: 108, trainingloss: 0.009756933062112536 | validation loss: 0.0102606899176063
Epoch: 109, trainingloss: 0.008575066185960946 | validation loss: 0.009199962493278029
Epoch: 110, trainingloss: 0.010384951328733152 | validation loss: 0.010855382523393712
Epoch: 111, trainingloss: 0.009157824315748148 | validation loss: 0.009719794274391055
Epoch: 112, trainingloss: 0.00880703858896747 | validation loss: 0.0093813620228904
Epoch: 113, trainingloss: 0.009596456811115803 | validation loss: 0.010110301032866115
Epoch: 114, trainingloss: 0.008844516548770559 | validation loss: 0.009435631290385993
Epoch: 115, trainingloss: 0.008779364933217643 | validation loss: 0.009400703454935863
Epoch: 116, trainingloss: 0.008842762615978111 | validation loss: 0.009383997440301679
Epoch: 117, trainingloss: 0.00906976120966686 | validation loss: 0.00965350027777896
Epoch: 118, trainingloss: 0.009198097952757112 | validation loss: 0.009754983247584304
Epoch: 119, trainingloss: 0.009483661039290396 | validation loss: 0.009983199420114011
Epoch: 120, trainingloss: 0.009629938090670191 | validation loss: 0.010093358332647597
Epoch: 121, trainingloss: 0.008391163034404169 | validation loss: 0.008976219904212662
Epoch: 122, trainingloss: 0.008356000915924684 | validation loss: 0.00891281823851256
Epoch: 123, trainingloss: 0.010170005274065908 | validation loss: 0.010677730401280998
Epoch: 124, trainingloss: 0.008494284576268352 | validation loss: 0.009010525233813451
Epoch: 125, trainingloss: 0.009002118781767255 | validation loss: 0.009547779088692823
Epoch: 126, trainingloss: 0.010207822960972862 | validation loss: 0.010706462289293386
Epoch: 127, trainingloss: 0.008841327433397599 | validation loss: 0.009408494424983925
Epoch: 128, trainingloss: 0.009130262857392189 | validation loss: 0.009712929094038297
Epoch: 129, trainingloss: 0.009603872368964077 | validation loss: 0.010073970718915255
Epoch: 130, trainingloss: 0.009344220235383241 | validation loss: 0.00975609213679974
Epoch: 131, trainingloss: 0.008001493324265804 | validation loss: 0.00855657832422338
Epoch: 132, trainingloss: 0.008466544426385926 | validation loss: 0.008991528207121374
Epoch: 133, trainingloss: 0.008548958764503893 | validation loss: 0.009021795834919919
Epoch: 134, trainingloss: 0.008699288025636133 | validation loss: 0.009163443637779371
Epoch: 135, trainingloss: 0.00881107716011817 | validation loss: 0.00933093409253812
Epoch: 136, trainingloss: 0.008442970967965424 | validation loss: 0.008963417597225675
Epoch: 137, trainingloss: 0.009000474792243845 | validation loss: 0.009497013337625905
Epoch: 138, trainingloss: 0.008578123594030415 | validation loss: 0.009079841751933892
Epoch: 139, trainingloss: 0.00773442967665458 | validation loss: 0.0082950795482832
Epoch: 140, trainingloss: 0.008204796786172797 | validation loss: 0.008733048623561689
Epoch: 141, trainingloss: 0.008783908081818352 | validation loss: 0.009268085885339693
Epoch: 142, trainingloss: 0.007961026235088644 | validation loss: 0.00848565472889213
Epoch: 143, trainingloss: 0.007567867803758261 | validation loss: 0.008155011232015631
Epoch: 144, trainingloss: 0.00759210852767884 | validation loss: 0.008117368343943988
Epoch: 145, trainingloss: 0.00804102169170279 | validation loss: 0.00852403602793799
Epoch: 146, trainingloss: 0.008366103964527019 | validation loss: 0.008844842288533227
Epoch: 147, trainingloss: 0.008878764417936651 | validation loss: 0.009373029834297554
Epoch: 148, trainingloss: 0.009208851815985693 | validation loss: 0.009650653337338605
Epoch: 149, trainingloss: 0.008478134959905233 | validation loss: 0.008953967693792331
Epoch: 150, trainingloss: 0.008348851518274221 | validation loss: 0.00884718939712248
Epoch: 151, trainingloss: 0.00964404177334316 | validation loss: 0.0100445913050084
Epoch: 152, trainingloss: 0.008342760031962106 | validation loss: 0.008808632968551805
Epoch: 153, trainingloss: 0.007408087772561302 | validation loss: 0.007979750187765089
Epoch: 154, trainingloss: 0.008499166031624726 | validation loss: 0.009032777689895619
Epoch: 155, trainingloss: 0.009311600878143957 | validation loss: 0.009716850476264773
Epoch: 156, trainingloss: 0.008264087150037536 | validation loss: 0.008736063952463007
Epoch: 157, trainingloss: 0.008398926021865967 | validation loss: 0.008891275728616777
Epoch: 158, trainingloss: 0.008142714765044188 | validation loss: 0.008676188087141134
Epoch: 159, trainingloss: 0.007837967772821738 | validation loss: 0.008341998162056259
Epoch: 160, trainingloss: 0.00881587726135234 | validation loss: 0.009267901815510269
Epoch: 161, trainingloss: 0.008485306962516556 | validation loss: 0.009005330803047254
Epoch: 162, trainingloss: 0.00810492545898855 | validation loss: 0.008587958286169003
Epoch: 163, trainingloss: 0.008593348679282749 | validation loss: 0.009039561072341018
Epoch: 164, trainingloss: 0.00885324781979471 | validation loss: 0.009295490291713933
Epoch: 165, trainingloss: 0.007574763927070239 | validation loss: 0.008167029791432402
Epoch: 166, trainingloss: 0.008098642823354665 | validation loss: 0.008632061015800819
Epoch: 167, trainingloss: 0.007642629947090667 | validation loss: 0.008174292359896404
Epoch: 168, trainingloss: 0.008577493066946934 | validation loss: 0.009071664996268141
Epoch: 169, trainingloss: 0.007849434900096628 | validation loss: 0.008346234509710802
Epoch: 170, trainingloss: 0.007975210466183737 | validation loss: 0.008499250133169111
Epoch: 171, trainingloss: 0.007931710827321255 | validation loss: 0.008451347756338788
Epoch: 172, trainingloss: 0.00881400683498068 | validation loss: 0.009254772096777256
Epoch: 173, trainingloss: 0.008593852124231745 | validation loss: 0.00911446663761052
Epoch: 174, trainingloss: 0.007912279674374727 | validation loss: 0.008470988324568387
Epoch: 175, trainingloss: 0.007636581573609277 | validation loss: 0.00822087185197179
Epoch: 176, trainingloss: 0.007894041983528844 | validation loss: 0.008378531807118606
Epoch: 177, trainingloss: 0.00833972078111218 | validation loss: 0.008817112829292038
Epoch: 178, trainingloss: 0.00801436116513949 | validation loss: 0.008514541323039197
Epoch: 179, trainingloss: 0.008050571555813586 | validation loss: 0.008557552865608307
Epoch: 180, trainingloss: 0.008284011655286458 | validation loss: 0.008713521535323955
Epoch: 181, trainingloss: 0.00850949187787219 | validation loss: 0.009006710551957255
Epoch: 182, trainingloss: 0.008392738516855989 | validation loss: 0.008900945438911187
Epoch: 183, trainingloss: 0.007713300243574943 | validation loss: 0.008212371878417841
Epoch: 184, trainingloss: 0.007635905458475216 | validation loss: 0.00815190828339585
Epoch: 185, trainingloss: 0.007726736726533847 | validation loss: 0.008229018741885025
Epoch: 186, trainingloss: 0.007754755005437798 | validation loss: 0.008276131875210705
Epoch: 187, trainingloss: 0.007563011056687481 | validation loss: 0.008096304224058682
Epoch: 188, trainingloss: 0.008067666366616467 | validation loss: 0.008545860538698985
Epoch: 189, trainingloss: 0.008538814942908089 | validation loss: 0.008985825729676282
Epoch: 190, trainingloss: 0.00817918284094767 | validation loss: 0.008693399862437744
Epoch: 191, trainingloss: 0.008157833461888187 | validation loss: 0.008640890961322874
Epoch: 192, trainingloss: 0.0077623436711149775 | validation loss: 0.008254513545229653
Epoch: 193, trainingloss: 0.00812015811605923 | validation loss: 0.008620025252995529
Epoch: 194, trainingloss: 0.007896132918431394 | validation loss: 0.008364948079072272
Epoch: 195, trainingloss: 0.007492763807627284 | validation loss: 0.008007292936798624
Epoch: 196, trainingloss: 0.0074496664163819035 | validation loss: 0.008028078784519796
Epoch: 197, trainingloss: 0.00756181135243595 | validation loss: 0.008115262298049547
Epoch: 198, trainingloss: 0.007707853617251189 | validation loss: 0.00823285206889183
Epoch: 199, trainingloss: 0.007990613611078216 | validation loss: 0.008495884939916383
Epoch: 200, trainingloss: 0.008686472952128826 | validation loss: 0.00911005058523808
Epoch: 201, trainingloss: 0.0070177160165285045 | validation loss: 0.00756697134398467
Epoch: 202, trainingloss: 0.007461817933360996 | validation loss: 0.007967687514387216
Epoch: 203, trainingloss: 0.008706483857740819 | validation loss: 0.009180320267986276
Epoch: 204, trainingloss: 0.007147692607697982 | validation loss: 0.007703503569541142
Epoch: 205, trainingloss: 0.007689026415043409 | validation loss: 0.008181740137997287
Epoch: 206, trainingloss: 0.006870912188619397 | validation loss: 0.007428018306330085
Epoch: 207, trainingloss: 0.00737802264432512 | validation loss: 0.007890438791278475
Epoch: 208, trainingloss: 0.007428391409540507 | validation loss: 0.007935983507959935
Epoch: 209, trainingloss: 0.007636488374045658 | validation loss: 0.008130016413706687
Epoch: 210, trainingloss: 0.007980144493025918 | validation loss: 0.008516121083060985
Epoch: 211, trainingloss: 0.007580672520124204 | validation loss: 0.008097146610907952
Epoch: 212, trainingloss: 0.007663316676468628 | validation loss: 0.008160074487787447
Epoch: 213, trainingloss: 0.007358556593874311 | validation loss: 0.007852718503567653
Epoch: 214, trainingloss: 0.007113105660517016 | validation loss: 0.00766819181825962
Epoch: 215, trainingloss: 0.007789185866206326 | validation loss: 0.008233507560069126
Epoch: 216, trainingloss: 0.0073334806862921965 | validation loss: 0.007881466547785893
Epoch: 217, trainingloss: 0.007706916867604925 | validation loss: 0.008234252843624333
Epoch: 218, trainingloss: 0.006831699736065009 | validation loss: 0.007401292038314176
Epoch: 219, trainingloss: 0.007664089152899665 | validation loss: 0.008166744240083802
Epoch: 220, trainingloss: 0.007336753137294639 | validation loss: 0.007824460853653263
Epoch: 221, trainingloss: 0.0073643541161820866 | validation loss: 0.007904329321452035
Epoch: 222, trainingloss: 0.008312680951602895 | validation loss: 0.008807805090434462
Epoch: 223, trainingloss: 0.007799742224900692 | validation loss: 0.008306956104780182
Epoch: 224, trainingloss: 0.007937815936207113 | validation loss: 0.008431254117337496
Epoch: 225, trainingloss: 0.007766896279961847 | validation loss: 0.008303006073272891
Epoch: 226, trainingloss: 0.006889795646110378 | validation loss: 0.007478163625689869
Epoch: 227, trainingloss: 0.008051318700558559 | validation loss: 0.008488017335542143
Epoch: 228, trainingloss: 0.007832872958559438 | validation loss: 0.008322440660697757
Epoch: 229, trainingloss: 0.007132173090579432 | validation loss: 0.007669693092806681
Epoch: 230, trainingloss: 0.008138878649695633 | validation loss: 0.008599301083575978
Epoch: 231, trainingloss: 0.008029000263391919 | validation loss: 0.00849914907260478
Epoch: 232, trainingloss: 0.007935499159942835 | validation loss: 0.00840545735703942
Epoch: 233, trainingloss: 0.007198891751519538 | validation loss: 0.0077052649544254205
Epoch: 234, trainingloss: 0.008722651472214437 | validation loss: 0.009154452480851075
Epoch: 235, trainingloss: 0.007812805391194144 | validation loss: 0.008275893615337412
Epoch: 236, trainingloss: 0.008252573119356276 | validation loss: 0.00871783702518401
Epoch: 237, trainingloss: 0.007730330979630112 | validation loss: 0.00824032262503072
Epoch: 238, trainingloss: 0.007554014270090104 | validation loss: 0.008021200497544168
Epoch: 239, trainingloss: 0.007002529538193811 | validation loss: 0.0075405314691789046
Epoch: 240, trainingloss: 0.007272661336332577 | validation loss: 0.007836674619896658
Epoch: 241, trainingloss: 0.007407534433170301 | validation loss: 0.007890730574045915
Epoch: 242, trainingloss: 0.007734714368875099 | validation loss: 0.008207670224530023
Epoch: 243, trainingloss: 0.007586613992075968 | validation loss: 0.008065751005935193
Epoch: 244, trainingloss: 0.007308618977073843 | validation loss: 0.007808911248931481
Epoch: 245, trainingloss: 0.008579196558479621 | validation loss: 0.008980956579793873
Epoch: 246, trainingloss: 0.007939467783618296 | validation loss: 0.008393199717588035
Epoch: 247, trainingloss: 0.009252593325444581 | validation loss: 0.009619221404853748
Epoch: 248, trainingloss: 0.007661222052810959 | validation loss: 0.008187657347093846
Epoch: 249, trainingloss: 0.008189173271995528 | validation loss: 0.00861555696572903
Epoch: 250, trainingloss: 0.008278049522528521 | validation loss: 0.008736696708650866
Epoch: 251, trainingloss: 0.00714214421089342 | validation loss: 0.0076477033724403455
Epoch: 252, trainingloss: 0.007296015405798788 | validation loss: 0.0077932612429565925
Epoch: 253, trainingloss: 0.006823723096602001 | validation loss: 0.007340179018071936
Epoch: 254, trainingloss: 0.0076388509598704106 | validation loss: 0.008115588947235212
Epoch: 255, trainingloss: 0.007271344084850726 | validation loss: 0.007738158329076012
Epoch: 256, trainingloss: 0.0065912810001337845 | validation loss: 0.007127498859386586
Epoch: 257, trainingloss: 0.006825970596698434 | validation loss: 0.00732908708545086
Epoch: 258, trainingloss: 0.00762367149869362 | validation loss: 0.008104402581964194
Epoch: 259, trainingloss: 0.007218650084468122 | validation loss: 0.007701971676602241
Epoch: 260, trainingloss: 0.007062165567165641 | validation loss: 0.007591839054060082
Epoch: 261, trainingloss: 0.006474359186394666 | validation loss: 0.0070257823340168475
Epoch: 262, trainingloss: 0.007529832002366942 | validation loss: 0.00799743619542318
Epoch: 263, trainingloss: 0.007275949403821209 | validation loss: 0.007772730778219759
Epoch: 264, trainingloss: 0.0064851655810995385 | validation loss: 0.007064409544900914
Epoch: 265, trainingloss: 0.007683333266410015 | validation loss: 0.008126734421265165
Epoch: 266, trainingloss: 0.007824922235425394 | validation loss: 0.00826785127586718
Epoch: 267, trainingloss: 0.007482864099474906 | validation loss: 0.007936646988938352
Epoch: 268, trainingloss: 0.007073715504405879 | validation loss: 0.007621291078727136
Epoch: 269, trainingloss: 0.006198450408957281 | validation loss: 0.006782997349739523
Epoch: 270, trainingloss: 0.007553267472941519 | validation loss: 0.00801061352140228
Epoch: 271, trainingloss: 0.006614296898239899 | validation loss: 0.007187953428838732
Epoch: 272, trainingloss: 0.0070468623932780005 | validation loss: 0.007566291131156939
Epoch: 273, trainingloss: 0.006840601313949357 | validation loss: 0.007345007755281367
Epoch: 274, trainingloss: 0.006763264959101312 | validation loss: 0.007257882411558579
Epoch: 275, trainingloss: 0.00784053397366875 | validation loss: 0.008274246812197081
Epoch: 276, trainingloss: 0.006931488442871197 | validation loss: 0.007423694805017965
Epoch: 277, trainingloss: 0.007700530326997099 | validation loss: 0.00817216596612481
Epoch: 278, trainingloss: 0.008120248565591431 | validation loss: 0.008538829843037027
Epoch: 279, trainingloss: 0.007112604835350604 | validation loss: 0.007593928466689488
Epoch: 280, trainingloss: 0.006922944486538907 | validation loss: 0.0074140952197894105
Epoch: 281, trainingloss: 0.006964412539009055 | validation loss: 0.007484568009026438
Epoch: 282, trainingloss: 0.006900197080289476 | validation loss: 0.0074207012430735336
Epoch: 283, trainingloss: 0.006922133097200051 | validation loss: 0.007435737410548753
Epoch: 284, trainingloss: 0.007100172307132268 | validation loss: 0.007627330698155486
Epoch: 285, trainingloss: 0.007519189312383102 | validation loss: 0.007950957371040615
Epoch: 286, trainingloss: 0.00709115514934407 | validation loss: 0.007630401876022952
Epoch: 287, trainingloss: 0.006647530816302745 | validation loss: 0.007189127674490048
Epoch: 288, trainingloss: 0.006912498520567715 | validation loss: 0.007391342832681948
Epoch: 289, trainingloss: 0.007126995480258033 | validation loss: 0.007656961014860028
Epoch: 290, trainingloss: 0.007101463336915945 | validation loss: 0.0076082858581739184
Epoch: 291, trainingloss: 0.006793643863424919 | validation loss: 0.007312063045357968
Epoch: 292, trainingloss: 0.007125850236775551 | validation loss: 0.007593757905258567
Epoch: 293, trainingloss: 0.006807387751009798 | validation loss: 0.00734393776719881
Epoch: 294, trainingloss: 0.006989941460657357 | validation loss: 0.00752282512017585
Epoch: 295, trainingloss: 0.006494649096457822 | validation loss: 0.007055477780128407
Epoch: 296, trainingloss: 0.007900647063259993 | validation loss: 0.008310704906768059
Epoch: 297, trainingloss: 0.007470253712659329 | validation loss: 0.007936024830929906
Epoch: 298, trainingloss: 0.006094534286794859 | validation loss: 0.006663821732514353
Epoch: 299, trainingloss: 0.006634374701313701 | validation loss: 0.007148854934737379
Epoch: 300, trainingloss: 0.006150430961938898 | validation loss: 0.006735043796612639
Epoch: 301, trainingloss: 0.006636571026360898 | validation loss: 0.0072072634416415525
Epoch: 302, trainingloss: 0.005967274614713274 | validation loss: 0.006572655671628382
Epoch: 303, trainingloss: 0.006456789006931234 | validation loss: 0.007026305341375796
Epoch: 304, trainingloss: 0.006600187310081501 | validation loss: 0.0071072689192561486
Epoch: 305, trainingloss: 0.007049641475110664 | validation loss: 0.007523147070758141
Epoch: 306, trainingloss: 0.006856015274758538 | validation loss: 0.007377503889867113
Epoch: 307, trainingloss: 0.006795550611655947 | validation loss: 0.007332178196456638
Epoch: 308, trainingloss: 0.007102984457608267 | validation loss: 0.00756990627186191
Epoch: 309, trainingloss: 0.006309576889641092 | validation loss: 0.006830055837653697
Epoch: 310, trainingloss: 0.006842038455632078 | validation loss: 0.007326960673994674
Epoch: 311, trainingloss: 0.006291343462362658 | validation loss: 0.0068754456058805
Epoch: 312, trainingloss: 0.006354449667856311 | validation loss: 0.0068833677355819075
Epoch: 313, trainingloss: 0.00670408499438486 | validation loss: 0.007228489393677957
Epoch: 314, trainingloss: 0.006611308682401798 | validation loss: 0.00709241623814662
Epoch: 315, trainingloss: 0.006220110227634748 | validation loss: 0.0067574950050277695
Epoch: 316, trainingloss: 0.0067936065793843 | validation loss: 0.007283744361833692
Epoch: 317, trainingloss: 0.0060273755870186175 | validation loss: 0.006574972384890788
Epoch: 318, trainingloss: 0.006506873938238347 | validation loss: 0.007028937688893199
Epoch: 319, trainingloss: 0.006300909675068414 | validation loss: 0.006845191006169478
Epoch: 320, trainingloss: 0.006573805209420995 | validation loss: 0.007096306786135882
Epoch: 321, trainingloss: 0.006899499526924504 | validation loss: 0.007376419075610033
Epoch: 322, trainingloss: 0.006434110773791869 | validation loss: 0.006974166914045741
Epoch: 323, trainingloss: 0.0061378794149083175 | validation loss: 0.0066743669763150324
Epoch: 324, trainingloss: 0.00595268644657958 | validation loss: 0.0065163030028087
Epoch: 325, trainingloss: 0.005683860228708967 | validation loss: 0.006297743569043065
Epoch: 326, trainingloss: 0.006668267352436152 | validation loss: 0.0071797802893745185
Epoch: 327, trainingloss: 0.006144232711718933 | validation loss: 0.0066631936082873384
Epoch: 328, trainingloss: 0.00600852845552851 | validation loss: 0.006542873878743742
Epoch: 329, trainingloss: 0.006175683986920338 | validation loss: 0.00670124030413892
Epoch: 330, trainingloss: 0.00819481406366398 | validation loss: 0.008558190330725924
Epoch: 331, trainingloss: 0.006936793852495166 | validation loss: 0.00740249401927478
Epoch: 332, trainingloss: 0.007385097028149524 | validation loss: 0.007821571820990508
Epoch: 333, trainingloss: 0.006274282990261754 | validation loss: 0.0068220657762702724
Epoch: 334, trainingloss: 0.006895546615017238 | validation loss: 0.00739323115256835
Epoch: 335, trainingloss: 0.0063977829113725454 | validation loss: 0.0069033309018896845
Epoch: 336, trainingloss: 0.006434744358889848 | validation loss: 0.006952940452072117
Epoch: 337, trainingloss: 0.005863689398959937 | validation loss: 0.006441227826695847
Epoch: 338, trainingloss: 0.006163541181456172 | validation loss: 0.006712942414653062
Epoch: 339, trainingloss: 0.0074327297445469665 | validation loss: 0.007874173437525145
Epoch: 340, trainingloss: 0.006351885309152579 | validation loss: 0.0068696697029166035
Epoch: 341, trainingloss: 0.0060604172422173445 | validation loss: 0.0066235439371127814
Epoch: 342, trainingloss: 0.006294553504453429 | validation loss: 0.006855765157744389
Epoch: 343, trainingloss: 0.006544902159170356 | validation loss: 0.007032356856857211
Epoch: 344, trainingloss: 0.006476796602554225 | validation loss: 0.007016664895788719
Epoch: 345, trainingloss: 0.005932278427852039 | validation loss: 0.0064901389809128044
Epoch: 346, trainingloss: 0.006108510725185235 | validation loss: 0.006650251689999548
Epoch: 347, trainingloss: 0.0076273759529199 | validation loss: 0.008046979039906373
Epoch: 348, trainingloss: 0.0064764245413679875 | validation loss: 0.006994035221532272
Epoch: 349, trainingloss: 0.006086131553185987 | validation loss: 0.006640408770029873
Epoch: 350, trainingloss: 0.006384999724662303 | validation loss: 0.006892450694934923
Epoch: 351, trainingloss: 0.006478329930731727 | validation loss: 0.0069642439953526035
Epoch: 352, trainingloss: 0.005866671644199737 | validation loss: 0.00643764846527244
Epoch: 353, trainingloss: 0.006187835364288577 | validation loss: 0.006714091285669502
Epoch: 354, trainingloss: 0.006231665493965349 | validation loss: 0.006757741483158211
Epoch: 355, trainingloss: 0.006412833168969325 | validation loss: 0.006915671384347573
Epoch: 356, trainingloss: 0.00567803765152034 | validation loss: 0.0062657287905723705
Epoch: 357, trainingloss: 0.006443221012606733 | validation loss: 0.006974773434321998
Epoch: 358, trainingloss: 0.00640291597895401 | validation loss: 0.006905193851833808
Epoch: 359, trainingloss: 0.005900391719268379 | validation loss: 0.0064979680983598895
Epoch: 360, trainingloss: 0.0068432925749237795 | validation loss: 0.007330412352292985
Epoch: 361, trainingloss: 0.006523285937027461 | validation loss: 0.007021230387060742
Epoch: 362, trainingloss: 0.007395259664689762 | validation loss: 0.00782448402208401
Epoch: 363, trainingloss: 0.005807076761884243 | validation loss: 0.0063857353518930625
Epoch: 364, trainingloss: 0.006328735049787897 | validation loss: 0.006875265443037952
Epoch: 365, trainingloss: 0.006213957653940649 | validation loss: 0.006738543078451919
Epoch: 366, trainingloss: 0.00605136208037754 | validation loss: 0.006569866650655848
Epoch: 367, trainingloss: 0.006189050161313729 | validation loss: 0.006723131263543323
Epoch: 368, trainingloss: 0.0061762328180109 | validation loss: 0.006702707339741022
Epoch: 369, trainingloss: 0.006388871025975203 | validation loss: 0.0069057531631374946
Epoch: 370, trainingloss: 0.006114164205565623 | validation loss: 0.006667929102964396
Epoch: 371, trainingloss: 0.006267970964006986 | validation loss: 0.006779450790445901
Epoch: 372, trainingloss: 0.006600177748506277 | validation loss: 0.007096853278044161
Epoch: 373, trainingloss: 0.006686568863238176 | validation loss: 0.007178914739688565
Epoch: 374, trainingloss: 0.0061874323848883275 | validation loss: 0.006725679884018622
Epoch: 375, trainingloss: 0.006082391822933873 | validation loss: 0.006641049432553396
Epoch: 376, trainingloss: 0.0059864438041752595 | validation loss: 0.006549176784297834
Epoch: 377, trainingloss: 0.0058887985465181526 | validation loss: 0.0064237039856276145
Epoch: 378, trainingloss: 0.006415446928529496 | validation loss: 0.0069423885955913036
Epoch: 379, trainingloss: 0.0060864489193068975 | validation loss: 0.0066211115659699045
Epoch: 380, trainingloss: 0.0071817350381279494 | validation loss: 0.0076383575336808835
Epoch: 381, trainingloss: 0.006025349671740112 | validation loss: 0.006551244393278102
Epoch: 382, trainingloss: 0.0057591315098557 | validation loss: 0.00635235451476739
Epoch: 383, trainingloss: 0.00626605375356166 | validation loss: 0.006770215529999483
Epoch: 384, trainingloss: 0.006691629381672027 | validation loss: 0.007166984719333683
Epoch: 385, trainingloss: 0.006546112171814227 | validation loss: 0.007032072840824165
Epoch: 386, trainingloss: 0.00583916231078632 | validation loss: 0.006391865645844181
Epoch: 387, trainingloss: 0.007343312056551952 | validation loss: 0.007810604370868029
Epoch: 388, trainingloss: 0.005647025984706431 | validation loss: 0.006255720950518159
Epoch: 389, trainingloss: 0.005826327219814659 | validation loss: 0.0063975918080242805
Epoch: 390, trainingloss: 0.006791116786359541 | validation loss: 0.007258750496190544
Epoch: 391, trainingloss: 0.006167726137125342 | validation loss: 0.006746689199910453
Epoch: 392, trainingloss: 0.006158247216141595 | validation loss: 0.006674358610180893
Epoch: 393, trainingloss: 0.007884185081766184 | validation loss: 0.00828986120802031
Epoch: 394, trainingloss: 0.006439095376730657 | validation loss: 0.006953240836238092
Epoch: 395, trainingloss: 0.006789782246803125 | validation loss: 0.007287272939833369
Epoch: 396, trainingloss: 0.006463692492727086 | validation loss: 0.0069513687907382885
Epoch: 397, trainingloss: 0.0059690948440944075 | validation loss: 0.006527486282879911
Epoch: 398, trainingloss: 0.006541218452646409 | validation loss: 0.007027855564171216
Epoch: 399, trainingloss: 0.006562786391020864 | validation loss: 0.007060114937947177
Epoch: 400, trainingloss: 0.006631567113402306 | validation loss: 0.007154854977722434
Epoch: 401, trainingloss: 0.006112344588279795 | validation loss: 0.006660929621166275
Epoch: 402, trainingloss: 0.006078991752652397 | validation loss: 0.006621637361761302
Epoch: 403, trainingloss: 0.006359700147967219 | validation loss: 0.0068717662533351155
Epoch: 404, trainingloss: 0.006109324711545505 | validation loss: 0.006640820161371815
Epoch: 405, trainingloss: 0.005796096210731639 | validation loss: 0.006334478804553778
Epoch: 406, trainingloss: 0.005930864978788699 | validation loss: 0.0064946549794982
Epoch: 407, trainingloss: 0.0065313838580401155 | validation loss: 0.007040624658353852
Epoch: 408, trainingloss: 0.006989966080342288 | validation loss: 0.007455105989173014
Epoch: 409, trainingloss: 0.005974520611826476 | validation loss: 0.006527350997230318
Epoch: 410, trainingloss: 0.007243087339788082 | validation loss: 0.0076992490276332065
Epoch: 411, trainingloss: 0.0059213836443760505 | validation loss: 0.006454250502173787
Epoch: 412, trainingloss: 0.005995259563828769 | validation loss: 0.006503140168825968
Epoch: 413, trainingloss: 0.005349326347092252 | validation loss: 0.0059750678866344374
Epoch: 414, trainingloss: 0.006393459015442922 | validation loss: 0.006910741337272768
Epoch: 415, trainingloss: 0.007007866125299873 | validation loss: 0.007439022892604457
Epoch: 416, trainingloss: 0.006538236950682673 | validation loss: 0.007064447768908536
Epoch: 417, trainingloss: 0.006239366215788629 | validation loss: 0.00671106360942083
Epoch: 418, trainingloss: 0.006799761569203672 | validation loss: 0.007292383123262216
Epoch: 419, trainingloss: 0.006130537397752924 | validation loss: 0.006657518647727682
Epoch: 420, trainingloss: 0.006098183288210261 | validation loss: 0.00663808644959029
Epoch: 421, trainingloss: 0.006126673804846919 | validation loss: 0.006643366462435523
Epoch: 422, trainingloss: 0.006362974132106649 | validation loss: 0.006896993566526727
Epoch: 423, trainingloss: 0.006594443763469651 | validation loss: 0.007073480121713721
Epoch: 424, trainingloss: 0.005947309696409294 | validation loss: 0.0064657828909081925
Epoch: 425, trainingloss: 0.006162004095963982 | validation loss: 0.006676247439718651
Epoch: 426, trainingloss: 0.006685085158024299 | validation loss: 0.007173295964348439
Epoch: 427, trainingloss: 0.006518711010547122 | validation loss: 0.007051961268064292
Epoch: 428, trainingloss: 0.007527125331224145 | validation loss: 0.007982945318968458
Epoch: 429, trainingloss: 0.006008039076777019 | validation loss: 0.006536678548293259
Epoch: 430, trainingloss: 0.005871175240042487 | validation loss: 0.006412137537567702
Epoch: 431, trainingloss: 0.007409823375205363 | validation loss: 0.007856096491983667
Epoch: 432, trainingloss: 0.007005242669024466 | validation loss: 0.007445209358863588
Epoch: 433, trainingloss: 0.006892474627730925 | validation loss: 0.007343113762080958
Epoch: 434, trainingloss: 0.005524704507436516 | validation loss: 0.006106912246309994
Epoch: 435, trainingloss: 0.005756458636896325 | validation loss: 0.006283142985796827
Epoch: 436, trainingloss: 0.0060482148810451835 | validation loss: 0.006565342021571706
Epoch: 437, trainingloss: 0.006074272549831857 | validation loss: 0.006588751139663986
Epoch: 438, trainingloss: 0.0058742159914816836 | validation loss: 0.006449336083347606
Epoch: 439, trainingloss: 0.006467980032469563 | validation loss: 0.006944151866634678
Epoch: 440, trainingloss: 0.00570336914938119 | validation loss: 0.006266254999346255
Epoch: 441, trainingloss: 0.007108115981969414 | validation loss: 0.007535619600849719
Epoch: 442, trainingloss: 0.005976315842754136 | validation loss: 0.006477003190536433
Epoch: 443, trainingloss: 0.007620306093016276 | validation loss: 0.008073901319520146
Epoch: 444, trainingloss: 0.006933912477266558 | validation loss: 0.0074324956989944456
Epoch: 445, trainingloss: 0.006845201434942928 | validation loss: 0.007335701892871069
Epoch: 446, trainingloss: 0.0056884160450421635 | validation loss: 0.006245336297223752
Epoch: 447, trainingloss: 0.006386813828338768 | validation loss: 0.006864496363578885
Epoch: 448, trainingloss: 0.006628201830910868 | validation loss: 0.007097966999467966
Epoch: 449, trainingloss: 0.006245222348474936 | validation loss: 0.0067547073783402484
Epoch: 450, trainingloss: 0.007608327510485108 | validation loss: 0.008033294063372644
Epoch: 451, trainingloss: 0.006482893574502613 | validation loss: 0.006989163602989974
Epoch: 452, trainingloss: 0.005530599906997222 | validation loss: 0.0060914366528987225
Epoch: 453, trainingloss: 0.006188169004645847 | validation loss: 0.006697838730280333
Epoch: 454, trainingloss: 0.006851329552206405 | validation loss: 0.007319837167235741
Epoch: 455, trainingloss: 0.005761708498977707 | validation loss: 0.006304578451948444
Epoch: 456, trainingloss: 0.005652255058448458 | validation loss: 0.006203066432402555
Epoch: 457, trainingloss: 0.006571359305426888 | validation loss: 0.007073598077807816
Epoch: 458, trainingloss: 0.006522219529353332 | validation loss: 0.006974982978836508
Epoch: 459, trainingloss: 0.0065846184695637815 | validation loss: 0.007052827312024064
Epoch: 460, trainingloss: 0.006360382905443979 | validation loss: 0.006844525424992392
Epoch: 461, trainingloss: 0.006747441341869148 | validation loss: 0.007199536662767917
Epoch: 462, trainingloss: 0.0073658679923917485 | validation loss: 0.0077656442585176365
Epoch: 463, trainingloss: 0.006798756035150191 | validation loss: 0.007273868020188205
Epoch: 464, trainingloss: 0.006617296834082552 | validation loss: 0.007128760339242264
Epoch: 465, trainingloss: 0.006150281658004839 | validation loss: 0.006658012287194086
Epoch: 466, trainingloss: 0.006176639814630357 | validation loss: 0.006694702309628624
Epoch: 467, trainingloss: 0.006568581773169518 | validation loss: 0.007051738678941942
Epoch: 468, trainingloss: 0.0063932267513399635 | validation loss: 0.006873674408636708
Epoch: 469, trainingloss: 0.0063834820905489175 | validation loss: 0.006847565335271506
Epoch: 470, trainingloss: 0.007030356356367574 | validation loss: 0.00744566066127752
Epoch: 471, trainingloss: 0.006567532535731371 | validation loss: 0.007022902784242882
Epoch: 472, trainingloss: 0.005774781319447955 | validation loss: 0.006319353699131547
Epoch: 473, trainingloss: 0.00700381350121379 | validation loss: 0.007458315249805091
Epoch: 474, trainingloss: 0.007026059005534061 | validation loss: 0.007483986853335589
Epoch: 475, trainingloss: 0.0062470968882760635 | validation loss: 0.006788562641229934
Epoch: 476, trainingloss: 0.0066008898807638616 | validation loss: 0.007052138350370275
Epoch: 477, trainingloss: 0.006510244708219842 | validation loss: 0.006994807258676668
Epoch: 478, trainingloss: 0.006263827095178162 | validation loss: 0.00675814970618971
Epoch: 479, trainingloss: 0.005922653516102365 | validation loss: 0.0064508607226947375
Epoch: 480, trainingloss: 0.005944873449067489 | validation loss: 0.0064922408887879545
Epoch: 481, trainingloss: 0.006702783157325914 | validation loss: 0.007207971221341671
Epoch: 482, trainingloss: 0.00638295572122481 | validation loss: 0.006841764651184314
Epoch: 483, trainingloss: 0.007721934878873105 | validation loss: 0.008107864070093593
Epoch: 484, trainingloss: 0.006216580684623389 | validation loss: 0.006701295844357355
Epoch: 485, trainingloss: 0.0055842297703279885 | validation loss: 0.006143009185487566
Epoch: 486, trainingloss: 0.006908069147227232 | validation loss: 0.00737041973954295
Epoch: 487, trainingloss: 0.005825449091084313 | validation loss: 0.0063498264065098495
Epoch: 488, trainingloss: 0.006032491566954718 | validation loss: 0.006538391275944634
Epoch: 489, trainingloss: 0.00595415269039674 | validation loss: 0.006482158030884983
Epoch: 490, trainingloss: 0.006611345258223992 | validation loss: 0.007094039366233494
Epoch: 491, trainingloss: 0.006197094303227414 | validation loss: 0.006688100724055332
Epoch: 492, trainingloss: 0.005437672838244496 | validation loss: 0.00598778746205855
Epoch: 493, trainingloss: 0.005435705041909313 | validation loss: 0.006038604195452772
Epoch: 494, trainingloss: 0.005814514411099029 | validation loss: 0.006350021858188898
Epoch: 495, trainingloss: 0.006639836860796022 | validation loss: 0.00713381416742115
Epoch: 496, trainingloss: 0.006356737617553762 | validation loss: 0.006857601628732564
Epoch: 497, trainingloss: 0.007346567930718644 | validation loss: 0.007801503390947592
Epoch: 498, trainingloss: 0.00594222771534614 | validation loss: 0.006484687509855509
Epoch: 499, trainingloss: 0.006334391690066199 | validation loss: 0.006813174477458395
Epoch: 500, trainingloss: 0.007266902308357172 | validation loss: 0.007686962881751978
Epoch: 501, trainingloss: 0.007020876235736961 | validation loss: 0.007495310758908728
Epoch: 502, trainingloss: 0.006941367614935753 | validation loss: 0.0073597821145254955
Epoch: 503, trainingloss: 0.006086425626757546 | validation loss: 0.00658766968725873
Epoch: 504, trainingloss: 0.006149750163325813 | validation loss: 0.0066790351679775544
Epoch: 505, trainingloss: 0.006912614026146574 | validation loss: 0.007373736286741838
Epoch: 506, trainingloss: 0.006108440664992763 | validation loss: 0.006639615503067871
Epoch: 507, trainingloss: 0.006400320065829787 | validation loss: 0.00690122591963659
Epoch: 508, trainingloss: 0.0056282320463241905 | validation loss: 0.00617308307549315
Epoch: 509, trainingloss: 0.007132360043159189 | validation loss: 0.007588566736801897
Epoch: 510, trainingloss: 0.006863311758612684 | validation loss: 0.007333166295767914
Epoch: 511, trainingloss: 0.007141155447320907 | validation loss: 0.007587978054371783
Epoch: 512, trainingloss: 0.005947673274595804 | validation loss: 0.006467024050838829