Epoch: 0, trainingloss: 1.7562293881121427 | validation loss: 1.7520427667608514
Epoch: 1, trainingloss: 0.19790008834436615 | validation loss: 0.19663048345553338
Epoch: 2, trainingloss: 0.1552976486995082 | validation loss: 0.15519117698720536
Epoch: 3, trainingloss: 0.14003006177247715 | validation loss: 0.13964429901225453
Epoch: 4, trainingloss: 0.12738607810402455 | validation loss: 0.12721333421627581
Epoch: 5, trainingloss: 0.11872302051856609 | validation loss: 0.11880324072213434
Epoch: 6, trainingloss: 0.09854741724324863 | validation loss: 0.09931440721614657
Epoch: 7, trainingloss: 0.09824815109776762 | validation loss: 0.09917480684966413
Epoch: 8, trainingloss: 0.09102549636571713 | validation loss: 0.0918374553250124
Epoch: 9, trainingloss: 0.08539480477461801 | validation loss: 0.08660064142144323
Epoch: 10, trainingloss: 0.07914800032278217 | validation loss: 0.08033645246400929
Epoch: 11, trainingloss: 0.07484708603577259 | validation loss: 0.07603118438932145
Epoch: 12, trainingloss: 0.07571897501769485 | validation loss: 0.07661613159109427
Epoch: 13, trainingloss: 0.07040946679178212 | validation loss: 0.0713344329931527
Epoch: 14, trainingloss: 0.07032810622883547 | validation loss: 0.07114375668110577
Epoch: 15, trainingloss: 0.06082108958215922 | validation loss: 0.061738747175571734
Epoch: 16, trainingloss: 0.05697921631508584 | validation loss: 0.05786343967705169
Epoch: 17, trainingloss: 0.05772562363908119 | validation loss: 0.058419778150872535
Epoch: 18, trainingloss: 0.057184354842063544 | validation loss: 0.05796819954247419
Epoch: 19, trainingloss: 0.055921075029820806 | validation loss: 0.05671958667347742
Epoch: 20, trainingloss: 0.05025620050097093 | validation loss: 0.05101476926167594
Epoch: 21, trainingloss: 0.05178041308338441 | validation loss: 0.05259300789980589
Epoch: 22, trainingloss: 0.054260475392368675 | validation loss: 0.054958376024617
Epoch: 23, trainingloss: 0.04654872132341585 | validation loss: 0.047558604302509654
Epoch: 24, trainingloss: 0.04665450523046476 | validation loss: 0.0473494117882943
Epoch: 25, trainingloss: 0.04464618980169332 | validation loss: 0.0452899450498728
Epoch: 26, trainingloss: 0.04588772287725492 | validation loss: 0.04644126300394281
Epoch: 27, trainingloss: 0.04300104105310347 | validation loss: 0.043820694568816265
Epoch: 28, trainingloss: 0.04782161192104205 | validation loss: 0.04845174726914685
Epoch: 29, trainingloss: 0.04199136508507038 | validation loss: 0.04266203983221656
Epoch: 30, trainingloss: 0.04245605154828362 | validation loss: 0.04322983652700519
Epoch: 31, trainingloss: 0.041773580896367506 | validation loss: 0.042560898653784957
Epoch: 32, trainingloss: 0.03925530930508889 | validation loss: 0.03985132196722067
Epoch: 33, trainingloss: 0.03915146324296798 | validation loss: 0.0397905998792883
Epoch: 34, trainingloss: 0.03828023621425702 | validation loss: 0.038832729552019205
Epoch: 35, trainingloss: 0.04371707427359114 | validation loss: 0.04409406115372184
Epoch: 36, trainingloss: 0.04110906238029977 | validation loss: 0.04175660870771081
Epoch: 37, trainingloss: 0.03711160564840512 | validation loss: 0.037950335802596234
Epoch: 38, trainingloss: 0.038417302209304796 | validation loss: 0.039250206547998184
Epoch: 39, trainingloss: 0.03451273705914957 | validation loss: 0.03531562035614544
Epoch: 40, trainingloss: 0.038384098207431626 | validation loss: 0.03882921636908625
Epoch: 41, trainingloss: 0.03555212684321929 | validation loss: 0.03626453781482258
Epoch: 42, trainingloss: 0.035852553808939425 | validation loss: 0.03669999333279535
Epoch: 43, trainingloss: 0.03682283780307973 | validation loss: 0.03730814485175037
Epoch: 44, trainingloss: 0.035824111851641 | validation loss: 0.03645431168980594
Epoch: 45, trainingloss: 0.03602723232584203 | validation loss: 0.03663468234201528
Epoch: 46, trainingloss: 0.03346796926422838 | validation loss: 0.034113890150583595
Epoch: 47, trainingloss: 0.03774410699410752 | validation loss: 0.038304865490654524
Epoch: 48, trainingloss: 0.03204060800721752 | validation loss: 0.03286431138168427
Epoch: 49, trainingloss: 0.03422392735659028 | validation loss: 0.03483571490365322
Epoch: 50, trainingloss: 0.032812880864143995 | validation loss: 0.03349163000848266
Epoch: 51, trainingloss: 0.031198403807397277 | validation loss: 0.03185252976805397
Epoch: 52, trainingloss: 0.031206026636238993 | validation loss: 0.03177070488255025
Epoch: 53, trainingloss: 0.03251854089536622 | validation loss: 0.0332022641965144
Epoch: 54, trainingloss: 0.02900504162977071 | validation loss: 0.029712988606205887
Epoch: 55, trainingloss: 0.03494915297689689 | validation loss: 0.03554950141795892
Epoch: 56, trainingloss: 0.028926660775012044 | validation loss: 0.029789882947966372
Epoch: 57, trainingloss: 0.029856776674754792 | validation loss: 0.03052227207783535
Epoch: 58, trainingloss: 0.03397912671603879 | validation loss: 0.034592920774646506
Epoch: 59, trainingloss: 0.030521237353988602 | validation loss: 0.03108720148539038
Epoch: 60, trainingloss: 0.029769947234041593 | validation loss: 0.03029753563004714
Epoch: 61, trainingloss: 0.03157116901877951 | validation loss: 0.03214293237505778
Epoch: 62, trainingloss: 0.02860109831656566 | validation loss: 0.02926675254962969
Epoch: 63, trainingloss: 0.029950563996637605 | validation loss: 0.030585114091219317
Epoch: 64, trainingloss: 0.02877402912412753 | validation loss: 0.02932388318823834
Epoch: 65, trainingloss: 0.03210687707095936 | validation loss: 0.03271046881404608
Epoch: 66, trainingloss: 0.029214207183622627 | validation loss: 0.02984707777213669
Epoch: 67, trainingloss: 0.028137570649318423 | validation loss: 0.02886616780696164
Epoch: 68, trainingloss: 0.028305374807312683 | validation loss: 0.028915748740484703
Epoch: 69, trainingloss: 0.02681748709492171 | validation loss: 0.027510204945118237
Epoch: 70, trainingloss: 0.030964482144010565 | validation loss: 0.03129120957289086
Epoch: 71, trainingloss: 0.03542417228512199 | validation loss: 0.03583775484861385
Epoch: 72, trainingloss: 0.03218156712997844 | validation loss: 0.03254726148200233
Epoch: 73, trainingloss: 0.028369527935940254 | validation loss: 0.029016306100552787
Epoch: 74, trainingloss: 0.027067349105657963 | validation loss: 0.027618448342410364
Epoch: 75, trainingloss: 0.029536024685886456 | validation loss: 0.029876637959658496
Epoch: 76, trainingloss: 0.026751501511076994 | validation loss: 0.02727103187540721
Epoch: 77, trainingloss: 0.02984606135533784 | validation loss: 0.03020006389619755
Epoch: 78, trainingloss: 0.026305091628660376 | validation loss: 0.02688125287121099
Epoch: 79, trainingloss: 0.02664417095433219 | validation loss: 0.027185599955100555
Epoch: 80, trainingloss: 0.025303013222145516 | validation loss: 0.02583288460228623
Epoch: 81, trainingloss: 0.027603180464530863 | validation loss: 0.028101040549926255
Epoch: 82, trainingloss: 0.028064868630966588 | validation loss: 0.028493093129801948
Epoch: 83, trainingloss: 0.035354100206944725 | validation loss: 0.03559480824171499
Epoch: 84, trainingloss: 0.027228824160799987 | validation loss: 0.02767336062248496
Epoch: 85, trainingloss: 0.02819394792916279 | validation loss: 0.028531073235026447
Epoch: 86, trainingloss: 0.028245569651212485 | validation loss: 0.02871165187716956
Epoch: 87, trainingloss: 0.0287306799733528 | validation loss: 0.02915646981461174
Epoch: 88, trainingloss: 0.025551594783041646 | validation loss: 0.02588965877845359
Epoch: 89, trainingloss: 0.02630439840216467 | validation loss: 0.026700611692522126
Epoch: 90, trainingloss: 0.026213542250998183 | validation loss: 0.02661607753186838
Epoch: 91, trainingloss: 0.027512627925357146 | validation loss: 0.027836074960701705
Epoch: 92, trainingloss: 0.024359725058658604 | validation loss: 0.024719522422379625
Epoch: 93, trainingloss: 0.026168963158309397 | validation loss: 0.026520405238217637
Epoch: 94, trainingloss: 0.027026004545358865 | validation loss: 0.0274871025389269
Epoch: 95, trainingloss: 0.024680115665075903 | validation loss: 0.025065681318927217
Epoch: 96, trainingloss: 0.029807835832035893 | validation loss: 0.030203231746061692
Epoch: 97, trainingloss: 0.023342221279050376 | validation loss: 0.023755087207515464
Epoch: 98, trainingloss: 0.028233578403804013 | validation loss: 0.02866270253208571
Epoch: 99, trainingloss: 0.02477267915781211 | validation loss: 0.025230243830314435
Epoch: 100, trainingloss: 0.02586431828939647 | validation loss: 0.02628615053727417
Epoch: 101, trainingloss: 0.02490175788550245 | validation loss: 0.02531179081970865
Epoch: 102, trainingloss: 0.02539964496957796 | validation loss: 0.025724824322813856
Epoch: 103, trainingloss: 0.023878806759140572 | validation loss: 0.02424353375681043
Epoch: 104, trainingloss: 0.029389681818914177 | validation loss: 0.02977678682661408
Epoch: 105, trainingloss: 0.02471089127370232 | validation loss: 0.025195641456282662
Epoch: 106, trainingloss: 0.027918992677078598 | validation loss: 0.028260148199463493
Epoch: 107, trainingloss: 0.024297978460842144 | validation loss: 0.024797528499738243
Epoch: 108, trainingloss: 0.025565110625359527 | validation loss: 0.025956141198528543
Epoch: 109, trainingloss: 0.024509824002303823 | validation loss: 0.02488075232458656
Epoch: 110, trainingloss: 0.030744076324815624 | validation loss: 0.031179726824228714
Epoch: 111, trainingloss: 0.027944260532924915 | validation loss: 0.02833984946337296
Epoch: 112, trainingloss: 0.028418216839823783 | validation loss: 0.028798445267936876
Epoch: 113, trainingloss: 0.02730482866265877 | validation loss: 0.027680397922540283
Epoch: 114, trainingloss: 0.021200817340445936 | validation loss: 0.02167444873644819
Epoch: 115, trainingloss: 0.026682809806554447 | validation loss: 0.026973195442847764
Epoch: 116, trainingloss: 0.026645904838554488 | validation loss: 0.027094853514073026
Epoch: 117, trainingloss: 0.025049601867314048 | validation loss: 0.02536626476755862
Epoch: 118, trainingloss: 0.02522895554374728 | validation loss: 0.025731635245077995
Epoch: 119, trainingloss: 0.023821781663509144 | validation loss: 0.024253818600456965
Epoch: 120, trainingloss: 0.02471458380862232 | validation loss: 0.02520861323194203
Epoch: 121, trainingloss: 0.025480438806876886 | validation loss: 0.025941781969313602
Epoch: 122, trainingloss: 0.024216241062870927 | validation loss: 0.02463188954258574
Epoch: 123, trainingloss: 0.022657530237204456 | validation loss: 0.02311468095748387
Epoch: 124, trainingloss: 0.022801765687558317 | validation loss: 0.023180529129468424
Epoch: 125, trainingloss: 0.021259891474920734 | validation loss: 0.02165951315782528
Epoch: 126, trainingloss: 0.021855323499307997 | validation loss: 0.022348121448158717
Epoch: 127, trainingloss: 0.024612312679304766 | validation loss: 0.024884962725451945
Epoch: 128, trainingloss: 0.02697121840168804 | validation loss: 0.027256728227380733
Epoch: 129, trainingloss: 0.025321281197445235 | validation loss: 0.02571876718613282
Epoch: 130, trainingloss: 0.024347440819897412 | validation loss: 0.02463009413699691
Epoch: 131, trainingloss: 0.025128123219184277 | validation loss: 0.025487629712539716
Epoch: 132, trainingloss: 0.026816221796446882 | validation loss: 0.027203368515360114
Epoch: 133, trainingloss: 0.02303962499223246 | validation loss: 0.02341717478627689
Epoch: 134, trainingloss: 0.023956374244887682 | validation loss: 0.024259353220952837
Epoch: 135, trainingloss: 0.02415758120052135 | validation loss: 0.024498274516809894
Epoch: 136, trainingloss: 0.02283433902283519 | validation loss: 0.0232842142967389
Epoch: 137, trainingloss: 0.02333451453594013 | validation loss: 0.023728556570221503
Epoch: 138, trainingloss: 0.024092949806343127 | validation loss: 0.02449496339712011
Epoch: 139, trainingloss: 0.023967651430881004 | validation loss: 0.02445696380976109
Epoch: 140, trainingloss: 0.02564730041409691 | validation loss: 0.0259206186780735
Epoch: 141, trainingloss: 0.025694336692999236 | validation loss: 0.026025857479381666
Epoch: 142, trainingloss: 0.02107385059710526 | validation loss: 0.021637678368489087
Epoch: 143, trainingloss: 0.024480561501929406 | validation loss: 0.02486696875065343
Epoch: 144, trainingloss: 0.02499677058425848 | validation loss: 0.02536893920126327
Epoch: 145, trainingloss: 0.02425846611851676 | validation loss: 0.024662265318265486
Epoch: 146, trainingloss: 0.02638711554815291 | validation loss: 0.026607536955965225
Epoch: 147, trainingloss: 0.021879414538691373 | validation loss: 0.02226207644192579
Epoch: 148, trainingloss: 0.02267515887741305 | validation loss: 0.02301389532275506
Epoch: 149, trainingloss: 0.023156200239459874 | validation loss: 0.023543964769056923
Epoch: 150, trainingloss: 0.022172160858902095 | validation loss: 0.022539467619271402
Epoch: 151, trainingloss: 0.023219466767864672 | validation loss: 0.023634105713343376
Epoch: 152, trainingloss: 0.02337096819715627 | validation loss: 0.023719401599780532
Epoch: 153, trainingloss: 0.024454263695739067 | validation loss: 0.024712528431065122
Epoch: 154, trainingloss: 0.023756902393196697 | validation loss: 0.0241182050446539
Epoch: 155, trainingloss: 0.022101102847139294 | validation loss: 0.022477323922262746
Epoch: 156, trainingloss: 0.02379297272210082 | validation loss: 0.024195333306027755
Epoch: 157, trainingloss: 0.023780195130807914 | validation loss: 0.024232694829264413
Epoch: 158, trainingloss: 0.021938195635234387 | validation loss: 0.02234079986830682
Epoch: 159, trainingloss: 0.02260235191749975 | validation loss: 0.0230803242747507
Epoch: 160, trainingloss: 0.02306842525641816 | validation loss: 0.023464667100048155
Epoch: 161, trainingloss: 0.02112292879112036 | validation loss: 0.021558304935650124
Epoch: 162, trainingloss: 0.024211637097172153 | validation loss: 0.024594277738521027
Epoch: 163, trainingloss: 0.02417649368604026 | validation loss: 0.024543896045503045
Epoch: 164, trainingloss: 0.03167860090950581 | validation loss: 0.031953731464917576
Epoch: 165, trainingloss: 0.02425036552280239 | validation loss: 0.02454744922668275
Epoch: 166, trainingloss: 0.022619455409294192 | validation loss: 0.023045402408189055
Epoch: 167, trainingloss: 0.02353526010180945 | validation loss: 0.023811483902892092
Epoch: 168, trainingloss: 0.022932848786388477 | validation loss: 0.023336704767137475
Epoch: 169, trainingloss: 0.02408321057316187 | validation loss: 0.02438724541120332
Epoch: 170, trainingloss: 0.024240423138800683 | validation loss: 0.024551872251061705
Epoch: 171, trainingloss: 0.02118191839747367 | validation loss: 0.021642268165104023
Epoch: 172, trainingloss: 0.02250522113868534 | validation loss: 0.022878337693485934
Epoch: 173, trainingloss: 0.023775857066292084 | validation loss: 0.02412798574457743
Epoch: 174, trainingloss: 0.02472823777236711 | validation loss: 0.02512686065773843
Epoch: 175, trainingloss: 0.02715011194858882 | validation loss: 0.027568152628602263
Epoch: 176, trainingloss: 0.023073658800304788 | validation loss: 0.02343452662414316
Epoch: 177, trainingloss: 0.023825390367054566 | validation loss: 0.02428135135411436
Epoch: 178, trainingloss: 0.020584094159798994 | validation loss: 0.02108945617417533
Epoch: 179, trainingloss: 0.02317073596584531 | validation loss: 0.0235429773207631
Epoch: 180, trainingloss: 0.027560825611868456 | validation loss: 0.027865141152010005
Epoch: 181, trainingloss: 0.022717726780349976 | validation loss: 0.02301200429865945
Epoch: 182, trainingloss: 0.023740272504270108 | validation loss: 0.024169855845164585
Epoch: 183, trainingloss: 0.023834485365638487 | validation loss: 0.024212002006113773
Epoch: 184, trainingloss: 0.024765165217760052 | validation loss: 0.02513207100744621
Epoch: 185, trainingloss: 0.022658209304999677 | validation loss: 0.023067645792405774
Epoch: 186, trainingloss: 0.02392958384263573 | validation loss: 0.024298343689125323
Epoch: 187, trainingloss: 0.02395921658733937 | validation loss: 0.024308010602714616
Epoch: 188, trainingloss: 0.030028815877834292 | validation loss: 0.030321589229912117
Epoch: 189, trainingloss: 0.02232776165694695 | validation loss: 0.022771256629571027
Epoch: 190, trainingloss: 0.020578953354181462 | validation loss: 0.0209123974840006
Epoch: 191, trainingloss: 0.026115511476208702 | validation loss: 0.02648065186557806
Epoch: 192, trainingloss: 0.02313079835827549 | validation loss: 0.023497235894193964
Epoch: 193, trainingloss: 0.024538948026369734 | validation loss: 0.024857094516318675
Epoch: 194, trainingloss: 0.023142139291965003 | validation loss: 0.02343310323145109
Epoch: 195, trainingloss: 0.023951292501076357 | validation loss: 0.02421153423251998
Epoch: 196, trainingloss: 0.021326164281927063 | validation loss: 0.021674483730038902
Epoch: 197, trainingloss: 0.024840359779190385 | validation loss: 0.025009158090756104
Epoch: 198, trainingloss: 0.0255414943612094 | validation loss: 0.02584080309736152
Epoch: 199, trainingloss: 0.02551789448881811 | validation loss: 0.02577210786015925
Epoch: 200, trainingloss: 0.022050504106124497 | validation loss: 0.022474965324624428
Epoch: 201, trainingloss: 0.020674368500260977 | validation loss: 0.02109431285144313
Epoch: 202, trainingloss: 0.02282986395794381 | validation loss: 0.023191472050206483
Epoch: 203, trainingloss: 0.02354942412954484 | validation loss: 0.023939537213961064
Epoch: 204, trainingloss: 0.023637078829915482 | validation loss: 0.0239074180359239
Epoch: 205, trainingloss: 0.02376201802685942 | validation loss: 0.024108926989728035
Epoch: 206, trainingloss: 0.021830932810728645 | validation loss: 0.02211215358099775
Epoch: 207, trainingloss: 0.022336962756236874 | validation loss: 0.0227685951130004
Epoch: 208, trainingloss: 0.023393673980544406 | validation loss: 0.02373231030638297
Epoch: 209, trainingloss: 0.023878812195616418 | validation loss: 0.024244427562384856
Epoch: 210, trainingloss: 0.022999921884669844 | validation loss: 0.02322577242217238
Epoch: 211, trainingloss: 0.020728046960365672 | validation loss: 0.0211707213958151
Epoch: 212, trainingloss: 0.020954813375438995 | validation loss: 0.021261004271118586
Epoch: 213, trainingloss: 0.02625345070090998 | validation loss: 0.026543316020070592
Epoch: 214, trainingloss: 0.021286646020026865 | validation loss: 0.021717219941151607
Epoch: 215, trainingloss: 0.025235424553583744 | validation loss: 0.025480984427531817
Epoch: 216, trainingloss: 0.025730311593288525 | validation loss: 0.02608429143043535
Epoch: 217, trainingloss: 0.02143502631901621 | validation loss: 0.021837732686243283
Epoch: 218, trainingloss: 0.01924595588719875 | validation loss: 0.01975908457132586
Epoch: 219, trainingloss: 0.023890854445115663 | validation loss: 0.02420285021603267
Epoch: 220, trainingloss: 0.02575734118855736 | validation loss: 0.02607677116165647
Epoch: 221, trainingloss: 0.020588430665578132 | validation loss: 0.020989246193860465
Epoch: 222, trainingloss: 0.025369206845438506 | validation loss: 0.02576076352444303
Epoch: 223, trainingloss: 0.023138967352585336 | validation loss: 0.023507503093748338
Epoch: 224, trainingloss: 0.02191290087778385 | validation loss: 0.02232442358898868
Epoch: 225, trainingloss: 0.022294755847535225 | validation loss: 0.022645480762373615
Epoch: 226, trainingloss: 0.02062642219539587 | validation loss: 0.021060184680926075
Epoch: 227, trainingloss: 0.0237819204162667 | validation loss: 0.024094619843976855
Epoch: 228, trainingloss: 0.021210269042512043 | validation loss: 0.0216396474930258
Epoch: 229, trainingloss: 0.027389188612759244 | validation loss: 0.027775260622134784
Epoch: 230, trainingloss: 0.024615658991916343 | validation loss: 0.024990588782506627
Epoch: 231, trainingloss: 0.0221175142791029 | validation loss: 0.022486899865293647
Epoch: 232, trainingloss: 0.021778166587852418 | validation loss: 0.02216311556278738
Epoch: 233, trainingloss: 0.02210746708970774 | validation loss: 0.022453978305568098
Epoch: 234, trainingloss: 0.023499520689694436 | validation loss: 0.023874811663501617
Epoch: 235, trainingloss: 0.02595627775285211 | validation loss: 0.02628694903269677
Epoch: 236, trainingloss: 0.02048767990346306 | validation loss: 0.020841037268246296
Epoch: 237, trainingloss: 0.02285126377758832 | validation loss: 0.023214122841265443
Epoch: 238, trainingloss: 0.01952159609149415 | validation loss: 0.019943118097227205
Epoch: 239, trainingloss: 0.02215356598793574 | validation loss: 0.022515937703121183
Epoch: 240, trainingloss: 0.02338270424955282 | validation loss: 0.023812122092014845
Epoch: 241, trainingloss: 0.022569279658761057 | validation loss: 0.022906454898040836
Epoch: 242, trainingloss: 0.027620561394775426 | validation loss: 0.027909095194136466
Epoch: 243, trainingloss: 0.021579822074416763 | validation loss: 0.022000838473302572
Epoch: 244, trainingloss: 0.02079498349091073 | validation loss: 0.02119510421340788
Epoch: 245, trainingloss: 0.019853331676499372 | validation loss: 0.02017354181985065
Epoch: 246, trainingloss: 0.0241270047182111 | validation loss: 0.024493212670555563
Epoch: 247, trainingloss: 0.021236475144715942 | validation loss: 0.02168655481437684
Epoch: 248, trainingloss: 0.0221438579721084 | validation loss: 0.022501245974435903
Epoch: 249, trainingloss: 0.02484954632780139 | validation loss: 0.02511186266005686
Epoch: 250, trainingloss: 0.02063511408249114 | validation loss: 0.021012713067522094
Epoch: 251, trainingloss: 0.01985425486785414 | validation loss: 0.020212049601784493
Epoch: 252, trainingloss: 0.02390360814515684 | validation loss: 0.0242448338794484
Epoch: 253, trainingloss: 0.02041009294074681 | validation loss: 0.020852804607678077
Epoch: 254, trainingloss: 0.020441301191998253 | validation loss: 0.020784905130436643
Epoch: 255, trainingloss: 0.02026099110463329 | validation loss: 0.020666475414737977
Epoch: 256, trainingloss: 0.02148270751615678 | validation loss: 0.021783473000758377
Epoch: 257, trainingloss: 0.020631419607427936 | validation loss: 0.02095518293152537
Epoch: 258, trainingloss: 0.02013600510057227 | validation loss: 0.020516706974395442
Epoch: 259, trainingloss: 0.024059517093664193 | validation loss: 0.02444820252206718
Epoch: 260, trainingloss: 0.024526158246836408 | validation loss: 0.024908007909494535
Epoch: 261, trainingloss: 0.02224758531723818 | validation loss: 0.02259505266042499
Epoch: 262, trainingloss: 0.0193182521969988 | validation loss: 0.019797773025339343
Epoch: 263, trainingloss: 0.01832100382755322 | validation loss: 0.018762552864926646
Epoch: 264, trainingloss: 0.02313146106837152 | validation loss: 0.023485344925337204
Epoch: 265, trainingloss: 0.021629597761417495 | validation loss: 0.021987217189483578
Epoch: 266, trainingloss: 0.023273653532260734 | validation loss: 0.02365096006060527
Epoch: 267, trainingloss: 0.021090253957502633 | validation loss: 0.021413788865167722
Epoch: 268, trainingloss: 0.022544257708431065 | validation loss: 0.022916032758948636
Epoch: 269, trainingloss: 0.02036311486692143 | validation loss: 0.02069739862741716
Epoch: 270, trainingloss: 0.02031506674844588 | validation loss: 0.020696363503581654
Epoch: 271, trainingloss: 0.01838993971035281 | validation loss: 0.01877300700895226
Epoch: 272, trainingloss: 0.022880042306502313 | validation loss: 0.023309270799172093
Epoch: 273, trainingloss: 0.023021735162369758 | validation loss: 0.02340385684869024
Epoch: 274, trainingloss: 0.024194059914662343 | validation loss: 0.02460763581159782
Epoch: 275, trainingloss: 0.022905945953309297 | validation loss: 0.02328277373417759
Epoch: 276, trainingloss: 0.02020963018571766 | validation loss: 0.020518300549404175
Epoch: 277, trainingloss: 0.0254269933689154 | validation loss: 0.02570659074123052
Epoch: 278, trainingloss: 0.023176817737838768 | validation loss: 0.02359133361206343
Epoch: 279, trainingloss: 0.02221900453048792 | validation loss: 0.02257372766415945
Epoch: 280, trainingloss: 0.021498154687102346 | validation loss: 0.021759402381595266
Epoch: 281, trainingloss: 0.02706807713526425 | validation loss: 0.0273431902236274
Epoch: 282, trainingloss: 0.01808763859328184 | validation loss: 0.018595905690208615
Epoch: 283, trainingloss: 0.021313086565230434 | validation loss: 0.021632477944986857
Epoch: 284, trainingloss: 0.02310944907319819 | validation loss: 0.02340265836848915
Epoch: 285, trainingloss: 0.022724983362323866 | validation loss: 0.02300169714586033
Epoch: 286, trainingloss: 0.02177807922654182 | validation loss: 0.022130113068360335
Epoch: 287, trainingloss: 0.026596162511472524 | validation loss: 0.026959706596388213
Epoch: 288, trainingloss: 0.023221962560979206 | validation loss: 0.023524520856944252
Epoch: 289, trainingloss: 0.02535865718458467 | validation loss: 0.025704938823629495
Epoch: 290, trainingloss: 0.020647615964419337 | validation loss: 0.020901708220682585
Epoch: 291, trainingloss: 0.023602344677880957 | validation loss: 0.023977884139365677
Epoch: 292, trainingloss: 0.018208097978482725 | validation loss: 0.01860373000135601
Epoch: 293, trainingloss: 0.028536066046663724 | validation loss: 0.028895986511467867
Epoch: 294, trainingloss: 0.022088234883211946 | validation loss: 0.022486461213088706
Epoch: 295, trainingloss: 0.021941485551702243 | validation loss: 0.0223022836917174
Epoch: 296, trainingloss: 0.01995493442915851 | validation loss: 0.02026468446662456
Epoch: 297, trainingloss: 0.025600041260257365 | validation loss: 0.026004419009782016
Epoch: 298, trainingloss: 0.022406953195703086 | validation loss: 0.022725728780806923
Epoch: 299, trainingloss: 0.019953146962268294 | validation loss: 0.020333682946776965
Epoch: 300, trainingloss: 0.018850252955572227 | validation loss: 0.019249931115904947
Epoch: 301, trainingloss: 0.024095754818155193 | validation loss: 0.024444607989520497
Epoch: 302, trainingloss: 0.028782344462598565 | validation loss: 0.02902827648773984
Epoch: 303, trainingloss: 0.02076728786608918 | validation loss: 0.021070574595910614
Epoch: 304, trainingloss: 0.01844570279440161 | validation loss: 0.018779555275013873
Epoch: 305, trainingloss: 0.03133038660317137 | validation loss: 0.03153194629109545
Epoch: 306, trainingloss: 0.02840482329380294 | validation loss: 0.02866235650853361
Epoch: 307, trainingloss: 0.024289055459891032 | validation loss: 0.024598461046370278
Epoch: 308, trainingloss: 0.022386730338369045 | validation loss: 0.022744256542311006
Epoch: 309, trainingloss: 0.01946111966725204 | validation loss: 0.01976803496470784
Epoch: 310, trainingloss: 0.01944337539844616 | validation loss: 0.019821979186111827
Epoch: 311, trainingloss: 0.02703838740696119 | validation loss: 0.0272606688591372
Epoch: 312, trainingloss: 0.02004395337063205 | validation loss: 0.020318568660177627
Epoch: 313, trainingloss: 0.024736894783162374 | validation loss: 0.025086284875180376
Epoch: 314, trainingloss: 0.025123849693206215 | validation loss: 0.02540977945542261
Epoch: 315, trainingloss: 0.01974870732117167 | validation loss: 0.02010584484772038
Epoch: 316, trainingloss: 0.019612324227309175 | validation loss: 0.01995842785270485
Epoch: 317, trainingloss: 0.019114183804642325 | validation loss: 0.019504964419366357
Epoch: 318, trainingloss: 0.019817305641222544 | validation loss: 0.020197137102899106
Epoch: 319, trainingloss: 0.023125317301768207 | validation loss: 0.023400179227228132
Epoch: 320, trainingloss: 0.01874892169313217 | validation loss: 0.019190123715745622
Epoch: 321, trainingloss: 0.01834846311086729 | validation loss: 0.018673294235987476
Epoch: 322, trainingloss: 0.032204925257056746 | validation loss: 0.03242241566277848
Epoch: 323, trainingloss: 0.019022930085877982 | validation loss: 0.01944889533678589
Epoch: 324, trainingloss: 0.02132274696314861 | validation loss: 0.021603967966790275
Epoch: 325, trainingloss: 0.020085561648453275 | validation loss: 0.020373571063198762
Epoch: 326, trainingloss: 0.01792730372973137 | validation loss: 0.018324743434266197
Epoch: 327, trainingloss: 0.021827887024683468 | validation loss: 0.022189792829825222
Epoch: 328, trainingloss: 0.026267836429186172 | validation loss: 0.026625154615117778
Epoch: 329, trainingloss: 0.022552865676197364 | validation loss: 0.022832368220793525
Epoch: 330, trainingloss: 0.022797762123723447 | validation loss: 0.023061756936625637
Epoch: 331, trainingloss: 0.020290224351360412 | validation loss: 0.020753143769610908
Epoch: 332, trainingloss: 0.02154764917686788 | validation loss: 0.021909335825065837
Epoch: 333, trainingloss: 0.020220599128480864 | validation loss: 0.02049496645614136
Epoch: 334, trainingloss: 0.020888002354618046 | validation loss: 0.021255972081393855
Epoch: 335, trainingloss: 0.019107437663559552 | validation loss: 0.01941205189596356
Epoch: 336, trainingloss: 0.020644868422122254 | validation loss: 0.02103330513018379
Epoch: 337, trainingloss: 0.023556211695750926 | validation loss: 0.023937692256578453
Epoch: 338, trainingloss: 0.022154011862274774 | validation loss: 0.022495666785195198
Epoch: 339, trainingloss: 0.019787542220584514 | validation loss: 0.02018289530268115
Epoch: 340, trainingloss: 0.024949594869497896 | validation loss: 0.025222999081057067
Epoch: 341, trainingloss: 0.01922738207470188 | validation loss: 0.01963624901438797
Epoch: 342, trainingloss: 0.026251767729340306 | validation loss: 0.026488862109638727
Epoch: 343, trainingloss: 0.022116751859085338 | validation loss: 0.022490784535243728
Epoch: 344, trainingloss: 0.022000368115408894 | validation loss: 0.022317465587417946
Epoch: 345, trainingloss: 0.01844812229010744 | validation loss: 0.01880687398949569
Epoch: 346, trainingloss: 0.01938408038181716 | validation loss: 0.01968370327616543
Epoch: 347, trainingloss: 0.021652093682881783 | validation loss: 0.021915979508193947
Epoch: 348, trainingloss: 0.027423983937490265 | validation loss: 0.027561149963750843
Epoch: 349, trainingloss: 0.02098328901917511 | validation loss: 0.021328072259640403
Epoch: 350, trainingloss: 0.01937182281474491 | validation loss: 0.019666519440864935
Epoch: 351, trainingloss: 0.02017795724099221 | validation loss: 0.020581973994332176
Epoch: 352, trainingloss: 0.02299334113525399 | validation loss: 0.023186061032592853
Epoch: 353, trainingloss: 0.023707690865120836 | validation loss: 0.023978824515630447
Epoch: 354, trainingloss: 0.023795787073320616 | validation loss: 0.024055275590206596
Epoch: 355, trainingloss: 0.021669906556634453 | validation loss: 0.021901077039289476
Epoch: 356, trainingloss: 0.02019168417011164 | validation loss: 0.020500856972136564
Epoch: 357, trainingloss: 0.020633953629081287 | validation loss: 0.021013728182269632
Epoch: 358, trainingloss: 0.019230797650092998 | validation loss: 0.01959592843529182
Epoch: 359, trainingloss: 0.0199204903502121 | validation loss: 0.020245229047444663
Epoch: 360, trainingloss: 0.017835574724749777 | validation loss: 0.018230030250363613
Epoch: 361, trainingloss: 0.021435449964184415 | validation loss: 0.021822916908220132
Epoch: 362, trainingloss: 0.0231400225323664 | validation loss: 0.023427903906906185
Epoch: 363, trainingloss: 0.01941126572226246 | validation loss: 0.019729547822355222
Epoch: 364, trainingloss: 0.01918469158071491 | validation loss: 0.019448410146283446
Epoch: 365, trainingloss: 0.02281731100319197 | validation loss: 0.02311626837633426
Epoch: 366, trainingloss: 0.02154551658679301 | validation loss: 0.021913113952319256
Epoch: 367, trainingloss: 0.018301814407548876 | validation loss: 0.018582846152740463
Epoch: 368, trainingloss: 0.02069523058842775 | validation loss: 0.02104245319185352
Epoch: 369, trainingloss: 0.017944807228602127 | validation loss: 0.01830716135996829
Epoch: 370, trainingloss: 0.024314551397467167 | validation loss: 0.024652184053306242
Epoch: 371, trainingloss: 0.0218838076467827 | validation loss: 0.022218955611446718
Epoch: 372, trainingloss: 0.022603059564157105 | validation loss: 0.022962273983359014
Epoch: 373, trainingloss: 0.021002219582658948 | validation loss: 0.021332287785217518
Epoch: 374, trainingloss: 0.021923788770907966 | validation loss: 0.022224419583116273
Epoch: 375, trainingloss: 0.023298027765393803 | validation loss: 0.023604745390713985
Epoch: 376, trainingloss: 0.017121668758451614 | validation loss: 0.01746951175179807
Epoch: 377, trainingloss: 0.02209151146722753 | validation loss: 0.02239281959834674
Epoch: 378, trainingloss: 0.02203921834493567 | validation loss: 0.022270266965258214
Epoch: 379, trainingloss: 0.020374352556912046 | validation loss: 0.020637920378919417
Epoch: 380, trainingloss: 0.022974364820552536 | validation loss: 0.023292517778015946
Epoch: 381, trainingloss: 0.01796328840925767 | validation loss: 0.018328153115328646
Epoch: 382, trainingloss: 0.01736843042404182 | validation loss: 0.017773181084131853
Epoch: 383, trainingloss: 0.02330977365552903 | validation loss: 0.023619197792844295
Epoch: 384, trainingloss: 0.018855498607344822 | validation loss: 0.019149193131474625
Epoch: 385, trainingloss: 0.01963717166170319 | validation loss: 0.02003252545984261
Epoch: 386, trainingloss: 0.02184683871906459 | validation loss: 0.022121225530523918
Epoch: 387, trainingloss: 0.02492734019446692 | validation loss: 0.025291726965265014
Epoch: 388, trainingloss: 0.018669715348042314 | validation loss: 0.018998786401787485
Epoch: 389, trainingloss: 0.018973854827586154 | validation loss: 0.01939363779199887
Epoch: 390, trainingloss: 0.02547192572514628 | validation loss: 0.02591982410329773
Epoch: 391, trainingloss: 0.0258653420022708 | validation loss: 0.026141291229219894
Epoch: 392, trainingloss: 0.01898485049468908 | validation loss: 0.01934792250333748
Epoch: 393, trainingloss: 0.019682872507596205 | validation loss: 0.019997925411557198
Epoch: 394, trainingloss: 0.02212227093297257 | validation loss: 0.022345200206734462
Epoch: 395, trainingloss: 0.019767796862243062 | validation loss: 0.020020026114882284
Epoch: 396, trainingloss: 0.02055861113579898 | validation loss: 0.02094521964626291
Epoch: 397, trainingloss: 0.019199483465590545 | validation loss: 0.019472740139667297
Epoch: 398, trainingloss: 0.022120331443217962 | validation loss: 0.0224583078256333
Epoch: 399, trainingloss: 0.01913234439835687 | validation loss: 0.019409193217468798
Epoch: 400, trainingloss: 0.020621903929008048 | validation loss: 0.020971471492820158
Epoch: 401, trainingloss: 0.019219911109839373 | validation loss: 0.019425469106053316
Epoch: 402, trainingloss: 0.019004243047704837 | validation loss: 0.019343407110522855
Epoch: 403, trainingloss: 0.022043381521418506 | validation loss: 0.022392564889317897
Epoch: 404, trainingloss: 0.022587462172137255 | validation loss: 0.022944844184802277
Epoch: 405, trainingloss: 0.019509183106933784 | validation loss: 0.019879477914623807
Epoch: 406, trainingloss: 0.019688801668691438 | validation loss: 0.019928279305573487
Epoch: 407, trainingloss: 0.017595197928121767 | validation loss: 0.017857417593979016
Epoch: 408, trainingloss: 0.017181574775435443 | validation loss: 0.0175171587704276
Epoch: 409, trainingloss: 0.020461024082055662 | validation loss: 0.020671286798136016
Epoch: 410, trainingloss: 0.018521017721312347 | validation loss: 0.018902026628723787
Epoch: 411, trainingloss: 0.024787211455846853 | validation loss: 0.025028915468496213
Epoch: 412, trainingloss: 0.022273304800025387 | validation loss: 0.022548613322215978
Epoch: 413, trainingloss: 0.03066432221283325 | validation loss: 0.0309801272155532
Epoch: 414, trainingloss: 0.022373327945786427 | validation loss: 0.02270112073082637
Epoch: 415, trainingloss: 0.01878471315487591 | validation loss: 0.019162178942882736
Epoch: 416, trainingloss: 0.019703921335413845 | validation loss: 0.019992261542181942
Epoch: 417, trainingloss: 0.020550956542466896 | validation loss: 0.02078589005742195
Epoch: 418, trainingloss: 0.02024804940515531 | validation loss: 0.020585920875462245
Epoch: 419, trainingloss: 0.019967202926799994 | validation loss: 0.02028873882523974
Epoch: 420, trainingloss: 0.01723332580885998 | validation loss: 0.01757696916367226
Epoch: 421, trainingloss: 0.01790042762550992 | validation loss: 0.018248798537668445
Epoch: 422, trainingloss: 0.01996580466679903 | validation loss: 0.02023614892696042
Epoch: 423, trainingloss: 0.019266115142568225 | validation loss: 0.019562193138317554
Epoch: 424, trainingloss: 0.02049012757638354 | validation loss: 0.02084573208100169
Epoch: 425, trainingloss: 0.017126337448271207 | validation loss: 0.017510623289536436
Epoch: 426, trainingloss: 0.0220882929404069 | validation loss: 0.02240885696369881
Epoch: 427, trainingloss: 0.022762291443990883 | validation loss: 0.02298519725546999
Epoch: 428, trainingloss: 0.019354526259840913 | validation loss: 0.019582570216390503
Epoch: 429, trainingloss: 0.01830492006046354 | validation loss: 0.018667092853574492
Epoch: 430, trainingloss: 0.01869808379786401 | validation loss: 0.019089357734043258
Epoch: 431, trainingloss: 0.024646957331466636 | validation loss: 0.0248928898265087
Epoch: 432, trainingloss: 0.01721658480066503 | validation loss: 0.017726597031900444
Epoch: 433, trainingloss: 0.02237122189838249 | validation loss: 0.022676298286784368
Epoch: 434, trainingloss: 0.021183854298364845 | validation loss: 0.021522900771795507
Epoch: 435, trainingloss: 0.017378726172877754 | validation loss: 0.017688080756263498
Epoch: 436, trainingloss: 0.018697219939041835 | validation loss: 0.0190881805058545
Epoch: 437, trainingloss: 0.02285331183368405 | validation loss: 0.02314415119585211
Epoch: 438, trainingloss: 0.01934295329833802 | validation loss: 0.019643225591696286
Epoch: 439, trainingloss: 0.017409461456155385 | validation loss: 0.017738201240826076
Epoch: 440, trainingloss: 0.023019347398931675 | validation loss: 0.02331975074355525
Epoch: 441, trainingloss: 0.017615951555448164 | validation loss: 0.017986530510943594
Epoch: 442, trainingloss: 0.020077126247221407 | validation loss: 0.020335859146860612
Epoch: 443, trainingloss: 0.019310921390781954 | validation loss: 0.019688522352539668
Epoch: 444, trainingloss: 0.020042660875625763 | validation loss: 0.020348997896263637
Epoch: 445, trainingloss: 0.019151388229210333 | validation loss: 0.019523697959227586
Epoch: 446, trainingloss: 0.01884451555105483 | validation loss: 0.019150137931682524
Epoch: 447, trainingloss: 0.018299685506973053 | validation loss: 0.018669674275635505
Epoch: 448, trainingloss: 0.01831862366918217 | validation loss: 0.018738944980008627
Epoch: 449, trainingloss: 0.018024701731457832 | validation loss: 0.01841983574078704
Epoch: 450, trainingloss: 0.020163317883868426 | validation loss: 0.020523793686727385
Epoch: 451, trainingloss: 0.020834091400624175 | validation loss: 0.02122350650327153
Epoch: 452, trainingloss: 0.021787431410971402 | validation loss: 0.022091408775753656
Epoch: 453, trainingloss: 0.02180353450182458 | validation loss: 0.02188802809708745
Epoch: 454, trainingloss: 0.022947410984054308 | validation loss: 0.023195242978337877
Epoch: 455, trainingloss: 0.02435250580476346 | validation loss: 0.024670305530101685
Epoch: 456, trainingloss: 0.020603614827145497 | validation loss: 0.02083529217006142
Epoch: 457, trainingloss: 0.020681917422689555 | validation loss: 0.02093322037878974
Epoch: 458, trainingloss: 0.02324250461100827 | validation loss: 0.02350103457694456
Epoch: 459, trainingloss: 0.020657449096375194 | validation loss: 0.020960200380540705
Epoch: 460, trainingloss: 0.01989085864366638 | validation loss: 0.020191314731141535
Epoch: 461, trainingloss: 0.016989942793295642 | validation loss: 0.017344224948293054
Epoch: 462, trainingloss: 0.018994373567075416 | validation loss: 0.019272555250730745
Epoch: 463, trainingloss: 0.021979273852803682 | validation loss: 0.022370887343730977
Epoch: 464, trainingloss: 0.017652986699211958 | validation loss: 0.018057544198051455
Epoch: 465, trainingloss: 0.020131685237599613 | validation loss: 0.020374296028317456
Epoch: 466, trainingloss: 0.018486936251935714 | validation loss: 0.018845231523424964
Epoch: 467, trainingloss: 0.018034622653140996 | validation loss: 0.01833916504754486
Epoch: 468, trainingloss: 0.02028225931957198 | validation loss: 0.020530287941345923
Epoch: 469, trainingloss: 0.023409366566878625 | validation loss: 0.023636052707020013
Epoch: 470, trainingloss: 0.02161127202864617 | validation loss: 0.021984076629776098
Epoch: 471, trainingloss: 0.02077067681082451 | validation loss: 0.021015144292489327
Epoch: 472, trainingloss: 0.02131927467947 | validation loss: 0.021672871827248967
Epoch: 473, trainingloss: 0.02036992458503202 | validation loss: 0.020699373841139793
Epoch: 474, trainingloss: 0.02033980618779672 | validation loss: 0.020682687869449976
Epoch: 475, trainingloss: 0.018412473877267372 | validation loss: 0.018828350232513943
Epoch: 476, trainingloss: 0.02011329960914721 | validation loss: 0.0204942166452876
Epoch: 477, trainingloss: 0.01768100007295637 | validation loss: 0.018043109955511484
Epoch: 478, trainingloss: 0.024835475612208103 | validation loss: 0.025069379169200944
Epoch: 479, trainingloss: 0.018692046358443497 | validation loss: 0.018969031579191137
Epoch: 480, trainingloss: 0.020072604215130324 | validation loss: 0.02040153913945869
Epoch: 481, trainingloss: 0.01968366689849151 | validation loss: 0.019880898200911424
Epoch: 482, trainingloss: 0.02043620460673864 | validation loss: 0.020753826814045893
Epoch: 483, trainingloss: 0.017461337859708027 | validation loss: 0.017803088563445573
Epoch: 484, trainingloss: 0.02153813593545725 | validation loss: 0.021878047251598212
Epoch: 485, trainingloss: 0.01887672467921422 | validation loss: 0.01917761942082381
Epoch: 486, trainingloss: 0.018772911216979396 | validation loss: 0.019142001918422007
Epoch: 487, trainingloss: 0.019064713889626647 | validation loss: 0.019379849014822755
Epoch: 488, trainingloss: 0.019676150205357318 | validation loss: 0.019946746844691894
Epoch: 489, trainingloss: 0.023660326168652508 | validation loss: 0.02396268457822046
Epoch: 490, trainingloss: 0.01822295108393081 | validation loss: 0.018596928936697905
Epoch: 491, trainingloss: 0.020016294063221425 | validation loss: 0.020419782453492227
Epoch: 492, trainingloss: 0.016918163545861942 | validation loss: 0.01726955998578336
Epoch: 493, trainingloss: 0.017647690801028414 | validation loss: 0.017992418894172614
Epoch: 494, trainingloss: 0.016651690637797464 | validation loss: 0.017002647541619675
Epoch: 495, trainingloss: 0.021948930242358576 | validation loss: 0.02207123643364589
Epoch: 496, trainingloss: 0.01624462716406418 | validation loss: 0.016587521476885844
Epoch: 497, trainingloss: 0.018222023454303588 | validation loss: 0.01854295532005391
Epoch: 498, trainingloss: 0.020823728612245646 | validation loss: 0.021086396593231894
Epoch: 499, trainingloss: 0.017696968481446067 | validation loss: 0.018052461317039463
Epoch: 500, trainingloss: 0.018688357256678948 | validation loss: 0.01908346324108193
Epoch: 501, trainingloss: 0.020601413053254008 | validation loss: 0.020935434166921865
Epoch: 502, trainingloss: 0.02238967605907138 | validation loss: 0.02266563876018551
Epoch: 503, trainingloss: 0.019979814977932078 | validation loss: 0.020291982888370676
Epoch: 504, trainingloss: 0.01924066298797301 | validation loss: 0.019468613662080192
Epoch: 505, trainingloss: 0.01899384333492914 | validation loss: 0.019267855444337578
Epoch: 506, trainingloss: 0.02059364407592056 | validation loss: 0.020879193583158213
Epoch: 507, trainingloss: 0.0182752649550783 | validation loss: 0.018526030717432695
Epoch: 508, trainingloss: 0.016599266143314313 | validation loss: 0.017029527441173913
Epoch: 509, trainingloss: 0.018297801989935226 | validation loss: 0.01865789292382002
Epoch: 510, trainingloss: 0.01959750788074382 | validation loss: 0.01990626956244766
Epoch: 511, trainingloss: 0.021207389352438343 | validation loss: 0.02139778656293826
Epoch: 512, trainingloss: 0.020046172366166275 | validation loss: 0.020348489556662425